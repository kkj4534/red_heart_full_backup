#!/usr/bin/env python3
"""
Red Heart AI ì‹¤ì œ í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ í…ŒìŠ¤íŠ¸
Real Integrated Training Test for Red Heart AI System

ì‹¤ì œ ëª¨ë“ˆë“¤ì„ í˜¸ì¶œí•˜ì—¬ ì§„ì§œ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸
"""

import asyncio
import logging
import time
import numpy as np
import torch
import json
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, field
import traceback
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('RedHeart_Real_Training')

# ì‹œìŠ¤í…œ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from advanced_emotion_analyzer import AdvancedEmotionAnalyzer
    from advanced_bentham_calculator import AdvancedBenthamCalculator
    from advanced_regret_analyzer import AdvancedRegretAnalyzer
    from advanced_surd_analyzer import AdvancedSURDAnalyzer
    from advanced_experience_database import AdvancedExperienceDatabase
    from data_models import EthicalSituation, EmotionData, HedonicValues
    MODULES_AVAILABLE = True
except ImportError as e:
    MODULES_AVAILABLE = False
    logger.error(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")

@dataclass
class TrainingScenario:
    """í›ˆë ¨ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° êµ¬ì¡°"""
    id: str
    title: str
    description: str
    context: Dict[str, Any]
    stakeholders: Dict[str, float]
    optimal_choice: str
    alternative_choices: List[str]

@dataclass
class RealTrainingResult:
    """ì‹¤ì œ í›ˆë ¨ ê²°ê³¼ ë°ì´í„° êµ¬ì¡°"""
    scenario_id: str
    processing_time: float
    emotion_analysis: Dict[str, Any]
    bentham_calculation: Dict[str, Any]
    regret_analysis: Dict[str, Any]
    surd_analysis: Dict[str, Any]
    success: bool
    error_message: Optional[str] = None

class RealIntegratedTrainingTestSystem:
    """ì‹¤ì œ í†µí•© í›ˆë ¨ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.emotion_analyzer = None
        self.bentham_calculator = None
        self.regret_analyzer = None
        self.surd_analyzer = None
        self.experience_db = None
        
        # í›ˆë ¨ ë©”íŠ¸ë¦­
        self.training_metrics = {
            'total_scenarios': 0,
            'successful_completions': 0,
            'total_processing_time': 0,
            'module_call_times': {
                'emotion': [],
                'bentham': [],
                'regret': [],
                'surd': []
            }
        }
        
    async def initialize_system(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("=== Red Heart AI ì‹¤ì œ í†µí•© í›ˆë ¨ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ===")
        
        try:
            # ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”
            logger.info("ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”...")
            self.emotion_analyzer = AdvancedEmotionAnalyzer()
            logger.info("âœ… ê°ì • ë¶„ì„ê¸° ì¤€ë¹„ ì™„ë£Œ")
            
            # ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™”
            logger.info("ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™”...")
            self.bentham_calculator = AdvancedBenthamCalculator()
            logger.info("âœ… ë²¤ë‹´ ê³„ì‚°ê¸° ì¤€ë¹„ ì™„ë£Œ")
            
            # í›„íšŒ ë¶„ì„ê¸° ì´ˆê¸°í™”
            logger.info("í›„íšŒ ë¶„ì„ê¸° ì´ˆê¸°í™”...")
            try:
                self.regret_analyzer = AdvancedRegretAnalyzer()
                logger.info("âœ… í›„íšŒ ë¶„ì„ê¸° ì¤€ë¹„ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ í›„íšŒ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.regret_analyzer = None
            
            # SURD ë¶„ì„ê¸° ì´ˆê¸°í™”
            logger.info("SURD ë¶„ì„ê¸° ì´ˆê¸°í™”...")
            self.surd_analyzer = AdvancedSURDAnalyzer()
            logger.info("âœ… SURD ë¶„ì„ê¸° ì¤€ë¹„ ì™„ë£Œ")
            
            # ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            logger.info("ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”...")
            self.experience_db = AdvancedExperienceDatabase()
            logger.info("âœ… ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì¤€ë¹„ ì™„ë£Œ")
            
            logger.info("ğŸ¯ ì‹¤ì œ í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return False
    
    def create_test_scenarios(self) -> List[TrainingScenario]:
        """3ê°œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)"""
        
        scenarios = [
            TrainingScenario(
                id="real_test_001",
                title="ììœ¨ì£¼í–‰ì°¨ ìœ¤ë¦¬ì  ë”œë ˆë§ˆ",
                description="ììœ¨ì£¼í–‰ì°¨ê°€ ê¸‰ë¸Œë ˆì´í¬ ì‹¤íŒ¨ ì‹œ ì§ì§„í•˜ì—¬ 5ëª…ì„ ì¹  ê²ƒì¸ê°€, ì˜†ê¸¸ë¡œ í‹€ì–´ 1ëª…ì„ ì¹  ê²ƒì¸ê°€?",
                context={
                    "situation_type": "autonomous_vehicle",
                    "urgency_level": 0.95,
                    "legal_implications": 0.8,
                    "public_safety": 0.9,
                    "individual_rights": 0.7
                },
                stakeholders={
                    "passenger": 0.8,
                    "pedestrians_group": 0.9,
                    "individual_pedestrian": 0.95,
                    "society": 0.6,
                    "manufacturer": 0.5
                },
                optimal_choice="minimize_total_harm",
                alternative_choices=["protect_passenger", "random_choice", "no_action"]
            ),
            
            TrainingScenario(
                id="real_test_002", 
                title="ì˜ë£Œ ìì› ë°°ë¶„ ë”œë ˆë§ˆ",
                description="ì½”ë¡œë‚˜19 ìƒí™©ì—ì„œ ì¸ê³µí˜¸í¡ê¸° 1ëŒ€ë¥¼ ë‘ê³  90ì„¸ í™˜ìì™€ 30ì„¸ í™˜ì ì¤‘ ëˆ„êµ¬ë¥¼ ì„ íƒí•  ê²ƒì¸ê°€?",
                context={
                    "situation_type": "medical_resource",
                    "urgency_level": 0.9,
                    "life_expectancy_factor": 0.8,
                    "social_contribution": 0.6,
                    "medical_priority": 0.7
                },
                stakeholders={
                    "elderly_patient": 0.9,
                    "young_patient": 0.9,
                    "families": 0.8,
                    "medical_staff": 0.7,
                    "healthcare_system": 0.6
                },
                optimal_choice="medical_priority_based",
                alternative_choices=["age_priority", "first_come_first_served", "lottery_system"]
            ),
            
            TrainingScenario(
                id="real_test_003",
                title="ê°œì¸ì •ë³´ vs ê³µê³µì•ˆì „",
                description="í…ŒëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì‹œë¯¼ë“¤ì˜ ê°œì¸ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ê°ì‹œí•  ê²ƒì¸ê°€, ê°œì¸ì˜ í”„ë¼ì´ë²„ì‹œë¥¼ ë³´í˜¸í•  ê²ƒì¸ê°€?",
                context={
                    "situation_type": "privacy_security",
                    "urgency_level": 0.8,
                    "security_threat": 0.9,
                    "privacy_rights": 0.9,
                    "democratic_values": 0.8
                },
                stakeholders={
                    "citizens": 0.9,
                    "government": 0.7,
                    "potential_victims": 0.9,
                    "civil_rights_groups": 0.8,
                    "security_agencies": 0.6
                },
                optimal_choice="balanced_approach",
                alternative_choices=["full_surveillance", "no_surveillance", "voluntary_participation"]
            )
        ]
        
        return scenarios
    
    async def _safe_module_call(self, module_name: str, func_call, context: str, max_retries: int = 2):
        """ì•ˆì „í•œ ëª¨ë“ˆ í˜¸ì¶œ (Circuit Breaker íŒ¨í„´)"""
        import asyncio
        import gc
        
        for attempt in range(max_retries + 1):
            try:
                # ë©”ëª¨ë¦¬ ì²´í¬
                import psutil
                memory = psutil.virtual_memory()
                if memory.percent > 90:
                    logger.warning(f"ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê°ì§€: {memory.percent}%, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰")
                    gc.collect()
                
                # GPU ë©”ëª¨ë¦¬ ì²´í¬
                import torch
                if torch.cuda.is_available():
                    gpu_percent = (torch.cuda.memory_allocated() / torch.cuda.get_device_properties(0).total_memory) * 100
                    if gpu_percent > 85:
                        logger.warning(f"ë†’ì€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {gpu_percent:.1f}%, ìºì‹œ ì •ë¦¬")
                        torch.cuda.empty_cache()
                
                # ì‹¤ì œ ëª¨ë“ˆ í˜¸ì¶œ
                if asyncio.iscoroutinefunction(func_call):
                    result = await func_call()
                else:
                    result = func_call()
                
                if result:
                    logger.info(f"âœ… {module_name} ëª¨ë“ˆ ì„±ê³µ (ì‹œë„ {attempt + 1}/{max_retries + 1})")
                    return result
                else:
                    logger.warning(f"âš ï¸ {module_name} ëª¨ë“ˆ ê²°ê³¼ ì—†ìŒ (ì‹œë„ {attempt + 1}/{max_retries + 1})")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ {module_name} ëª¨ë“ˆ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {e}")
                
                if attempt < max_retries:
                    # ì¬ì‹œë„ ì „ ëŒ€ê¸° (ì§€ìˆ˜ì  ë°±ì˜¤í”„)
                    wait_time = 2 ** attempt
                    logger.info(f"ğŸ”„ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                else:
                    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
                    error_msg = f"{module_name} ë¶„ì„ ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€: {e}"
                    logger.error(f"âŒ {error_msg}")
                    raise RuntimeError(error_msg)
        
        # ê²°ê³¼ê°€ ì—†ê³  ëª¨ë“  ì¬ì‹œë„ ì™„ë£Œ ì‹œ
        error_msg = f"{module_name} ë¶„ì„ì´ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€"
        logger.error(f"âŒ {error_msg}")
        raise RuntimeError(error_msg)
    
    async def run_real_scenario_training(self, scenario: TrainingScenario) -> RealTrainingResult:
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì‹¤ì œ í†µí•© í›ˆë ¨ ìˆ˜í–‰"""
        logger.info(f"\nğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ '{scenario.title}' ì‹¤ì œ í†µí•© í›ˆë ¨ ì‹œì‘")
        
        start_time = time.time()
        
        try:
            # 1. ì‹¤ì œ ê°ì • ë¶„ì„ ìˆ˜í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            logger.info("1ï¸âƒ£ ì‹¤ì œ ê°ì • ë¶„ì„ ìˆ˜í–‰...")
            emotion_start = time.time()
            
            emotion_result = await self._safe_module_call(
                'emotion', 
                lambda: self.emotion_analyzer.analyze_emotion(scenario.description),
                scenario.title
            )
            emotion_time = time.time() - emotion_start
            self.training_metrics['module_call_times']['emotion'].append(emotion_time)
            
            if emotion_result:
                logger.info(f"   âœ… ê°ì • ë¶„ì„ ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {emotion_time:.2f}ì´ˆ")
                
                # ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ì†ì„± í™•ì¸ (fallback ê¸ˆì§€)
                if not hasattr(emotion_result, 'primary_emotion'):
                    raise RuntimeError(f"ê°ì • ê²°ê³¼ì— primary_emotion ì†ì„±ì´ ì—†ìŒ: {type(emotion_result)}")
                if not hasattr(emotion_result, 'confidence'):
                    raise RuntimeError(f"ê°ì • ê²°ê³¼ì— confidence ì†ì„±ì´ ì—†ìŒ: {type(emotion_result)}")
                if not hasattr(emotion_result, 'arousal'):
                    raise RuntimeError(f"ê°ì • ê²°ê³¼ì— arousal ì†ì„±ì´ ì—†ìŒ: {type(emotion_result)}")
                if not hasattr(emotion_result, 'valence'):
                    raise RuntimeError(f"ê°ì • ê²°ê³¼ì— valence ì†ì„±ì´ ì—†ìŒ: {type(emotion_result)}")
                
                emotion_data = {
                    'emotion': emotion_result.primary_emotion.name,  # EmotionState enumì˜ name
                    'confidence': emotion_result.confidence,
                    'arousal': emotion_result.arousal,
                    'valence': emotion_result.valence,
                    'intensity': emotion_result.intensity.name,  # EmotionIntensity enumì˜ name
                    'processing_method': emotion_result.processing_method,
                    'processing_time': emotion_time,
                    'success': True
                }
                
                logger.info(f"   ğŸ“Š ê°ì • ë¶„ì„ ì‹¤ì œ ê°’:")
                logger.info(f"      ì£¼ìš” ê°ì •: {emotion_result.primary_emotion.name}")
                logger.info(f"      ì‹ ë¢°ë„: {emotion_result.confidence:.3f}")
                logger.info(f"      ê°•ë„: {emotion_result.intensity.name}")
                logger.info(f"      ê°ì„±ë„: {emotion_result.arousal:.3f}")
                logger.info(f"      ê°ì •ê°€: {emotion_result.valence:.3f}")
                logger.info(f"      ì²˜ë¦¬ ë°©ë²•: {emotion_result.processing_method}")
            else:
                # fallback ê¸ˆì§€ ì›ì¹™: ê°ì • ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì‹œìŠ¤í…œ ì •ì§€
                error_msg = "LLM ê°ì • ë¶„ì„ ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€: LLM ê°ì • ë¶„ì„ì´ Noneì„ ë°˜í™˜ - EmoLLMs ì „ì²˜ë¦¬ í›„ì—ë„ ì‹¤íŒ¨"
                logger.error(f"   âŒ {error_msg}")
                
                # ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ì‹œìŠ¤í…œ ì •ì§€
                raise RuntimeError(error_msg)
            
            # 2. ì‹¤ì œ ë²¤ë‹´ ê³„ì‚° ìˆ˜í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            logger.info("2ï¸âƒ£ ì‹¤ì œ ë²¤ë‹´ ê³„ì‚° ìˆ˜í–‰...")
            bentham_start = time.time()
            
            # EthicalSituation ê°ì²´ ìƒì„± (ì˜¬ë°”ë¥¸ ë§¤ê°œë³€ìˆ˜ ì‚¬ìš©)
            ethical_situation = EthicalSituation(
                title=scenario.title,
                description=scenario.description,
                context={
                    **scenario.context,
                    'stakeholders': scenario.stakeholders,
                    'alternatives': scenario.alternative_choices
                }
            )
            
            bentham_result = await self._safe_module_call(
                'bentham',
                lambda: self.bentham_calculator.calculate_with_ethical_reasoning(
                    input_data={
                        'situation': ethical_situation,
                        'text': scenario.description
                    },
                    community_emotion=emotion_result if emotion_result else None
                ),
                scenario.title
            )
            bentham_time = time.time() - bentham_start
            self.training_metrics['module_call_times']['bentham'].append(bentham_time)
            
            if bentham_result:
                logger.info(f"   âœ… ë²¤ë‹´ ê³„ì‚° ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {bentham_time:.2f}ì´ˆ")
                
                # ì‹¤ì œ ë²¤ë‹´ ê³„ì‚° ê²°ê³¼ ì†ì„± í™•ì¸ (fallback ê¸ˆì§€)
                if not hasattr(bentham_result, 'final_score'):
                    raise RuntimeError(f"ë²¤ë‹´ ê²°ê³¼ì— final_score ì†ì„±ì´ ì—†ìŒ: {type(bentham_result)}")
                if not hasattr(bentham_result, 'confidence_score'):
                    raise RuntimeError(f"ë²¤ë‹´ ê²°ê³¼ì— confidence_score ì†ì„±ì´ ì—†ìŒ: {type(bentham_result)}")
                if not hasattr(bentham_result, 'hedonic_values'):
                    raise RuntimeError(f"ë²¤ë‹´ ê²°ê³¼ì— hedonic_values ì†ì„±ì´ ì—†ìŒ: {type(bentham_result)}")
                
                bentham_data = {
                    'final_score': bentham_result.final_score,
                    'base_score': bentham_result.base_score,
                    'confidence_score': bentham_result.confidence_score,
                    'intensity': bentham_result.hedonic_values.intensity,
                    'duration': bentham_result.hedonic_values.duration,
                    'certainty': bentham_result.hedonic_values.certainty,
                    'purity': bentham_result.hedonic_values.purity,
                    'extent': bentham_result.hedonic_values.extent,
                    'hedonic_total': bentham_result.hedonic_values.hedonic_total,
                    'processing_time': bentham_time,
                    'success': True
                }
                
                logger.info(f"   ğŸ“Š ë²¤ë‹´ ê³„ì‚° ì‹¤ì œ ê°’:")
                logger.info(f"      ìµœì¢… ì ìˆ˜: {bentham_result.final_score:.3f}")
                logger.info(f"      ê¸°ë³¸ ì ìˆ˜: {bentham_result.base_score:.3f}")
                logger.info(f"      ì‹ ë¢°ë„: {bentham_result.confidence_score:.3f}")
                logger.info(f"      ê°•ë„: {bentham_result.hedonic_values.intensity:.3f}")
                logger.info(f"      ì§€ì†ì„±: {bentham_result.hedonic_values.duration:.3f}")
                logger.info(f"      í™•ì‹¤ì„±: {bentham_result.hedonic_values.certainty:.3f}")
                logger.info(f"      ì´ ì¾Œë½ê°’: {bentham_result.hedonic_values.hedonic_total:.3f}")
            else:
                # fallback ê¸ˆì§€ ì›ì¹™: ë²¤ë‹´ ê³„ì‚° ì‹¤íŒ¨ ì‹œ ì‹œìŠ¤í…œ ì •ì§€
                error_msg = "ë²¤ë‹´ ê³„ì‚° ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€: ë²¤ë‹´ ê³„ì‚°ì´ Noneì„ ë°˜í™˜"
                logger.error(f"   âŒ {error_msg}")
                
                # ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ì‹œìŠ¤í…œ ì •ì§€
                raise RuntimeError(error_msg)
            
            # 3. ì‹¤ì œ í›„íšŒ ë¶„ì„ ìˆ˜í–‰ (ê°€ëŠ¥í•œ ê²½ìš°)
            regret_data = {'success': False, 'processing_time': 0.0}
            if self.regret_analyzer:
                logger.info("3ï¸âƒ£ ì‹¤ì œ í›„íšŒ ë¶„ì„ ìˆ˜í–‰...")
                regret_start = time.time()
                
                try:
                    # í›„íšŒ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
                    decision_data = {
                        'text': scenario.description,
                        'context': scenario.context,
                        'alternatives': scenario.alternative_choices,
                        'optimal_choice': scenario.optimal_choice,
                        'stakeholders': scenario.stakeholders
                    }
                    
                    # ì‹¤ì œ í›„íšŒ ë¶„ì„ ìˆ˜í–‰
                    regret_result = await self.regret_analyzer.analyze_regret(decision_data)
                    regret_time = time.time() - regret_start
                    self.training_metrics['module_call_times']['regret'].append(regret_time)
                    
                    logger.info(f"   âœ… í›„íšŒ ë¶„ì„ ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {regret_time:.2f}ì´ˆ")
                    
                    # ì‹¤ì œ í›„íšŒ ë¶„ì„ ê²°ê³¼ ì†ì„± í™•ì¸ (fallback ê¸ˆì§€)
                    if not hasattr(regret_result, 'regret_intensity'):
                        raise RuntimeError(f"í›„íšŒ ê²°ê³¼ì— regret_intensity ì†ì„±ì´ ì—†ìŒ: {type(regret_result)}")
                    if not hasattr(regret_result, 'anticipated_regret'):
                        raise RuntimeError(f"í›„íšŒ ê²°ê³¼ì— anticipated_regret ì†ì„±ì´ ì—†ìŒ: {type(regret_result)}")
                    if not hasattr(regret_result, 'experienced_regret'):
                        raise RuntimeError(f"í›„íšŒ ê²°ê³¼ì— experienced_regret ì†ì„±ì´ ì—†ìŒ: {type(regret_result)}")
                    
                    regret_data = {
                        'regret_intensity': regret_result.regret_intensity,
                        'anticipated_regret': regret_result.anticipated_regret,
                        'experienced_regret': regret_result.experienced_regret,
                        'regret_duration': regret_result.regret_duration,
                        'semantic_regret_score': regret_result.semantic_regret_score,
                        'model_confidence': regret_result.model_confidence,
                        'uncertainty_estimate': regret_result.uncertainty_estimate,
                        'processing_time': regret_time,
                        'success': True
                    }
                    
                    logger.info(f"   ğŸ“Š í›„íšŒ ë¶„ì„ ì‹¤ì œ ê°’:")
                    logger.info(f"      í›„íšŒ ê°•ë„: {regret_result.regret_intensity:.3f}")
                    logger.info(f"      ì˜ˆìƒ í›„íšŒ: {regret_result.anticipated_regret:.3f}")
                    logger.info(f"      ê²½í—˜ í›„íšŒ: {regret_result.experienced_regret:.3f}")
                    logger.info(f"      í›„íšŒ ì§€ì†: {regret_result.regret_duration:.3f}")
                    logger.info(f"      ì˜ë¯¸ì  í›„íšŒ: {regret_result.semantic_regret_score:.3f}")
                    logger.info(f"      ëª¨ë¸ ì‹ ë¢°ë„: {regret_result.model_confidence:.3f}")
                except Exception as e:
                    # fallback ê¸ˆì§€ ì›ì¹™: í›„íšŒ ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì‹œìŠ¤í…œ ì •ì§€
                    error_msg = f"í›„íšŒ ë¶„ì„ ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€: {e}"
                    logger.error(f"   âŒ {error_msg}")
                    
                    # ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ì‹œìŠ¤í…œ ì •ì§€
                    raise RuntimeError(error_msg)
            else:
                # fallback ê¸ˆì§€ ì›ì¹™: í›„íšŒ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ì‹œìŠ¤í…œ ì •ì§€
                error_msg = "í›„íšŒ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€: í›„íšŒ ë¶„ì„ê¸°ê°€ None"
                logger.error(f"   âŒ {error_msg}")
                
                # ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ì‹œìŠ¤í…œ ì •ì§€
                raise RuntimeError(error_msg)
            
            # 4. ì‹¤ì œ SURD ë¶„ì„ ìˆ˜í–‰
            logger.info("4ï¸âƒ£ ì‹¤ì œ SURD ë¶„ì„ ìˆ˜í–‰...")
            surd_start = time.time()
            
            try:
                # ì‹¤ì œ SURD ë¶„ì„ ìˆ˜í–‰ (í†µí•© ì‹œìŠ¤í…œ ë¶„ì„)
                surd_result = await self.surd_analyzer.analyze_integrated_system(
                    emotion_data=emotion_data,
                    bentham_data=bentham_data,
                    target_variable='decision_quality',
                    additional_context={
                        'scenario': scenario.description,
                        'context': scenario.context,
                        'stakeholders': scenario.stakeholders
                    }
                )
                surd_time = time.time() - surd_start
                self.training_metrics['module_call_times']['surd'].append(surd_time)
                
                logger.info(f"   âœ… SURD ë¶„ì„ ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {surd_time:.2f}ì´ˆ")
                
                # ì‹¤ì œ SURD ë¶„ì„ ê²°ê³¼ ê°’ ì‚¬ìš© (fallback ê¸ˆì§€)
                if not hasattr(surd_result, 'synergy_score'):
                    raise RuntimeError(f"SURD ê²°ê³¼ì— synergy_score ì†ì„±ì´ ì—†ìŒ: {type(surd_result)}")
                if not hasattr(surd_result, 'uniqueness_score'):
                    raise RuntimeError(f"SURD ê²°ê³¼ì— uniqueness_score ì†ì„±ì´ ì—†ìŒ: {type(surd_result)}")
                if not hasattr(surd_result, 'redundancy_score'):
                    raise RuntimeError(f"SURD ê²°ê³¼ì— redundancy_score ì†ì„±ì´ ì—†ìŒ: {type(surd_result)}")
                if not hasattr(surd_result, 'determinism_score'):
                    raise RuntimeError(f"SURD ê²°ê³¼ì— determinism_score ì†ì„±ì´ ì—†ìŒ: {type(surd_result)}")
                
                surd_data = {
                    'synergy_score': surd_result.synergy_score,
                    'unique_score': surd_result.uniqueness_score,
                    'redundant_score': surd_result.redundancy_score,
                    'deterministic_score': surd_result.determinism_score,
                    'overall_score': surd_result.overall_score,
                    'confidence_score': surd_result.confidence_score,
                    'processing_time': surd_time,
                    'success': True
                }
                
                logger.info(f"   ğŸ“Š SURD ì‹¤ì œ ë¶„ì„ ê°’:")
                logger.info(f"      ì‹œë„ˆì§€: {surd_result.synergy_score:.3f}")
                logger.info(f"      ê³ ìœ ì„±: {surd_result.uniqueness_score:.3f}")  
                logger.info(f"      ì¤‘ë³µì„±: {surd_result.redundancy_score:.3f}")
                logger.info(f"      ê²°ì •ì„±: {surd_result.determinism_score:.3f}")
                logger.info(f"      ì¢…í•©ì ìˆ˜: {surd_result.overall_score:.3f}")
                logger.info(f"      ì‹ ë¢°ë„: {surd_result.confidence_score:.3f}")
            except Exception as e:
                # fallback ê¸ˆì§€ ì›ì¹™: SURD ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì‹œìŠ¤í…œ ì •ì§€
                error_msg = f"SURD ë¶„ì„ ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€: {e}"
                logger.error(f"   âŒ {error_msg}")
                
                # ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒìœ¼ë¡œ ì‹œìŠ¤í…œ ì •ì§€
                raise RuntimeError(error_msg)
            
            # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            total_time = time.time() - start_time
            
            # í›ˆë ¨ ê²°ê³¼ ìƒì„±
            result = RealTrainingResult(
                scenario_id=scenario.id,
                processing_time=total_time,
                emotion_analysis=emotion_data,
                bentham_calculation=bentham_data,
                regret_analysis=regret_data,
                surd_analysis=surd_data,
                success=True
            )
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ 
            self.training_metrics['total_scenarios'] += 1
            self.training_metrics['successful_completions'] += 1
            self.training_metrics['total_processing_time'] += total_time
            
            logger.info(f"âœ… ì‹œë‚˜ë¦¬ì˜¤ '{scenario.title}' ì‹¤ì œ í›ˆë ¨ ì™„ë£Œ")
            logger.info(f"   ì „ì²´ ì²˜ë¦¬ì‹œê°„: {total_time:.3f}ì´ˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ '{scenario.title}' ì‹¤ì œ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            
            return RealTrainingResult(
                scenario_id=scenario.id,
                processing_time=time.time() - start_time,
                emotion_analysis={'success': False},
                bentham_calculation={'success': False},
                regret_analysis={'success': False},
                surd_analysis={'success': False},
                success=False,
                error_message=str(e)
            )
    
    async def run_real_integrated_training(self) -> Dict[str, Any]:
        """3ê°œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì‹¤ì œ í†µí•© í›ˆë ¨ ì‹¤í–‰"""
        logger.info("ğŸš€ Red Heart AI ì‹¤ì œ í†µí•© í›ˆë ¨ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        scenarios = self.create_test_scenarios()
        logger.info(f"ğŸ“‹ {len(scenarios)}ê°œ ì‹¤ì œ í›ˆë ¨ ì‹œë‚˜ë¦¬ì˜¤ ì¤€ë¹„ ì™„ë£Œ")
        
        training_results = []
        
        # ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹¤ì œ í›ˆë ¨
        for i, scenario in enumerate(scenarios, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ {i}/{len(scenarios)} ì‹¤ì œ í›ˆë ¨ ì¤‘...")
            logger.info(f"{'='*60}")
            
            result = await self.run_real_scenario_training(scenario)
            training_results.append(result)
            
            # ì‹œë‚˜ë¦¬ì˜¤ ê°„ ê°„ê²© (GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œê°„)
            await asyncio.sleep(2.0)
        
        # ì „ì²´ í›ˆë ¨ ê²°ê³¼ ë¶„ì„
        return self._analyze_real_training_results(training_results)
    
    def _analyze_real_training_results(self, results: List[RealTrainingResult]) -> Dict[str, Any]:
        """ì‹¤ì œ í›ˆë ¨ ê²°ê³¼ ì¢…í•© ë¶„ì„"""
        logger.info(f"\nğŸ“Š ì‹¤ì œ í›ˆë ¨ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        
        if not results:
            return {"error": "í›ˆë ¨ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        successful_results = [r for r in results if r.success]
        success_rate = len(successful_results) / len(results) * 100
        
        total_processing_time = sum(r.processing_time for r in results)
        avg_processing_time = total_processing_time / len(results)
        
        # ëª¨ë“ˆë³„ ì„±ëŠ¥ ë¶„ì„
        module_performance = {
            'emotion': {
                'success_rate': sum(1 for r in results if r.emotion_analysis.get('success', False)) / len(results) * 100,
                'avg_time': np.mean(self.training_metrics['module_call_times']['emotion']) if self.training_metrics['module_call_times']['emotion'] else 0
            },
            'bentham': {
                'success_rate': sum(1 for r in results if r.bentham_calculation.get('success', False)) / len(results) * 100,
                'avg_time': np.mean(self.training_metrics['module_call_times']['bentham']) if self.training_metrics['module_call_times']['bentham'] else 0
            },
            'regret': {
                'success_rate': sum(1 for r in results if r.regret_analysis.get('success', False)) / len(results) * 100,
                'avg_time': np.mean(self.training_metrics['module_call_times']['regret']) if self.training_metrics['module_call_times']['regret'] else 0
            },
            'surd': {
                'success_rate': sum(1 for r in results if r.surd_analysis.get('success', False)) / len(results) * 100,
                'avg_time': np.mean(self.training_metrics['module_call_times']['surd']) if self.training_metrics['module_call_times']['surd'] else 0
            }
        }
        
        # ì¢…í•© ê²°ê³¼
        analysis_result = {
            'real_training_summary': {
                'total_scenarios': len(results),
                'successful_completions': len(successful_results),
                'success_rate': success_rate,
                'total_processing_time': total_processing_time,
                'avg_processing_time': avg_processing_time
            },
            'module_performance': module_performance,
            'detailed_results': [
                {
                    'scenario_id': r.scenario_id,
                    'success': r.success,
                    'processing_time': r.processing_time,
                    'emotion_success': r.emotion_analysis.get('success', False),
                    'bentham_success': r.bentham_calculation.get('success', False),
                    'regret_success': r.regret_analysis.get('success', False),
                    'surd_success': r.surd_analysis.get('success', False),
                    'error': r.error_message
                }
                for r in results
            ],
            'performance_insights': self._generate_real_performance_insights(module_performance, success_rate)
        }
        
        return analysis_result
    
    def _generate_real_performance_insights(self, module_performance: Dict, success_rate: float) -> List[str]:
        """ì‹¤ì œ ì„±ëŠ¥ ê¸°ë°˜ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        insights = []
        
        if success_rate < 70:
            insights.append("ì „ì²´ ì„±ê³µë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ì•ˆì •ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        elif success_rate >= 90:
            insights.append("ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. ë” ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        for module, perf in module_performance.items():
            if perf['success_rate'] < 70:
                insights.append(f"{module} ëª¨ë“ˆì˜ ì„±ê³µë¥ ì´ {perf['success_rate']:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤.")
            if perf['avg_time'] > 60:
                insights.append(f"{module} ëª¨ë“ˆì˜ í‰ê·  ì²˜ë¦¬ì‹œê°„ì´ {perf['avg_time']:.1f}ì´ˆë¡œ ê¹ë‹ˆë‹¤.")
        
        if not insights:
            insights.append("ëª¨ë“  ëª¨ë“ˆì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        return insights


async def main():
    """ë©”ì¸ ì‹¤ì œ í›ˆë ¨ í•¨ìˆ˜"""
    if not MODULES_AVAILABLE:
        logger.error("âŒ í•„ìˆ˜ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì‹¤ì œ í†µí•© í›ˆë ¨ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    training_system = RealIntegratedTrainingTestSystem()
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if not await training_system.initialize_system():
        logger.error("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return
    
    # ì‹¤ì œ í†µí•© í›ˆë ¨ ì‹¤í–‰
    results = await training_system.run_real_integrated_training()
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info(f"\n{'='*80}")
    logger.info("ğŸ‰ Red Heart AI ì‹¤ì œ í†µí•© í›ˆë ¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info(f"{'='*80}")
    
    if 'error' not in results:
        summary = results['real_training_summary']
        performance = results['module_performance']
        
        logger.info(f"\nğŸ“Š ì‹¤ì œ í›ˆë ¨ ìš”ì•½:")
        logger.info(f"  - ì´ ì‹œë‚˜ë¦¬ì˜¤: {summary['total_scenarios']}ê°œ")
        logger.info(f"  - ì„±ê³µë¥ : {summary['success_rate']:.1f}%")
        logger.info(f"  - í‰ê·  ì²˜ë¦¬ì‹œê°„: {summary['avg_processing_time']:.3f}ì´ˆ")
        logger.info(f"  - ì´ ì²˜ë¦¬ì‹œê°„: {summary['total_processing_time']:.3f}ì´ˆ")
        
        logger.info(f"\nğŸ”§ ëª¨ë“ˆë³„ ì„±ëŠ¥:")
        for module, perf in performance.items():
            logger.info(f"  - {module}: ì„±ê³µë¥  {perf['success_rate']:.1f}%, í‰ê· ì‹œê°„ {perf['avg_time']:.2f}ì´ˆ")
        
        logger.info(f"\nğŸ’¡ ì„±ëŠ¥ ì¸ì‚¬ì´íŠ¸:")
        for insight in results['performance_insights']:
            logger.info(f"  - {insight}")
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_file = Path(f'real_integrated_training_results_{timestamp}.json')
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"\nğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {result_file}")
    else:
        logger.error(f"âŒ ì‹¤ì œ í›ˆë ¨ ì‹¤íŒ¨: {results['error']}")

if __name__ == "__main__":
    asyncio.run(main())