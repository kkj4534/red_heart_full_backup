"""
Red Heart Linux Advanced - ê³ ê¸‰ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ
Transformers, Sentence Transformers ê¸°ë°˜ ê³ ì„±ëŠ¥ ê°ì • ë¶„ì„
"""

__all__ = ['AdvancedEmotionAnalyzer']

import os
# CVE-2025-32434ëŠ” ê°€ì§œ CVE - torch_security_patch import ì œê±°
# import torch_security_patch

import logging
import time
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Union
# pathlib ì œê±° - WSL í˜¸í™˜ì„±ì„ ìœ„í•´ os.path ì‚¬ìš©
import json
import torch

# ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ - ê°œë°œìš© í•„ìˆ˜ ëª¨ë“œ
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    pipeline, AutoModel
)
# SentenceTransformerëŠ” sentence_transformer_singletonì„ í†µí•´ ì‚¬ìš©
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import torch.nn.functional as F
import torch.nn as nn
ADVANCED_LIBS_AVAILABLE = True

from config import SYSTEM_CONFIG, ADVANCED_CONFIG, EMOTION_MODELS_DIR
from data_models import EmotionData, EmotionState, EmotionIntensity, Biosignal
from mixture_of_experts import create_emotion_moe, MixtureOfExperts
from emotion_dsp_simulator import EmotionDSPSimulator, DynamicKalmanFilter

# loggerë¥¼ import í›„ ì¦‰ì‹œ ìƒì„±í•˜ì—¬ except ë¸”ë¡ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ í•¨
logger = logging.getLogger('RedHeartLinux.AdvancedEmotion')

# ìƒˆë¡œìš´ ê³„ì¸µì  ê°ì • ëª¨ë¸ ì„í¬íŠ¸
try:
    from models.hierarchical_emotion.emotion_phase_models import (
        HierarchicalEmotionModel, EmotionModelManager, 
        emotion_vector_to_dict, EMOTION_DIMENSIONS
    )
    NEW_EMOTION_MODELS_AVAILABLE = True
except ImportError as e:
    logger.error(f"âŒ í•„ìˆ˜ ëª¨ë“ˆ hierarchical_emotion.emotion_phase_models import ì‹¤íŒ¨: {e}")
    raise ImportError(f"í•„ìˆ˜ ê³„ì¸µì  ê°ì • ëª¨ë¸ ì‹œìŠ¤í…œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}") from e

# LLM í†µí•©
try:
    from llm_module.advanced_llm_engine import get_llm_engine, interpret_emotions
    LLM_INTEGRATION_AVAILABLE = True
except ImportError as e:
    logger.error(f"âŒ í•„ìˆ˜ ëª¨ë“ˆ llm_module.advanced_llm_engine import ì‹¤íŒ¨: {e}")
    raise ImportError(f"í•„ìˆ˜ LLM í†µí•© ì‹œìŠ¤í…œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}") from e

def get_local_device():
    """ë””ë°”ì´ìŠ¤ ê°ì§€ (ë¡œì»¬ í•¨ìˆ˜)"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    return torch.device('cpu')

# ëª¨ë“ˆ ê°€ìš©ì„± ë¡œê¹…
if not NEW_EMOTION_MODELS_AVAILABLE:
    logger.warning("ìƒˆë¡œìš´ ê³„ì¸µì  ê°ì • ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if not LLM_INTEGRATION_AVAILABLE:
    logger.warning("LLM í†µí•©ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# TODO: LocalTranslatorê°€ ë³„ë„ ëª¨ë“ˆ(local_translator.py)ë¡œ ë¶„ë¦¬ë¨
# ì „ì—­ ëª¨ë“ˆë¡œ ë“±ë¡ë˜ì–´ MasterMemoryOrchestratorê°€ ê´€ë¦¬í•˜ë„ë¡ êµ¬ì¡° ê°œì„ 
# ì •ìƒ ì‘ë™ í™•ì¸ í›„ ì•„ë˜ ì£¼ì„ ì²˜ë¦¬ëœ ì½”ë“œ ì‚­ì œ ì˜ˆì •
"""
class LocalTranslator:
    '''ë¡œì»¬ OPUS-MT ê¸°ë°˜ í•œêµ­ì–´â†’ì˜ì–´ ë²ˆì—­ê¸° (Google Translate ëŒ€ì²´)'''
    
    def __init__(self):
        '''ë¡œì»¬ ë²ˆì—­ê¸° ì´ˆê¸°í™” (Lazy Loading)'''
        self.model_name = 'Helsinki-NLP/opus-mt-ko-en'
        self.tokenizer = None
        self.model = None
        self.device = None
        self.translation_cache = {}  # ë²ˆì—­ ê²°ê³¼ ìºì‹±
        self.initialized = False
        
        logger.info("LocalTranslator ì´ˆê¸°í™”ë¨ (ëª¨ë¸ì€ ì²« ì‚¬ìš©ì‹œ ë¡œë“œ)")
    
    def _initialize_model(self):
        '''ëª¨ë¸ ì´ˆê¸°í™” (ì²« ë²ˆì—­ ì‹œì—ë§Œ ì‹¤í–‰)'''
        if self.initialized:
            return
        
        try:
            logger.info(f"ğŸ”„ OPUS-MT ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_name}")
            start_time = time.time()
            
            from transformers import MarianMTModel, MarianTokenizer
            
            # HF ë˜í¼ë¥¼ í†µí•œ í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
            from hf_model_wrapper import get_hf_wrapper
            hf_wrapper = get_hf_wrapper()
            
            self.tokenizer = hf_wrapper.wrapped_tokenizer(
                self.model_name, 
                owner="local_translator", local_files_only=True
            )
            self.model = hf_wrapper.wrapped_from_pretrained(
                MarianMTModel, self.model_name, 
                owner="local_translator", local_files_only=True
            )
            
            # ë””ë°”ì´ìŠ¤ ì„¤ì • ë° ëª¨ë¸ ì´ë™
            self.device = get_smart_device()
            self.model = self.model.to(self.device)
            
            load_time = time.time() - start_time
            logger.info(f"âœ… OPUS-MT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {load_time:.1f}ì´ˆ, ë””ë°”ì´ìŠ¤: {self.device})")
            
            self.initialized = True
            
        except Exception as e:
            logger.error(f"âŒ OPUS-MT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.initialized = False
            raise RuntimeError(f"ë¡œì»¬ ë²ˆì—­ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _is_english_text(self, text: str) -> bool:
        '''í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ ì˜ì–´ì¸ì§€ ê°ì§€'''
        if not text or len(text.strip()) == 0:
            return True
        
        # í•œêµ­ì–´ ë¬¸ì ë¹„ìœ¨ ê³„ì‚° (ìœ ë‹ˆì½”ë“œ ë²”ìœ„ í™œìš©)
        korean_chars = 0
        total_chars = 0
        
        for char in text:
            if char.isalpha():  # ì•ŒíŒŒë²³ ë¬¸ìë§Œ ê³ ë ¤
                total_chars += 1
                # í•œê¸€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„: AC00-D7AF (ê°€-í£), 1100-11FF (ìëª¨)
                if '\uAC00' <= char <= '\uD7AF' or '\u1100' <= char <= '\u11FF':
                    korean_chars += 1
        
        if total_chars == 0:
            return True  # ì•ŒíŒŒë²³ì´ ì—†ìœ¼ë©´ ì˜ì–´ë¡œ ê°„ì£¼ (ìˆ«ì, ê¸°í˜¸ë§Œ ìˆëŠ” ê²½ìš°)
        
        korean_ratio = korean_chars / total_chars
        return korean_ratio < 0.1  # í•œêµ­ì–´ ë¹„ìœ¨ì´ 10% ë¯¸ë§Œì´ë©´ ì˜ì–´ë¡œ íŒë‹¨
    
    def translate_ko_to_en(self, korean_text: str) -> str:
        '''í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­'''
        if not korean_text or len(korean_text.strip()) == 0:
            return korean_text
        
        # ì˜ì–´ í…ìŠ¤íŠ¸ ê°ì§€
        if self._is_english_text(korean_text):
            logger.debug("í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ ì˜ì–´ë¡œ íŒë‹¨ë¨, ë²ˆì—­ ìƒëµ")
            return korean_text
        
        # ìºì‹œ í™•ì¸
        cache_key = hash(korean_text.strip())
        if cache_key in self.translation_cache:
            logger.debug("ë²ˆì—­ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
            return self.translation_cache[cache_key]
        
        try:
            # ëª¨ë¸ ì´ˆê¸°í™” (ì²« ë²ˆì—­ ì‹œì—ë§Œ)
            if not self.initialized:
                self._initialize_model()
            
            # ë²ˆì—­ ìˆ˜í–‰
            start_time = time.time()
            inputs = self.tokenizer([korean_text], return_tensors='pt', padding=True).to(self.device)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=128,      # ì¶©ë¶„í•œ ê¸¸ì´
                    num_beams=3,         # ì ë‹¹í•œ í’ˆì§ˆ
                    early_stopping=True, # íš¨ìœ¨ì„±
                    do_sample=False      # ì¼ê´€ì„±
                )
            
            translated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            translation_time = time.time() - start_time
            
            # ìºì‹œ ì €ì¥ (ë©”ëª¨ë¦¬ ì œí•œ)
            if len(self.translation_cache) < 1000:  # ìµœëŒ€ 1000ê°œ ìºì‹œ
                self.translation_cache[cache_key] = translated_text
            
            logger.debug(f"ë²ˆì—­ ì™„ë£Œ: \"{korean_text[:30]}...\" â†’ \"{translated_text[:30]}...\" ({translation_time:.2f}ì´ˆ)")
            return translated_text
            
        except Exception as e:
            logger.warning(f"ë¡œì»¬ ë²ˆì—­ ì‹¤íŒ¨: {e}, ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜")
            return korean_text
    
    def get_model_info(self) -> Dict[str, Any]:
        '''ëª¨ë¸ ì •ë³´ ë°˜í™˜'''
        info = {
            'model_name': self.model_name,
            'initialized': self.initialized,
            'cache_size': len(self.translation_cache),
            'device': str(self.device) if self.device else 'not_loaded'
        }
        
        if self.initialized and self.model:
            info['model_type'] = 'MarianMT'
            info['vocab_size'] = self.tokenizer.vocab_size if self.tokenizer else 'unknown'
        
        return info
    
    def clear_cache(self):
        '''ë²ˆì—­ ìºì‹œ ì •ë¦¬'''
        cache_size = len(self.translation_cache)
        self.translation_cache.clear()
        logger.info(f"ë²ˆì—­ ìºì‹œ ì •ë¦¬ë¨: {cache_size}ê°œ í•­ëª© ì‚­ì œ")
"""

class FocalLoss(nn.Module):
    """
    Focal Loss for Joy í¸í–¥ í•´ê²°
    í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì†ì‹¤ í•¨ìˆ˜
    """
    def __init__(self, alpha: float = 1.5, gamma: float = 2.0, size_average: bool = True):
        """
        Args:
            alpha: í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 1.5)
            gamma: focusing parameter (ê¸°ë³¸ê°’: 2.0)
            size_average: í‰ê· ì„ êµ¬í• ì§€ ì—¬ë¶€
        """
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.size_average = size_average
        
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        Focal Loss ê³„ì‚°
        
        Args:
            inputs: ëª¨ë¸ ì˜ˆì¸¡ê°’ (logits) [batch_size, num_classes]
            targets: ì‹¤ì œ ë ˆì´ë¸” [batch_size]
            
        Returns:
            focal loss ê°’
        """
        # Cross entropy loss ê³„ì‚°
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        
        # í™•ë¥  ê³„ì‚°
        pt = torch.exp(-ce_loss)
        
        # Focal loss ê³„ì‚°
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        
        if self.size_average:
            return focal_loss.mean()
        else:
            return focal_loss.sum()

class EmotionFocalLoss(nn.Module):
    """
    ê°ì • ë¶„ì„ ì „ìš© Focal Loss
    Joy í¸í–¥ í•´ê²°ì„ ìœ„í•œ íŠ¹í™”ëœ ì†ì‹¤ í•¨ìˆ˜
    """
    def __init__(self, emotion_weights: Optional[Dict[str, float]] = None, 
                 alpha: float = 1.5, gamma: float = 2.0):
        """
        Args:
            emotion_weights: ê° ê°ì •ë³„ ê°€ì¤‘ì¹˜
            alpha: focusing parameter alpha
            gamma: focusing parameter gamma
        """
        super(EmotionFocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        
        # Joy í¸í–¥ í•´ê²°ì„ ìœ„í•œ ê¸°ë³¸ ê°€ì¤‘ì¹˜
        if emotion_weights is None:
            self.emotion_weights = {
                'JOY': 0.5,        # Joy ê°€ì¤‘ì¹˜ ê°ì†Œ (í¸í–¥ í•´ê²°)
                'TRUST': 1.2,
                'FEAR': 1.3,
                'SURPRISE': 1.2,
                'SADNESS': 1.3,
                'DISGUST': 1.4,
                'ANGER': 1.3,
                'ANTICIPATION': 1.2,
                'NEUTRAL': 1.0
            }
        else:
            self.emotion_weights = emotion_weights
    
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor, 
                emotion_labels: Optional[List[str]] = None) -> torch.Tensor:
        """
        ê°ì • ê¸°ë°˜ Focal Loss ê³„ì‚°
        
        Args:
            inputs: ëª¨ë¸ ì˜ˆì¸¡ê°’ [batch_size, num_emotions]
            targets: ì‹¤ì œ ê°ì • ë ˆì´ë¸” [batch_size]
            emotion_labels: ê°ì • ë ˆì´ë¸” ëª©ë¡
            
        Returns:
            focal loss ê°’
        """
        # ê¸°ë³¸ focal loss ê³„ì‚°
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        
        # ê°ì •ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        if emotion_labels:
            weights = torch.ones_like(targets, dtype=torch.float)
            for i, target_idx in enumerate(targets):
                if target_idx.item() < len(emotion_labels):
                    emotion_name = emotion_labels[target_idx.item()]
                    weight = self.emotion_weights.get(emotion_name, 1.0)
                    weights[i] = weight
        else:
            weights = torch.ones_like(targets, dtype=torch.float)
        
        # Focal loss with emotion weights
        focal_loss = weights * self.alpha * (1 - pt) ** self.gamma * ce_loss
        
        return focal_loss.mean()

class AdvancedEmotionAnalyzer:
    """ê³ ê¸‰ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ - í´ë°± ì—†ëŠ” ì™„ì „ êµ¬í˜„"""
    
    def __init__(self):
        """ê³ ê¸‰ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        if not ADVANCED_LIBS_AVAILABLE:
            raise ImportError("ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        self.config = SYSTEM_CONFIG['emotion']
        from config import get_device
        self.device = get_device()
        
        # ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (WSL í˜¸í™˜ì„±)
        self.models_dir = EMOTION_MODELS_DIR
        os.makedirs(self.models_dir, exist_ok=True)
        
        # ë‹¤ì¤‘ ì–¸ì–´ ê°ì • ë¶„ì„ ëª¨ë¸ë“¤
        self.models = {}
        self.tokenizers = {}
        self.embedders = {}
        
        # ìƒì²´ì‹ í˜¸ ë¶„ì„ ëª¨ë¸ (ì£¼ì„ ì²˜ë¦¬ - í–¥í›„ ì—°ê²° ê°€ëŠ¥)
        # ì„¼ì„œ ì—°ê²° ì‹œ í™œì„±í™” ê°€ëŠ¥: EEG, ECG, GSR, ìŒì„±, ì‹œì„ ì¶”ì  ë“±
        # self.biosignal_model = None
        # self.biosignal_scaler = StandardScaler()
        self.biosignal_enabled = False  # ìƒì²´ì‹ í˜¸ ê¸°ëŠ¥ ë¹„í™œì„±í™” (ì—°ê²° ì‹œ Trueë¡œ ë³€ê²½)
        
        # ìºì‹œ
        self.embedding_cache = {}
        self.prediction_cache = {}
        
        # ë¡œì»¬ ë²ˆì—­ê¸° - ì „ì—­ ëª¨ë“ˆì—ì„œë§Œ ê°€ì ¸ì˜¤ê¸° (ì¤‘ë³µ ìƒì„± ë°©ì§€)
        from config import get_system_module
        self.local_translator = get_system_module('translator')
        if self.local_translator is None:
            # ì „ì—­ ëª¨ë“ˆì´ ì—†ìœ¼ë©´ ì—ëŸ¬ - translatorê°€ ë¨¼ì € ì´ˆê¸°í™”ë˜ì–´ì•¼ í•¨
            error_msg = "ì „ì—­ translator ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ëª¨ë“ˆ ì´ˆê¸°í™” ìˆœì„œ í™•ì¸ í•„ìš”"
            logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        # Focal Loss for Joy í¸í–¥ í•´ê²°
        self.focal_loss = EmotionFocalLoss(alpha=1.5, gamma=2.0)
        self.focal_loss_enabled = True
        
        # Mixture of Experts (ê°ì • ë¶„ì„ ê°•í™”)
        self.moe_enabled = True
        self.emotion_moe = None  # ëª…ì‹œì  ì´ˆê¸°í™”
        
        # DSP ì‹œë®¬ë ˆì´í„°ì™€ ì¹¼ë§Œ í•„í„° ì´ˆê¸°í™”
        self.dsp_simulator = None
        self.kalman_filter = None
        self.dsp_enabled = True
        self.prev_kalman_state = None  # ì¹¼ë§Œ í•„í„° ì´ì „ ìƒíƒœ
        
        # =====================================================
        # ê°•í™” ëª¨ë“ˆ í†µí•© (45M ì¶”ê°€ â†’ ì´ 50M)
        # =====================================================
        base_dim = 768
        
        # 1. ìƒì²´ì‹ í˜¸ ì²˜ë¦¬ ë„¤íŠ¸ì›Œí¬ (10M)
        self.biometric_processor = nn.ModuleDict({
            'eeg': self._create_biometric_network(32, base_dim),  # EEG 32ì±„ë„
            'ecg': self._create_biometric_network(12, base_dim),  # ECG 12ë¦¬ë“œ
            'gsr': self._create_biometric_network(4, base_dim),   # GSR 4ì„¼ì„œ
            'fusion': nn.Sequential(
                nn.Linear(base_dim * 3, base_dim * 2),
                nn.LayerNorm(base_dim * 2),
                nn.GELU(),
                nn.Dropout(0.1),
                nn.Linear(base_dim * 2, base_dim),
                nn.LayerNorm(base_dim)
            )
        }).to(self.device)
        
        # 2. ë©€í‹°ëª¨ë‹¬ ìœµí•© ë ˆì´ì–´ (10M)
        self.multimodal_fusion = nn.ModuleDict({
            'text_encoder': nn.TransformerEncoder(
                nn.TransformerEncoderLayer(
                    d_model=base_dim,
                    nhead=12,
                    dim_feedforward=base_dim * 4,
                    dropout=0.1,
                    batch_first=True
                ),
                num_layers=2
            ),
            'image_encoder': nn.Sequential(
                nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),
                nn.BatchNorm2d(64),
                nn.ReLU(),
                nn.MaxPool2d(3, stride=2, padding=1),
                nn.Conv2d(64, 128, kernel_size=3, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.AdaptiveAvgPool2d((1, 1)),
                nn.Flatten(),
                nn.Linear(128, base_dim)
            ),
            'audio_encoder': nn.Sequential(
                nn.Conv1d(1, 64, kernel_size=80, stride=10),
                nn.BatchNorm1d(64),
                nn.ReLU(),
                nn.Conv1d(64, 128, kernel_size=3, padding=1),
                nn.BatchNorm1d(128),
                nn.ReLU(),
                nn.AdaptiveAvgPool1d(1),
                nn.Flatten(),
                nn.Linear(128, base_dim)
            ),
            'cross_modal_attention': nn.MultiheadAttention(
                embed_dim=base_dim,
                num_heads=12,
                dropout=0.1,
                batch_first=True
            )
        }).to(self.device)
        
        # 3. ì‹œê³„ì—´ ê°ì • ì¶”ì  (10M)
        self.temporal_emotion = nn.ModuleDict({
            'lstm_tracker': nn.LSTM(
                input_size=base_dim,
                hidden_size=base_dim // 2,
                num_layers=3,
                batch_first=True,
                dropout=0.1,
                bidirectional=True
            ),
            'temporal_attention': nn.Sequential(
                nn.Linear(base_dim, base_dim),
                nn.LayerNorm(base_dim),
                nn.GELU(),
                nn.Linear(base_dim, base_dim // 2),
                nn.Linear(base_dim // 2, 1),
                nn.Softmax(dim=1)
            ),
            'emotion_memory': nn.GRUCell(base_dim, base_dim),
            'trend_predictor': nn.Sequential(
                nn.Linear(base_dim * 2, base_dim),
                nn.LayerNorm(base_dim),
                nn.GELU(),
                nn.Linear(base_dim, base_dim // 2),
                nn.Linear(base_dim // 2, 7)  # 7 emotions
            )
        }).to(self.device)
        
        # 4. ë¬¸í™”ì  ë‰˜ì•™ìŠ¤ ê°ì§€ (10M + 3M ì¶”ê°€ = 13M)
        self.cultural_nuance = nn.ModuleDict({
            'korean': self._create_cultural_network(base_dim),
            'western': self._create_cultural_network(base_dim),
            'eastern': self._create_cultural_network(base_dim),
            'fusion': nn.Sequential(
                nn.Linear(base_dim * 3, base_dim * 2),
                nn.LayerNorm(base_dim * 2),
                nn.GELU(),
                nn.Linear(base_dim * 2, base_dim),
                nn.LayerNorm(base_dim)
            ),
            # ì¶”ê°€ ë ˆì´ì–´ (3M)
            'deep_cultural': nn.Sequential(
                nn.Linear(base_dim, 1024),
                nn.LayerNorm(1024),
                nn.GELU(),
                nn.Dropout(0.1),
                nn.Linear(1024, 768),
                nn.LayerNorm(768),
                nn.GELU(),
                nn.Linear(768, base_dim)
            )
        }).to(self.device)
        
        # 5. ê³ ê¸‰ MoE í™•ì¥ (5M)
        self.advanced_moe = nn.ModuleDict({
            'micro_experts': nn.ModuleList([
                nn.Sequential(
                    nn.Linear(base_dim, base_dim // 2),
                    nn.GELU(),
                    nn.Linear(base_dim // 2, base_dim // 4),
                    nn.Linear(base_dim // 4, 7)
                ) for _ in range(16)  # 16 micro experts
            ]),
            'router': nn.Sequential(
                nn.Linear(base_dim, base_dim // 2),
                nn.GELU(),
                nn.Linear(base_dim // 2, 16),
                nn.Softmax(dim=-1)
            )
        }).to(self.device)
        
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        total_params = sum(p.numel() for p in [
            *self.biometric_processor.parameters(),
            *self.multimodal_fusion.parameters(),
            *self.temporal_emotion.parameters(),
            *self.cultural_nuance.parameters(),
            *self.advanced_moe.parameters()
        ])
        logger.info(f"âœ… ê°ì • ë¶„ì„ê¸° ê°•í™” ëª¨ë“ˆ í†µí•©: {total_params/1e6:.1f}M íŒŒë¼ë¯¸í„° ì¶”ê°€")
        
        if self.moe_enabled:
            try:
                # ê°ì • ì„ë² ë”© ì°¨ì› (ê¸°ë³¸ê°’)
                emotion_input_dim = 768  # ë¬¸ì¥ ë³€í™˜ê¸° ì„ë² ë”© ì°¨ì›
                emotion_output_dim = len(EmotionState)  # ê°ì • ìƒíƒœ ìˆ˜
                
                self.emotion_moe = create_emotion_moe(
                    input_dim=emotion_input_dim,
                    output_dim=emotion_output_dim,
                    num_experts=4
                ).to(self.device)
                
                logger.info("ê°ì • ë¶„ì„ìš© MoE ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (4ê°œ ì „ë¬¸ê°€)")
                logger.info(f"  - emotion_moe íƒ€ì…: {type(self.emotion_moe)}")
                logger.info(f"  - emotion_moe None ì—¬ë¶€: {self.emotion_moe is None}")
                
            except Exception as e:
                logger.error(f"MoE ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.emotion_moe = None  # ì‹¤íŒ¨ ì‹œ ëª…ì‹œì ìœ¼ë¡œ None ì„¤ì •
                
                # í”„ë¡œì íŠ¸ ê·œì¹™: fallback ì—†ëŠ” ìˆœìˆ˜ ì¬ì‹œë„ ë°©ì‹
                retry_count = 0
                max_retries = 3
                while retry_count < max_retries:
                    retry_count += 1
                    logger.info(f"MoE ì´ˆê¸°í™” ì¬ì‹œë„ {retry_count}/{max_retries}")
                    try:
                        self.emotion_moe = create_emotion_moe(
                            input_dim=emotion_input_dim,
                            output_dim=emotion_output_dim,
                            num_experts=4
                        ).to(self.device)
                        logger.info(f"ì¬ì‹œë„ {retry_count}: MoE ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ")
                        break
                    except Exception as retry_error:
                        logger.error(f"ì¬ì‹œë„ {retry_count} ì‹¤íŒ¨: {retry_error}")
                        self.emotion_moe = None
                        if retry_count >= max_retries:
                            logger.error("MoE ì´ˆê¸°í™” ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì¢…ë£Œ")
                            raise Exception(f"MoE ì‹œìŠ¤í…œ ì´ˆê¸°í™” ìµœì¢… ì‹¤íŒ¨: {retry_error}") from e
        
        # DSP ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._init_dsp_components()
        
        # í•œêµ­ì–´ ê°ì • í‚¤ì›Œë“œ (ê³ ê¸‰ ë²„ì „)
        self.korean_emotion_keywords = self._initialize_advanced_korean_keywords()
        
        # ëª¨ë¸ ì´ˆê¸°í™”ëŠ” initialize() ë©”ì„œë“œì—ì„œ ìˆ˜í–‰
        # self._initialize_models()ë¥¼ ì—¬ê¸°ì„œ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ
        
        # ìƒˆë¡œìš´ ê³„ì¸µì  ê°ì • ëª¨ë¸ ì´ˆê¸°í™”
        global NEW_EMOTION_MODELS_AVAILABLE
        if NEW_EMOTION_MODELS_AVAILABLE:
            try:
                self.hierarchical_model = HierarchicalEmotionModel()
                self.hierarchical_model.to(self.device)
                self.emotion_model_manager = EmotionModelManager(os.path.join(self.models_dir, "hierarchical"))
                logger.info("ê³„ì¸µì  ê°ì • ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"ê³„ì¸µì  ê°ì • ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                NEW_EMOTION_MODELS_AVAILABLE = False
        
        # LLM ì—”ì§„ ì—°ê²°
        global LLM_INTEGRATION_AVAILABLE
        if LLM_INTEGRATION_AVAILABLE:
            try:
                self.llm_engine = get_llm_engine()
                logger.info("LLM ì—”ì§„ ì—°ê²° ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"LLM ì—”ì§„ ì—°ê²° ì‹¤íŒ¨: {e}")
                LLM_INTEGRATION_AVAILABLE = False
        
        logger.info("ê³ ê¸‰ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ë“±ë¡ ë‹¨ê³„ì—ì„œ get_pytorch_networkê°€ ì‘ë™í•˜ë„ë¡ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ë³´ì¥
        self._ensure_default_network()
    
    def _ensure_default_network(self):
        """ìµœì†Œ í•˜ë‚˜ì˜ PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì¡´ì¬í•˜ë„ë¡ ë³´ì¥"""
        # ë¨¼ì € ê¸°ì¡´ ë„¤íŠ¸ì›Œí¬ í™•ì¸
        existing_network = None
        
        # hierarchical_model í™•ì¸
        if hasattr(self, 'hierarchical_model') and isinstance(self.hierarchical_model, nn.Module):
            existing_network = self.hierarchical_model
            logger.info("ğŸ” hierarchical_modelì´ ì´ë¯¸ ì¡´ì¬í•¨")
        
        # emotion_moe í™•ì¸  
        elif hasattr(self, 'emotion_moe') and isinstance(self.emotion_moe, nn.Module):
            existing_network = self.emotion_moe
            logger.info("ğŸ” emotion_moeê°€ ì´ë¯¸ ì¡´ì¬í•¨")
            
        # ë„¤íŠ¸ì›Œí¬ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„±
        if existing_network is None:
            logger.info("ğŸ”¨ ê¸°ë³¸ PyTorch ë„¤íŠ¸ì›Œí¬ ìƒì„± ì¤‘...")
            self._build_default_network()
        else:
            # ìºì‹œì— ì €ì¥
            self._primary_nn = existing_network
    
    def _build_default_network(self):
        """
        ê¸°ë³¸ PyTorch ë„¤íŠ¸ì›Œí¬ ìƒì„±
        - ë“±ë¡/í—¤ë“œ ë°”ì¸ë”©ì„ ìœ„í•œ ìµœì†Œ ë„¤íŠ¸ì›Œí¬
        - ê°€ë³ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
        """
        import torch.nn as nn
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        
        # ê°„ë‹¨í•œ ê°ì • ë¶„ë¥˜ê¸° ë„¤íŠ¸ì›Œí¬
        class DefaultEmotionNetwork(nn.Module):
            def __init__(self):
                super().__init__()
                self.embedding = nn.Embedding(1000, 128)  # ì‘ì€ ì„ë² ë”©
                self.lstm = nn.LSTM(128, 64, batch_first=True)
                self.classifier = nn.Linear(64, len(EmotionState))
                
            def forward(self, x):
                x = self.embedding(x)
                lstm_out, _ = self.lstm(x)
                # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ë§Œ ì‚¬ìš©
                last_hidden = lstm_out[:, -1, :]
                return self.classifier(last_hidden)
        
        # ë„¤íŠ¸ì›Œí¬ ìƒì„± ë° ì„¤ì •
        self.default_network = DefaultEmotionNetwork().to(device)
        self._primary_nn = self.default_network
        
        logger.info(f"âœ… ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì™„ë£Œ (device: {device})")
        logger.info(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in self.default_network.parameters()):,}")
        
        # emotion_moeê°€ Noneì´ë©´ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ë¡œ ì„¤ì •
        if not hasattr(self, 'emotion_moe') or self.emotion_moe is None:
            self.emotion_moe = self.default_network
            logger.info("ğŸ”— emotion_moeë¥¼ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ë¡œ ì„¤ì •")
    
    async def initialize(self):
        """ë¹„ë™ê¸° ì´ˆê¸°í™” ë©”ì„œë“œ - unified_system_orchestratorì—ì„œ í˜¸ì¶œë¨"""
        logger.info("AdvancedEmotionAnalyzer ë¹„ë™ê¸° ì´ˆê¸°í™” ì‹œì‘...")
        
        # 1. ë¨¼ì € ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ë¡œ emotion_empathy_head ì„ ë“±ë¡ (NO FALLBACK)
        from dynamic_swap_manager import get_swap_manager, SwapPriority
        swap_manager = get_swap_manager()
        if swap_manager:
            # get_pytorch_network()ëŠ” í•­ìƒ nn.Moduleì„ ë°˜í™˜í•˜ë„ë¡ ë³´ì¥ë¨
            try:
                primary = self.get_pytorch_network()  # ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„±/íšë“
                if primary is not None:
                    swap_manager.register_model(
                        "emotion_empathy_head",
                        primary,
                        priority=SwapPriority.HIGH
                    )
                    logger.info(f"âœ… emotion_empathy_head ì„ ë“±ë¡ ì™„ë£Œ (ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬: {primary.__class__.__name__})")
                else:
                    logger.error("âŒ emotion_empathy_head ì„ ë“±ë¡ ì‹¤íŒ¨: get_pytorch_network()ê°€ None ë°˜í™˜")
            except Exception as e:
                logger.error(f"âŒ emotion_empathy_head ì„ ë“±ë¡ ì¤‘ ì—ëŸ¬: {e}")
        
        try:
            # 2. ëª¨ë¸ ì´ˆê¸°í™” ìˆ˜í–‰ (ì‹¤íŒ¨í•´ë„ í—¤ë“œëŠ” ì´ë¯¸ ë“±ë¡ë¨)
            self._initialize_models()
            
            # 3. ëŒ€í˜• ëª¨ë¸ ë¡œë“œ ì„±ê³µí•˜ë©´ emotion_empathy_head ì—…ë°ì´íŠ¸
            if 'multilingual_direct' in self.models and self.models['multilingual_direct'] is not None:
                if swap_manager:
                    swap_manager.register_model(
                        "emotion_empathy_head",
                        self.models['multilingual_direct'],  # ëŒ€í˜• ëª¨ë¸ë¡œ êµì²´
                        priority=SwapPriority.HIGH
                    )
                    logger.info(f"âœ… emotion_empathy_head ì—…ë°ì´íŠ¸ ì™„ë£Œ (ëŒ€í˜• ëª¨ë¸: multilingual_direct)")
            
            logger.info("AdvancedEmotionAnalyzer ë¹„ë™ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info("âœ… EmotionAnalyzer GPU ì´ˆê¸°í™” ì„±ê³µ, í—¤ë“œ ë“±ë¡ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"AdvancedEmotionAnalyzer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ëŒ€í˜• ëª¨ë¸ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ëŠ” ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìœ¼ë¯€ë¡œ raise í•˜ì§€ ì•ŠìŒ
            logger.warning("âš ï¸ ëŒ€í˜• ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨í–ˆì§€ë§Œ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ë¡œ ê³„ì† ì§„í–‰")
    
    def _hf_kwargs_clean(self, **kwargs):
        """HF í˜¸ì¶œ ì „ kwargsì—ì„œ owner ì œê±°"""
        if 'owner' in kwargs:
            logger.warning("[EmotionAnalyzer] removing stray 'owner' from kwargs")
            kwargs.pop('owner', None)
        return kwargs
    
    def _create_biometric_network(self, input_channels: int, output_dim: int) -> nn.Module:
        """ìƒì²´ì‹ í˜¸ ì²˜ë¦¬ ë„¤íŠ¸ì›Œí¬ ìƒì„±"""
        return nn.Sequential(
            nn.Linear(input_channels, 256),
            nn.LayerNorm(256),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(256, 512),
            nn.LayerNorm(512),
            nn.GELU(),
            nn.Linear(512, output_dim)
        )
    
    def _create_cultural_network(self, dim: int) -> nn.Module:
        """ë¬¸í™”ë³„ ê°ì • í•´ì„ ë„¤íŠ¸ì›Œí¬"""
        return nn.Sequential(
            nn.Linear(dim, dim),
            nn.LayerNorm(dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(dim, dim // 2),
            nn.LayerNorm(dim // 2),
            nn.GELU(),
            nn.Linear(dim // 2, dim)
        )
    
    def _initialize_models(self):
        """ëª¨ë“  ê°ì • ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # 1. ë‹¤êµ­ì–´ ê°ì • ë¶„ì„ ëª¨ë¸
            logger.info("ë‹¤êµ­ì–´ ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë”©...")
            self._load_multilingual_emotion_model()
            
            # 2. í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸
            logger.info("í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ë¡œë”©...")
            self._load_korean_emotion_model()
            
            # 3. ê°ì • ì„ë² ë”© ëª¨ë¸
            logger.info("ê°ì • ì„ë² ë”© ëª¨ë¸ ë¡œë”©...")
            self._load_emotion_embedding_model()
            
            # 4. ìƒì²´ì‹ í˜¸ ë¶„ì„ ëª¨ë¸ (í˜„ì¬ ë¹„í™œì„±í™”)
            if self.biosignal_enabled:
                logger.info("ìƒì²´ì‹ í˜¸ ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™”...")
                self._initialize_biosignal_model()
            else:
                logger.info("ìƒì²´ì‹ í˜¸ ë¶„ì„ ëª¨ë¸ ë¹„í™œì„±í™”ë¨ (ì„¼ì„œ ë¯¸ì—°ê²°)")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _load_multilingual_emotion_model(self):
        """ë‹¤êµ­ì–´ ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ"""
        model_name = self.config['multilingual_model']
        
        try:
            # HF ë˜í¼ë¥¼ í†µí•œ Zero-shot classification íŒŒì´í”„ë¼ì¸ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
            from hf_model_wrapper import get_hf_wrapper
            hf_wrapper = get_hf_wrapper()
            
            self.models['multilingual'] = hf_wrapper.wrapped_pipeline(
                "zero-shot-classification",
                model=model_name,
                owner="emotion_analyzer",
                **self._hf_kwargs_clean(
                    device=0 if self.device.type == 'cuda' else -1,
                    local_files_only=True
                )
            )
            
            # HF ë˜í¼ë¥¼ í†µí•œ ëª¨ë¸ ë¡œë“œ (ì„¸ë°€í•œ ì œì–´ìš©, ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
            from hf_model_wrapper import get_hf_wrapper
            hf_wrapper = get_hf_wrapper()
            
            self.tokenizers['multilingual'] = hf_wrapper.wrapped_tokenizer(
                model_name, 
                owner="emotion_analyzer",
                **self._hf_kwargs_clean(local_files_only=True)
            )
            self.models['multilingual_direct'] = hf_wrapper.wrapped_from_pretrained(
                AutoModelForSequenceClassification, model_name, 
                owner="emotion_analyzer",
                **self._hf_kwargs_clean(local_files_only=True)
            )
            self.models['multilingual_direct'].to(self.device)
            
            logger.info(f"ë‹¤êµ­ì–´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
            
        except Exception as e:
            logger.error(f"ë‹¤êµ­ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _load_korean_emotion_model(self):
        """í•œêµ­ì–´ íŠ¹í™” ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ"""
        model_name = self.config['korean_model']
        
        try:
            # HF ë˜í¼ë¥¼ í†µí•œ í•œêµ­ì–´ BERT ëª¨ë¸ ë¡œë“œ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
            from hf_model_wrapper import get_hf_wrapper
            hf_wrapper = get_hf_wrapper()
            
            self.tokenizers['korean'] = hf_wrapper.wrapped_tokenizer(
                model_name, 
                owner="emotion_analyzer",
                **self._hf_kwargs_clean(local_files_only=True)
            )
            self.models['korean'] = hf_wrapper.wrapped_from_pretrained(
                AutoModel, model_name, 
                owner="emotion_analyzer",
                **self._hf_kwargs_clean(local_files_only=True)
            )
            self.models['korean'].to(self.device)
            
            # í•œêµ­ì–´ ê°ì • ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ (ê°€ëŠ¥í•œ ê²½ìš°, ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
            try:
                from hf_model_wrapper import get_hf_wrapper
                hf_wrapper = get_hf_wrapper()
                
                self.models['korean_pipeline'] = hf_wrapper.wrapped_pipeline(
                    "text-classification",
                    model=model_name,
                    tokenizer=model_name,
                    owner="emotion_analyzer",
                    **self._hf_kwargs_clean(
                        device=0 if self.device.type == 'cuda' else -1,
                        local_files_only=True
                    )
                )
            except Exception as pipeline_error:
                logger.warning(f"í•œêµ­ì–´ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹¤íŒ¨, ì§ì ‘ ëª¨ë¸ ì‚¬ìš©: {pipeline_error}")
            
            logger.info(f"í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
            
        except Exception as e:
            logger.warning(f"í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ (ì˜µì…˜ ê¸°ëŠ¥): {e}")
            logger.info("ë‹¤êµ­ì–´ ëª¨ë¸ë¡œ í•œêµ­ì–´ ë¶„ì„ ëŒ€ì²´ ê°€ëŠ¥ - ì‹œìŠ¤í…œ ê³„ì† ì§„í–‰")
            # í•œêµ­ì–´ ëª¨ë¸ ì—†ì–´ë„ ë‹¤êµ­ì–´ ëª¨ë¸ë¡œ ëŒ€ì²´ ê°€ëŠ¥
    
    def _load_emotion_embedding_model(self):
        """ê°ì • ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        try:
            # semantic ì„¤ì •ì—ì„œ ì„ë² ë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
            from config import SYSTEM_CONFIG
            from sentence_transformer_singleton import get_sentence_transformer
            
            semantic_config = SYSTEM_CONFIG.get('semantic', {})
            multilingual_model = semantic_config.get('sentence_model', 'paraphrase-multilingual-mpnet-base-v2')
            
            # ì‹±ê¸€í†¤ ë§¤ë‹ˆì €ë¥¼ í†µí•´ ê³µìœ  ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            self.embedders['multilingual'] = get_sentence_transformer(
                multilingual_model,
                device=str(self.device)
            )
            
            # í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ (ì‹±ê¸€í†¤ ë§¤ë‹ˆì € ì‚¬ìš©)
            korean_embedding_model = semantic_config.get('korean_model', 'jhgan/ko-sroberta-multitask')
            self.embedders['korean'] = get_sentence_transformer(
                korean_embedding_model,
                device=str(self.device)
            )
            
            logger.info(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì‹±ê¸€í†¤): {multilingual_model}, {korean_embedding_model}")
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # fallback ì—†ìŒ - ë°”ë¡œ ì˜ˆì™¸ ë°œìƒ
            raise RuntimeError(f"SentenceTransformer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}") from e
    
    def _initialize_biosignal_model(self):
        """ìƒì²´ì‹ í˜¸ ê¸°ë°˜ ê°ì • ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™”"""
        raise RuntimeError("ìƒì²´ì‹ í˜¸ ë¶„ì„ ëª¨ë¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ ìƒì²´ì‹ í˜¸ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    
    
    def _initialize_advanced_korean_keywords(self) -> Dict[str, Dict[str, List[str]]]:
        """ê³ ê¸‰ í•œêµ­ì–´ ê°ì • í‚¤ì›Œë“œ ì´ˆê¸°í™”"""
        return {
            EmotionState.JOY.value: {
                'primary': ['ê¸°ì˜', 'í–‰ë³µ', 'ì¦ê±°', 'ì¢‹', 'ë§Œì¡±', 'íë­‡', 'ì‹ ë‚˜', 'ë“¤ëœ¨'],
                'secondary': ['ì›ƒ', 'ì›ƒìŒ', 'ì›ƒê¸°', 'ì¬ë¯¸', 'ìœ ì¾Œ', 'ìƒì¾Œ', 'í†µì¾Œ', 'ì‹œì›'],
                'intensity': ['ë§¤ìš°', 'ì •ë§', 'ë„ˆë¬´', 'ì•„ì£¼', 'ì™„ì „íˆ', 'ì—„ì²­', 'êµ‰ì¥íˆ'],
                'cultural': ['ê¸°ë¶„ì¢‹', 'ë§ˆìŒì¢‹', 'ì†ì‹œì›', 'ê°œìš´', 'ë¿Œë“¯']
            },
            EmotionState.SADNESS.value: {
                'primary': ['ìŠ¬í”„', 'ìš°ìš¸', 'ëˆˆë¬¼', 'ì•„í”„', 'í˜ë“¤', 'ì„œê¸€', 'ì²˜ëŸ‰', 'ì•”ìš¸'],
                'secondary': ['ìš¸', 'ìš¸ìŒ', 'ìš¸ê³ ', 'ì“¸ì“¸', 'ì™¸ë¡œ', 'í—ˆì „', 'ê³µí—ˆ', 'ë§‰ë§‰'],
                'intensity': ['ë„ˆë¬´', 'ì •ë§', 'ë§¤ìš°', 'ì‹¬í•˜ê²Œ', 'ê¹Šì´'],
                'cultural': ['ë§ˆìŒì•„í”„', 'ê°€ìŠ´ì•„í”„', 'ë§˜ì´ë¬´ê±°', 'í•œìˆ¨', 'ì²´ë…']
            },
            EmotionState.ANGER.value: {
                'primary': ['í™”ë‚˜', 'í™”ê°€', 'ì§œì¦', 'ë¶„ë…¸', 'ì—´ë°›', 'ë¹¡ì¹˜', 'ì–µìš¸', 'ë¶„í•´', 'ê´˜ì”¸'],
                'secondary': ['ì„±ë‚´', 'í™”ë‚´', 'ìš•í•˜', 'ì†Œë¦¬ì§€ë¥´', 'ê³ í•¨', 'ë¶„í†µ', 'ìš¸í™”'],
                'intensity': ['ì •ë§', 'ë„ˆë¬´', 'ê·¹ë„ë¡œ', 'ì‹¬í•˜ê²Œ', 'ì™„ì „íˆ'],
                'cultural': ['ì—´ë¶ˆë‚˜', 'ì•½ì˜¤ë¥´', 'ë¹¡ëŒ', 'ëšœê»‘ì—´ë¦¬', 'í”¼êº¼ì†Ÿ']
            },
            EmotionState.FEAR.value: {
                'primary': ['ë¬´ì„œ', 'ë‘ë ¤', 'ê±±ì •', 'ë¶ˆì•ˆ', 'ê²ë‚˜', 'ë–¨ë¦¬', 'ì˜¤ì‹¹', 'ì†Œë¦„'],
                'secondary': ['ë–¨', 'ë–¨ë¦¼', 'ë²Œë²Œ', 'ì‹¬ì¥ë°•ë™', 'ì‹ì€ë•€', 'ê³µí¬', 'ê²½ì•…'],
                'intensity': ['ë§¤ìš°', 'ë„ˆë¬´', 'ì •ë§', 'ê·¹ë„ë¡œ', 'ì‹¬í•˜ê²Œ'],
                'cultural': ['ê°„ë‹´ì„œëŠ˜', 'ë“±ê³¨ì˜¤ì‹¹', 'ì‹¬ì¥ë–¨ì–´ëœ¨ë¦´', 'ê°„ë–¨ì–´ì§ˆ']
            },
            EmotionState.SURPRISE.value: {
                'primary': ['ë†€ë¼', 'ê¹œì§', 'ì˜ˆìƒ', 'ì‹ ê¸°', 'ì˜ì™¸', 'ëœ»ë°–', 'ê°‘ìê¸°'],
                'secondary': ['ì–´', 'í—‰', 'ì™€', 'ì–´ë¨¸', 'ì´ëŸ°', 'ì„¸ìƒì—', 'ì§„ì§œ'],
                'intensity': ['ì •ë§', 'ë„ˆë¬´', 'ì™„ì „íˆ', 'ì—„ì²­'],
                'cultural': ['ì–´ì´ì—†', 'ê¸°ê°€ë§‰íˆ', 'ì–´ì•ˆì´ë²™ë²™']
            },
            EmotionState.DISGUST.value: {
                'primary': ['ì—­ê²¨', 'ì‹«', 'í˜ì˜¤', 'ë”ëŸ¬', 'êµ¬ì—­ì§ˆ', 'ì§•ê·¸', 'ê¼´ë¶ˆê²¬'],
                'secondary': ['í† í•˜', 'ë©”ìŠ¤êº¼', 'êµ¬í† ', 'ì°œì°œ', 'ë¶ˆì¾Œ', 'ê¸°ë¶„ë‚˜ì˜'],
                'intensity': ['ì •ë§', 'ë„ˆë¬´', 'ë§¤ìš°', 'ê·¹ë„ë¡œ'],
                'cultural': ['ëˆˆê¼´ì‚¬ë‚˜', 'ë³´ê¸°ì‹«', 'ì¹˜ì‚¬']
            }
        }
    
    def analyze_emotion(self, text: str, language: str = "ko", 
                       biosignal_data: Optional[Biosignal] = None,
                       use_cache: bool = True) -> EmotionData:
        """ê³ ê¸‰ ê°ì • ë¶„ì„ - ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”"""
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (512 í† í° ì•ˆì „ ë§ˆì§„ìœ¼ë¡œ 800ì)
        if len(text) > 800:
            logger.warning(f"í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹€ ({len(text)}ì), ì²˜ìŒ 800ìë¡œ ì œí•œ")
            text = text[:800]
        
        # ìºì‹œ í™•ì¸
        cache_key = f"{text}_{language}_{hash(str(biosignal_data))}"
        if use_cache and cache_key in self.prediction_cache:
            return self.prediction_cache[cache_key]
        
        start_time = time.time()
        
        # 1. í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë¶„ì„
        text_emotion = self._analyze_text_emotion(text, language)
        
        # 2. ìƒì²´ì‹ í˜¸ ê¸°ë°˜ ê°ì • ë¶„ì„ (ìˆëŠ” ê²½ìš°)
        biosignal_emotion = None
        if biosignal_data:
            biosignal_emotion = self._analyze_biosignal_emotion(biosignal_data)
        
        # 3. ê²°ê³¼ í†µí•©
        final_emotion = self._integrate_emotion_results(
            text_emotion, biosignal_emotion, text, language
        )
        
        # 4. MoE ê¸°ë°˜ ê°ì • ë¶„ì„ ë³´ì •
        if self.moe_enabled:
            final_emotion = self._apply_moe_analysis(final_emotion, text, language)
        
        # 5. DSP ì‹œë®¬ë ˆì´í„°ì™€ ì¹¼ë§Œ í•„í„° ìœµí•©
        if self.dsp_enabled and self.dsp_simulator and self.kalman_filter:
            final_emotion = self._apply_dsp_kalman_fusion(final_emotion, text, language)
        
        # 6. Focal Loss ê¸°ë°˜ Joy í¸í–¥ ë³´ì •
        if self.focal_loss_enabled:
            final_emotion = self._apply_focal_loss_correction(final_emotion, text)
        
        # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
        processing_time = time.time() - start_time
        final_emotion.processing_method = "advanced_ensemble_with_moe_and_focal_correction"
        
        # ê°ì • ì„ë² ë”© ìƒì„±
        final_emotion.embedding = self._generate_emotion_embedding(text, language, final_emotion)
        
        # ìºì‹œ ì €ì¥
        if use_cache:
            self.prediction_cache[cache_key] = final_emotion
        
        logger.debug(f"ê°ì • ë¶„ì„ ì™„ë£Œ: {final_emotion.primary_emotion.value} "
                    f"(ì‹ ë¢°ë„: {final_emotion.confidence:.3f}, ì‹œê°„: {processing_time:.3f}s)")
        
        return final_emotion
    
    def _apply_moe_analysis(self, emotion_data: EmotionData, text: str, language: str) -> EmotionData:
        """
        MoE ê¸°ë°˜ ê°ì • ë¶„ì„ ë³´ì •
        
        Args:
            emotion_data: ì›ë³¸ ê°ì • ë¶„ì„ ê²°ê³¼
            text: ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸
            language: ì–¸ì–´
            
        Returns:
            MoEë¡œ ë³´ì •ëœ ê°ì • ë¶„ì„ ê²°ê³¼
        """
        try:
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            text_embedding = self._get_text_embedding_for_moe(text, language)
            
            if text_embedding is None:
                return emotion_data
            
            # MoE ì¶”ë¡ 
            moe_result = self.emotion_moe(text_embedding, temperature=0.8, return_expert_outputs=True)
            
            # MoE ê²°ê³¼ë¥¼ ê°ì • í™•ë¥ ë¡œ ë³€í™˜ (ì•ˆì „í•œ ì°¨ì› ì²˜ë¦¬)
            softmax_output = F.softmax(moe_result.final_output, dim=-1)
            if softmax_output.dim() > 1 and softmax_output.size(0) == 1:
                emotion_probs = softmax_output.squeeze(0)
            else:
                emotion_probs = softmax_output
            
            # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ê°ì • ì„ íƒ
            max_prob_idx = torch.argmax(emotion_probs).item()
            moe_confidence = emotion_probs[max_prob_idx].item()
            
            # EmotionState ë§¤í•‘
            emotion_states = list(EmotionState)
            if max_prob_idx < len(emotion_states):
                moe_emotion = emotion_states[max_prob_idx]
            else:
                moe_emotion = EmotionState.NEUTRAL
            
            # ì›ë³¸ ê²°ê³¼ì™€ MoE ê²°ê³¼ ìœµí•©
            original_confidence = emotion_data.confidence
            
            # ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ê²°ì •
            if moe_confidence > original_confidence * 1.2:
                # MoE ê²°ê³¼ê°€ í›¨ì”¬ í™•ì‹ ì ì´ë©´ MoE ê²°ê³¼ ì±„íƒ
                corrected_emotion = EmotionData(
                    primary_emotion=moe_emotion,
                    confidence=moe_confidence,
                    language=emotion_data.language,
                    processing_method=f"{emotion_data.processing_method}_moe_enhanced",
                    intensity=emotion_data.intensity,
                    secondary_emotions=emotion_data.secondary_emotions
                )
                
                # ë³´ì¡° ê°ì • ì—…ë°ì´íŠ¸
                secondary_emotions = {}
                for i, prob in enumerate(emotion_probs):
                    if i != max_prob_idx and i < len(emotion_states) and prob > 0.1:
                        secondary_emotions[emotion_states[i]] = prob.item()
                
                if secondary_emotions:
                    corrected_emotion.secondary_emotions = secondary_emotions
                
                # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                corrected_emotion.metadata = emotion_data.metadata.copy()
                corrected_emotion.metadata.update({
                    'moe_analysis': True,
                    'original_emotion': emotion_data.primary_emotion.name,
                    'original_confidence': original_confidence,
                    'moe_confidence': moe_confidence,
                    'experts_used': moe_result.total_experts_used,
                    'diversity_score': moe_result.diversity_score,
                    'expert_details': [
                        {
                            'expert_id': eo.expert_id,
                            'confidence': eo.confidence,
                            'weight': eo.weight
                        } for eo in moe_result.expert_outputs[:3]  # ìƒìœ„ 3ê°œë§Œ
                    ]
                })
                
            else:
                # ì›ë³¸ ê²°ê³¼ ìœ ì§€í•˜ë˜ MoE ì •ë³´ ì¶”ê°€
                corrected_emotion = emotion_data
                corrected_emotion.metadata = emotion_data.metadata.copy()
                corrected_emotion.metadata.update({
                    'moe_analysis': True,
                    'moe_suggestion': moe_emotion.name,
                    'moe_confidence': moe_confidence,
                    'confidence_ratio': moe_confidence / original_confidence,
                    'experts_used': moe_result.total_experts_used
                })
            
            return corrected_emotion
            
        except Exception as e:
            logger.error(f"MoE ë¶„ì„ ì‹¤íŒ¨: {e}")
            return emotion_data
    
    def _get_text_embedding_for_moe(self, text: str, language: str) -> Optional[torch.Tensor]:
        """
        MoEìš© í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        
        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸
            language: ì–¸ì–´
            
        Returns:
            í…ìŠ¤íŠ¸ ì„ë² ë”© í…ì„œ
        """
        try:
            # ê¸°ì¡´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
            if hasattr(self, 'embedders') and 'multilingual_embedder' in self.embedders:
                embedding = self.embedders['multilingual_embedder'].encode(
                    text, convert_to_tensor=True, device=self.device
                )
                
                # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                if embedding.dim() == 1:
                    embedding = embedding.unsqueeze(0)
                
                return embedding
            
            # ëŒ€ì•ˆ: í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸
            elif hasattr(self, 'embedders') and 'korean_embedder' in self.embedders:
                embedding = self.embedders['korean_embedder'].encode(
                    text, convert_to_tensor=True, device=self.device
                )
                
                if embedding.dim() == 1:
                    embedding = embedding.unsqueeze(0)
                
                return embedding
            
            # ê¸°ë³¸ ëŒ€ì•ˆ: ê°ì • ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
            elif hasattr(self, 'emotion_embedder') and self.emotion_embedder is not None:
                embedding = self.emotion_embedder.encode(
                    text, convert_to_tensor=True, device=self.device
                )
                
                if embedding.dim() == 1:
                    embedding = embedding.unsqueeze(0)
                
                return embedding
            
            # NO FALLBACK - ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì‹¤íŒ¨
            else:
                logger.error("ì „ìš© MoE ì„ë² ë”© ëª¨ë¸ì´ ì—†ìŒ")
                raise RuntimeError("MoE embedding model not available")
                
        except Exception as e:
            logger.error(f"MoE ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            # NO FALLBACK - ì¦‰ì‹œ ì˜ˆì™¸ ë°œìƒ
            raise RuntimeError(f"MoE embedding generation failed: {e}")
    
    def _init_dsp_components(self):
        """DSP ì‹œë®¬ë ˆì´í„°ì™€ ì¹¼ë§Œ í•„í„° ì´ˆê¸°í™”"""
        if not self.dsp_enabled:
            return
            
        try:
            # DSP ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™” (20M íŒŒë¼ë¯¸í„°)
            self.dsp_simulator = EmotionDSPSimulator({
                'hidden_dim': 256,  # ì¶•ì†Œëœ ì°¨ì›
            }).to(self.device)
            
            # ë™ì  ì¹¼ë§Œ í•„í„° ì´ˆê¸°í™” (7ê°œ ê°ì • ìƒíƒœ)
            self.kalman_filter = DynamicKalmanFilter(
                state_dim=len(EmotionState)
            ).to(self.device)
            
            logger.info("âœ… DSP ì‹œë®¬ë ˆì´í„°ì™€ ì¹¼ë§Œ í•„í„° ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info(f"  - DSP ì‹œë®¬ë ˆì´í„°: 20M íŒŒë¼ë¯¸í„°")
            logger.info(f"  - ì¹¼ë§Œ í•„í„°: ìœµí•©ìš©")
            
        except Exception as e:
            logger.error(f"DSP ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.dsp_simulator = None
            self.kalman_filter = None
            self.dsp_enabled = False
    
    def _apply_dsp_kalman_fusion(self, emotion_data: EmotionData, text: str, language: str) -> EmotionData:
        """
        DSP ì‹œë®¬ë ˆì´í„°ì™€ ì¹¼ë§Œ í•„í„°ë¥¼ í†µí•œ ê°ì • ìœµí•©
        
        Args:
            emotion_data: ê¸°ì¡´ ê°ì • ë¶„ì„ ê²°ê³¼
            text: ë¶„ì„ í…ìŠ¤íŠ¸
            language: ì–¸ì–´
            
        Returns:
            ì¹¼ë§Œ í•„í„°ë¡œ ìœµí•©ëœ ê°ì • ë°ì´í„°
        """
        try:
            # 1. í…ìŠ¤íŠ¸ë¥¼ DSP ì…ë ¥ìœ¼ë¡œ ë³€í™˜
            text_embedding = self._get_text_embedding_for_moe(text, language)
            if text_embedding is None or text_embedding.shape[-1] != 256:
                # ì„ë² ë”© ì°¨ì› ì¡°ì • (768 -> 256)
                if text_embedding is not None:
                    linear_proj = nn.Linear(text_embedding.shape[-1], 256).to(self.device)
                    text_embedding = linear_proj(text_embedding)
                else:
                    # ë”ë¯¸ ì„ë² ë”© ìƒì„±
                    text_embedding = torch.randn(1, 256).to(self.device)
            
            # 2. DSP ì‹œë®¬ë ˆì´í„° ì‹¤í–‰
            dsp_result = self.dsp_simulator(text_embedding)
            dsp_emotions = dsp_result['final_emotions']  # (batch, 7)
            
            # 3. ê¸°ì¡´ ê°ì •ì„ í…ì„œë¡œ ë³€í™˜
            emotion_states = list(EmotionState)
            traditional_emotions = torch.zeros(1, len(emotion_states)).to(self.device)
            
            # ì£¼ ê°ì • ì„¤ì •
            primary_idx = emotion_states.index(emotion_data.primary_emotion)
            traditional_emotions[0, primary_idx] = emotion_data.confidence
            
            # ë³´ì¡° ê°ì • ì„¤ì •
            if emotion_data.secondary_emotions:
                for sec_emotion, sec_conf in emotion_data.secondary_emotions.items():
                    if sec_emotion in emotion_states:
                        sec_idx = emotion_states.index(sec_emotion)
                        traditional_emotions[0, sec_idx] = sec_conf
            
            # ì •ê·œí™”
            traditional_emotions = F.softmax(traditional_emotions, dim=-1)
            
            # 4. ì¹¼ë§Œ í•„í„°ë¡œ ìœµí•©
            fused_emotions = self.kalman_filter(
                traditional_emotions=traditional_emotions,
                dsp_emotions=dsp_emotions,
                prev_state=self.prev_kalman_state
            )
            
            # ì¹¼ë§Œ ìƒíƒœ ì—…ë°ì´íŠ¸
            self.prev_kalman_state = fused_emotions.detach()
            
            # 5. ìœµí•© ê²°ê³¼ë¥¼ EmotionDataë¡œ ë³€í™˜
            fused_emotions_cpu = fused_emotions[0].cpu().numpy()
            max_idx = np.argmax(fused_emotions_cpu)
            
            # ìƒˆë¡œìš´ ì£¼ ê°ì •ê³¼ ì‹ ë¢°ë„
            emotion_data.primary_emotion = emotion_states[max_idx]
            emotion_data.confidence = float(fused_emotions_cpu[max_idx])
            
            # ë³´ì¡° ê°ì • ì—…ë°ì´íŠ¸
            emotion_data.secondary_emotions = {}
            for i, prob in enumerate(fused_emotions_cpu):
                if i != max_idx and prob > 0.1:  # 10% ì´ìƒì¸ ê°ì •ë§Œ
                    emotion_data.secondary_emotions[emotion_states[i]] = float(prob)
            
            # DSP íŠ¹ì§• ì €ì¥ (ë©”íƒ€ë°ì´í„°)
            emotion_data.metadata = emotion_data.metadata or {}
            emotion_data.metadata['dsp_valence_arousal'] = dsp_result['valence_arousal'].cpu().numpy().tolist()
            emotion_data.metadata['dsp_emotion_spectrum'] = dsp_result['emotion_spectrum'].cpu().numpy().tolist()
            emotion_data.metadata['fusion_method'] = 'kalman_filter'
            
            logger.debug(f"DSP-ì¹¼ë§Œ ìœµí•© ì™„ë£Œ: {emotion_data.primary_emotion.value} "
                        f"(ì‹ ë¢°ë„: {emotion_data.confidence:.3f})")
            
        except Exception as e:
            logger.error(f"DSP-ì¹¼ë§Œ ìœµí•© ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜ (NO FALLBACK ì›ì¹™ì´ì§€ë§Œ ìœµí•©ì€ ì„ íƒì  ê°œì„ )
            
        return emotion_data
    
    def _apply_focal_loss_correction(self, emotion_data: EmotionData, text: str) -> EmotionData:
        """
        Focal Loss ê¸°ë°˜ Joy í¸í–¥ ë³´ì •
        
        Args:
            emotion_data: ì›ë³¸ ê°ì • ë¶„ì„ ê²°ê³¼
            text: ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸
            
        Returns:
            ë³´ì •ëœ ê°ì • ë¶„ì„ ê²°ê³¼
        """
        try:
            # Joy í¸í–¥ ê°ì§€ ë° ë³´ì •
            corrected_emotion = emotion_data
            
            # Joyê°€ ì£¼ìš” ê°ì •ì¸ ê²½ìš° ë³´ì • ì ìš©
            if emotion_data.primary_emotion == EmotionState.JOY:
                # ì‹ ë¢°ë„ ê¸°ë°˜ ë³´ì •
                original_confidence = emotion_data.confidence
                
                # Joy ì‹ ë¢°ë„ ê°ì†Œ (focal loss ê°€ì¤‘ì¹˜ ì ìš©)
                joy_weight = self.focal_loss.emotion_weights.get('JOY', 0.5)
                corrected_confidence = original_confidence * joy_weight
                
                # ë‹¤ë¥¸ ê°ì • ê°€ëŠ¥ì„± ì¬ê²€í† 
                alternative_emotions = self._analyze_alternative_emotions(text, emotion_data)
                
                # ë³´ì •ëœ ì‹ ë¢°ë„ê°€ ì„ê³„ê°’(0.6) ì´í•˜ì´ë©´ ëŒ€ì•ˆ ê°ì • ê³ ë ¤
                if corrected_confidence < 0.6 and alternative_emotions:
                    best_alternative = max(alternative_emotions.items(), key=lambda x: x[1])
                    alt_emotion, alt_confidence = best_alternative
                    
                    # ëŒ€ì•ˆ ê°ì •ì´ ë” ì ì ˆí•˜ë©´ êµì²´
                    if alt_confidence > corrected_confidence * 1.2:
                        corrected_emotion = EmotionData(
                            primary_emotion=alt_emotion,
                            confidence=alt_confidence,
                            language=emotion_data.language,
                            processing_method=f"{emotion_data.processing_method}_focal_corrected",
                            intensity=emotion_data.intensity,
                            secondary_emotions=emotion_data.secondary_emotions
                        )
                        
                        # ë©”íƒ€ë°ì´í„°ì— ë³´ì • ì •ë³´ ì¶”ê°€
                        corrected_emotion.metadata = emotion_data.metadata.copy()
                        corrected_emotion.metadata.update({
                            'focal_loss_correction': True,
                            'original_emotion': emotion_data.primary_emotion.name,
                            'original_confidence': original_confidence,
                            'correction_reason': 'joy_bias_correction'
                        })
                    else:
                        # Joy ìœ ì§€í•˜ë˜ ì‹ ë¢°ë„ë§Œ ë³´ì •
                        corrected_emotion.confidence = corrected_confidence
                        corrected_emotion.metadata = emotion_data.metadata.copy()
                        corrected_emotion.metadata.update({
                            'focal_loss_correction': True,
                            'confidence_adjusted': True
                        })
                else:
                    # Joy ìœ ì§€í•˜ë˜ ì‹ ë¢°ë„ë§Œ ë³´ì •
                    corrected_emotion.confidence = corrected_confidence
                    corrected_emotion.metadata = emotion_data.metadata.copy()
                    corrected_emotion.metadata.update({
                        'focal_loss_correction': True,
                        'confidence_adjusted': True
                    })
            
            # ë‹¤ë¥¸ ê°ì •ë“¤ì˜ ìƒëŒ€ì  ê°•í™”
            if hasattr(corrected_emotion, 'secondary_emotions') and corrected_emotion.secondary_emotions:
                enhanced_secondary = {}
                for emotion, score in corrected_emotion.secondary_emotions.items():
                    weight = self.focal_loss.emotion_weights.get(emotion.name, 1.0)
                    enhanced_secondary[emotion] = min(1.0, score * weight)
                corrected_emotion.secondary_emotions = enhanced_secondary
            
            return corrected_emotion
            
        except Exception as e:
            logger.error(f"Focal loss ë³´ì • ì‹¤íŒ¨: {e}")
            return emotion_data
    
    def _analyze_alternative_emotions(self, text: str, original_emotion: EmotionData) -> Dict[EmotionState, float]:
        """
        ëŒ€ì•ˆ ê°ì • ë¶„ì„
        
        Args:
            text: ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸
            original_emotion: ì›ë³¸ ê°ì • ë¶„ì„ ê²°ê³¼
            
        Returns:
            ëŒ€ì•ˆ ê°ì •ë“¤ê³¼ ì‹ ë¢°ë„
        """
        alternatives = {}
        
        try:
            # í‚¤ì›Œë“œ ê¸°ë°˜ ëŒ€ì•ˆ ê°ì • ë¶„ì„
            text_lower = text.lower()
            
            # ê°ì •ë³„ í‚¤ì›Œë“œ ì‚¬ì „
            emotion_keywords = {
                EmotionState.SADNESS: ['ìŠ¬í”„', 'ìš°ìš¸', 'ì§œì¦', 'ì‹¤ë§', 'ì¢Œì ˆ', 'ëˆˆë¬¼', 'ì•„í”„', 'í˜ë“¤'],
                EmotionState.ANGER: ['í™”ë‚˜', 'ì§œì¦', 'ë¶„ë…¸', 'ì—´ë°›', 'ë¹¡ì³', 'ì‹«ì–´', 'ë¯¸ì›Œ'],
                EmotionState.FEAR: ['ë¬´ì„œ', 'ë‘ë ¤', 'ê±±ì •', 'ë¶ˆì•ˆ', 'ê²ë‚˜', 'ë–¨ë ¤'],
                EmotionState.SURPRISE: ['ë†€ë¼', 'ê¹œì§', 'ì–´?', 'í—‰', 'ì™€', 'ëŒ€ë°•'],
                EmotionState.DISGUST: ['ì—­ê²¨', 'ë”ëŸ¬', 'ì‹«ì–´', 'êµ¬ì—­ì§ˆ', 'ëª»ìƒ', 'ì¶”ì•…'],
                EmotionState.TRUST: ['ë¯¿', 'ì‹ ë¢°', 'ì•ˆì „', 'ë“ ë“ ', 'í™•ì‹ '],
                EmotionState.ANTICIPATION: ['ê¸°ëŒ€', 'ì„¤ë ˆ', 'ê¸°ë‹¤', 'ë°”ë¼', 'í¬ë§']
            }
            
            for emotion, keywords in emotion_keywords.items():
                if emotion != original_emotion.primary_emotion:
                    score = 0.0
                    for keyword in keywords:
                        if keyword in text_lower:
                            score += 0.15
                    
                    # í‚¤ì›Œë“œ ë°€ë„ ê³„ì‚°
                    if score > 0:
                        keyword_density = score / len(text) * 100
                        final_score = min(0.9, score + keyword_density)
                        alternatives[emotion] = final_score
            
            return alternatives
            
        except Exception as e:
            logger.error(f"ëŒ€ì•ˆ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _analyze_text_emotion(self, text: str, language: str) -> EmotionData:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë¶„ì„"""
        
        if language == "ko":
            # í•œêµ­ì–´ íŠ¹í™” ë¶„ì„
            return self._analyze_korean_text(text)
        else:
            # ë‹¤êµ­ì–´ ë¶„ì„
            return self._analyze_multilingual_text(text)
    
    def _analyze_korean_text(self, text: str) -> EmotionData:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        
        # 1. í•œêµ­ì–´ ëª¨ë¸ ì‚¬ìš© (ì‹ ë¢°ë„ê°€ ë†’ì€ ê²½ìš°ë§Œ)
        if 'korean_pipeline' in self.models:
            try:
                result = self.models['korean_pipeline'](text)
                # ê²°ê³¼ ì²˜ë¦¬ - ì‹ ë¢°ë„ê°€ 0.7 ì´ìƒì¸ ê²½ìš°ë§Œ ì‚¬ìš©
                if result and result[0]['score'] > 0.7:
                    emotion_label = result[0]['label'].lower()
                    confidence = result[0]['score']
                    
                    # ê°ì • ë§¤í•‘ (í•œêµ­ì–´ ëª¨ë¸ ë ˆì´ë¸” í¬í•¨)
                    emotion_mapping = {
                        'positive': EmotionState.JOY,
                        'negative': EmotionState.SADNESS,
                        'joy': EmotionState.JOY,
                        'sadness': EmotionState.SADNESS,
                        'anger': EmotionState.ANGER,
                        'fear': EmotionState.FEAR,
                        'surprise': EmotionState.SURPRISE,
                        'disgust': EmotionState.DISGUST,
                        'label_0': EmotionState.SADNESS,    # í•œêµ­ì–´ ëª¨ë¸ ë ˆì´ë¸”
                        'label_1': EmotionState.JOY,       # í•œêµ­ì–´ ëª¨ë¸ ë ˆì´ë¸”
                        'label_2': EmotionState.ANGER,     # í•œêµ­ì–´ ëª¨ë¸ ë ˆì´ë¸”
                        'label_3': EmotionState.FEAR,      # í•œêµ­ì–´ ëª¨ë¸ ë ˆì´ë¸”
                        'label_4': EmotionState.SURPRISE,  # í•œêµ­ì–´ ëª¨ë¸ ë ˆì´ë¸”
                        'label_5': EmotionState.DISGUST,   # í•œêµ­ì–´ ëª¨ë¸ ë ˆì´ë¸”
                    }
                    
                    primary_emotion = emotion_mapping.get(emotion_label, EmotionState.NEUTRAL)
                    
                    if primary_emotion != EmotionState.NEUTRAL:
                        return EmotionData(
                            primary_emotion=primary_emotion,
                            confidence=confidence,
                            language="ko",
                            processing_method="korean_transformer"
                        )
            except Exception as e:
                logger.warning(f"í•œêµ­ì–´ ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # 2. ê³ ê¸‰ í‚¤ì›Œë“œ ë¶„ì„ (ê¸°ë³¸ ë°©ë²•)
        return self._analyze_korean_keywords_advanced(text)
    
    def _analyze_korean_keywords_advanced(self, text: str) -> EmotionData:
        """ê³ ê¸‰ í•œêµ­ì–´ í‚¤ì›Œë“œ ë¶„ì„ + LLM ë³´ì¡°"""
        text_lower = text.lower()
        emotion_scores = {}
        detected_emotions = []
        
        for emotion_name, keywords_dict in self.korean_emotion_keywords.items():
            total_score = 0
            matches = []
            
            # Primary í‚¤ì›Œë“œ ì ìˆ˜ (ê°€ì¤‘ì¹˜ 1.0)
            for keyword in keywords_dict['primary']:
                if keyword in text_lower:
                    total_score += 1.0
                    matches.append(('primary', keyword))
            
            # Secondary í‚¤ì›Œë“œ ì ìˆ˜ (ê°€ì¤‘ì¹˜ 0.7)
            for keyword in keywords_dict['secondary']:
                if keyword in text_lower:
                    total_score += 0.7
                    matches.append(('secondary', keyword))
            
            # Intensity ìˆ˜ì‹ì–´ ì ìˆ˜ (ê°€ì¤‘ì¹˜ 0.5, ê³±ì…ˆ)
            intensity_multiplier = 1.0
            for modifier in keywords_dict['intensity']:
                if modifier in text_lower:
                    intensity_multiplier += 0.5
                    matches.append(('intensity', modifier))
            
            # Cultural í‚¤ì›Œë“œ ì ìˆ˜ (ê°€ì¤‘ì¹˜ 0.8)
            for keyword in keywords_dict['cultural']:
                if keyword in text_lower:
                    total_score += 0.8
                    matches.append(('cultural', keyword))
            
            final_score = total_score * intensity_multiplier
            emotion_scores[emotion_name] = final_score
            
            if final_score > 0:
                detected_emotions.append({
                    'emotion': emotion_name,
                    'score': final_score,
                    'matches': matches
                })
        
        # í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ LLMìœ¼ë¡œ ê²€ì¦
        if emotion_scores and max(emotion_scores.values()) > 0:
            best_emotion = max(emotion_scores, key=emotion_scores.get)
            best_score = emotion_scores[best_emotion]
            
            # LLMì„ í†µí•œ ê°ì • ë¶„ì„ ê°•í™” (ì¡°ê±´ë¶€)
            llm_result = self._enhance_with_llm_analysis(text, best_emotion, best_score)
            if llm_result:
                # LLM ê²°ê³¼ë¡œ ì¡°ì •
                best_emotion = llm_result.get('emotion', best_emotion) 
                confidence = llm_result.get('confidence', best_score / 5.0)
                reasoning = llm_result.get('reasoning', '')
            else:
                # ê¸°ì¡´ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
                confidence = min(0.95, best_score / 5.0)
                reasoning = f"í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„: {detected_emotions}"
            
            # ê°•ë„ ê³„ì‚°
            intensity = self._calculate_intensity_from_score(best_score)
            
            # ê°ì •ê°€ ë° ê°ì„±ë„ ê³„ì‚°
            valence, arousal = self._calculate_valence_arousal(best_emotion, best_score)
            
            return EmotionData(
                primary_emotion=EmotionState(best_emotion),
                intensity=intensity,
                confidence=confidence,
                valence=valence,
                arousal=arousal,
                secondary_emotions={EmotionState(k): v/5.0 
                                  for k, v in emotion_scores.items() 
                                  if v > 0 and k != best_emotion},
                language="ko",
                processing_method="advanced_korean_keywords_llm",
                metadata={'llm_reasoning': reasoning}
            )
        
        # ê°ì •ì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš° - LLM ì „ì²´ ë¶„ì„ (ì§ì ‘ ê²°ê³¼ ì‚¬ìš©)
        try:
            llm_result = self._deep_llm_emotion_analysis(text)
            
            # ë°˜í™˜ íƒ€ì… ê²€ì¦: _deep_llm_emotion_analysisëŠ” ì™„ì „íˆ ì²˜ë¦¬ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜
            if llm_result is None:
                raise RuntimeError("LLM ê°ì • ë¶„ì„ì´ Noneì„ ë°˜í™˜")
            elif not isinstance(llm_result, dict):
                raise RuntimeError(f"LLM ê°ì • ë¶„ì„ì´ ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì… ë°˜í™˜: {type(llm_result)}")
            elif 'emotion' not in llm_result:
                raise RuntimeError("LLM ê°ì • ë¶„ì„ ê²°ê³¼ì— 'emotion' í•„ë“œê°€ ì—†ìŒ")
        except Exception as e:
            logger.error(f"LLM ë¶„ì„ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"LLM ê°ì • ë¶„ì„ ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€: {e}")
            
        if llm_result and llm_result.get('emotion') != EmotionState.NEUTRAL.value:
            # intensity ê°’ ì•ˆì „í•˜ê²Œ ê²€ì¦
            intensity_value = llm_result.get('intensity', 3)
            if not isinstance(intensity_value, int) or intensity_value < 1 or intensity_value > 6:
                logger.warning(f"ì˜ëª»ëœ intensity ê°’: {intensity_value}, ê¸°ë³¸ê°’ 3ìœ¼ë¡œ ì„¤ì •")
                intensity_value = 3
            
            return EmotionData(
                primary_emotion=EmotionState(llm_result['emotion']),
                intensity=EmotionIntensity(intensity_value),
                confidence=llm_result.get('confidence', 0.6),
                valence=llm_result.get('valence', 0.0),
                arousal=llm_result.get('arousal', 0.0),
                language="ko",
                processing_method="deep_llm_analysis",
                metadata={'llm_reasoning': llm_result.get('reasoning', '')}
            )
        
        # ëª¨ë“  ë¶„ì„ì´ ì‹¤íŒ¨í•œ ê²½ìš° - fallback ì œê±°ë¡œ ì‹œìŠ¤í…œ ì •ì§€
        logger.error("ëª¨ë“  ê°ì • ë¶„ì„ ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. fallback ë©”ì»¤ë‹ˆì¦˜ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        raise RuntimeError("ê°ì • ë¶„ì„ ì™„ì „ ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€")
    
    def _basic_emotion_analysis(self, text: str, language: str = "ko") -> EmotionData:
        """ê¸°ë³¸ ê°ì • ë¶„ì„ (fallbackì´ ì•„ë‹Œ ê¸°ë³¸ ë¶„ì„)"""
        try:
            # ë‹¨ìˆœ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„
            emotion_scores = {
                EmotionState.JOY: 0,
                EmotionState.SADNESS: 0,
                EmotionState.ANGER: 0,
                EmotionState.FEAR: 0,
                EmotionState.SURPRISE: 0,
                EmotionState.DISGUST: 0,
                EmotionState.TRUST: 0,
                EmotionState.ANTICIPATION: 0
            }
            
            # ê°„ë‹¨í•œ ê°ì • í‚¤ì›Œë“œ ë§¤ì¹­
            text_lower = text.lower()
            
            # ê¸°ì¨ í‚¤ì›Œë“œ
            joy_keywords = ['ê¸°ì˜', 'í–‰ë³µ', 'ì¦ê±°', 'ì¢‹', 'ë§Œì¡±', 'ì›ƒ', 'ê¸°ë»', 'ì‚¬ë‘']
            for keyword in joy_keywords:
                if keyword in text_lower:
                    emotion_scores[EmotionState.JOY] += 1
            
            # ìŠ¬í”” í‚¤ì›Œë“œ
            sadness_keywords = ['ìŠ¬í”„', 'ìš°ìš¸', 'ëˆˆë¬¼', 'ìŠ¬í”ˆ', 'ì•„í”„', 'ìƒì²˜', 'ê´´ë¡œ']
            for keyword in sadness_keywords:
                if keyword in text_lower:
                    emotion_scores[EmotionState.SADNESS] += 1
            
            # ë¶„ë…¸ í‚¤ì›Œë“œ
            anger_keywords = ['í™”ë‚˜', 'ì§œì¦', 'ë¶„ë…¸', 'ì—´ë°›', 'ë¹¡', 'ë¯¸ì¹˜', 'ì‹«']
            for keyword in anger_keywords:
                if keyword in text_lower:
                    emotion_scores[EmotionState.ANGER] += 1
            
            # ë‘ë ¤ì›€ í‚¤ì›Œë“œ
            fear_keywords = ['ë¬´ì„œ', 'ë‘ë ¤', 'ê±±ì •', 'ë¶ˆì•ˆ', 'ìœ„í—˜', 'ê²']
            for keyword in fear_keywords:
                if keyword in text_lower:
                    emotion_scores[EmotionState.FEAR] += 1
            
            # ì£¼ìš” ê°ì • ê²°ì •
            max_emotion = max(emotion_scores, key=emotion_scores.get)
            max_score = emotion_scores[max_emotion]
            
            if max_score == 0:
                # ê°ì •ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ì¤‘ë¦½
                primary_emotion = EmotionState.NEUTRAL
                intensity = EmotionIntensity.MODERATE
                confidence = 0.3
            else:
                primary_emotion = max_emotion
                # ì ìˆ˜ì— ë”°ë¥¸ ê°•ë„ ê²°ì •
                if max_score >= 3:
                    intensity = EmotionIntensity.VERY_HIGH
                elif max_score >= 2:
                    intensity = EmotionIntensity.HIGH
                else:
                    intensity = EmotionIntensity.MODERATE
                confidence = min(0.8, 0.3 + max_score * 0.1)
            
            return EmotionData(
                primary_emotion=primary_emotion,
                intensity=intensity,
                confidence=confidence,
                valence=0.5 if primary_emotion == EmotionState.JOY else -0.3,
                arousal=0.4,
                language=language,
                processing_method="basic_keyword_analysis",
                metadata={'keyword_scores': {e.value: s for e, s in emotion_scores.items()}}
            )
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ ê°ì • ë¶„ì„ë„ ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ê¸°ë³¸ê°’
            return EmotionData(
                primary_emotion=EmotionState.NEUTRAL,
                intensity=EmotionIntensity.MODERATE,
                confidence=0.2,
                valence=0.0,
                arousal=0.0,
                language=language,
                processing_method="emergency_fallback",
                metadata={'error': str(e)}
            )
    
    def _analyze_multilingual_text(self, text: str) -> EmotionData:
        """ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        
        # Zero-shot classification ì‚¬ìš©
        emotion_labels = [e.value for e in EmotionState if e != EmotionState.NEUTRAL]
        
        try:
            result = self.models['multilingual'](text, emotion_labels)
            
            if result:
                best_label = result['labels'][0]
                best_score = result['scores'][0]
                
                # ëª¨ë“  ê°ì • ì ìˆ˜
                emotion_scores = dict(zip(result['labels'], result['scores']))
                
                primary_emotion = EmotionState(best_label)
                
                return EmotionData(
                    primary_emotion=primary_emotion,
                    confidence=best_score,
                    secondary_emotions={EmotionState(k): v for k, v in emotion_scores.items() 
                                      if k != best_label and v > 0.1},
                    processing_method="multilingual_transformer"
                )
                
        except Exception as e:
            logger.error(f"ë‹¤êµ­ì–´ ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ë‹¤êµ­ì–´ ê°ì • ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•œ ê²½ìš°
        raise RuntimeError("ë‹¤êµ­ì–´ ê°ì • ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def _analyze_biosignal_emotion(self, biosignal: Biosignal) -> Optional[EmotionData]:
        """ìƒì²´ì‹ í˜¸ ê¸°ë°˜ ê°ì • ë¶„ì„ (ì£¼ì„ ì²˜ë¦¬ - í–¥í›„ ì—°ê²° ê°€ëŠ¥)
        
        ì„¼ì„œ ì—°ê²° ì‹œ í™œì„±í™” ë°©ë²•:
        1. self.biosignal_enabled = Trueë¡œ ë³€ê²½
        2. ìƒì²´ì‹ í˜¸ ì„¼ì„œ í•˜ë“œì›¨ì–´ ì—°ê²° (EEG, ECG, GSR ë“±)
        3. ìƒì²´ì‹ í˜¸ ML ëª¨ë¸ í›ˆë ¨ ë° ë¡œë“œ
        4. ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
        """
        if not self.biosignal_enabled:
            raise RuntimeError("ìƒì²´ì‹ í˜¸ ë¶„ì„ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¼ì„œ ì—°ê²° ì‹œ í™œì„±í™” ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        try:
            # íŠ¹ì„± ë²¡í„° ìƒì„±
            features = np.array([[
                biosignal.heart_rate,
                biosignal.gsr,
                biosignal.eeg_alpha,
                biosignal.eeg_beta,
                biosignal.eeg_theta,
                biosignal.eeg_delta,
                biosignal.respiratory_rate,
                biosignal.skin_temperature
            ]])
            
            # ìŠ¤ì¼€ì¼ë§
            features_scaled = self.biosignal_scaler.transform(features)
            
            # ì˜ˆì¸¡
            prediction = self.biosignal_model.predict(features_scaled)[0]
            probabilities = self.biosignal_model.predict_proba(features_scaled)[0]
            
            # ìµœê³  í™•ë¥  ì°¾ê¸°
            max_prob_idx = np.argmax(probabilities)
            confidence = probabilities[max_prob_idx]
            
            # ê°ì • ìƒíƒœ ë³€í™˜
            emotion_classes = self.biosignal_model.classes_
            predicted_emotion = EmotionState(emotion_classes[max_prob_idx])
            
            # ê°ì„±ë„ ê³„ì‚° (ì‹¬ë°•ìˆ˜ì™€ GSR ê¸°ë°˜)
            arousal = self._calculate_arousal_from_biosignal(biosignal)
            
            # ê°ì •ê°€ ê³„ì‚° (ê°ì • ìœ í˜• ê¸°ë°˜)
            valence = self._calculate_valence_from_emotion(predicted_emotion)
            
            return EmotionData(
                primary_emotion=predicted_emotion,
                confidence=confidence,
                arousal=arousal,
                valence=valence,
                biosignal_data=biosignal,
                processing_method="biosignal_ml"
            )
            
        except Exception as e:
            logger.error(f"ìƒì²´ì‹ í˜¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ìƒì²´ì‹ í˜¸ ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def _integrate_emotion_results(self, text_emotion: EmotionData, 
                                 biosignal_emotion: Optional[EmotionData],
                                 text: str, language: str) -> EmotionData:
        """ê°ì • ë¶„ì„ ê²°ê³¼ í†µí•©"""
        
        if biosignal_emotion is None:
            return text_emotion
        
        # ê°€ì¤‘ì¹˜ ì„¤ì • (í…ìŠ¤íŠ¸ vs ìƒì²´ì‹ í˜¸)
        text_weight = 0.7
        biosignal_weight = 0.3
        
        # ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê· 
        combined_confidence = (text_emotion.confidence * text_weight + 
                             biosignal_emotion.confidence * biosignal_weight)
        
        # ì£¼ ê°ì • ê²°ì • (ë” ë†’ì€ ì‹ ë¢°ë„ ê¸°ì¤€)
        if text_emotion.confidence >= biosignal_emotion.confidence:
            primary_emotion = text_emotion.primary_emotion
        else:
            primary_emotion = biosignal_emotion.primary_emotion
        
        # ê°ì„±ë„ì™€ ê°ì •ê°€ í†µí•©
        combined_arousal = (text_emotion.arousal * text_weight + 
                          biosignal_emotion.arousal * biosignal_weight)
        combined_valence = (text_emotion.valence * text_weight + 
                          biosignal_emotion.valence * biosignal_weight)
        
        # ê°•ë„ ê³„ì‚°
        intensity = self._calculate_intensity_from_confidence(combined_confidence)
        
        return EmotionData(
            primary_emotion=primary_emotion,
            intensity=intensity,
            confidence=combined_confidence,
            arousal=combined_arousal,
            valence=combined_valence,
            biosignal_data=biosignal_emotion.biosignal_data,
            language=language,
            processing_method="integrated_advanced"
        )
    
    def _generate_emotion_embedding(self, text: str, language: str) -> np.ndarray:
        """ê°ì • ì„ë² ë”© ìƒì„±"""
        try:
            # ì–¸ì–´ë³„ ì„ë² ë”© ëª¨ë¸ ì„ íƒ
            if language == "ko" and 'korean' in self.embedders:
                embedder = self.embedders['korean']
            else:
                embedder = self.embedders['multilingual']
            
            # ì„ë² ë”© ìƒì„±
            embedding = embedder.encode(text, convert_to_numpy=True)
            
            return embedding
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ê°ì • ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _calculate_intensity_from_score(self, score: float) -> EmotionIntensity:
        """ì ìˆ˜ì—ì„œ ê°ì • ê°•ë„ ê³„ì‚°"""
        if score >= 4.0:
            return EmotionIntensity.EXTREME
        elif score >= 3.0:
            return EmotionIntensity.VERY_STRONG
        elif score >= 2.0:
            return EmotionIntensity.STRONG
        elif score >= 1.0:
            return EmotionIntensity.MODERATE
        elif score >= 0.5:
            return EmotionIntensity.WEAK
        else:
            return EmotionIntensity.VERY_WEAK
    
    def _calculate_intensity_from_confidence(self, confidence: float) -> EmotionIntensity:
        """ì‹ ë¢°ë„ì—ì„œ ê°ì • ê°•ë„ ê³„ì‚°"""
        if confidence >= 0.9:
            return EmotionIntensity.EXTREME
        elif confidence >= 0.8:
            return EmotionIntensity.VERY_STRONG
        elif confidence >= 0.7:
            return EmotionIntensity.STRONG
        elif confidence >= 0.6:
            return EmotionIntensity.MODERATE
        elif confidence >= 0.5:
            return EmotionIntensity.WEAK
        else:
            return EmotionIntensity.VERY_WEAK
    
    def _calculate_valence_arousal(self, emotion: str, score: float) -> Tuple[float, float]:
        """ê°ì •ì—ì„œ ê°ì •ê°€ì™€ ê°ì„±ë„ ê³„ì‚°"""
        # ê°ì •ë³„ ê¸°ë³¸ ê°ì •ê°€/ê°ì„±ë„ (ì—°êµ¬ ê¸°ë°˜)
        emotion_va = {
            'joy': (0.8, 0.7),
            'sadness': (-0.6, -0.4),
            'anger': (-0.7, 0.8),
            'fear': (-0.8, 0.9),
            'surprise': (0.2, 0.8),
            'disgust': (-0.7, 0.3),
            'trust': (0.6, 0.3),
            'anticipation': (0.5, 0.6),
            'neutral': (0.0, 0.0)
        }
        
        base_valence, base_arousal = emotion_va.get(emotion, (0.0, 0.0))
        
        # ì ìˆ˜ì— ë”°ë¥¸ ì¡°ì •
        intensity_factor = min(1.0, score / 3.0)
        
        valence = base_valence * intensity_factor
        arousal = base_arousal * intensity_factor
        
        return valence, arousal
    
    def _calculate_arousal_from_biosignal(self, biosignal: Biosignal) -> float:
        """ìƒì²´ì‹ í˜¸ì—ì„œ ê°ì„±ë„ ê³„ì‚°"""
        # ì •ê·œí™”ëœ ê°’ë“¤
        hr_norm = (biosignal.heart_rate - 60) / 40  # 60-100 bpm ë²”ìœ„
        gsr_norm = biosignal.gsr
        resp_norm = (biosignal.respiratory_rate - 12) / 8  # 12-20 ë²”ìœ„
        
        arousal = (hr_norm * 0.4 + gsr_norm * 0.4 + resp_norm * 0.2)
        
        return max(-1.0, min(1.0, arousal))
    
    def _calculate_valence_from_emotion(self, emotion: EmotionState) -> float:
        """ê°ì • ìƒíƒœì—ì„œ ê°ì •ê°€ ê³„ì‚°"""
        valence_map = {
            EmotionState.JOY: 0.8,
            EmotionState.TRUST: 0.6,
            EmotionState.ANTICIPATION: 0.5,
            EmotionState.SURPRISE: 0.2,
            EmotionState.NEUTRAL: 0.0,
            EmotionState.DISGUST: -0.5,
            EmotionState.SADNESS: -0.6,
            EmotionState.ANGER: -0.7,
            EmotionState.FEAR: -0.8
        }
        
        return valence_map.get(emotion, 0.0)
    
    def batch_analyze_emotions(self, texts: List[str], 
                             language: str = "ko") -> List[EmotionData]:
        """ë°°ì¹˜ ê°ì • ë¶„ì„"""
        results = []
        
        # ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™” ì‹œ
        if self.config.get('batch_processing', True) and len(texts) > 1:
            # ì„ë² ë”© ë°°ì¹˜ ìƒì„±
            if language == "ko" and 'korean' in self.embedders:
                embedder = self.embedders['korean']
            else:
                embedder = self.embedders['multilingual']
            
            embeddings = embedder.encode(texts, batch_size=self.config.get('batch_size', 16))
            
            # ê° í…ìŠ¤íŠ¸ë³„ ë¶„ì„
            for i, text in enumerate(texts):
                emotion_data = self.analyze_emotion(text, language, use_cache=False)
                emotion_data.embedding = embeddings[i]
                results.append(emotion_data)
        else:
            # ê°œë³„ ì²˜ë¦¬
            for text in texts:
                results.append(self.analyze_emotion(text, language))
        
        return results
    
    def analyze_text_advanced(self, text: str, language: str = "ko", context: str = None) -> EmotionData:
        """ê³ ê¸‰ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ - main.py í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ ë©”ì„œë“œ"""
        # contextëŠ” í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„± ìœ ì§€
        return self.analyze_emotion(text=text, language=language)
    
    def get_emotion_similarity(self, emotion1: EmotionData, 
                             emotion2: EmotionData) -> float:
        """ë‘ ê°ì • ê°„ ìœ ì‚¬ë„ ê³„ì‚°"""
        if emotion1.embedding is not None and emotion2.embedding is not None:
            # ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„
            from sklearn.metrics.pairwise import cosine_similarity
            similarity = cosine_similarity(
                emotion1.embedding.reshape(1, -1),
                emotion2.embedding.reshape(1, -1)
            )[0][0]
            return float(similarity)
        else:
            # ê°ì • ìƒíƒœ ê¸°ë°˜ ìœ ì‚¬ë„
            if emotion1.primary_emotion == emotion2.primary_emotion:
                return 0.9
            elif self._are_emotions_similar(emotion1.primary_emotion, emotion2.primary_emotion):
                return 0.6
            else:
                return 0.2
    
    def _are_emotions_similar(self, emotion1: EmotionState, emotion2: EmotionState) -> bool:
        """ê°ì • ê°„ ìœ ì‚¬ì„± íŒë‹¨"""
        similar_groups = [
            {EmotionState.JOY, EmotionState.TRUST, EmotionState.ANTICIPATION},
            {EmotionState.SADNESS, EmotionState.FEAR, EmotionState.DISGUST},
            {EmotionState.ANGER, EmotionState.DISGUST},
            {EmotionState.SURPRISE, EmotionState.ANTICIPATION}
        ]
        
        for group in similar_groups:
            if emotion1 in group and emotion2 in group:
                return True
        
        return False
    
    def save_model_cache(self, file_path: str):
        """ëª¨ë¸ ìºì‹œ ì €ì¥"""
        try:
            cache_data = {
                'prediction_cache': self.prediction_cache,
                'embedding_cache': self.embedding_cache
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
                
            logger.info(f"ëª¨ë¸ ìºì‹œ ì €ì¥ ì™„ë£Œ: {file_path}")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_model_cache(self, file_path: str):
        """ëª¨ë¸ ìºì‹œ ë¡œë“œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            self.prediction_cache.update(cache_data.get('prediction_cache', {}))
            self.embedding_cache.update(cache_data.get('embedding_cache', {}))
            
            logger.info(f"ëª¨ë¸ ìºì‹œ ë¡œë“œ ì™„ë£Œ: {file_path}")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def analyze_hierarchical_emotions(self, text: str, 
                                    other_emotion: Optional[torch.Tensor] = None,
                                    regret_vector: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """ê³„ì¸µì  ê°ì • ë¶„ì„ (Phase 0-2)"""
        if not NEW_EMOTION_MODELS_AVAILABLE or not hasattr(self, 'hierarchical_model'):
            raise RuntimeError("ê³„ì¸µì  ê°ì • ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê³„ì¸µì  ê°ì • ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        try:
            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            text_embedding = self._generate_text_embedding(text)
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            if other_emotion is None:
                other_emotion = torch.zeros(6)  # 6ì°¨ì› ê°ì • ë²¡í„°
            if regret_vector is None:
                regret_vector = torch.zeros(6)
            
            # ê³„ì¸µì  ëª¨ë¸ë¡œ ë¶„ì„
            with torch.no_grad():
                results = self.hierarchical_model(text_embedding, other_emotion, regret_vector)
            
            # ê²°ê³¼ í•´ì„
            final_emotion_dict = emotion_vector_to_dict(results['final_emotion'])
            
            return {
                'final_emotion': final_emotion_dict,
                'phase0_emotion': emotion_vector_to_dict(results['phase0_emotion']),
                'phase1_empathy': emotion_vector_to_dict(results['phase1_empathy']),
                'phase2_integrated': emotion_vector_to_dict(results['phase2_integrated']),
                'regret_intensity': results['regret_intensity'].item(),
                'emotion_evolution': self._analyze_emotion_evolution(results),
                'confidence': self._calculate_hierarchical_confidence(results)
            }
            
        except Exception as e:
            logger.error(f"ê³„ì¸µì  ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ê³„ì¸µì  ê°ì • ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def _generate_text_embedding(self, text: str) -> torch.Tensor:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        # ìºì‹œ í™•ì¸
        cache_key = hash(text)
        if cache_key in self.embedding_cache:
            return self.embedding_cache[cache_key]
        
        try:
            # Sentence Transformer ì‚¬ìš© (ìˆëŠ” ê²½ìš°)
            if hasattr(self, 'sentence_embedder'):
                embedding = self.sentence_embedder.encode(text)
                embedding_tensor = torch.tensor(embedding, dtype=torch.float32)
            else:
                # ê°„ë‹¨í•œ í†µê³„ì  ì„ë² ë”© ìƒì„±
                words = text.split()
                features = [
                    len(text), len(words), 
                    len([w for w in words if w in self.korean_emotion_keywords]),
                    text.count('!'), text.count('?')
                ]
                # 768ì°¨ì›ìœ¼ë¡œ íŒ¨ë”©
                embedding = np.zeros(768)
                embedding[:len(features)] = features
                embedding_tensor = torch.tensor(embedding, dtype=torch.float32)
            
            # ìºì‹œ ì €ì¥
            self.embedding_cache[cache_key] = embedding_tensor
            return embedding_tensor
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _analyze_emotion_evolution(self, results: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """ê°ì • ì§„í™” ê³¼ì • ë¶„ì„"""
        evolution = {}
        
        try:
            # Phaseë³„ ê°ì • ê°•ë„ ë³€í™”
            phase0_intensity = torch.norm(results['phase0_emotion']).item()
            phase1_intensity = torch.norm(results['phase1_empathy']).item()
            phase2_intensity = torch.norm(results['phase2_integrated']).item()
            
            evolution['intensity_progression'] = [phase0_intensity, phase1_intensity, phase2_intensity]
            evolution['intensity_trend'] = 'increasing' if phase2_intensity > phase0_intensity else 'decreasing'
            
            # ì£¼ìš” ê°ì • ì°¨ì› ë³€í™”
            phase0_dict = emotion_vector_to_dict(results['phase0_emotion'])
            phase2_dict = emotion_vector_to_dict(results['phase2_integrated'])
            
            dimension_changes = {}
            for dim in EMOTION_DIMENSIONS.keys():
                change = phase2_dict[dim] - phase0_dict[dim]
                dimension_changes[dim] = change
            
            evolution['dimension_changes'] = dimension_changes
            evolution['most_changed_dimension'] = max(dimension_changes.items(), key=lambda x: abs(x[1]))
            
        except Exception as e:
            logger.error(f"ê°ì • ì§„í™” ë¶„ì„ ì‹¤íŒ¨: {e}")
            evolution = {'error': str(e)}
        
        return evolution
    
    def _calculate_hierarchical_confidence(self, results: Dict[str, torch.Tensor]) -> float:
        """ê³„ì¸µì  ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # ì—¬ëŸ¬ ìš”ì†Œ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
            base_confidence = 0.5
            
            # ê°ì • ë²¡í„°ì˜ ì¼ê´€ì„±
            final_norm = torch.norm(results['final_emotion']).item()
            if final_norm > 0.1:
                base_confidence += 0.2
            
            # í›„íšŒ ê°•ë„ (ì ì ˆí•œ ë²”ìœ„ ë‚´)
            regret_intensity = results['regret_intensity'].item()
            if 0.1 < regret_intensity < 0.9:
                base_confidence += 0.2
            
            # Phase ê°„ ì¼ê´€ì„±
            phase_consistency = self._calculate_phase_consistency(results)
            base_confidence += phase_consistency * 0.1
            
            return min(1.0, max(0.0, base_confidence))
            
        except Exception as e:
            logger.error(f"ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    def _calculate_phase_consistency(self, results: Dict[str, torch.Tensor]) -> float:
        """Phase ê°„ ì¼ê´€ì„± ê³„ì‚°"""
        try:
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì¼ê´€ì„±
            phase0 = results['phase0_emotion']
            phase1 = results['phase1_empathy']
            phase2 = results['phase2_integrated']
            
            cos01 = F.cosine_similarity(phase0.unsqueeze(0), phase1.unsqueeze(0)).item()
            cos12 = F.cosine_similarity(phase1.unsqueeze(0), phase2.unsqueeze(0)).item()
            cos02 = F.cosine_similarity(phase0.unsqueeze(0), phase2.unsqueeze(0)).item()
            
            return (cos01 + cos12 + cos02) / 3
            
        except Exception as e:
            logger.error(f"ì¼ê´€ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    
    async def analyze_with_llm_interpretation(self, text: str, 
                                            include_hierarchical: bool = True) -> Dict[str, Any]:
        """LLM í•´ì„ì„ í¬í•¨í•œ ê°ì • ë¶„ì„"""
        if not LLM_INTEGRATION_AVAILABLE:
            return {'error': 'LLM í†µí•©ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        try:
            # ê¸°ë³¸ ê°ì • ë¶„ì„
            basic_result = self.analyze_emotion(text)
            
            # ê³„ì¸µì  ë¶„ì„ (ì„ íƒì )
            hierarchical_result = None
            if include_hierarchical and NEW_EMOTION_MODELS_AVAILABLE:
                hierarchical_result = self.analyze_hierarchical_emotions(text)
            
            # LLM í•´ì„ ìš”ì²­
            emotion_data = self._format_emotion_for_llm(basic_result, hierarchical_result)
            llm_interpretation = await interpret_emotions(emotion_data)
            
            result = {
                'basic_analysis': {
                    'primary_emotion': basic_result.primary_emotion.value,
                    'confidence': basic_result.confidence,
                    'intensity': basic_result.intensity.value
                },
                'text': text
            }
            
            if hierarchical_result:
                result['hierarchical_analysis'] = hierarchical_result
            
            if llm_interpretation.success:
                result['llm_interpretation'] = {
                    'explanation': llm_interpretation.generated_text,
                    'confidence': llm_interpretation.confidence,
                    'insights': self._extract_emotion_insights(llm_interpretation.generated_text)
                }
            
            return result
            
        except Exception as e:
            logger.error(f"LLM ê°ì • í•´ì„ ì‹¤íŒ¨: {e}")
    
    def _generate_emotion_embedding(self, text: str, language: str, 
                                   emotion_data: EmotionData) -> Optional[np.ndarray]:
        """ê°ì • íŠ¹í™” ì„ë² ë”© ìƒì„±"""
        try:
            # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì„ë² ë”©
            text_embedding = self._generate_text_embedding(text)
            
            # ê°ì • ìƒíƒœ ë²¡í„°
            emotion_vector = self._create_emotion_state_vector(emotion_data)
            
            # ê°ì •ê³¼ í…ìŠ¤íŠ¸ ì„ë² ë”© ê²°í•©
            if text_embedding is not None and emotion_vector is not None:
                # ì ì ˆí•œ í¬ê¸°ë¡œ ë§ì¶¤
                min_len = min(len(text_embedding), len(emotion_vector))
                combined_embedding = np.concatenate([
                    text_embedding[:min_len] * 0.8,
                    emotion_vector[:min_len] * 0.2
                ])
                return combined_embedding
            
            return text_embedding
            
        except Exception as e:
            self.logger.error(f"ê°ì • ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_text_embedding(self, text: str) -> Optional[np.ndarray]:
        """í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì„ë² ë”© ìƒì„±"""
        try:
            # ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
            if hasattr(self, 'embedders') and 'multilingual' in self.embedders:
                embedding = self.embedders['multilingual'].encode(
                    text, 
                    convert_to_numpy=True,
                    normalize_embeddings=True
                )
                return embedding
            else:
                raise RuntimeError("í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
                
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _create_emotion_state_vector(self, emotion_data: EmotionData) -> Optional[np.ndarray]:
        """ê°ì • ìƒíƒœ íŠ¹ì§• ë²¡í„° ìƒì„±"""
        try:
            # ê¸°ë³¸ ê°ì • íŠ¹ì§• (16ì°¨ì›)
            emotion_features = [
                emotion_data.primary_emotion.value / 16.0,  # ì •ê·œí™”ëœ ê°ì • ID
                emotion_data.intensity.value / 6.0,         # ì •ê·œí™”ëœ ê°•ë„
                emotion_data.confidence,                    # ì‹ ë¢°ë„
                getattr(emotion_data, 'valence', 0.5),      # ê°ì •ê°€
                getattr(emotion_data, 'arousal', 0.5),      # ê°ì„±ë„
                getattr(emotion_data, 'dominance', 0.5),    # ì§€ë°°ì„±
                0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  # ì˜ˆì•½ëœ íŠ¹ì§•ë“¤
            ]
            
            return np.array(emotion_features, dtype=np.float32)
            
        except Exception as e:
            self.logger.error(f"ê°ì • ë²¡í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _format_emotion_for_llm(self, basic_result: EmotionData, 
                              hierarchical_result: Optional[Dict[str, Any]] = None) -> str:
        """ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ LLM ì…ë ¥ìš©ìœ¼ë¡œ í¬ë§·"""
        parts = [f"ê°ì • ë¶„ì„ ê²°ê³¼:"]
        
        # ê¸°ë³¸ ë¶„ì„
        parts.append(f"- ì£¼ìš” ê°ì •: {basic_result.primary_emotion.value}")
        parts.append(f"- ì‹ ë¢°ë„: {basic_result.confidence:.3f}")
        parts.append(f"- ê°•ë„: {basic_result.intensity.value}")
        
        # ê³„ì¸µì  ë¶„ì„
        if hierarchical_result:
            parts.append("\nê³„ì¸µì  ê°ì • ë¶„ì„:")
            for phase, emotion_dict in [
                ("Phase 0 (ìì•„íˆ¬ì˜)", hierarchical_result['phase0_emotion']),
                ("Phase 1 (ê³µê°)", hierarchical_result['phase1_empathy']),
                ("Phase 2 (í†µí•©)", hierarchical_result['phase2_integrated'])
            ]:
                parts.append(f"- {phase}:")
                for dim, value in emotion_dict.items():
                    if abs(value) > 0.1:  # ìœ ì˜ë¯¸í•œ ê°’ë§Œ
                        parts.append(f"  * {dim}: {value:.3f}")
            
            parts.append(f"- í›„íšŒ ê°•ë„: {hierarchical_result['regret_intensity']:.3f}")
        
        return "\n".join(parts)
    
    def _extract_emotion_insights(self, llm_text: str) -> List[str]:
        """LLM ì‘ë‹µì—ì„œ ê°ì • ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        lines = llm_text.split('\n')
        for line in lines:
            line = line.strip()
            if any(keyword in line.lower() for keyword in 
                  ['ê°ì •', 'ëŠë‚Œ', 'ì‹¬ë¦¬', 'ìƒíƒœ', 'ì›ì¸', 'ì˜í–¥']):
                if len(line) > 15:
                    insights.append(line)
        
        return insights[:3]
    
    def _emollms_preprocess_response(self, llm_response: Optional[Any], text: str) -> Optional[Dict[str, Any]]:
        """EmoLLMs ë…¼ë¬¸ ë°©ì‹: None ì‘ë‹µ ì „ì²˜ë¦¬ (í’ˆì§ˆ ë³´ì¥ + ì‹¤íŒ¨ ìœ í˜•ë³„ ì°¨ë³„í™”)"""
        
        # Step 1: Null record ì²˜ë¦¬ (ì¹˜ëª…ì  ì‹¤íŒ¨)
        if llm_response is None:
            logger.error(f"âŒ ì¹˜ëª…ì  ì‹¤íŒ¨: LLM ì‘ë‹µì´ None - ì‹œìŠ¤í…œ ì •ì§€: {text[:50]}...")
            return None
        
        # Step 2: ì‘ë‹µ ì„±ê³µ ì—¬ë¶€ í™•ì¸ (ì¹˜ëª…ì  ì‹¤íŒ¨)
        if hasattr(llm_response, 'success') and not llm_response.success:
            logger.error("âŒ ì¹˜ëª…ì  ì‹¤íŒ¨: LLM ì‘ë‹µ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì •ì§€")
            return None
        
        # Step 3: ìƒì„±ëœ í…ìŠ¤íŠ¸ ê¸°ë³¸ ê²€ì¦
        if not hasattr(llm_response, 'generated_text'):
            logger.error("âŒ ì¹˜ëª…ì  ì‹¤íŒ¨: generated_text ì†ì„± ì—†ìŒ")
            return None
            
        generated_text = llm_response.generated_text
        if not generated_text:
            logger.error("âŒ ì¹˜ëª…ì  ì‹¤íŒ¨: ìƒì„±ëœ í…ìŠ¤íŠ¸ê°€ ì™„ì „íˆ ë¹„ì–´ìˆìŒ")
            return None
        
        # Step 4: ì‹¤íŒ¨ ìœ í˜•ë³„ ì°¨ë³„í™” ì²˜ë¦¬
        if len(generated_text.strip()) < 10:
            logger.warning("âš ï¸ ë³µêµ¬ ê°€ëŠ¥í•œ ì‹¤íŒ¨: ìƒì„±ëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ (10ì ë¯¸ë§Œ)")
            # ì§§ì€ í…ìŠ¤íŠ¸ë„ íŒŒì‹± ì‹œë„ (ë¶€ë¶„ ì‘ë‹µ ì²˜ë¦¬)
        
        # Step 5: finish_reason í™•ì¸ (ë³µêµ¬ ê°€ëŠ¥í•œ ì‹¤íŒ¨)
        if hasattr(llm_response, 'finish_reason'):
            if llm_response.finish_reason == 'length':
                logger.warning("âš ï¸ ë³µêµ¬ ê°€ëŠ¥í•œ ì‹¤íŒ¨: finish_reasonì´ 'length' - ë¶€ë¶„ ì‘ë‹µ ì²˜ë¦¬")
                # ë¶€ë¶„ ì‘ë‹µì´ì§€ë§Œ íŒŒì‹± ì‹œë„
            elif llm_response.finish_reason == 'stop':
                logger.info("âœ… ì •ìƒ ì™„ë£Œ: finish_reasonì´ 'stop'")
            else:
                logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” finish_reason: {llm_response.finish_reason}")
        
        # Step 6: ì‘ë‹µ íŒŒì‹± ì‹œë„ (ê°•í™”ëœ íŒŒì‹± ë¡œì§ ì‚¬ìš©)
        try:
            parsed_result = self._parse_deep_llm_response(generated_text)
            if parsed_result is not None:
                logger.info("âœ… ì „ì²˜ë¦¬ ì„±ê³µ: íŒŒì‹± ì™„ë£Œ")
                return parsed_result
            else:
                logger.error("âŒ íŒŒì‹± ì‹¤íŒ¨: íŒŒì‹± ê²°ê³¼ê°€ None")
                return None
                
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return None
    
    
    def get_enhanced_emotion_metrics(self) -> Dict[str, Any]:
        """í–¥ìƒëœ ê°ì • ë¶„ì„ ë©”íŠ¸ë¦­"""
        base_stats = {
            'cache_size': len(self.prediction_cache),
            'embedding_cache_size': len(self.embedding_cache),
            'models_loaded': len(self.models)
        }
        
        enhanced_stats = {
            'base_statistics': base_stats,
            'model_capabilities': {
                'hierarchical_available': NEW_EMOTION_MODELS_AVAILABLE,
                'llm_integration_available': LLM_INTEGRATION_AVAILABLE,
                'device': self.device
            },
            'korean_keywords_count': len(self.korean_emotion_keywords)
        }
        
        # ê³„ì¸µì  ëª¨ë¸ í†µê³„
        if NEW_EMOTION_MODELS_AVAILABLE and hasattr(self, 'emotion_model_manager'):
            try:
                enhanced_stats['hierarchical_model_stats'] = self.emotion_model_manager.get_training_stats()
            except Exception as stats_error:
                logger.debug(f"ê³„ì¸µì  ëª¨ë¸ í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¹„í•µì‹¬ ê¸°ëŠ¥): {stats_error}")
                enhanced_stats['hierarchical_model_stats'] = {}
        
        # LLM ì—”ì§„ í†µê³„
        if LLM_INTEGRATION_AVAILABLE and hasattr(self, 'llm_engine'):
            try:
                enhanced_stats['llm_performance'] = self.llm_engine.get_performance_stats()
            except Exception as llm_stats_error:
                logger.debug(f"LLM ì„±ëŠ¥ í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¹„í•µì‹¬ ê¸°ëŠ¥): {llm_stats_error}")
                enhanced_stats['llm_performance'] = {}
        
        return enhanced_stats

    def _enhance_with_llm_analysis(self, text: str, keyword_emotion: int, keyword_score: float) -> Optional[Dict[str, Any]]:
        """LLMìœ¼ë¡œ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ê°•í™” (ì¡°ê±´ë¶€ í˜¸ì¶œ)"""
        
        # ì¡°ê±´ë¶€ LLM í˜¸ì¶œ ê²°ì •
        should_use_llm = self._should_use_llm_for_emotion(text, keyword_score)
        if not should_use_llm:
            return None
            
        # LLM í†µí•©ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° - ì¡°ê±´ë¶€ ì²˜ë¦¬ 
        if not LLM_INTEGRATION_AVAILABLE:
            logger.debug("LLM í†µí•©ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return None
        
        try:
            import asyncio
            from llm_module.advanced_llm_engine import get_llm_engine, LLMRequest, TaskComplexity
            
            # í‚¤ì›Œë“œ ê°ì •ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            emotion_name = self._emotion_id_to_name(keyword_emotion)
            
            # ê°•í™”ëœ ChatML í…œí”Œë¦¿ - ë§¤í•‘ í…Œì´ë¸”ê³¼ ë™ê¸°í™”ëœ ì—„ê²©í•œ ì œì•½
            prompt = f"""<|im_start|>system
ë‹¹ì‹ ì€ HelpingAI, ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš” ì œì•½ì‚¬í•­:
- ë°˜ë“œì‹œ ì§€ì •ëœ ê°ì • ëª©ë¡ì—ì„œë§Œ ì„ íƒí•˜ì„¸ìš”
- ë‹¤ë¥¸ ê°ì • ì´ë¦„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”
- ì¶”ê°€ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ê¸ˆì§€ì…ë‹ˆë‹¤

í•„ìˆ˜ JSON í˜•ì‹:
{{
    "emotion": "ê°ì •ëª…",
    "intensity": ì •ìˆ˜1-6,
    "confidence": ì‹¤ìˆ˜0.0-1.0,
    "valence": ì‹¤ìˆ˜-1.0-1.0,
    "arousal": ì‹¤ìˆ˜0.0-1.0,
    "reasoning": "ê°„ë‹¨í•œ_ì„¤ëª…"
}}

í—ˆìš©ëœ ê°ì • (ì´ê²ƒ ì™¸ ì‚¬ìš© ê¸ˆì§€):
- joy: ê¸°ì¨, í–‰ë³µ
- trust: ì‹ ë¢°, ë¯¿ìŒ  
- fear: ë‘ë ¤ì›€, ë¶ˆì•ˆ
- surprise: ë†€ëŒ, ì¶©ê²©
- sadness: ìŠ¬í””, ìš°ìš¸
- disgust: í˜ì˜¤, ê±°ë¶€ê°
- anger: ë¶„ë…¸, í™”ë‚¨ (frustration í¬í•¨)
- anticipation: ê¸°ëŒ€, í¬ë§
- neutral: ì¤‘ë¦½, ë¬´ê°ì •

ì˜ˆì‹œ:
{{"emotion": "anger", "intensity": 3, "confidence": 0.8, "valence": -0.3, "arousal": 0.6, "reasoning": "ë¶„ë…¸ í‘œí˜„ì´ ê°ì§€ë¨"}}

ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°: ìœ„ 9ê°œ ê°ì • ì¤‘ì—ì„œë§Œ ì„ íƒí•˜ê³ , ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.<|im_end|>
<|im_start|>user
{text}<|im_end|>
<|im_start|>assistant
"""

            # ì¤‘ì²© í•¨ìˆ˜ì—ì„œ ì‚¬ìš©í•  í† í° ìˆ˜ ë¯¸ë¦¬ ê³„ì‚°
            dynamic_tokens = self._calculate_dynamic_token_limit_direct(text, base_tokens=400)
            
            # ì´ë²¤íŠ¸ ë£¨í”„ ì•ˆì „í•œ ì‹¤í–‰ì„ ìœ„í•œ ë˜í¼
            def run_llm_analysis():
                try:
                    import threading
                    import concurrent.futures
                    
                    # ìƒˆë¡œìš´ ìŠ¤ë ˆë“œì—ì„œ ë¹„ë™ê¸° ì‹¤í–‰
                    def async_llm_call():
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            engine = get_llm_engine()
                            request = LLMRequest(
                                prompt=prompt,
                                task_type="emotion_analysis",  # HelpingAI EQ 95.89 ìš°ì„ 
                                complexity=TaskComplexity.MODERATE,
                                max_tokens=dynamic_tokens,
                                temperature=0.3
                            )
                            
                            response = loop.run_until_complete(engine.generate_async(request))
                            return response
                        finally:
                            loop.close()
                    
                    # ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰
                    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                        future = executor.submit(async_llm_call)
                        response = future.result(timeout=30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                    
                    if response and response.success:
                        # ì•ˆì „í•œ ì†ì„± ì ‘ê·¼ - generated_text ì†ì„± í™•ì¸
                        if hasattr(response, 'generated_text') and response.generated_text:
                            logger.info(f"âœ… LLM ì‘ë‹µ ì„±ê³µ - ê¸¸ì´: {len(response.generated_text)}")
                            return self._parse_llm_emotion_response(response.generated_text, keyword_emotion)
                        else:
                            logger.error(f"âŒ ì¹˜ëª…ì  ì‹¤íŒ¨: generated_text ì†ì„± ì—†ìŒ - ì‘ë‹µ êµ¬ì¡°: {type(response).__name__}")
                            logger.error(f"ì‘ë‹µ ì†ì„±ë“¤: {dir(response)}")
                            return None
                    else:
                        logger.warning(f"LLM ê°ì • ë¶„ì„ ì‹¤íŒ¨: {response.error_message if response else 'No response'}")
                        return None
                        
                except Exception as e:
                    logger.error(f"LLM ë¶„ì„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                    return None
            
            return run_llm_analysis()
            
        except Exception as e:
            logger.error(f"LLM ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    def _should_use_llm_for_emotion(self, text: str, keyword_score: float) -> bool:
        """LLM ì‚¬ìš© ì¡°ê±´ ê²°ì • (ìµœì í™”ëœ ê³ í’ˆì§ˆ AI ë¶„ì„)"""
        
        # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
        if not text or len(text.strip()) == 0:
            return False
            
        # 1. í‚¤ì›Œë“œ ì ìˆ˜ê°€ ëª¨í˜¸í•œ ê²½ìš° (1.0~2.5 ì‚¬ì´) - ë²”ìœ„ í™•ëŒ€
        if 1.0 <= keyword_score <= 2.5:
            return True
            
        # 2. ë³µì¡í•œ í…ìŠ¤íŠ¸ (ê¸¸ì´ ê¸°ì¤€ ê°•í™”)
        if len(text) > 30:  # ê¸°ì¡´ 50ì—ì„œ 30ìœ¼ë¡œ ê°•í™”
            return True
            
        # 3. ë³µí•© ê°ì • í‘œí˜„ì´ ìˆëŠ” ê²½ìš° (ì„ê³„ê°’ ë‚®ì¶¤)
        emotion_keywords_count = sum(1 for emotion_dict in self.korean_emotion_keywords.values() 
                                   for keyword_list in emotion_dict.values()
                                   for keyword in keyword_list 
                                   if keyword in text.lower())
        if emotion_keywords_count >= 2:  # 3ê°œì—ì„œ 2ê°œë¡œ ê°•í™”
            return True
            
        # 4. ë¶€ì •ë¬¸ì´ë‚˜ ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡° (ì¡°ê±´ í™•ì¥)
        complex_patterns = ['ì•Š', 'ì—†', 'ëª»', 'ì•„ë‹ˆ', 'ê·¸ëŸ¬ë‚˜', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 
                           'ì˜¤íˆë ¤', 'ë°˜ë©´', 'ëŒ€ì‹ ', 'ë¬¼ë¡ ', 'í•˜ì§€ë§Œ', 'ê·¸ë ‡ì§€ë§Œ']
        if any(pattern in text for pattern in complex_patterns):
            return True
            
        # 5. ê°ì • ê°•ë„ í‘œí˜„ (ìƒˆë¡œìš´ ì¡°ê±´)
        intensity_words = ['ë§¤ìš°', 'ì •ë§', 'ë„ˆë¬´', 'ì•„ì£¼', 'ì™„ì „íˆ', 'ì—„ì²­', 'êµ‰ì¥íˆ', 
                          'ì‹¬í•˜ê²Œ', 'ê¹Šì´', 'ê·¹ë„ë¡œ', 'ìƒë‹¹íˆ', 'ê½¤', 'ì œë²•']
        if any(word in text for word in intensity_words):
            return True
            
        # 6. ë³µí•© ë¬¸ì¥ êµ¬ì¡° (ìƒˆë¡œìš´ ì¡°ê±´)
        if text.count(',') >= 2 or text.count('.') >= 2 or '?' in text or '!' in text:
            return True
            
        # 7. ë¯¸ë¬˜í•œ ê°ì • í‘œí˜„ (ìƒˆë¡œìš´ ì¡°ê±´)
        subtle_emotions = ['ë¯¸ë¬˜', 'ì• ë§¤', 'ë³µì¡', 'í˜¼ë€', 'ê°ˆë“±', 'ë”œë ˆë§ˆ', 'ê³ ë¯¼', 
                          'ìƒê°', 'ëŠë‚Œ', 'ê¸°ë¶„', 'ë¶„ìœ„ê¸°', 'ë‰˜ì•™ìŠ¤']
        if any(word in text for word in subtle_emotions):
            return True
            
        # ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ê°ì • í‘œí˜„ë§Œ í‚¤ì›Œë“œ ë¶„ì„ ì‚¬ìš©
        return False

    def _emotion_id_to_name(self, emotion_id: int) -> str:
        """ê°ì • IDë¥¼ í•œêµ­ì–´ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        emotion_mapping = {
            1: "ê¸°ì¨",    # JOY
            2: "ì‹ ë¢°",    # TRUST  
            3: "ë‘ë ¤ì›€",  # FEAR
            4: "ë†€ëŒ",    # SURPRISE
            5: "ìŠ¬í””",    # SADNESS
            6: "í˜ì˜¤",    # DISGUST
            7: "ë¶„ë…¸",    # ANGER
            8: "ê¸°ëŒ€",    # ANTICIPATION
            0: "ì¤‘ë¦½"     # NEUTRAL
        }
        return emotion_mapping.get(emotion_id, "ì•Œ ìˆ˜ ì—†ìŒ")

    def _parse_llm_emotion_response(self, response_text: str, original_emotion: int) -> Dict[str, Any]:
        """LLM ê°ì • ë¶„ì„ ì‘ë‹µ íŒŒì‹± (JSON ìš°ì„ , í…ìŠ¤íŠ¸ íŒŒì‹± fallback)"""
        try:
            # 1. JSON íŒŒì‹± ì‹œë„
            try:
                import json
                import re
                
                # ë‹¤ì–‘í•œ JSON íŒ¨í„´ ì‹œë„ (ê°œì„ ëœ íŒŒì‹±)
                json_patterns = [
                    r'\{[^{}]*\}',  # ë‹¨ìˆœ JSON ë¸”ë¡
                    r'\{[^{}]*?"[^"]*"[^{}]*\}',  # ë¬¸ìì—´ í¬í•¨ JSON
                    r'\{.*?\}',  # ëª¨ë“  ë¬¸ì í¬í•¨ JSON (ìµœëŒ€í•œ ìœ ì—°)
                ]
                
                parsed_json = None
                for pattern in json_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL)
                    for match in matches:
                        try:
                            # ê³µë°± ë¬¸ì ì •ë¦¬
                            cleaned_json = re.sub(r'\s+', ' ', match).strip()
                            
                            # ì¼ë°˜ì ì¸ JSON íŒŒì‹± ì˜¤ë¥˜ ìˆ˜ì •
                            cleaned_json = cleaned_json.replace('" emotion"', '"emotion"')
                            cleaned_json = cleaned_json.replace('" confidence"', '"confidence"')
                            cleaned_json = cleaned_json.replace('" intensity"', '"intensity"')
                            cleaned_json = cleaned_json.replace('" valence"', '"valence"')
                            cleaned_json = cleaned_json.replace('" arousal"', '"arousal"')
                            cleaned_json = cleaned_json.replace('" reasoning"', '"reasoning"')
                            
                            parsed_json = json.loads(cleaned_json)
                            logger.info(f"JSON íŒŒì‹± ì„±ê³µ: {cleaned_json}")
                            break
                        except json.JSONDecodeError:
                            continue
                    if parsed_json:
                        break
                
                if parsed_json:
                    # JSONì—ì„œ ê²°ê³¼ ì¶”ì¶œ
                    result = {
                        'emotion': original_emotion,  # ê¸°ë³¸ê°’
                        'confidence': 0.5,
                        'reasoning': response_text
                    }
                    
                    # ì˜ì–´ í•„ë“œëª… ì²˜ë¦¬ (HelpingAI ì‘ë‹µ í˜•ì‹)
                    if 'emotion' in parsed_json:
                        emotion_text = parsed_json['emotion']
                        mapped_emotion = self._name_to_emotion_id(emotion_text)
                        if mapped_emotion is None:
                            logger.error(f"âŒ ê°ì • ë§¤í•‘ ì‹¤íŒ¨ë¡œ ì¸í•œ íŒŒì‹± ì‹¤íŒ¨: '{emotion_text}'")
                            return None  # í•™ìŠµ ì˜¤ì—¼ ë°©ì§€ë¥¼ ìœ„í•œ ëª…í™•í•œ ì‹¤íŒ¨ ë°˜í™˜
                        result['emotion'] = mapped_emotion
                    
                    # ì‹ ë¢°ë„ ì²˜ë¦¬
                    if 'confidence' in parsed_json:
                        try:
                            result['confidence'] = float(parsed_json['confidence'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    # ê°ì •ê°•ë„ ì²˜ë¦¬
                    if 'intensity' in parsed_json:
                        try:
                            result['intensity'] = int(parsed_json['intensity'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    # valenceì™€ arousal ì²˜ë¦¬
                    if 'valence' in parsed_json:
                        try:
                            result['valence'] = float(parsed_json['valence'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    if 'arousal' in parsed_json:
                        try:
                            result['arousal'] = float(parsed_json['arousal'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    # ì¶”ê°€ ì •ë³´
                    if 'reasoning' in parsed_json:
                        result['reasoning'] = parsed_json['reasoning']
                    
                    # í•œêµ­ì–´ í•„ë“œëª… ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
                    if 'ì£¼ìš”ê°ì •' in parsed_json:
                        emotion_text = parsed_json['ì£¼ìš”ê°ì •']
                        mapped_emotion = self._name_to_emotion_id(emotion_text)
                        if mapped_emotion is None:
                            logger.error(f"âŒ í•œêµ­ì–´ ê°ì • ë§¤í•‘ ì‹¤íŒ¨ë¡œ ì¸í•œ íŒŒì‹± ì‹¤íŒ¨: '{emotion_text}'")
                            return None  # í•™ìŠµ ì˜¤ì—¼ ë°©ì§€ë¥¼ ìœ„í•œ ëª…í™•í•œ ì‹¤íŒ¨ ë°˜í™˜
                        result['emotion'] = mapped_emotion
                    
                    if 'ì‹ ë¢°ë„' in parsed_json:
                        try:
                            result['confidence'] = float(parsed_json['ì‹ ë¢°ë„'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    if 'ê°ì •ê°•ë„' in parsed_json:
                        try:
                            result['intensity'] = int(parsed_json['ê°ì •ê°•ë„'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    if 'ì›ì¸ë¶„ì„' in parsed_json:
                        result['cause_analysis'] = parsed_json['ì›ì¸ë¶„ì„']
                    
                    logger.info(f"JSON íŒŒì‹± ì„±ê³µ: ê°ì •={result['emotion']}, ì‹ ë¢°ë„={result['confidence']}")
                    return result
                    
            except (json.JSONDecodeError, AttributeError) as e:
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ì „í™˜: {e}")
            
            # 2. ê¸°ì¡´ í…ìŠ¤íŠ¸ íŒŒì‹± (fallback)
            lines = response_text.split('\n')
            result = {
                'emotion': original_emotion,  # ê¸°ë³¸ê°’
                'confidence': 0.5,
                'reasoning': response_text
            }
            
            for line in lines:
                line = line.strip()
                if 'ì£¼ìš” ê°ì •:' in line or 'ì£¼ìš”ê°ì •:' in line:
                    emotion_text = line.split(':')[1].strip()
                    mapped_emotion = self._name_to_emotion_id(emotion_text)
                    if mapped_emotion is None:
                        logger.error(f"âŒ í…ìŠ¤íŠ¸ íŒŒì‹± ê°ì • ë§¤í•‘ ì‹¤íŒ¨: '{emotion_text}'")
                        return None  # í•™ìŠµ ì˜¤ì—¼ ë°©ì§€
                    result['emotion'] = mapped_emotion
                elif 'ì‹ ë¢°ë„:' in line:
                    try:
                        conf_text = line.split(':')[1].strip()
                        result['confidence'] = float(conf_text)
                    except:
                        pass
                elif 'ê°ì •ê°•ë„:' in line:
                    try:
                        intensity_text = line.split(':')[1].strip()
                        result['intensity'] = int(intensity_text)
                    except:
                        pass
                        
            logger.info(f"í…ìŠ¤íŠ¸ íŒŒì‹± ì„±ê³µ: ê°ì •={result['emotion']}, ì‹ ë¢°ë„={result['confidence']}")
            return result
            
        except Exception as e:
            logger.error(f"LLM ì‘ë‹µ íŒŒì‹± ì™„ì „ ì‹¤íŒ¨: {e}")
            # fallback ê¸ˆì§€ ì›ì¹™ì— ë”°ë¼ None ë°˜í™˜
            return None

    def _name_to_emotion_id(self, emotion_name: str) -> int:
        """í•œêµ­ì–´/ì˜ì–´ ê°ì • ì´ë¦„ì„ IDë¡œ ë³€í™˜ (ì˜¤íƒ€ í—ˆìš© fuzzy matching í¬í•¨)"""
        name_mapping = {
            # í•œêµ­ì–´ ê°ì • ì´ë¦„
            "ê¸°ì¨": 1, "í–‰ë³µ": 1, "ê¸°ë¹”": 1, "ì¦ê±°ì›€": 1,
            "ì‹ ë¢°": 2, "ë¯¿ìŒ": 2, "í™•ì‹ ": 2,
            "ë‘ë ¤ì›€": 3, "ë¶ˆì•ˆ": 3, "ê±±ì •": 3, "ê³µí¬": 3, "ë¬´ì„œì›€": 3,
            "ë†€ëŒ": 4, "ê¹œì§": 4, "ë†€ë¼ì›€": 4, "ì¶©ê²©": 4,
            "ìŠ¬í””": 5, "ìš°ìš¸": 5, "ìŠ¬í””": 5, "ìš°ìš¸í•¨": 5, "ì•„í””": 5,
            "í˜ì˜¤": 6, "ì‹«ìŒ": 6, "ì—­ê²¨ì›€": 6, "ê±°ë¶€ê°": 6,
            "ë¶„ë…¸": 7, "í™”": 7, "ì§œì¦": 7, "ì„±ë‚¨": 7, "í™”ë‚¨": 7,
            "ê¸°ëŒ€": 8, "ì˜ˆìƒ": 8, "ê¸°ëŒ€ê°": 8, "í¬ë§": 8,
            "ì¤‘ë¦½": 0, "ë¬´ê°ì •": 0, "ì¤‘ì„±": 0,
            
            # ì˜ì–´ ê°ì • ì´ë¦„ (HelpingAI ì‘ë‹µ í˜•ì‹)
            "joy": 1, "happy": 1, "happiness": 1, "joyful": 1, "pleased": 1,
            "trust": 2, "confidence": 2, "belief": 2, "reliance": 2,
            "fear": 3, "anxiety": 3, "worry": 3, "afraid": 3, "scared": 3, "anxious": 3,
            "surprise": 4, "shocked": 4, "amazed": 4, "astonished": 4, "surprised": 4,
            "sadness": 5, "sad": 5, "depression": 5, "sorrow": 5, "grief": 5, "melancholy": 5,
            "disgust": 6, "hate": 6, "dislike": 6, "revulsion": 6, "contempt": 6,
            "anger": 7, "angry": 7, "mad": 7, "rage": 7, "fury": 7, "irritation": 7, "frustration": 7, "frustrated": 7,
            "anticipation": 8, "anticipate": 8, "expectation": 8, "expect": 8, "hope": 8, "excitement": 8,
            "neutral": 0, "none": 0, "no emotion": 0, "normal": 0, "calm": 0
        }
        
        emotion_name_clean = emotion_name.lower().strip().replace(' ', '').replace('-', '').replace('_', '')
        
        # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­
        for name, emotion_id in name_mapping.items():
            name_clean = name.lower().replace(' ', '').replace('-', '').replace('_', '')
            if name_clean == emotion_name_clean or name_clean in emotion_name_clean:
                return emotion_id
        
        # 2ë‹¨ê³„: fuzzy matching (Levenshtein distance ê¸°ë°˜)
        def levenshtein_distance(s1, s2):
            if len(s1) < len(s2):
                return levenshtein_distance(s2, s1)
            if len(s2) == 0:
                return len(s1)
            
            previous_row = list(range(len(s2) + 1))
            for i, c1 in enumerate(s1):
                current_row = [i + 1]
                for j, c2 in enumerate(s2):
                    insertions = previous_row[j + 1] + 1
                    deletions = current_row[j] + 1
                    substitutions = previous_row[j] + (c1 != c2)
                    current_row.append(min(insertions, deletions, substitutions))
                previous_row = current_row
            return previous_row[-1]
        
        # 3ë‹¨ê³„: ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (í¸ì§‘ ê±°ë¦¬ 2 ì´í•˜)
        best_match = None
        best_distance = float('inf')
        
        for name, emotion_id in name_mapping.items():
            name_clean = name.lower().replace(' ', '').replace('-', '').replace('_', '')
            distance = levenshtein_distance(emotion_name_clean, name_clean)
            
            # ê¸¸ì´ì— ë¹„ë¡€í•œ í—ˆìš© ì˜¤ì°¨ (ì§§ì€ ë‹¨ì–´ëŠ” ë” ì—„ê²©í•˜ê²Œ)
            max_allowed_distance = max(1, len(name_clean) // 3)
            
            if distance <= max_allowed_distance and distance < best_distance:
                best_distance = distance
                best_match = emotion_id
        
        if best_match is not None:
            logger.info(f"ğŸ”§ fuzzy matching ì„±ê³µ: '{emotion_name}' -> emotion_id={best_match} (distance={best_distance})")
            return best_match
        
        # ë§¤í•‘ ì‹¤íŒ¨ ì‹œ ëª…í™•í•œ ì—ëŸ¬ ë¡œê·¸ ë° None ë°˜í™˜ (í•™ìŠµ ì˜¤ì—¼ ë°©ì§€)
        allowed_emotions = ["joy", "trust", "fear", "surprise", "sadness", "disgust", "anger", "anticipation", "neutral"]
        logger.error(f"âŒ ê°ì • ë§¤í•‘ ì‹¤íŒ¨: '{emotion_name}' -> í—ˆìš©ëœ ê°ì • ëª©ë¡ì— ì—†ìŒ")
        logger.error(f"ğŸ¯ í—ˆìš©ëœ ê°ì •: {allowed_emotions}")
        logger.error(f"ğŸ”§ ì œì•ˆ: HelpingAI í”„ë¡¬í”„íŠ¸ ì œì•½ì„ ë” ê°•í™”í•˜ê±°ë‚˜ ë§¤í•‘ í…Œì´ë¸”ì— ì¶”ê°€ í•„ìš”")
        return None  # ëª…í™•í•œ ì‹¤íŒ¨ í‘œì‹œ
    
    def _translate_to_english(self, korean_text: str) -> str:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ (ë¡œì»¬ OPUS-MT ì‚¬ìš©, ì™„ì „ ì˜¤í”„ë¼ì¸)"""
        try:
            return self.local_translator.translate_ko_to_en(korean_text)
        except Exception as e:
            logger.warning(f"ë¡œì»¬ ë²ˆì—­ ì˜¤ë¥˜: {e}, ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
            return korean_text

    def _deep_llm_emotion_analysis(self, text: str) -> Optional[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ë¶„ì„ì´ ì‹¤íŒ¨í•œ ê²½ìš° LLM ì „ì²´ ë¶„ì„ (ë¯¼ê°ì„± ê°ì§€ ë° ì¤‘ë¦½í™” ì‹œìŠ¤í…œ í†µí•©)"""
        
        if not LLM_INTEGRATION_AVAILABLE:
            return None
        
        try:
            import asyncio
            import concurrent.futures
            from llm_module.advanced_llm_engine import get_llm_engine, LLMRequest, TaskComplexity
            from sensitivity_detection_singleton import detect_and_neutralize_sensitive_content
            
            prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ê°ì •ì„ ê¹Šì´ ë¶„ì„í•´ì£¼ì„¸ìš”.

í…ìŠ¤íŠ¸: "{text}"

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ê°ì •: [ê¸°ì¨/ìŠ¬í””/ë¶„ë…¸/ë‘ë ¤ì›€/ë†€ëŒ/í˜ì˜¤/ì‹ ë¢°/ê¸°ëŒ€/ì¤‘ë¦½]
2. ê°ì • ê°•ë„: [1-6 ì²™ë„]
3. ì‹ ë¢°ë„: [0.0-1.0]
4. ê°ì •ê°€: [-1.0~1.0, ë¶€ì •ì ~ê¸ì •ì ]
5. ê°ì„±ë„: [-1.0~1.0, ë‚®ìŒ~ë†’ìŒ]
6. ì‹¬ì¸µ ë¶„ì„: [ê°ì •ì˜ ì›ì¸, ë§¥ë½, ì˜ë¯¸]"""

            def run_deep_analysis(current_text=text):
                # WSL2 í™˜ê²½ ë§ì¶¤ ì¬ì‹œë„ ë¡œì§ + ë¯¼ê°ì„± ê°ì§€ ì‹œìŠ¤í…œ
                max_retries = 3
                retry_delays = [1, 3, 5]  # ì§€ìˆ˜ì  ë°±ì˜¤í”„
                response_texts = []  # ì‘ë‹µ ì¶”ì ìš©
                
                for attempt in range(max_retries):
                    try:
                        # ë©”ëª¨ë¦¬ ì²´í¬ (WSL2 ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§)
                        import psutil
                        memory = psutil.virtual_memory()
                        if memory.percent > 90:
                            logger.warning(f"WSL2 ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {memory.percent}%")
                            import gc
                            gc.collect()
                            if attempt < max_retries - 1:
                                time.sleep(retry_delays[attempt])
                                continue
                        
                        # GPU ë©”ëª¨ë¦¬ ì²´í¬
                        if torch.cuda.is_available():
                            gpu_memory_percent = (torch.cuda.memory_allocated() / torch.cuda.get_device_properties(0).total_memory) * 100
                            if gpu_memory_percent > 85:
                                logger.warning(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {gpu_memory_percent:.1f}%")
                                torch.cuda.empty_cache()
                        
                        # í† í° ìˆ˜ ë¯¸ë¦¬ ê³„ì‚° (ì¤‘ì²© í•¨ìˆ˜ì—ì„œ self ì ‘ê·¼ ë¶ˆê°€ ë¬¸ì œ í•´ê²°)
                        dynamic_tokens = 1200  # JSON ì‘ë‹µ ì™„ì „ì„± ë³´ì¥ì„ ìœ„í•œ í† í° í• ë‹¹
                        
                        # í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ (ì•ˆì •ì„± í–¥ìƒ)
                        translated_text = self._translate_to_english(current_text)
                        
                        # ì˜ì–´ ê¸°ë°˜ JSON í”„ë¡¬í”„íŠ¸ (ì•ˆì •ì„± í–¥ìƒ)
                        current_prompt = f"""<|begin_of_text|><|start_header_id|>system<|end_header_id|>

You are an emotion analysis expert. Respond only in simple and accurate JSON format.

<|eot_id|><|start_header_id|>user<|end_header_id|>

Text: "{translated_text}"

Respond only in this exact JSON format:
{{
  "emotion": "joy",
  "intensity": 3,
  "confidence": 0.8,
  "valence": 0.5,
  "arousal": 0.5,
  "reasoning": "Brief explanation of the emotional cause"
}}

The emotion value must be one of: joy, sadness, anger, fear, surprise, disgust, trust, anticipation, neutral

<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""
                        
                        def async_llm_call():
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            try:
                                engine = get_llm_engine()
                                request = LLMRequest(
                                    prompt=current_prompt,
                                    task_type="emotion_analysis",  # HelpingAI EQ 95.89 ìš°ì„  ì„ íƒ
                                    complexity=TaskComplexity.COMPLEX,
                                    max_tokens=dynamic_tokens,
                                    temperature=0.2
                                )
                                
                                response = loop.run_until_complete(engine.generate_async(request))
                                return response
                            finally:
                                loop.close()
                        
                        # íƒ€ì„ì•„ì›ƒë„ ì¬ì‹œë„ì— ë”°ë¼ ì¡°ì •
                        timeout = 30 + (attempt * 10)  # 30s, 40s, 50s
                        
                        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                            future = executor.submit(async_llm_call)
                            response = future.result(timeout=timeout)
                        
                        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì €ì¥
                        response_text = ""
                        if response and hasattr(response, 'generated_text'):
                            response_text = response.generated_text or ""
                        response_texts.append(response_text)
                        
                        if response and response.success and response_text:
                            parsed_result = self._parse_deep_llm_response(response_text)
                            if parsed_result and parsed_result.get('emotion'):
                                logger.info(f"âœ… LLM ë¶„ì„ ì„±ê³µ (ì‹œë„ {attempt + 1}/{max_retries})")
                                return parsed_result
                            else:
                                logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨, ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                        else:
                            logger.warning(f"âš ï¸ LLM ì‘ë‹µ ì‹¤íŒ¨ (ì‘ë‹µ ê¸¸ì´: {len(response_text)}), ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                        
                        # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                        if attempt < max_retries - 1:
                            time.sleep(retry_delays[attempt])
                            
                    except Exception as e:
                        logger.warning(f"âš ï¸ ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {e}")
                        response_texts.append("")  # ì˜ˆì™¸ ì‹œì—ë„ ë¹ˆ ì‘ë‹µ ê¸°ë¡
                        if attempt < max_retries - 1:
                            time.sleep(retry_delays[attempt])
                        else:
                            logger.error(f"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {e}")
                
                # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ í›„ ì‘ë‹µ ë¶„ì„ ë° ë¯¼ê°ì„± ê°ì§€ ì‹œìŠ¤í…œ íŠ¸ë¦¬ê±° íŒë‹¨
                logger.info(f"ğŸ” ëª¨ë“  ì¬ì‹œë„ ì†Œì§„ (ì´ {max_retries}íšŒ) - ì‘ë‹µ ë¶„ì„ ì‹œì‘")
                
                # ì‘ë‹µ ìƒíƒœ ë¶„ì„
                all_empty_responses = all(len(resp.strip()) == 0 for resp in response_texts)
                has_substantial_responses = any(len(resp.strip()) > 50 for resp in response_texts)
                avg_response_length = sum(len(resp) for resp in response_texts) / len(response_texts) if response_texts else 0
                
                logger.info(f"ğŸ“Š ì‘ë‹µ ë¶„ì„ ê²°ê³¼:")
                logger.info(f"   - ì´ ì‘ë‹µ ìˆ˜: {len(response_texts)}")
                logger.info(f"   - ëª¨ë‘ ë¹ˆ ì‘ë‹µ: {all_empty_responses}")
                logger.info(f"   - ì‹¤ì§ˆì  ì‘ë‹µ ì¡´ì¬: {has_substantial_responses}")
                logger.info(f"   - í‰ê·  ì‘ë‹µ ê¸¸ì´: {avg_response_length:.1f}ì")
                for i, resp in enumerate(response_texts):
                    logger.info(f"   - ì‘ë‹µ {i+1}: {len(resp)}ì ({resp[:100]}...)")
                
                # ë¯¼ê°ì„± ê°ì§€ íŠ¸ë¦¬ê±° ì¡°ê±´: ëª¨ë“  ì‘ë‹µì´ ë¹„ì–´ìˆê³  ì›ë³¸ í…ìŠ¤íŠ¸ì¸ ê²½ìš°ë§Œ
                should_trigger_sensitivity = (
                    all_empty_responses and 
                    current_text == text and  # ì›ë³¸ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì²« ë²ˆì§¸ ì‹œë„
                    avg_response_length < 10  # í‰ê·  ì‘ë‹µ ê¸¸ì´ê°€ ë§¤ìš° ì§§ìŒ
                )
                
                if should_trigger_sensitivity:
                    logger.info("ğŸ” ë¯¼ê°ì„± ê°ì§€ ì¡°ê±´ ë§Œì¡± - ì¤‘ë¦½í™” ì‹œìŠ¤í…œ íŠ¸ë¦¬ê±°")
                    try:
                        # ë¯¼ê°ì„± ê°ì§€ ë° ì¤‘ë¦½í™” ì‹œë„
                        was_sensitive, neutralized_text, metadata = detect_and_neutralize_sensitive_content(text)
                        
                        if was_sensitive and neutralized_text and neutralized_text != text:
                            logger.info(f"ğŸ”„ ë¯¼ê°ì„± ê°ì§€ë¨ - ì¤‘ë¦½í™”ëœ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„")
                            logger.info(f"ğŸ“ ì›ë³¸: '{text[:50]}...'")
                            logger.info(f"ğŸ“ ë³€í™˜: '{neutralized_text[:50]}...'")
                            
                            # ì¤‘ë¦½í™”ëœ í…ìŠ¤íŠ¸ë¡œ ì¬ê·€ í˜¸ì¶œ (ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ 1íšŒë§Œ)
                            return run_deep_analysis(neutralized_text)
                        else:
                            logger.info("ğŸ” ë¯¼ê°ì„± ë¯¸ê°ì§€ ë˜ëŠ” ì¤‘ë¦½í™” ì‹¤íŒ¨")
                            
                    except Exception as e:
                        logger.error(f"âŒ ë¯¼ê°ì„± ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                
                elif has_substantial_responses:
                    logger.info("ğŸ“„ ì‹¤ì§ˆì ì¸ ì‘ë‹µì€ ìƒì„±ë˜ì—ˆìœ¼ë‚˜ íŒŒì‹± ì‹¤íŒ¨ - JSON êµ¬ì¡° ë¬¸ì œë¡œ íŒë‹¨")
                    logger.info("   â†’ ë¯¼ê°ì„± ê°ì§€ ì‹œìŠ¤í…œ íŠ¸ë¦¬ê±°í•˜ì§€ ì•ŠìŒ")
                else:
                    logger.info("â“ ì‘ë‹µ ê¸¸ì´ëŠ” ìˆìœ¼ë‚˜ ë¹ˆ ë‚´ìš© - ê¸°íƒ€ ì›ì¸ìœ¼ë¡œ íŒë‹¨")
                
                logger.error("âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì •ì§€")
                return None
            
            return run_deep_analysis()
            
        except Exception as e:
            logger.error(f"ê¹Šì€ LLM ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    def _extract_partial_emotion_data(self, response_text: str) -> Optional[Dict[str, Any]]:
        """ë¶€ë¶„ ì‘ë‹µì—ì„œ ê°ì • ë°ì´í„° ì¶”ì¶œ (ê°•í™”ëœ íŒ¨í„´ ë§¤ì¹­)"""
        try:
            import re
            
            # ê°•í™”ëœ ê°ì • íŒ¨í„´ ì¶”ì¶œ
            emotion_patterns = [
                # JSON í•„ë“œ íŒ¨í„´
                r'"emotion"\s*:\s*"([^"]+)"',
                r'"emotion"\s*:\s*([a-zA-Zê°€-í£]+)',
                # ì¼ë°˜ í…ìŠ¤íŠ¸ íŒ¨í„´
                r'(?:emotion|ê°ì •)(?:\s*is)?\s*[:=]\s*"?([a-zA-Zê°€-í£]+)"?',
                r'(?:ì£¼ìš”\s*ê°ì •|ê°ì •)\s*[:=]\s*"?([a-zA-Zê°€-í£]+)"?',
                # ì§ì ‘ ê°ì • ì–¸ê¸‰
                r'\b(joy|sadness|anger|fear|surprise|disgust|trust|anticipation|neutral)\b',
                r'\b(ê¸°ì¨|ìŠ¬í””|ë¶„ë…¸|ë‘ë ¤ì›€|ë†€ëŒ|í˜ì˜¤|ì‹ ë¢°|ê¸°ëŒ€|ì¤‘ë¦½)\b',
                # ë¶ˆì™„ì „í•œ JSONì—ì„œ ê°ì •ë§Œ ì¶”ì¶œ
                r'(?:anticipation|joy|fear|sadness|anger|disgust|trust|surprise|ê¸°ëŒ€|ê¸°ì¨|ë‘ë ¤ì›€|ìŠ¬í””|ë¶„ë…¸|í˜ì˜¤|ì‹ ë¢°|ë†€ëŒ)'
            ]
            
            intensity_patterns = [
                r'"intensity"\s*:\s*(\d+)',
                r'"intensity"\s*:\s*"(\d+)"',
                r'(?:intensity|ê°•ë„)(?:\s*is)?\s*[:=]\s*(\d+)',
                r'(?:ê°ì •\s*ê°•ë„|ê°•ë„)\s*[:=]\s*(\d+)',
                r'(\d+)\s*(?:out\s*of\s*[56]|/[56])',  # "3 out of 5" or "3/5" í˜•ì‹
            ]
            
            confidence_patterns = [
                r'"confidence"\s*:\s*([0-9.]+)',
                r'"confidence"\s*:\s*"([0-9.]+)"',
                r'(?:confidence|ì‹ ë¢°ë„)(?:\s*is)?\s*[:=]\s*([0-9.]+)',
                r'(?:ì‹ ë¢°ë„|í™•ì‹¤ë„)\s*[:=]\s*([0-9.]+)%?',
            ]
            
            valence_patterns = [
                r'"valence"\s*:\s*([-0-9.]+)',
                r'(?:valence|ê°ì •ê°€)\s*[:=]\s*([-0-9.]+)',
            ]
            
            arousal_patterns = [
                r'"arousal"\s*:\s*([-0-9.]+)',
                r'(?:arousal|ê°ì„±ë„)\s*[:=]\s*([-0-9.]+)',
            ]
            
            result = {
                'emotion': EmotionState.NEUTRAL.value,
                'intensity': 3,
                'confidence': 0.5,
                'valence': 0.0,
                'arousal': 0.0,
                'reasoning': response_text[:200] + '...' if len(response_text) > 200 else response_text
            }
            
            extracted_count = 0
            
            # ê°ì • ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ íŒ¨í„´ ìˆœì„œë¡œ)
            for pattern in emotion_patterns:
                match = re.search(pattern, response_text, re.IGNORECASE)
                if match:
                    emotion_name = match.group(1).strip().strip('"')
                    new_emotion_id = self._name_to_emotion_id(emotion_name)
                    if new_emotion_id != EmotionState.NEUTRAL.value:  # ìœ íš¨í•œ ê°ì •ë§Œ ì±„íƒ
                        result['emotion'] = new_emotion_id
                        extracted_count += 1
                        logger.debug(f"âœ… ê°ì • ì¶”ì¶œ: '{emotion_name}' -> {new_emotion_id}")
                        break
            
            # ê°•ë„ ì¶”ì¶œ
            for pattern in intensity_patterns:
                match = re.search(pattern, response_text, re.IGNORECASE)
                if match:
                    try:
                        intensity_value = int(match.group(1))
                        if 1 <= intensity_value <= 6:  # ìœ íš¨ ë²”ìœ„ í™•ì¸
                            result['intensity'] = intensity_value
                            extracted_count += 1
                            logger.debug(f"âœ… ê°•ë„ ì¶”ì¶œ: {intensity_value}")
                            break
                    except ValueError:
                        pass
            
            # ì‹ ë¢°ë„ ì¶”ì¶œ
            for pattern in confidence_patterns:
                match = re.search(pattern, response_text, re.IGNORECASE)
                if match:
                    try:
                        conf_value = float(match.group(1))
                        # ë°±ë¶„ìœ¨ í˜•ì‹ì¸ ê²½ìš° 0-1 ë²”ìœ„ë¡œ ë³€í™˜
                        if conf_value > 1.0:
                            conf_value = conf_value / 100.0
                        if 0.0 <= conf_value <= 1.0:  # ìœ íš¨ ë²”ìœ„ í™•ì¸
                            result['confidence'] = conf_value
                            extracted_count += 1
                            logger.debug(f"âœ… ì‹ ë¢°ë„ ì¶”ì¶œ: {conf_value}")
                            break
                    except ValueError:
                        pass
            
            # ê°ì •ê°€ ì¶”ì¶œ
            for pattern in valence_patterns:
                match = re.search(pattern, response_text, re.IGNORECASE)
                if match:
                    try:
                        valence_value = float(match.group(1))
                        if -1.0 <= valence_value <= 1.0:  # ìœ íš¨ ë²”ìœ„ í™•ì¸
                            result['valence'] = valence_value
                            extracted_count += 1
                            logger.debug(f"âœ… ê°ì •ê°€ ì¶”ì¶œ: {valence_value}")
                            break
                    except ValueError:
                        pass
            
            # ê°ì„±ë„ ì¶”ì¶œ
            for pattern in arousal_patterns:
                match = re.search(pattern, response_text, re.IGNORECASE)
                if match:
                    try:
                        arousal_value = float(match.group(1))
                        if -1.0 <= arousal_value <= 1.0:  # ìœ íš¨ ë²”ìœ„ í™•ì¸
                            result['arousal'] = arousal_value
                            extracted_count += 1
                            logger.debug(f"âœ… ê°ì„±ë„ ì¶”ì¶œ: {arousal_value}")
                            break
                    except ValueError:
                        pass
            
            # í’ˆì§ˆ ì²´í¬: reasoning í•„ë“œì˜ ì´ìƒí•œ í…ìŠ¤íŠ¸ ê°ì§€
            reasoning_text = result.get('reasoning', '')
            is_corrupted = (
                len(re.findall(r'(.)\1{5,}', reasoning_text)) > 0 or  # ê°™ì€ ë¬¸ì 6íšŒ ì´ìƒ ë°˜ë³µ
                len(re.findall(r'[a-zA-Z]{15,}', reasoning_text)) > 2 or  # 15ì ì´ìƒ ê¸´ ë‹¨ì–´ 2ê°œ ì´ìƒ
                'reatkage' in reasoning_text or 'existsizing' in reasoning_text  # ì•Œë ¤ì§„ ê¹¨ì§„ ë‹¨ì–´
            )
            
            if is_corrupted:
                logger.warning(f"âŒ ë¶€ë¶„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: reasoning í•„ë“œê°€ ì†ìƒë¨")
                logger.warning(f"   ì†ìƒëœ reasoning: {reasoning_text[:100]}...")
                return None
            
            # ìµœì†Œ 2ê°œ ì´ìƒì˜ ìœ ì˜ë¯¸í•œ ë°ì´í„°ê°€ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
            if extracted_count >= 1 and (result['emotion'] != EmotionState.NEUTRAL.value or result['intensity'] != 3):
                logger.info(f"âœ… ë¶€ë¶„ ë°ì´í„° ì¶”ì¶œ ì„±ê³µ: {extracted_count}ê°œ í•„ë“œ ì¶”ì¶œë¨")
                logger.info(f"   emotion={result['emotion']}, intensity={result['intensity']}, confidence={result['confidence']}")
                return result
            
            logger.debug(f"âŒ ë¶€ë¶„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {extracted_count}ê°œ í•„ë“œë§Œ ì¶”ì¶œë¨")
            return None
            
        except Exception as e:
            logger.error(f"ë¶€ë¶„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def _parse_deep_llm_response(self, response_text: str) -> Dict[str, Any]:
        """ê¹Šì€ LLM ë¶„ì„ ì‘ë‹µ íŒŒì‹± (ë‹¤ë‹¨ê³„ fallback ë©”ì»¤ë‹ˆì¦˜)"""
        try:
            import json
            import re
            
            logger.info(f"ğŸ”§ LLM ì‘ë‹µ íŒŒì‹± ì‹œì‘: {len(response_text)} ë¬¸ì")
            logger.info(f"ğŸ”§ ì‘ë‹µ ì²« 500ì: {response_text[:500]}...")
            
            # 1ë‹¨ê³„: json_repairë¥¼ ì‚¬ìš©í•œ ìë™ ìˆ˜ì • ì‹œë„
            try:
                from json_repair import repair_json
                
                logger.info("ğŸ”§ 1ë‹¨ê³„: json_repair ìë™ ìˆ˜ì • ì‹œë„")
                repaired_json = repair_json(response_text)
                logger.info(f"ğŸ”§ ìˆ˜ì •ëœ JSON: {repaired_json[:200]}...")
                json_response = json.loads(repaired_json)
                
                # LLM ì‘ë‹µì´ ë³µí•© ê°ì²´ì¼ ê²½ìš° emotions í•„ë“œ í™•ì¸
                if 'emotions' in json_response:
                    emotions_data = json_response['emotions']
                    # ê°€ì¥ ë†’ì€ ê°’ì„ ê°€ì§„ ê°ì • ì°¾ê¸°
                    max_emotion = max(emotions_data.items(), key=lambda x: float(x[1]))
                    emotion_name = max_emotion[0]
                    
                    # intensity, confidence ë“± í™•ì¸
                    intensity_data = json_response.get('intensity', {})
                    confidence_data = json_response.get('confidence', {})
                    valence_data = json_response.get('valence', {})
                    arousal_data = json_response.get('arousal', {})
                    
                    result = {
                        'emotion': self._name_to_emotion_id(emotion_name),
                        'intensity': int(intensity_data.get(emotion_name, 3)),
                        'confidence': float(confidence_data.get(emotion_name, 0.5)),
                        'valence': float(valence_data.get(emotion_name, 0.0)),
                        'arousal': float(arousal_data.get(emotion_name, 0.0)),
                        'reasoning': str(json_response.get('reasoning', {}).get(emotion_name, ''))
                    }
                    
                    logger.info(f"âœ… json_repair ì„±ê³µ (ë³µí•©ê°ì²´): emotion={emotion_name} -> id={result['emotion']}")
                    return result
                
                # ë‹¨ìˆœ ê°ì²´ì¸ ê²½ìš°
                elif 'emotion' in json_response:
                    emotion_name = str(json_response.get('emotion', 'neutral')).strip()
                    result = {
                        'emotion': self._name_to_emotion_id(emotion_name),
                        'intensity': int(json_response.get('intensity', 3)),
                        'confidence': float(json_response.get('confidence', 0.5)),
                        'valence': float(json_response.get('valence', 0.0)),
                        'arousal': float(json_response.get('arousal', 0.0)),
                        'reasoning': str(json_response.get('reasoning', ''))
                    }
                    
                    logger.info(f"âœ… json_repair ì„±ê³µ (ë‹¨ìˆœê°ì²´): emotion={emotion_name} -> id={result['emotion']}")
                    return result
                    
            except Exception as e:
                logger.info(f"ğŸ”§ json_repair ì‹¤íŒ¨: {e}")
            
            # 2ë‹¨ê³„: ê°•í™”ëœ ì „ì²˜ë¦¬ í›„ JSON íŒŒì‹± ì‹œë„
            logger.info("ğŸ”§ 2ë‹¨ê³„: ê°•í™”ëœ ì „ì²˜ë¦¬ í›„ JSON íŒŒì‹±")
            preprocessed_text = self._preprocess_llm_json(response_text)
            
            # ë‹¤ì–‘í•œ JSON íŒ¨í„´ ì‹œë„ (ë¶€ë¶„ ì‘ë‹µ ëŒ€ì‘)
            json_patterns = [
                r'\{[^}]*\}',              # ì™„ì „í•œ JSON ê°ì²´
                r'\{[^}]*',                # ë¶ˆì™„ì „í•œ JSON ê°ì²´ (lengthë¡œ ì˜ë¦¼)
                r'"emotion"\s*:\s*"[^"]*"', # ê°ì • í•„ë“œë§Œ
                r'"intensity"\s*:\s*\d+',   # ê°•ë„ í•„ë“œë§Œ
                r'"confidence"\s*:\s*[\d.]+' # ì‹ ë¢°ë„ í•„ë“œë§Œ
            ]
            
            for pattern in json_patterns:
                json_match = re.search(pattern, preprocessed_text, re.DOTALL)
                if json_match:
                    json_text = json_match.group(0)
                    
                    # ë¶ˆì™„ì „í•œ JSON ê°ì²´ ì™„ì„± ì‹œë„
                    if not json_text.endswith('}'):
                        json_text += '}'
                    
                    try:
                        json_response = json.loads(json_text)
                        emotion_name = str(json_response.get('emotion', 'neutral')).strip()
                        
                        result = {
                            'emotion': self._name_to_emotion_id(emotion_name),
                            'intensity': int(json_response.get('intensity', 3)),
                            'confidence': float(json_response.get('confidence', 0.5)),
                            'valence': float(json_response.get('valence', 0.0)),
                            'arousal': float(json_response.get('arousal', 0.0)),
                            'reasoning': str(json_response.get('reasoning', ''))
                        }
                        
                        logger.info(f"âœ… ì „ì²˜ë¦¬ JSON íŒŒì‹± ì„±ê³µ (íŒ¨í„´ {pattern}): emotion={emotion_name} -> id={result['emotion']}")
                        return result
                        
                    except (json.JSONDecodeError, ValueError, TypeError) as e:
                        logger.debug(f"íŒ¨í„´ {pattern} íŒŒì‹± ì‹¤íŒ¨: {e}")
                        continue
            
            # 3ë‹¨ê³„: ë¶€ë¶„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            logger.info("ğŸ”§ 3ë‹¨ê³„: ë¶€ë¶„ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
            partial_result = self._extract_partial_emotion_data(response_text)
            if partial_result:
                logger.info("âœ… ë¶€ë¶„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                return partial_result
            
            # 4ë‹¨ê³„: í•œêµ­ì–´ í˜•ì‹ íŒŒì‹±
            logger.info("ğŸ”§ 4ë‹¨ê³„: í•œêµ­ì–´ í˜•ì‹ íŒŒì‹±")
            return self._parse_korean_format_response(response_text)
            
        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ íŒŒì‹± ì „ì²´ ì‹¤íŒ¨: {e}")
            logger.error(f"âŒ ì‹¤íŒ¨í•œ ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text[:200]}...")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ê°’ ë°˜í™˜ (None ë°˜í™˜ ë°©ì§€)
            return {
                'emotion': EmotionState.NEUTRAL.value,
                'intensity': 3,
                'confidence': 0.1,
                'valence': 0.0,
                'arousal': 0.0,
                'reasoning': f'parsing_failed: {str(e)}'
            }
    
    def _preprocess_llm_json(self, text: str) -> str:
        """LLM JSON ì‘ë‹µ ì „ì²˜ë¦¬ (ìœ ë‹ˆì½”ë“œ íŠ¹ìˆ˜ë¬¸ì, ìŒë”°ì˜´í‘œ ë³´ì •, ê°•í™”ëœ ì˜¤ë¥˜ ìˆ˜ì •)"""
        import re
        
        # ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ChatML í…œí”Œë¦¿ ì œê±°)
        json_start = text.find('{')
        if json_start > 0:
            text = text[json_start:]
        
        # ìœ ë‹ˆì½”ë“œ íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
        text = text.replace('â€³', '"')  # ìœ ë‹ˆì½”ë“œ ìŒë”°ì˜´í‘œ
        text = text.replace('â€³ï¼Œ', '",')  # ìŒë”°ì˜´í‘œ + ì¤‘êµ­ì–´ ì‰¼í‘œ
        text = text.replace('""', '"')  # ì—°ì† ìŒë”°ì˜´í‘œ
        text = text.replace('"""', '"')  # 3ê°œ ì—°ì† ìŒë”°ì˜´í‘œ
        text = text.replace('"', '"').replace('"', '"')  # í•œêµ­ì–´ ë”°ì˜´í‘œ
        
        # JSON í‚¤ ê³µë°± ë¬¸ì œ ì™„ì „ í•´ê²° (HelpingAI íŠ¹í™”)
        text = re.sub(r'"\s+(\w+)"\s*:', r'"\1":', text)  # " emotion": -> "emotion":
        text = re.sub(r'{\s*"\s+', r'{"', text)  # {"  -> {"
        text = re.sub(r',\s*"\s+', r', "', text)  # ,  " -> , "
        text = re.sub(r':\s*"\s+', r': "', text)  # : "value -> : "value
        text = re.sub(r'\s+"\s*:', r'":', text)  # space"space: -> ":
        # HelpingAI íŠ¹í™” íŒ¨í„´: í‚¤ ì•ë’¤ ê³µë°± ì œê±°
        for key in ['emotion', 'intensity', 'confidence', 'valence', 'arousal', 'reasoning']:
            text = re.sub(rf'"\s*{key}\s*"', f'"{key}"', text)  # " emotion " -> "emotion"
        
        # ì¼ë°˜ì ì¸ ì˜¤íƒ€ ìˆ˜ì •
        text = re.sub(r'(\w+)\s*:\s*(\w+)', r'"\1": "\2"', text)  # key: value -> "key": "value"
        text = re.sub(r'"(\w+)"\s*:\s*(\d+\.?\d*)', r'"\1": \2', text)  # "key": 123 (ìˆ«ìëŠ” ë”°ì˜´í‘œ ì œê±°)
        
        # ë¶ˆì™„ì „í•œ í‚¤ì— ìŒë”°ì˜´í‘œ ì¶”ê°€
        text = re.sub(r'(\w+)\s*:', r'"\1":', text)  # key: -> "key":
        
        # ê°’ ì£¼ë³€ ìŒë”°ì˜´í‘œ ìˆ˜ì • (ë” ì •êµí•˜ê²Œ)
        text = re.sub(r':\s*([a-zA-Zê°€-í£][^,}"\d]*)', r': "\1"', text)  # ë¬¸ìì—´ ê°’ ìŒë”°ì˜´í‘œ
        
        # ì˜ëª»ëœ ì‰¼í‘œ ìˆ˜ì •
        text = re.sub(r',\s*}', '}', text)  # trailing comma ì œê±°
        text = re.sub(r',\s*,', ',', text)  # ì¤‘ë³µ ì‰¼í‘œ ì œê±°
        
        # ë¶ˆì™„ì „í•œ ì¢…ë£Œ ìˆ˜ì •
        open_brackets = text.count('{')
        close_brackets = text.count('}')
        if open_brackets > close_brackets:
            text += '}' * (open_brackets - close_brackets)
        
        # ë¶ˆì™„ì „í•œ ë”°ì˜´í‘œ ìˆ˜ì •
        quote_count = text.count('"')
        if quote_count % 2 != 0:
            text += '"'
        
        logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {text[:100]}...")
        return text
    
    def _parse_korean_format_response(self, response_text: str) -> Dict[str, Any]:
        """í•œêµ­ì–´ í˜•ì‹ ì‘ë‹µ íŒŒì‹± (ê¸°ì¡´ ë¡œì§)"""
        try:
            lines = response_text.split('\n')
            result = {
                'emotion': EmotionState.NEUTRAL.value,
                'intensity': 3,
                'confidence': 0.5,
                'valence': 0.0,
                'arousal': 0.0,
                'reasoning': response_text
            }
            
            for line in lines:
                line = line.strip()
                if 'ì£¼ìš” ê°ì •:' in line:
                    emotion_text = line.split(':')[1].strip()
                    result['emotion'] = self._name_to_emotion_id(emotion_text)
                elif 'ê°ì • ê°•ë„:' in line:
                    try:
                        intensity_text = line.split(':')[1].strip()
                        result['intensity'] = int(intensity_text)
                    except:
                        pass
                elif 'ì‹ ë¢°ë„:' in line:
                    try:
                        conf_text = line.split(':')[1].strip()
                        result['confidence'] = float(conf_text)
                    except:
                        pass
                elif 'ê°ì •ê°€:' in line:
                    try:
                        valence_text = line.split(':')[1].strip()
                        result['valence'] = float(valence_text)
                    except:
                        pass
                elif 'ê°ì„±ë„:' in line:
                    try:
                        arousal_text = line.split(':')[1].strip()
                        result['arousal'] = float(arousal_text)
                    except:
                        pass
                        
            return result
            
        except Exception as e:
            logger.error(f"í•œêµ­ì–´ í˜•ì‹ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    def _detect_complex_ethical_question(self, text: str) -> bool:
        """ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ ê°ì§€ (fallback ì—†ì´)"""
        try:
            # ìœ¤ë¦¬ì  ë”œë ˆë§ˆ í‚¤ì›Œë“œ íŒ¨í„´
            ethical_keywords = [
                # í•µì‹¬ ìœ¤ë¦¬ ê°œë…
                'ìœ¤ë¦¬', 'ë„ë•', 'ì„ íƒ', 'ë”œë ˆë§ˆ', 'ê°ˆë“±', 'íŒë‹¨',
                # ìƒëª…ê³¼ ê´€ë ¨
                'ìƒëª…', 'ì£½ìŒ', 'ì‚´í•´', 'êµ¬ì¡°', 'í¬ìƒ', 'ì•ˆì „',
                # ì •ì˜ì™€ ê³µì •ì„±
                'ì •ì˜', 'ê³µì •', 'í‰ë“±', 'ì°¨ë³„', 'ê¶Œë¦¬', 'ì˜ë¬´',
                # ììœ¨ì„±ê³¼ ììœ 
                'ììœ ', 'ììœ¨', 'ê°•ì œ', 'ì–µì••', 'ì„ íƒê¶Œ', 'ì˜ì‚¬ê²°ì •',
                # ì±…ì„ê³¼ ê²°ê³¼
                'ì±…ì„', 'ê²°ê³¼', 'í”¼í•´', 'ì´ìµ', 'ì†ì‹¤', 'ëŒ€ê°€',
                # ì‚¬íšŒì  ê´€ê³„
                'ì‚¬íšŒ', 'ê³µë™ì²´', 'ê°œì¸', 'ì§‘ë‹¨', 'ë‹¤ìˆ˜', 'ì†Œìˆ˜',
                # ì‹œë‚˜ë¦¬ì˜¤ë³„ í‚¤ì›Œë“œ
                'ììœ¨ì£¼í–‰', 'ì˜ë£Œ', 'ì¸ê³µí˜¸í¡ê¸°', 'ê°œì¸ì •ë³´', 'ê°ì‹œ', 'í…ŒëŸ¬',
                'ë¸Œë ˆì´í¬', 'ê¸‰ë¸Œë ˆì´í¬', 'ì¹ ', 'í‹€ì–´', 'ì§ì§„',
                'í™˜ì', 'ë‚˜ì´', 'ìš°ì„ ìˆœìœ„', 'ì„ íƒ',
                'í”„ë¼ì´ë²„ì‹œ', 'ê³µê³µì•ˆì „', 'ìˆ˜ì§‘', 'ë³´í˜¸'
            ]
            
            text_lower = text.lower()
            found_keywords = [keyword for keyword in ethical_keywords if keyword in text_lower]
            
            # ë³µì¡ì„± í‰ê°€ ê¸°ì¤€
            complexity_score = 0
            
            # 1. ìœ¤ë¦¬ì  í‚¤ì›Œë“œ ìˆ˜ (ê¸°ë³¸ ì ìˆ˜)
            complexity_score += len(found_keywords) * 2
            
            # 2. ì„ íƒ/ê²°ì • ê´€ë ¨ í‘œí˜„
            choice_patterns = ['í• ê¹Œ', 'ë§ê¹Œ', 'ê²ƒì¸ê°€', 'ì„ íƒ', 'ê²°ì •', 'íŒë‹¨', 'ê³ ë¯¼']
            choice_count = sum(1 for pattern in choice_patterns if pattern in text_lower)
            complexity_score += choice_count * 3
            
            # 3. ëŒ€ì¡°/ë¹„êµ í‘œí˜„
            contrast_patterns = ['vs', 'ëŒ€', 'ë°˜ë©´', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜', 'ì•„ë‹ˆë©´', 'ë˜ëŠ”']
            contrast_count = sum(1 for pattern in contrast_patterns if pattern in text_lower)
            complexity_score += contrast_count * 2
            
            # 4. ìˆ˜ì¹˜ì  ë¹„êµ (ë‚˜ì´, ìˆ˜ëŸ‰ ë“±)
            import re
            number_pattern = r'\d+ì„¸|\d+ëª…|\d+ëŒ€|\d+ê°œ'
            number_matches = len(re.findall(number_pattern, text))
            complexity_score += number_matches * 2
            
            # 5. ì§ˆë¬¸ í˜•íƒœ
            if '?' in text or text.endswith('ê°€?') or 'ì¸ê°€' in text:
                complexity_score += 5
            
            # ë³µì¡ì„± ì„ê³„ê°’: 8ì  ì´ìƒì´ë©´ ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨
            is_complex = complexity_score >= 8
            
            if is_complex:
                logger.info(f"ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ ê°ì§€ - ì ìˆ˜: {complexity_score}, í‚¤ì›Œë“œ: {found_keywords}")
            
            return is_complex
            
        except Exception as e:
            logger.error(f"ìœ¤ë¦¬ì  ì§ˆë¬¸ ê°ì§€ ì‹¤íŒ¨: {e}")
            # fallback ê¸ˆì§€ - ê¸°ë³¸ê°’ False ë°˜í™˜
            return False

    def _calculate_dynamic_token_limit_direct(self, text: str, base_tokens: int = 400) -> int:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ì— ë”°ë¥¸ ë™ì  í† í° í• ë‹¹ (ì¤‘ì²© í•¨ìˆ˜ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥)"""
        try:
            # ê¸°ë³¸ í† í° ìˆ˜
            tokens = base_tokens
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ ì¶”ê°€ í† í°
            if len(text) > 100:
                tokens += min(200, len(text) // 5)
            
            # ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ ê°ì§€
            if self._detect_complex_ethical_question(text):
                tokens += 300  # ë³µì¡í•œ ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ í† í°
            
            # ë³µí•© ê°ì • í‘œí˜„ ê°ì§€
            emotion_count = sum(1 for emotion_dict in self.korean_emotion_keywords.values() 
                               for keyword_list in emotion_dict.values()
                               for keyword in keyword_list 
                               if keyword in text.lower())
            if emotion_count >= 3:
                tokens += 150  # ë³µí•© ê°ì • ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ í† í°
            
            # ìµœëŒ€ í† í° ìˆ˜ ì œí•œ (ëª¨ë¸ ì„±ëŠ¥ ìµœì í™”)
            return min(tokens, 1500)
            
        except Exception as e:
            logger.warning(f"ë™ì  í† í° ê³„ì‚° ì˜¤ë¥˜: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return base_tokens
    
    def get_pytorch_network(self) -> Optional[nn.Module]:
        """
        í—¤ë“œ/ìŠ¤ì™‘ë§¤ë‹ˆì €ê°€ ì‚¬ìš©í•  ëŒ€í‘œ PyTorch ë„¤íŠ¸ì›Œí¬ë¥¼ ë°˜í™˜.
        - ê°€ëŠ¥í•œ í›„ë³´ë¥¼ ìˆœì„œëŒ€ë¡œ íƒìƒ‰í•´ì„œ nn.Moduleì„ ë°˜í™˜
        - í•œ ë²ˆ ì°¾ìœ¼ë©´ ìºì‹œ(self._primary_nn)í•´ ì¬ì‚¬ìš©
        - ëª¨ë“  í›„ë³´ê°€ ì—†ìœ¼ë©´ _build_default_network()ë¡œ ìƒì„±
        """
        import torch.nn as nn
        
        # ìºì‹œ ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
        if hasattr(self, "_primary_nn") and isinstance(self._primary_nn, nn.Module):
            return self._primary_nn
        
        candidates = []
        
        # 1) ìì£¼ ì“°ì´ëŠ” ë„¤ì´ë° ìš°ì„ 
        priority_names = ["hierarchical_model", "emotion_moe", "model", "network", "default_network"]
        for name in priority_names:
            if hasattr(self, name):
                obj = getattr(self, name, None)
                if obj is None:
                    continue
                    
                # callableì´ë©´ í•œ ë²ˆ í˜¸ì¶œí•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ íšë“
                try:
                    if callable(obj) and not isinstance(obj, nn.Module):
                        obj = obj()
                except Exception as e:
                    logger.debug(f"  - {name} í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    continue
                    
                if isinstance(obj, nn.Module):
                    candidates.append((name, obj))
                    logger.debug(f"  - {name} í›„ë³´ ë°œê²¬")
        
        # 2) ë©¤ë²„ ì¤‘ nn.Module ìë™ íƒìƒ‰ (ë°±ì—… ê²½ë¡œ)
        if not candidates:
            logger.info("ğŸ” ìš°ì„ ìˆœìœ„ í›„ë³´ì—ì„œ nn.Moduleì„ ì°¾ì§€ ëª»í•¨, ì „ì²´ íƒìƒ‰ ì‹œì‘...")
            try:
                for name, val in vars(self).items():
                    if name.startswith('_'):  # private ì†ì„± ê±´ë„ˆë›°ê¸°
                        continue
                    if isinstance(val, nn.Module):
                        candidates.append((name, val))
                        logger.debug(f"  - {name} í›„ë³´ ë°œê²¬ (ì „ì²´ íƒìƒ‰)")
            except Exception as e:
                logger.error(f"vars() íƒìƒ‰ ì˜¤ë¥˜: {e}")
        
        # 3) í›„ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„±
        if not candidates:
            logger.info("emotion_analyzer ë‚´ë¶€ì—ì„œ nn.Module í›„ë³´ë¥¼ ì°¾ì§€ ëª»í•¨ - ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„±")
            logger.debug(f"  - emotion_moe: {hasattr(self, 'emotion_moe')} / {type(getattr(self, 'emotion_moe', None))}")
            logger.debug(f"  - hierarchical_model: {hasattr(self, 'hierarchical_model')} / {type(getattr(self, 'hierarchical_model', None))}")
            logger.debug(f"  - default_network: {hasattr(self, 'default_network')} / {type(getattr(self, 'default_network', None))}")
            
            # ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ë¬´ì¡°ê±´ ìƒì„± (NO FALLBACK)
            logger.info("ğŸ”¨ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì¤‘...")
            self._build_default_network()
            
            # ìƒì„± í›„ ë°˜í™˜
            if hasattr(self, '_primary_nn') and isinstance(self._primary_nn, nn.Module):
                logger.info(f"âœ… ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì™„ë£Œ: {self._primary_nn.__class__.__name__}")
                return self._primary_nn
            elif hasattr(self, 'default_network') and isinstance(self.default_network, nn.Module):
                self._primary_nn = self.default_network
                logger.info(f"âœ… ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì™„ë£Œ: {self.default_network.__class__.__name__}")
                return self._primary_nn
            else:
                # NO FALLBACK - ì‹¤íŒ¨ì‹œ ì—ëŸ¬
                raise RuntimeError("emotion_analyzer nn.Module ìƒì„± ì‹¤íŒ¨ - NO FALLBACK")
        
        # 4) ê°€ì¥ í° ë„¤íŠ¸ì›Œí¬ë¥¼ ëŒ€í‘œë¡œ ì„ íƒ(íŒŒë¼ë¯¸í„° ìˆ˜ ê¸°ì¤€)
        def num_params(m): 
            try:
                return sum(p.numel() for p in m.parameters())
            except Exception:
                return 0
        
        best_name, best_model = max(candidates, key=lambda kv: num_params(kv[1]))
        
        logger.info(f"AdvancedEmotionAnalyzer: {best_name}ì„(ë¥¼) primary_nnìœ¼ë¡œ ì„ íƒ (íŒŒë¼ë¯¸í„° ìˆ˜: {num_params(best_model):,})")
        
        # ìºì‹œ í›„ ë°˜í™˜
        self._primary_nn = best_model
        return self._primary_nn


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_advanced_emotion_analyzer():
    """ê³ ê¸‰ ê°ì • ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸"""
    try:
        analyzer = AdvancedEmotionAnalyzer()
        
        # í•œêµ­ì–´ í…ŒìŠ¤íŠ¸
        test_texts = [
            "ì˜¤ëŠ˜ ì •ë§ ê¸°ë»ì„œ ì–´ì©” ì¤„ ëª¨ë¥´ê² ì–´ìš”!",
            "ë„ˆë¬´ ìŠ¬í”„ê³  ìš°ìš¸í•´ì„œ ëˆˆë¬¼ì´ ë‚˜ë„¤ìš”.",
            "í™”ê°€ ë‚˜ì„œ ì •ë§ ì°¸ì„ ìˆ˜ê°€ ì—†ì–´ìš”!",
            "ë¬´ì„œì›Œì„œ ë–¨ë¦¬ê³  ì‹ì€ë•€ì´ í˜ëŸ¬ìš”.",
            "ê¹œì§ ë†€ë¼ì„œ ì‹¬ì¥ì´ ë–¨ì–´ì§ˆ ë»”í–ˆì–´ìš”."
        ]
        
        for text in test_texts:
            emotion = analyzer.analyze_emotion(text, language="ko")
            print(f"í…ìŠ¤íŠ¸: {text}")
            print(f"ê°ì •: {emotion.primary_emotion.value} (ì‹ ë¢°ë„: {emotion.confidence:.3f})")
            print(f"ì²˜ë¦¬ ë°©ë²•: {emotion.processing_method}")
            print("-" * 50)
        
        # ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        batch_results = analyzer.batch_analyze_emotions(test_texts, language="ko")
        print(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(batch_results)}ê°œ í…ìŠ¤íŠ¸")
        
        print("ê³ ê¸‰ ê°ì • ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise

    def _enhance_with_llm_analysis(self, text: str, keyword_emotion: int, keyword_score: float) -> Optional[Dict[str, Any]]:
        """LLMìœ¼ë¡œ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ê°•í™” (ì¡°ê±´ë¶€ í˜¸ì¶œ)"""
        
        # ì¡°ê±´ë¶€ LLM í˜¸ì¶œ ê²°ì •
        should_use_llm = self._should_use_llm_for_emotion(text, keyword_score)
        if not should_use_llm:
            return None
            
        # LLM í†µí•©ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° - ì¡°ê±´ë¶€ ì²˜ë¦¬ 
        if not LLM_INTEGRATION_AVAILABLE:
            logger.debug("LLM í†µí•©ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return None
        
        try:
            import asyncio
            from llm_module.advanced_llm_engine import get_llm_engine, LLMRequest, TaskComplexity
            
            # í‚¤ì›Œë“œ ê°ì •ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            emotion_name = self._emotion_id_to_name(keyword_emotion)
            
            # ê°•í™”ëœ ChatML í…œí”Œë¦¿ - ë§¤í•‘ í…Œì´ë¸”ê³¼ ë™ê¸°í™”ëœ ì—„ê²©í•œ ì œì•½
            prompt = f"""<|im_start|>system
ë‹¹ì‹ ì€ HelpingAI, ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš” ì œì•½ì‚¬í•­:
- ë°˜ë“œì‹œ ì§€ì •ëœ ê°ì • ëª©ë¡ì—ì„œë§Œ ì„ íƒí•˜ì„¸ìš”
- ë‹¤ë¥¸ ê°ì • ì´ë¦„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì£¼ì„¸ìš”
- ì¶”ê°€ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª…ì€ ê¸ˆì§€ì…ë‹ˆë‹¤

í•„ìˆ˜ JSON í˜•ì‹:
{{
    "emotion": "ê°ì •ëª…",
    "intensity": ì •ìˆ˜1-6,
    "confidence": ì‹¤ìˆ˜0.0-1.0,
    "valence": ì‹¤ìˆ˜-1.0-1.0,
    "arousal": ì‹¤ìˆ˜0.0-1.0,
    "reasoning": "ê°„ë‹¨í•œ_ì„¤ëª…"
}}

í—ˆìš©ëœ ê°ì • (ì´ê²ƒ ì™¸ ì‚¬ìš© ê¸ˆì§€):
- joy: ê¸°ì¨, í–‰ë³µ
- trust: ì‹ ë¢°, ë¯¿ìŒ  
- fear: ë‘ë ¤ì›€, ë¶ˆì•ˆ
- surprise: ë†€ëŒ, ì¶©ê²©
- sadness: ìŠ¬í””, ìš°ìš¸
- disgust: í˜ì˜¤, ê±°ë¶€ê°
- anger: ë¶„ë…¸, í™”ë‚¨ (frustration í¬í•¨)
- anticipation: ê¸°ëŒ€, í¬ë§
- neutral: ì¤‘ë¦½, ë¬´ê°ì •

ì˜ˆì‹œ:
{{"emotion": "anger", "intensity": 3, "confidence": 0.8, "valence": -0.3, "arousal": 0.6, "reasoning": "ë¶„ë…¸ í‘œí˜„ì´ ê°ì§€ë¨"}}

ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°: ìœ„ 9ê°œ ê°ì • ì¤‘ì—ì„œë§Œ ì„ íƒí•˜ê³ , ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.<|im_end|>
<|im_start|>user
{text}<|im_end|>
<|im_start|>assistant
"""

            # ì¤‘ì²© í•¨ìˆ˜ì—ì„œ ì‚¬ìš©í•  í† í° ìˆ˜ ë¯¸ë¦¬ ê³„ì‚°
            dynamic_tokens = self._calculate_dynamic_token_limit_direct(text, base_tokens=400)
            
            # ì´ë²¤íŠ¸ ë£¨í”„ ì•ˆì „í•œ ì‹¤í–‰ì„ ìœ„í•œ ë˜í¼
            def run_llm_analysis():
                try:
                    import threading
                    import concurrent.futures
                    
                    # ìƒˆë¡œìš´ ìŠ¤ë ˆë“œì—ì„œ ë¹„ë™ê¸° ì‹¤í–‰
                    def async_llm_call():
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            engine = get_llm_engine()
                            request = LLMRequest(
                                prompt=prompt,
                                task_type="emotion_analysis",  # HelpingAI EQ 95.89 ìš°ì„ 
                                complexity=TaskComplexity.MODERATE,
                                max_tokens=dynamic_tokens,
                                temperature=0.3
                            )
                            
                            response = loop.run_until_complete(engine.generate_async(request))
                            return response
                        finally:
                            loop.close()
                    
                    # ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰
                    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                        future = executor.submit(async_llm_call)
                        response = future.result(timeout=30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                    
                    if response and response.success:
                        # ì•ˆì „í•œ ì†ì„± ì ‘ê·¼ - generated_text ì†ì„± í™•ì¸
                        if hasattr(response, 'generated_text') and response.generated_text:
                            logger.info(f"âœ… LLM ì‘ë‹µ ì„±ê³µ - ê¸¸ì´: {len(response.generated_text)}")
                            return self._parse_llm_emotion_response(response.generated_text, keyword_emotion)
                        else:
                            logger.error(f"âŒ ì¹˜ëª…ì  ì‹¤íŒ¨: generated_text ì†ì„± ì—†ìŒ - ì‘ë‹µ êµ¬ì¡°: {type(response).__name__}")
                            logger.error(f"ì‘ë‹µ ì†ì„±ë“¤: {dir(response)}")
                            return None
                    else:
                        logger.warning(f"LLM ê°ì • ë¶„ì„ ì‹¤íŒ¨: {response.error_message if response else 'No response'}")
                        return None
                        
                except Exception as e:
                    logger.error(f"LLM ë¶„ì„ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                    return None
            
            return run_llm_analysis()
            
        except Exception as e:
            logger.error(f"LLM ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    def _detect_complex_ethical_question(self, text: str) -> bool:
        """ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ì¸ì§€ ê°ì§€"""
        ethical_keywords = [
            "ìœ¤ë¦¬ì ", "ë”œë ˆë§ˆ", "vs", "ëŒ€", "ì„ íƒ", "ë°©ì§€", "ë³´í˜¸", "ê¶Œë¦¬", "ì•ˆì „", 
            "ê°œì¸ì •ë³´", "í”„ë¼ì´ë²„ì‹œ", "ê°ì‹œ", "í…ŒëŸ¬", "ì˜ë£Œ", "ìì›", "ë°°ë¶„",
            "ììœ¨ì£¼í–‰", "ë¸Œë ˆì´í¬", "í™˜ì", "ì¸ê³µí˜¸í¡ê¸°", "ì •ì˜", "ê³µì •", "ë„ë•ì "
        ]
        
        text_lower = text.lower()
        keyword_count = sum(1 for keyword in ethical_keywords if keyword in text_lower)
        
        # í‚¤ì›Œë“œ 3ê°œ ì´ìƒì´ê³  ê¸¸ì´ê°€ 50ì ì´ìƒì´ë©´ ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨
        is_complex = keyword_count >= 3 and len(text) >= 50
        
        if is_complex:
            logger.info(f"ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ ê°ì§€: í‚¤ì›Œë“œ {keyword_count}ê°œ, ê¸¸ì´ {len(text)}ì")
        
        return is_complex

    def _calculate_dynamic_token_limit(self, text: str, base_tokens: int = 400) -> int:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ì— ë”°ë¥¸ ë™ì  í† í° ì œí•œ ê³„ì‚°"""
        if self._detect_complex_ethical_question(text):
            # ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ì˜ ê²½ìš° 2ë°° í† í° í• ë‹¹
            dynamic_tokens = base_tokens * 2
            logger.info(f"ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€ - í† í° ì œí•œ ì¦ê°€: {base_tokens} â†’ {dynamic_tokens}")
            return dynamic_tokens
        elif len(text) > 100:
            # ê¸´ í…ìŠ¤íŠ¸ì˜ ê²½ìš° 1.5ë°° í† í° í• ë‹¹
            dynamic_tokens = int(base_tokens * 1.5)
            logger.info(f"ê¸´ í…ìŠ¤íŠ¸ ê°ì§€ - í† í° ì œí•œ ì¦ê°€: {base_tokens} â†’ {dynamic_tokens}")
            return dynamic_tokens
        else:
            return base_tokens

    def _retry_llm_analysis_with_increased_tokens(self, text: str, prompt: str, base_tokens: int, max_retries: int = 3) -> Optional[Dict[str, Any]]:
        """í† í° ìˆ˜ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¤ë©´ì„œ LLM ë¶„ì„ ì¬ì‹œë„"""
        for attempt in range(max_retries):
            try:
                # ì¬ì‹œë„ë§ˆë‹¤ í† í° ìˆ˜ ì¦ê°€ (1.5ë°°ì”©)
                current_tokens = int(base_tokens * (1.5 ** attempt))
                logger.info(f"LLM ë¶„ì„ ì¬ì‹œë„ {attempt + 1}/{max_retries}: í† í° ìˆ˜ {current_tokens}")
                
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                engine = get_llm_engine()
                request = LLMRequest(
                    prompt=prompt,
                    task_type="emotion_interpretation",
                    complexity=TaskComplexity.COMPLEX,
                    max_tokens=current_tokens,
                    temperature=0.2
                )
                
                response = loop.run_until_complete(engine.generate_async(request))
                loop.close()
                
                if response.success:
                    # ì‘ë‹µì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if hasattr(response, 'generated_text') and response.generated_text:
                        # finish_reason í™•ì¸
                        if hasattr(response, 'finish_reason'):
                            if response.finish_reason == 'length':
                                logger.warning(f"ì¬ì‹œë„ {attempt + 1}: finish_reasonì´ 'length'ì—¬ì„œ ê³„ì† ì¬ì‹œë„")
                                continue  # ë‹¤ìŒ ì¬ì‹œë„ë¡œ
                            elif response.finish_reason == 'stop':
                                logger.info(f"ì¬ì‹œë„ {attempt + 1}: finish_reasonì´ 'stop'ìœ¼ë¡œ ì •ìƒ ì™„ë£Œ")
                        
                        # ì‘ë‹µ íŒŒì‹± ì‹œë„
                        parsed_result = self._parse_deep_llm_response(response.generated_text)
                        if parsed_result is not None:
                            logger.info(f"ì¬ì‹œë„ {attempt + 1}: ì„±ê³µì ìœ¼ë¡œ íŒŒì‹± ì™„ë£Œ")
                            return parsed_result
                        else:
                            logger.warning(f"ì¬ì‹œë„ {attempt + 1}: íŒŒì‹± ì‹¤íŒ¨, ë‹¤ìŒ ì¬ì‹œë„ ì§„í–‰")
                    else:
                        logger.warning(f"ì¬ì‹œë„ {attempt + 1}: ìƒì„±ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŒ")
                else:
                    logger.warning(f"ì¬ì‹œë„ {attempt + 1}: ì‘ë‹µ ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.error(f"ì¬ì‹œë„ {attempt + 1}: ì˜ˆì™¸ ë°œìƒ - {e}")
                
            # ì¬ì‹œë„ ê°„ê²© (1ì´ˆì”© ì¦ê°€)
            if attempt < max_retries - 1:
                import time
                time.sleep(attempt + 1)
        
        logger.error(f"ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {max_retries}íšŒ ì‹œë„ í›„ í¬ê¸°")
        return None
    
    def _detect_complex_ethical_question(self, text: str) -> bool:
        """ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ì¸ì§€ ê°ì§€"""
        ethical_keywords = [
            "ìœ¤ë¦¬ì ", "ë”œë ˆë§ˆ", "vs", "ëŒ€", "ì„ íƒ", "ë°©ì§€", "ë³´í˜¸", "ê¶Œë¦¬", "ì•ˆì „", 
            "ê°œì¸ì •ë³´", "í”„ë¼ì´ë²„ì‹œ", "ê°ì‹œ", "í…ŒëŸ¬", "ì˜ë£Œ", "ìì›", "ë°°ë¶„",
            "ììœ¨ì£¼í–‰", "ë¸Œë ˆì´í¬", "í™˜ì", "ì¸ê³µí˜¸í¡ê¸°", "ì •ì˜", "ê³µì •", "ë„ë•ì "
        ]
        
        text_lower = text.lower()
        keyword_count = sum(1 for keyword in ethical_keywords if keyword in text_lower)
        
        # í‚¤ì›Œë“œ 3ê°œ ì´ìƒì´ê³  ê¸¸ì´ê°€ 50ì ì´ìƒì´ë©´ ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨
        is_complex = keyword_count >= 3 and len(text) >= 50
        
        if is_complex:
            logger.info(f"ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ ê°ì§€: í‚¤ì›Œë“œ {keyword_count}ê°œ, ê¸¸ì´ {len(text)}ì")
        
        return is_complex

    def _calculate_dynamic_token_limit(self, text: str, base_tokens: int = 400) -> int:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ì— ë”°ë¥¸ ë™ì  í† í° ì œí•œ ê³„ì‚°"""
        if self._detect_complex_ethical_question(text):
            # ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ì˜ ê²½ìš° 2ë°° í† í° í• ë‹¹
            dynamic_tokens = base_tokens * 2
            logger.info(f"ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€ - í† í° ì œí•œ ì¦ê°€: {base_tokens} â†’ {dynamic_tokens}")
            return dynamic_tokens
        elif len(text) > 100:
            # ê¸´ í…ìŠ¤íŠ¸ì˜ ê²½ìš° 1.5ë°° í† í° í• ë‹¹
            dynamic_tokens = int(base_tokens * 1.5)
            logger.info(f"ê¸´ í…ìŠ¤íŠ¸ ê°ì§€ - í† í° ì œí•œ ì¦ê°€: {base_tokens} â†’ {dynamic_tokens}")
            return dynamic_tokens
        else:
            return base_tokens

    def _retry_llm_analysis_with_increased_tokens(self, text: str, prompt: str, base_tokens: int, max_retries: int = 3) -> Optional[Dict[str, Any]]:
        """í† í° ìˆ˜ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¤ë©´ì„œ LLM ë¶„ì„ ì¬ì‹œë„"""
        for attempt in range(max_retries):
            try:
                # ì¬ì‹œë„ë§ˆë‹¤ í† í° ìˆ˜ ì¦ê°€ (1.5ë°°ì”©)
                current_tokens = int(base_tokens * (1.5 ** attempt))
                logger.info(f"LLM ë¶„ì„ ì¬ì‹œë„ {attempt + 1}/{max_retries}: í† í° ìˆ˜ {current_tokens}")
                
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                engine = get_llm_engine()
                request = LLMRequest(
                    prompt=prompt,
                    task_type="emotion_interpretation",
                    complexity=TaskComplexity.COMPLEX,
                    max_tokens=current_tokens,
                    temperature=0.2
                )
                
                response = loop.run_until_complete(engine.generate_async(request))
                loop.close()
                
                if response.success:
                    # ì‘ë‹µì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if hasattr(response, 'generated_text') and response.generated_text:
                        # finish_reason í™•ì¸
                        if hasattr(response, 'finish_reason'):
                            if response.finish_reason == 'length':
                                logger.warning(f"ì¬ì‹œë„ {attempt + 1}: finish_reasonì´ 'length'ì—¬ì„œ ê³„ì† ì¬ì‹œë„")
                                continue  # ë‹¤ìŒ ì¬ì‹œë„ë¡œ
                            elif response.finish_reason == 'stop':
                                logger.info(f"ì¬ì‹œë„ {attempt + 1}: finish_reasonì´ 'stop'ìœ¼ë¡œ ì •ìƒ ì™„ë£Œ")
                        
                        # ì‘ë‹µ íŒŒì‹± ì‹œë„
                        parsed_result = self._parse_deep_llm_response(response.generated_text)
                        if parsed_result is not None:
                            logger.info(f"ì¬ì‹œë„ {attempt + 1}: ì„±ê³µì ìœ¼ë¡œ íŒŒì‹± ì™„ë£Œ")
                            return parsed_result
                        else:
                            logger.warning(f"ì¬ì‹œë„ {attempt + 1}: íŒŒì‹± ì‹¤íŒ¨, ë‹¤ìŒ ì¬ì‹œë„ ì§„í–‰")
                    else:
                        logger.warning(f"ì¬ì‹œë„ {attempt + 1}: ìƒì„±ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŒ")
                else:
                    logger.warning(f"ì¬ì‹œë„ {attempt + 1}: ì‘ë‹µ ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.error(f"ì¬ì‹œë„ {attempt + 1}: ì˜ˆì™¸ ë°œìƒ - {e}")
                
            # ì¬ì‹œë„ ê°„ê²© (1ì´ˆì”© ì¦ê°€)
            if attempt < max_retries - 1:
                import time
                time.sleep(attempt + 1)
        
        logger.error(f"ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {max_retries}íšŒ ì‹œë„ í›„ í¬ê¸°")
        return None

    
    def _should_use_llm_for_emotion(self, text: str, keyword_score: float) -> bool:
        """LLM ì‚¬ìš© ì¡°ê±´ ê²°ì • (ìµœì í™”ëœ ê³ í’ˆì§ˆ AI ë¶„ì„)"""
        
        # ë¹ˆ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
        if not text or len(text.strip()) == 0:
            return False
            
        # 1. í‚¤ì›Œë“œ ì ìˆ˜ê°€ ëª¨í˜¸í•œ ê²½ìš° (1.0~2.5 ì‚¬ì´) - ë²”ìœ„ í™•ëŒ€
        if 1.0 <= keyword_score <= 2.5:
            return True
            
        # 2. ë³µì¡í•œ í…ìŠ¤íŠ¸ (ê¸¸ì´ ê¸°ì¤€ ê°•í™”)
        if len(text) > 30:  # ê¸°ì¡´ 50ì—ì„œ 30ìœ¼ë¡œ ê°•í™”
            return True
            
        # 3. ë³µí•© ê°ì • í‘œí˜„ì´ ìˆëŠ” ê²½ìš° (ì„ê³„ê°’ ë‚®ì¶¤)
        emotion_keywords_count = sum(1 for emotion_dict in self.korean_emotion_keywords.values() 
                                   for keyword_list in emotion_dict.values()
                                   for keyword in keyword_list 
                                   if keyword in text.lower())
        if emotion_keywords_count >= 2:  # 3ê°œì—ì„œ 2ê°œë¡œ ê°•í™”
            return True
            
        # 4. ë¶€ì •ë¬¸ì´ë‚˜ ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡° (ì¡°ê±´ í™•ì¥)
        complex_patterns = ['ì•Š', 'ì—†', 'ëª»', 'ì•„ë‹ˆ', 'ê·¸ëŸ¬ë‚˜', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 
                           'ì˜¤íˆë ¤', 'ë°˜ë©´', 'ëŒ€ì‹ ', 'ë¬¼ë¡ ', 'í•˜ì§€ë§Œ', 'ê·¸ë ‡ì§€ë§Œ']
        if any(pattern in text for pattern in complex_patterns):
            return True
            
        # 5. ê°ì • ê°•ë„ í‘œí˜„ (ìƒˆë¡œìš´ ì¡°ê±´)
        intensity_words = ['ë§¤ìš°', 'ì •ë§', 'ë„ˆë¬´', 'ì•„ì£¼', 'ì™„ì „íˆ', 'ì—„ì²­', 'êµ‰ì¥íˆ', 
                          'ì‹¬í•˜ê²Œ', 'ê¹Šì´', 'ê·¹ë„ë¡œ', 'ìƒë‹¹íˆ', 'ê½¤', 'ì œë²•']
        if any(word in text for word in intensity_words):
            return True
            
        # 6. ë³µí•© ë¬¸ì¥ êµ¬ì¡° (ìƒˆë¡œìš´ ì¡°ê±´)
        if text.count(',') >= 2 or text.count('.') >= 2 or '?' in text or '!' in text:
            return True
            
        # 7. ë¯¸ë¬˜í•œ ê°ì • í‘œí˜„ (ìƒˆë¡œìš´ ì¡°ê±´)
        subtle_emotions = ['ë¯¸ë¬˜', 'ì• ë§¤', 'ë³µì¡', 'í˜¼ë€', 'ê°ˆë“±', 'ë”œë ˆë§ˆ', 'ê³ ë¯¼', 
                          'ìƒê°', 'ëŠë‚Œ', 'ê¸°ë¶„', 'ë¶„ìœ„ê¸°', 'ë‰˜ì•™ìŠ¤']
        if any(word in text for word in subtle_emotions):
            return True
            
        # ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ê°ì • í‘œí˜„ë§Œ í‚¤ì›Œë“œ ë¶„ì„ ì‚¬ìš©
        return False
    
    def _emotion_id_to_name(self, emotion_id: int) -> str:
        """ê°ì • IDë¥¼ í•œêµ­ì–´ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
        emotion_mapping = {
            1: "ê¸°ì¨",    # JOY
            2: "ì‹ ë¢°",    # TRUST  
            3: "ë‘ë ¤ì›€",  # FEAR
            4: "ë†€ëŒ",    # SURPRISE
            5: "ìŠ¬í””",    # SADNESS
            6: "í˜ì˜¤",    # DISGUST
            7: "ë¶„ë…¸",    # ANGER
            8: "ê¸°ëŒ€",    # ANTICIPATION
            0: "ì¤‘ë¦½"     # NEUTRAL
        }
        return emotion_mapping.get(emotion_id, "ì•Œ ìˆ˜ ì—†ìŒ")
    
    def _parse_llm_emotion_response(self, response_text: str, original_emotion: int) -> Dict[str, Any]:
        """LLM ê°ì • ë¶„ì„ ì‘ë‹µ íŒŒì‹± (JSON ìš°ì„ , í…ìŠ¤íŠ¸ íŒŒì‹± fallback)"""
        try:
            # 1. JSON íŒŒì‹± ì‹œë„
            try:
                import json
                import re
                
                # ë‹¤ì–‘í•œ JSON íŒ¨í„´ ì‹œë„ (ê°œì„ ëœ íŒŒì‹±)
                json_patterns = [
                    r'\{[^{}]*\}',  # ë‹¨ìˆœ JSON ë¸”ë¡
                    r'\{[^{}]*?"[^"]*"[^{}]*\}',  # ë¬¸ìì—´ í¬í•¨ JSON
                    r'\{.*?\}',  # ëª¨ë“  ë¬¸ì í¬í•¨ JSON (ìµœëŒ€í•œ ìœ ì—°)
                ]
                
                parsed_json = None
                for pattern in json_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL)
                    for match in matches:
                        try:
                            # ê³µë°± ë¬¸ì ì •ë¦¬
                            cleaned_json = re.sub(r'\s+', ' ', match).strip()
                            
                            # ì¼ë°˜ì ì¸ JSON íŒŒì‹± ì˜¤ë¥˜ ìˆ˜ì •
                            cleaned_json = cleaned_json.replace('" emotion"', '"emotion"')
                            cleaned_json = cleaned_json.replace('" confidence"', '"confidence"')
                            cleaned_json = cleaned_json.replace('" intensity"', '"intensity"')
                            cleaned_json = cleaned_json.replace('" valence"', '"valence"')
                            cleaned_json = cleaned_json.replace('" arousal"', '"arousal"')
                            cleaned_json = cleaned_json.replace('" reasoning"', '"reasoning"')
                            
                            parsed_json = json.loads(cleaned_json)
                            logger.info(f"JSON íŒŒì‹± ì„±ê³µ: {cleaned_json}")
                            break
                        except json.JSONDecodeError:
                            continue
                    if parsed_json:
                        break
                
                if parsed_json:
                    # JSONì—ì„œ ê²°ê³¼ ì¶”ì¶œ
                    result = {
                        'emotion': original_emotion,  # ê¸°ë³¸ê°’
                        'confidence': 0.5,
                        'reasoning': response_text
                    }
                    
                    # ì˜ì–´ í•„ë“œëª… ì²˜ë¦¬ (HelpingAI ì‘ë‹µ í˜•ì‹)
                    if 'emotion' in parsed_json:
                        emotion_text = parsed_json['emotion']
                        mapped_emotion = self._name_to_emotion_id(emotion_text)
                        if mapped_emotion is None:
                            logger.error(f"âŒ ê°ì • ë§¤í•‘ ì‹¤íŒ¨ë¡œ ì¸í•œ íŒŒì‹± ì‹¤íŒ¨: '{emotion_text}'")
                            return None  # í•™ìŠµ ì˜¤ì—¼ ë°©ì§€ë¥¼ ìœ„í•œ ëª…í™•í•œ ì‹¤íŒ¨ ë°˜í™˜
                        result['emotion'] = mapped_emotion
                    
                    # ì‹ ë¢°ë„ ì²˜ë¦¬
                    if 'confidence' in parsed_json:
                        try:
                            result['confidence'] = float(parsed_json['confidence'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    # ê°ì •ê°•ë„ ì²˜ë¦¬
                    if 'intensity' in parsed_json:
                        try:
                            result['intensity'] = int(parsed_json['intensity'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    # valenceì™€ arousal ì²˜ë¦¬
                    if 'valence' in parsed_json:
                        try:
                            result['valence'] = float(parsed_json['valence'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    if 'arousal' in parsed_json:
                        try:
                            result['arousal'] = float(parsed_json['arousal'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    # ì¶”ê°€ ì •ë³´
                    if 'reasoning' in parsed_json:
                        result['reasoning'] = parsed_json['reasoning']
                    
                    # í•œêµ­ì–´ í•„ë“œëª… ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
                    if 'ì£¼ìš”ê°ì •' in parsed_json:
                        emotion_text = parsed_json['ì£¼ìš”ê°ì •']
                        mapped_emotion = self._name_to_emotion_id(emotion_text)
                        if mapped_emotion is None:
                            logger.error(f"âŒ í•œêµ­ì–´ ê°ì • ë§¤í•‘ ì‹¤íŒ¨ë¡œ ì¸í•œ íŒŒì‹± ì‹¤íŒ¨: '{emotion_text}'")
                            return None  # í•™ìŠµ ì˜¤ì—¼ ë°©ì§€ë¥¼ ìœ„í•œ ëª…í™•í•œ ì‹¤íŒ¨ ë°˜í™˜
                        result['emotion'] = mapped_emotion
                    
                    if 'ì‹ ë¢°ë„' in parsed_json:
                        try:
                            result['confidence'] = float(parsed_json['ì‹ ë¢°ë„'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    if 'ê°ì •ê°•ë„' in parsed_json:
                        try:
                            result['intensity'] = int(parsed_json['ê°ì •ê°•ë„'])
                        except (ValueError, TypeError) as parse_error:
                            logger.debug(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {parse_error}")
                    
                    if 'ì›ì¸ë¶„ì„' in parsed_json:
                        result['cause_analysis'] = parsed_json['ì›ì¸ë¶„ì„']
                    
                    logger.info(f"JSON íŒŒì‹± ì„±ê³µ: ê°ì •={result['emotion']}, ì‹ ë¢°ë„={result['confidence']}")
                    return result
                    
            except (json.JSONDecodeError, AttributeError) as e:
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹±ìœ¼ë¡œ ì „í™˜: {e}")
            
            # 2. ê¸°ì¡´ í…ìŠ¤íŠ¸ íŒŒì‹± (fallback)
            lines = response_text.split('\n')
            result = {
                'emotion': original_emotion,  # ê¸°ë³¸ê°’
                'confidence': 0.5,
                'reasoning': response_text
            }
            
            for line in lines:
                line = line.strip()
                if 'ì£¼ìš” ê°ì •:' in line or 'ì£¼ìš”ê°ì •:' in line:
                    emotion_text = line.split(':')[1].strip()
                    mapped_emotion = self._name_to_emotion_id(emotion_text)
                    if mapped_emotion is None:
                        logger.error(f"âŒ í…ìŠ¤íŠ¸ íŒŒì‹± ê°ì • ë§¤í•‘ ì‹¤íŒ¨: '{emotion_text}'")
                        return None  # í•™ìŠµ ì˜¤ì—¼ ë°©ì§€
                    result['emotion'] = mapped_emotion
                elif 'ì‹ ë¢°ë„:' in line:
                    try:
                        conf_text = line.split(':')[1].strip()
                        result['confidence'] = float(conf_text)
                    except:
                        pass
                elif 'ê°ì •ê°•ë„:' in line:
                    try:
                        intensity_text = line.split(':')[1].strip()
                        result['intensity'] = int(intensity_text)
                    except:
                        pass
                        
            logger.info(f"í…ìŠ¤íŠ¸ íŒŒì‹± ì„±ê³µ: ê°ì •={result['emotion']}, ì‹ ë¢°ë„={result['confidence']}")
            return result
            
        except Exception as e:
            logger.error(f"LLM ì‘ë‹µ íŒŒì‹± ì™„ì „ ì‹¤íŒ¨: {e}")
            # fallback ê¸ˆì§€ ì›ì¹™ì— ë”°ë¼ None ë°˜í™˜
            return None
    
    
    
    def _name_to_emotion_id(self, emotion_name: str) -> int:
        """í•œêµ­ì–´/ì˜ì–´ ê°ì • ì´ë¦„ì„ IDë¡œ ë³€í™˜ (ì´ì¤‘ ì–¸ì–´ ì§€ì›)"""
        # ì…ë ¥ ì •ê·œí™”
        emotion_name = emotion_name.lower().strip()
        
        name_mapping = {
            # í•œêµ­ì–´ ë§¤í•‘ (ê¸°ì¡´)
            "ê¸°ì¨": 1, "í–‰ë³µ": 1, "ì¦ê±°ì›€": 1,
            "ì‹ ë¢°": 2, "ë¯¿ìŒ": 2,
            "ë‘ë ¤ì›€": 3, "ë¶ˆì•ˆ": 3, "ê±±ì •": 3, "ë¬´ì„œì›€": 3,
            "ë†€ëŒ": 4, "ê¹œì§": 4, "ë†€ë¼ì›€": 4,
            "ìŠ¬í””": 5, "ìš°ìš¸": 5, "ì„œê¸€í””": 5,
            "í˜ì˜¤": 6, "ì‹«ìŒ": 6, "ì—­ê²¨ì›€": 6,
            "ë¶„ë…¸": 7, "í™”": 7, "ì§œì¦": 7, "í™”ë‚¨": 7,
            "ê¸°ëŒ€": 8, "ì˜ˆìƒ": 8, "ê¸°ëŒ€ê°": 8,
            "ì¤‘ë¦½": 0, "ë¬´ê°ì •": 0, "ë³´í†µ": 0,
            # ì¶”ê°€ ê°ì •ë“¤
            "ì•ˆë„": 10, "relief": 10,
            "ì£„ì±…ê°": 11, "guilt": 11,
            "ìˆ˜ì¹˜ì‹¬": 12, "shame": 12,
            "ìë¶€ì‹¬": 13, "pride": 13,
            "ê²½ë©¸": 14, "contempt": 14,
            "ì§ˆíˆ¬": 15, "envy": 15,
            "ê°ì‚¬": 16, "gratitude": 16,
            
            # ì˜ì–´ ë§¤í•‘ (LLM ì‘ë‹µìš©)
            "joy": 1, "happiness": 1, "happy": 1,
            "trust": 2,
            "fear": 3, "anxiety": 3, "worried": 3, "afraid": 3,
            "surprise": 4, "surprised": 4,
            "sadness": 5, "sad": 5, "depression": 5, "depressed": 5,
            "disgust": 6, "disgusted": 6,
            "anger": 7, "angry": 7, "rage": 7, "mad": 7,
            "anticipation": 8, "expectation": 8,
            "neutral": 0, "none": 0, "normal": 0
        }
        
        # ì •í™•í•œ ë§¤ì¹­ ìš°ì„ 
        if emotion_name in name_mapping:
            return name_mapping[emotion_name]
        
        # ë¶€ë¶„ ë§¤ì¹­ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        for name, emotion_id in name_mapping.items():
            if name in emotion_name or emotion_name in name:
                return emotion_id
                
        return EmotionState.NEUTRAL.value

# ìƒë‹´ì‚¬ ëª¨ë“ˆ ê¸°ëŠ¥ ì¶”ê°€
class EmotionCounselorModule:
    """ê°ì • ë¶„ì„ ìƒë‹´ì‚¬ ëª¨ë“ˆ - ê°ì • ì›ì¸ ë¶„ì„ ë° í›„íšŒ ì•Œê³ ë¦¬ì¦˜ ë³´ì¡°"""
    
    def __init__(self):
        self.llm_engine = None
        if LLM_INTEGRATION_AVAILABLE:
            try:
                from llm_module.advanced_llm_engine import get_llm_engine
                self.llm_engine = get_llm_engine()
            except Exception as e:
                logger.warning(f"ìƒë‹´ì‚¬ ëª¨ë“ˆ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def analyze_emotion_causality(self, emotion_data: EmotionData, context: str) -> Dict[str, Any]:
        """ê°ì • ì›ì¸ ë¶„ì„ - ìƒë‹´ì‚¬ ì—­í• """
        if not self.llm_engine:
            return {"analysis": "LLM ì—”ì§„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "confidence": 0.0}
        
        try:
            from llm_module.advanced_llm_engine import LLMRequest, TaskComplexity
            
            prompt = f"""ìƒë‹´ì‚¬ë¡œì„œ ë‹¤ìŒ ê°ì • ìƒíƒœì˜ ì›ì¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ê°ì • ì •ë³´:
- ì£¼ìš” ê°ì •: {emotion_data.primary_emotion.name}
- ê°•ë„: {emotion_data.intensity.name}
- ì‹ ë¢°ë„: {emotion_data.confidence:.3f}
- ê°ì •ê°€: {emotion_data.valence:.3f}
- ê°ì„±ë„: {emotion_data.arousal:.3f}

ìƒí™© ë§¥ë½: "{context}"

ìƒë‹´ì‚¬ ê´€ì ì—ì„œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ê°ì • ë°œìƒì˜ ê·¼ë³¸ ì›ì¸
2. ê°ì • ë°˜ì‘ì˜ ì ì ˆì„± í‰ê°€
3. ê°ì • ì¡°ì ˆ ë°©ì•ˆ
4. í–¥í›„ ìœ ì‚¬ ìƒí™© ëŒ€ì²˜ë²•
5. ì´ ê°ì •ì´ ì˜ì‚¬ê²°ì •ì— ë¯¸ì¹  ì˜í–¥"""

            request = LLMRequest(
                prompt=prompt,
                task_type="causal_explanation",
                complexity=TaskComplexity.EXPERT,
                max_tokens=1000,  # ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ì— ëŒ€í•œ ê³ ì • í† í° í• ë‹¹
                temperature=0.3
            )
            
            # ë™ê¸° ë°©ì‹ìœ¼ë¡œ LLM í˜¸ì¶œ
            def run_llm_causality():
                import concurrent.futures
                def async_llm_call():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        return loop.run_until_complete(self.llm_engine.generate_async(request))
                    finally:
                        loop.close()
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(async_llm_call)
                    return future.result(timeout=30)
            
            try:
                response = run_llm_causality()
                if response and response.success:
                    return {
                        "analysis": response.generated_text,
                        "confidence": response.confidence,
                        "processing_time": response.processing_time
                    }
                else:
                    return {"analysis": "ë¶„ì„ ì‹¤íŒ¨", "confidence": 0.0}
            except Exception as e:
                logger.error(f"ê°ì • ì›ì¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
                return {"analysis": "ë¶„ì„ ì˜¤ë¥˜", "confidence": 0.0}
                
        except Exception as e:
            logger.error(f"ê°ì • ì›ì¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"analysis": f"ì˜¤ë¥˜: {e}", "confidence": 0.0}
    
    def _detect_complex_ethical_question(self, text: str) -> bool:
        """ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ì¸ì§€ ê°ì§€"""
        ethical_keywords = [
            "ìœ¤ë¦¬ì ", "ë”œë ˆë§ˆ", "vs", "ëŒ€", "ì„ íƒ", "ë°©ì§€", "ë³´í˜¸", "ê¶Œë¦¬", "ì•ˆì „", 
            "ê°œì¸ì •ë³´", "í”„ë¼ì´ë²„ì‹œ", "ê°ì‹œ", "í…ŒëŸ¬", "ì˜ë£Œ", "ìì›", "ë°°ë¶„",
            "ììœ¨ì£¼í–‰", "ë¸Œë ˆì´í¬", "í™˜ì", "ì¸ê³µí˜¸í¡ê¸°", "ì •ì˜", "ê³µì •", "ë„ë•ì "
        ]
        
        text_lower = text.lower()
        keyword_count = sum(1 for keyword in ethical_keywords if keyword in text_lower)
        
        # í‚¤ì›Œë“œ 3ê°œ ì´ìƒì´ê³  ê¸¸ì´ê°€ 50ì ì´ìƒì´ë©´ ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨
        is_complex = keyword_count >= 3 and len(text) >= 50
        
        if is_complex:
            logger.info(f"ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ ê°ì§€: í‚¤ì›Œë“œ {keyword_count}ê°œ, ê¸¸ì´ {len(text)}ì")
        
        return is_complex

    def _calculate_dynamic_token_limit(self, text: str, base_tokens: int = 400) -> int:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ì— ë”°ë¥¸ ë™ì  í† í° ì œí•œ ê³„ì‚°"""
        if self._detect_complex_ethical_question(text):
            # ë³µì¡í•œ ìœ¤ë¦¬ì  ì§ˆë¬¸ì˜ ê²½ìš° 2ë°° í† í° í• ë‹¹
            dynamic_tokens = base_tokens * 2
            logger.info(f"ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€ - í† í° ì œí•œ ì¦ê°€: {base_tokens} â†’ {dynamic_tokens}")
            return dynamic_tokens
        elif len(text) > 100:
            # ê¸´ í…ìŠ¤íŠ¸ì˜ ê²½ìš° 1.5ë°° í† í° í• ë‹¹
            dynamic_tokens = int(base_tokens * 1.5)
            logger.info(f"ê¸´ í…ìŠ¤íŠ¸ ê°ì§€ - í† í° ì œí•œ ì¦ê°€: {base_tokens} â†’ {dynamic_tokens}")
            return dynamic_tokens
        else:
            return base_tokens

    async def validate_regret_reasoning(self, regret_data: Dict[str, Any], scenario: str) -> Dict[str, Any]:
        """í›„íšŒ ì•Œê³ ë¦¬ì¦˜ì˜ ì¶”ë¡  íƒ€ë‹¹ì„± ê²€ì¦"""
        if not self.llm_engine:
            return {"validation": "ê²€ì¦ ë¶ˆê°€", "confidence": 0.0}
        
        try:
            from llm_module.advanced_llm_engine import LLMRequest, TaskComplexity
            
            prompt = f"""í›„íšŒ ë¶„ì„ ê²°ê³¼ì˜ íƒ€ë‹¹ì„±ì„ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ê²€ì¦í•´ì£¼ì„¸ìš”.

ì‹œë‚˜ë¦¬ì˜¤: "{scenario}"

í›„íšŒ ë¶„ì„ ê²°ê³¼:
- í›„íšŒ ê°•ë„: {regret_data.get('intensity', 'N/A')}
- ì˜ˆì¸¡ ì˜¤ë¥˜: {regret_data.get('prediction_error', 'N/A')}
- ë” ë‚˜ì€ ì„ íƒ: {regret_data.get('better_options', 'N/A')}

ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. í›„íšŒ ê°•ë„ì˜ ì ì ˆì„±
2. ëŒ€ì•ˆ ì„ íƒì˜ í˜„ì‹¤ì„±
3. ì˜ˆì¸¡ ì˜¤ë¥˜ ê³„ì‚°ì˜ í•©ë¦¬ì„±
4. ëˆ„ë½ëœ ì¤‘ìš” ìš”ì†Œ
5. ì „ë°˜ì  íƒ€ë‹¹ì„± ì ìˆ˜ (0-100)"""

            request = LLMRequest(
                prompt=prompt,
                task_type="ethical_analysis",
                complexity=TaskComplexity.EXPERT,
                max_tokens=400,
                temperature=0.2
            )
            
            # ë™ê¸° ë°©ì‹ìœ¼ë¡œ LLM í˜¸ì¶œ
            def run_llm_validation():
                import concurrent.futures
                def async_llm_call():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        return loop.run_until_complete(self.llm_engine.generate_async(request))
                    finally:
                        loop.close()
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(async_llm_call)
                    return future.result(timeout=30)
            
            try:
                response = run_llm_validation()
                if response and response.success:
                    # íƒ€ë‹¹ì„± ì ìˆ˜ ì¶”ì¶œ
                    validity_score = self._extract_validity_score(response.generated_text)
                    
                    return {
                        "validation": response.generated_text,
                        "validity_score": validity_score,
                        "confidence": response.confidence
                    }
                else:
                    return {"validation": "ê²€ì¦ ì‹¤íŒ¨", "validity_score": 0}
            except Exception as e:
                logger.error(f"í›„íšŒ ì¶”ë¡  ê²€ì¦ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                return {"validation": f"ì‹¤í–‰ ì˜¤ë¥˜: {e}", "validity_score": 0}
                
        except Exception as e:
            logger.error(f"í›„íšŒ ì¶”ë¡  ê²€ì¦ ì˜¤ë¥˜: {e}")
            return {"validation": f"ì˜¤ë¥˜: {e}", "validity_score": 0}
    
    def _extract_validity_score(self, analysis_text: str) -> float:
        """ë¶„ì„ í…ìŠ¤íŠ¸ì—ì„œ íƒ€ë‹¹ì„± ì ìˆ˜ ì¶”ì¶œ"""
        import re
        
        # ì ìˆ˜ íŒ¨í„´ ì°¾ê¸°
        score_patterns = [
            r'íƒ€ë‹¹ì„± ì ìˆ˜[:\s]*(\d+)',
            r'ì ìˆ˜[:\s]*(\d+)',
            r'(\d+)ì ',
            r'(\d+)/100'
        ]
        
        for pattern in score_patterns:
            match = re.search(pattern, analysis_text)
            if match:
                try:
                    score = float(match.group(1))
                    return min(100.0, max(0.0, score)) / 100.0  # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
                except:
                    continue
        
        return 0.5  # ê¸°ë³¸ê°’

if __name__ == "__main__":
    test_advanced_emotion_analyzer()