🚀 Red Heart AI 통합 학습 시스템 시작
===========================================
[0;34m[INFO][0m 작업 디렉토리: /mnt/c/large_project/linux_red_heart
[0;34m[INFO][0m Red Heart AI 통합 환경 상태 확인 중...
[0;32m[SUCCESS][0m ✅ red_heart_env 가상환경 존재
[0;32m[SUCCESS][0m ✅ faiss-test conda 환경 존재
[0;32m[SUCCESS][0m ✅ FAISS 설치됨 및 작동 확인
✅ Red Heart AI 통합 환경 활성화 완료
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (함께 활성화됨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;32m[SUCCESS][0m ✅ 주요 패키지 (torch, transformers, numpy) 설치됨
[0;32m[SUCCESS][0m 🎉 모든 환경이 이미 준비되어 있습니다!
✅ Red Heart AI 통합 환경 활성화 완료
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (함께 활성화됨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;32m[SUCCESS][0m ✅ Red Heart AI 통합 환경 활성화 완료
[0;32m[SUCCESS][0m    - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
[0;32m[SUCCESS][0m    - conda: faiss-test 환경 준비됨
[0;32m[SUCCESS][0m    - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
[0;32m[SUCCESS][0m    - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;34m[INFO][0m Red Heart AI 통합 학습 시스템 시작
[0;34m[INFO][0m 환경 분리: conda(faiss) + venv(transformers,torch)
[0;34m[INFO][0m Red Heart AI 통합 학습 시스템 실행 시작...
[0;34m[INFO][0m 실행 모드: unified-test
[0;34m[INFO][0m 🧪 320M v2 통합 시스템 학습 테스트 모드...
[0;34m[INFO][0m    - 그래디언트 체크 (NaN, 끊김 검증)
[0;34m[INFO][0m    - 텐서 계산 무결성 확인
[0;34m[INFO][0m    - 파라미터 업데이트 없음 (베이스라인 회귀)
2025-08-12 22:31:30,000 - RedHeart.Config - INFO - GPU 직접 사용: None (사용률: 0.0%, 필요: 500MB)
2025-08-12 22:31:30,012 - workflow_aware_memory_manager - INFO - ✅ HF 모델 래퍼와 메모리 매니저 통합 완료
2025-08-12 22:31:30,012 - workflow_aware_memory_manager - INFO - ✅ HF 모델 래퍼와 메모리 매니저 통합 완료
2025-08-12 22:31:30,012 - dynamic_swap_manager - INFO - RedHeartDynamicSwapManager 초기화 완료
2025-08-12 22:31:30,013 - RedHeart.UnifiedTrainingV2 - INFO - ============================================================
2025-08-12 22:31:30,013 - RedHeart.UnifiedTrainingV2 - INFO - Red Heart AI 통합 학습 시스템 v2 초기화
2025-08-12 22:31:30,013 - RedHeart.UnifiedTrainingV2 - INFO -   - 모델 크기: 320M 파라미터
2025-08-12 22:31:30,013 - RedHeart.UnifiedTrainingV2 - INFO -   - 디바이스: cuda
2025-08-12 22:31:30,013 - RedHeart.UnifiedTrainingV2 - INFO -   - 모드: train-test
2025-08-12 22:31:30,013 - RedHeart.UnifiedTrainingV2 - INFO -   - 학습률: 0.0001
2025-08-12 22:31:30,014 - RedHeart.UnifiedTrainingV2 - INFO - ============================================================
2025-08-12 22:31:30,014 - RedHeart.UnifiedTrainingV2 - INFO - 
============================================================
2025-08-12 22:31:30,014 - RedHeart.UnifiedTrainingV2 - INFO - 🚀 Red Heart AI 통합 학습 시작
2025-08-12 22:31:30,014 - RedHeart.UnifiedTrainingV2 - INFO - ============================================================
2025-08-12 22:31:30,014 - RedHeart.UnifiedTrainingV2 - INFO - 
📊 데이터 준비 시작
2025-08-12 22:31:30,015 - RedHeart.UnifiedTrainingV2 - INFO - 🔄 LLM 전처리 시작...
2025-08-12 22:31:30,016 - RedHeart.DataPreprocessing - INFO - 데이터 전처리 파이프라인 초기화 (캐시: preprocessed_cache)
2025-08-12 22:31:30,017 - RedHeart.DataPreprocessing - INFO - 🔄 HelpingAI 9B 4-bit 모델 로딩 중...
2025-08-12 22:31:30,018 - RedHeart.AdvancedLLM - INFO - 모델 설정 준비 완료: ['helpingai', 'dialogpt', 'blenderbot']
2025-08-12 22:31:30,018 - RedHeart.AdvancedLLM - INFO - 동적 GPU-RAM 스왑 시스템 초기화 완료
2025-08-12 22:31:30,020 - RedHeart.AdvancedLLM - ERROR - Llama.cpp 모델 로드 실패: 'NoneType' object cannot be interpreted as an integer
2025-08-12 22:31:30,020 - RedHeart.AdvancedLLM - WARNING - Llama.cpp 모델 로드 실패, HuggingFace 모델로 폴백: 'NoneType' object cannot be interpreted as an integer
2025-08-12 22:31:30,023 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-08-12 22:31:30,241 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /microsoft/DialoGPT-small/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-08-12 22:31:30,247 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/microsoft/DialoGPT-small/49c537161a457d5256512f9d2d38a87d81ae0f0e/tokenizer_config.json HTTP/1.1" 200 0
2025-08-12 22:31:30,730 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/microsoft/DialoGPT-small/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-08-12 22:31:31,037 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /microsoft/DialoGPT-small/resolve/main/config.json HTTP/1.1" 307 0
2025-08-12 22:31:31,045 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/microsoft/DialoGPT-small/49c537161a457d5256512f9d2d38a87d81ae0f0e/config.json HTTP/1.1" 200 0
2025-08-12 22:31:41,051 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-08-12 22:31:41,700 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /microsoft/DialoGPT-small/resolve/main/generation_config.json HTTP/1.1" 307 0
2025-08-12 22:31:41,707 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/microsoft/DialoGPT-small/49c537161a457d5256512f9d2d38a87d81ae0f0e/generation_config.json HTTP/1.1" 200 0
2025-08-12 22:31:41,899 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /microsoft/DialoGPT-small/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
Device set to use cuda:0
2025-08-12 22:31:41,910 - RedHeart.AdvancedLLM - INFO - HuggingFace 모델 로드 완료: microsoft/DialoGPT-small
2025-08-12 22:31:41,910 - RedHeart.AdvancedLLM - INFO - HuggingFace 모델 로드 완료: microsoft/DialoGPT-small
2025-08-12 22:31:42,106 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /facebook/blenderbot-400M-distill/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-08-12 22:31:42,113 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/facebook/blenderbot-400M-distill/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/tokenizer_config.json HTTP/1.1" 200 0
2025-08-12 22:31:42,347 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/facebook/blenderbot-400M-distill/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-08-12 22:31:42,558 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /facebook/blenderbot-400M-distill/resolve/main/config.json HTTP/1.1" 307 0
2025-08-12 22:31:42,565 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/facebook/blenderbot-400M-distill/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/config.json HTTP/1.1" 200 0
2025-08-12 22:31:42,831 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /facebook/blenderbot-400M-distill/resolve/main/model.safetensors HTTP/1.1" 404 0
2025-08-12 22:31:42,833 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-08-12 22:31:42,844 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-08-12 22:31:43,038 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/facebook/blenderbot-400M-distill HTTP/1.1" 200 5369
2025-08-12 22:31:43,251 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/facebook/blenderbot-400M-distill/commits/main HTTP/1.1" 200 2762
2025-08-12 22:31:43,464 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/facebook/blenderbot-400M-distill/discussions?p=0 HTTP/1.1" 200 13826
2025-08-12 22:31:43,677 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/facebook/blenderbot-400M-distill/commits/refs%2Fpr%2F7 HTTP/1.1" 200 3727
2025-08-12 22:31:43,875 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /facebook/blenderbot-400M-distill/resolve/refs%2Fpr%2F7/model.safetensors.index.json HTTP/1.1" 404 0
2025-08-12 22:31:44,904 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /facebook/blenderbot-400M-distill/resolve/refs%2Fpr%2F7/model.safetensors HTTP/1.1" 302 0
2025-08-12 22:31:44,933 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /facebook/blenderbot-400M-distill/resolve/main/generation_config.json HTTP/1.1" 307 0
2025-08-12 22:31:44,939 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/facebook/blenderbot-400M-distill/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/generation_config.json HTTP/1.1" 200 0
2025-08-12 22:31:45,137 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /facebook/blenderbot-400M-distill/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
Device set to use cuda:0
2025-08-12 22:31:45,141 - RedHeart.AdvancedLLM - INFO - HuggingFace 모델 로드 완료: facebook/blenderbot-400M-distill
2025-08-12 22:31:45,141 - RedHeart.AdvancedLLM - INFO - HuggingFace 모델 로드 완료: facebook/blenderbot-400M-distill
2025-08-12 22:31:45,142 - RedHeart.AdvancedLLM - INFO - 기본 모델 설정: microsoft_DialoGPT-small
2025-08-12 22:31:45,142 - RedHeart.DataPreprocessing - INFO - ✅ 기본 모델 초기화 성공
2025-08-12 22:31:45,142 - RedHeart.DataPreprocessing - INFO - ✅ LLM 초기화 완료 (15.13초)
2025-08-12 22:31:45,144 - RedHeart.UnifiedTrainingV2 - INFO - 전처리할 샘플 수: 3
2025-08-12 22:31:45,144 - RedHeart.DataPreprocessing - INFO - 📊 배치 전처리 시작: 3개 샘플
2025-08-12 22:31:45,144 - RedHeart.DataPreprocessing - INFO - 처리 중: 1-3/3
2025-08-12 22:31:45,145 - RedHeart.DataPreprocessing - ERROR - 전처리 실패: 'AdvancedLLMEngine' object has no attribute 'generate'
2025-08-12 22:31:45,145 - RedHeart.DataPreprocessing - ERROR - 전처리 실패: 'AdvancedLLMEngine' object has no attribute 'generate'
2025-08-12 22:31:45,145 - RedHeart.DataPreprocessing - ERROR - 전처리 실패: 'AdvancedLLMEngine' object has no attribute 'generate'
2025-08-12 22:31:45,145 - RedHeart.DataPreprocessing - INFO - ✅ 배치 전처리 완료: 3개 성공
2025-08-12 22:31:45,145 - RedHeart.DataPreprocessing - INFO - 💾 전처리 데이터 저장: preprocessed_dataset_v2.json
2025-08-12 22:31:45,148 - RedHeart.DataPreprocessing - INFO - ✅ 3개 샘플 저장 완료
2025-08-12 22:31:45,149 - RedHeart.DataPreprocessing - INFO - 🧹 LLM 언로드 중...
2025-08-12 22:31:45,149 - RedHeart.AdvancedLLM - INFO - 모델 언로드: microsoft_DialoGPT-small
2025-08-12 22:31:45,150 - RedHeart.AdvancedLLM - INFO - 모델 언로드: facebook_blenderbot-400M-distill
2025-08-12 22:31:45,289 - RedHeart.AdvancedLLM - INFO - ✅ LLM 엔진 정리 완료
2025-08-12 22:31:45,411 - RedHeart.DataPreprocessing - INFO - ✅ LLM 언로드 완료
2025-08-12 22:31:45,533 - RedHeart.UnifiedTrainingV2 - INFO - ✅ LLM 전처리 완료
2025-08-12 22:31:45,533 - RedHeart.UnifiedTrainingV2 - INFO - 📂 전처리된 데이터 로드: preprocessed_dataset_v2.json
2025-08-12 22:31:45,535 - RedHeart.UnifiedTrainingV2 - INFO - ✅ 데이터 준비 완료
2025-08-12 22:31:45,535 - RedHeart.UnifiedTrainingV2 - INFO -   - 학습: 2 샘플
2025-08-12 22:31:45,535 - RedHeart.UnifiedTrainingV2 - INFO -   - 검증: 1 샘플
2025-08-12 22:31:45,535 - RedHeart.UnifiedTrainingV2 - INFO - 
🤖 모델 초기화 시작
2025-08-12 22:31:45,535 - RedHeart.ModuleSelector - INFO - 실행 모드 변경: training
2025-08-12 22:31:45,536 - RedHeart.ModuleSelector - INFO - 활성 모듈 수: 9
2025-08-12 22:31:45,536 - RedHeart.ModuleSelector - DEBUG - 활성 모듈: ['bentham_calculator', 'bentham_fromm_head', 'emotion_dsp_simulator', 'emotion_empathy_head', 'kalman_filter', 'meta_integration_head', 'regret_learning_head', 'semantic_surd_head', 'unified_backbone']
2025-08-12 22:31:45,536 - RedHeart.UnifiedTrainingV2 - INFO - 📊 메모리 상태:
2025-08-12 22:31:45,536 - RedHeart.UnifiedTrainingV2 - INFO -   - 필요: 400.0 MB
2025-08-12 22:31:45,536 - RedHeart.UnifiedTrainingV2 - INFO -   - 가용: 8191.6 MB
2025-08-12 22:31:45,537 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: bentham_calculator
2025-08-12 22:31:53,093 - RedHeart.AdvancedBenthamCalculator - INFO - ✅ 벤담 계산기 강화 모듈 통합: 72.8M 파라미터 추가
2025-08-12 22:31:53,108 - RedHeart.AdvancedBenthamCalculator - INFO - 벤담 계산기 윤리 MoE 시스템 초기화 완료 (4개 전문가)
2025-08-12 22:31:53,119 - dynamic_gpu_manager - INFO - Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-08-12 22:31:53,119 - RedHeart.ThreeViewScenarioSystem - INFO - 3뷰 시나리오 시스템 GPU 메모리 관리 활성화
2025-08-12 22:31:53,119 - RedHeart.ThreeViewScenarioSystem - INFO - 3뷰 시나리오 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-08-12 22:31:53,119 - RedHeart.AdvancedBenthamCalculator - INFO - 벤담 계산기 3뷰 시나리오 시스템 초기화 완료
2025-08-12 22:31:53,120 - RedHeart.AdvancedBenthamCalculator - INFO - 신경망 가중치 예측기 로딩 중...
2025-08-12 22:31:53,120 - RedHeart.Config - INFO - GPU 직접 사용: None (사용률: 3.5%, 필요: 100MB)
2025-08-12 22:31:53,126 - RedHeart.AdvancedBenthamCalculator - INFO - 신경망 가중치 예측기 로드: cuda (100MB)
2025-08-12 22:31:53,126 - RedHeart.AdvancedBenthamCalculator - INFO - 메모리 사용량: RAM 782MB, GPU 285MB
2025-08-12 22:31:53,127 - dynamic_gpu_manager - INFO - Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-08-12 22:31:53,127 - RedHeart.PhaseControllerHook - INFO - PhaseController Hook GPU 메모리 관리 활성화
2025-08-12 22:31:53,127 - RedHeart.PhaseControllerHook - INFO - PhaseController Hook 시스템 초기화 완료
2025-08-12 22:31:53,127 - RedHeart.PhaseControllerHook - INFO - 성능 모니터링 시작
2025-08-12 22:31:53,127 - RedHeart.AdvancedBenthamCalculator - INFO - 벤담 계산기 PhaseController Hook 초기화 완료
2025-08-12 22:31:53,128 - dynamic_gpu_manager - INFO - Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-08-12 22:31:53,128 - RedHeart.LegalExpertSystem - INFO - 법률 전문가 시스템 GPU 메모리 관리 활성화
2025-08-12 22:31:53,128 - RedHeart.LegalExpertSystem - INFO - 법률 전문가 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-08-12 22:31:53,128 - RedHeart.LegalExpertSystem - INFO - inference 모드 - 법률 전문가 시스템 활성화
2025-08-12 22:31:53,128 - RedHeart.AdvancedBenthamCalculator - INFO - 벤담 계산기 법률 전문가 시스템 초기화 완료
2025-08-12 22:31:53,129 - RedHeart.AdvancedBenthamCalculator - INFO - 고급 벤담 쾌락 계산기 초기화 완료 (레이지 로딩 활성화)
2025-08-12 22:31:53,129 - RedHeart.AdvancedBenthamCalculator - INFO - 🔨 벤담 계산기 기본 PyTorch 네트워크 생성 중...
2025-08-12 22:31:53,131 - RedHeart.AdvancedBenthamCalculator - INFO - ✅ 벤담 계산기 기본 네트워크 생성 완료 (device: cuda:0)
2025-08-12 22:31:53,131 - RedHeart.AdvancedBenthamCalculator - INFO -    - 파라미터 수: 3,137
2025-08-12 22:31:53,131 - RedHeart.UnifiedTrainingV2 - WARNING - 벤담 계산기 로드 실패: 'AdvancedBenthamCalculator' object has no attribute 'to'
2025-08-12 22:31:53,131 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: emotion_dsp_simulator
2025-08-12 22:31:53,160 - emotion_dsp_simulator - INFO - EmotionDSPSimulator 초기화 완료 (~20M 파라미터)
2025-08-12 22:31:53,177 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: kalman_filter
2025-08-12 22:31:53,181 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: unified_backbone
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
2025-08-12 22:31:53,579 - unified_backbone - INFO - 백본 총 파라미터: 92,817,412 (92.82M)
2025-08-12 22:31:53,579 - unified_backbone - INFO - 학습 가능 파라미터: 92,817,412 (92.82M)
2025-08-12 22:31:53,793 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: bentham_fromm_head
2025-08-12 22:31:53,828 - unified_heads - INFO - 벤담 헤드 파라미터: 5,460,699 (5.46M)
2025-08-12 22:31:53,843 - RedHeart.UnifiedTrainingV2 - INFO - ✅ 벤담 헤드 로드 성공 (20M)
2025-08-12 22:31:53,844 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: emotion_empathy_head
2025-08-12 22:31:53,871 - unified_heads - INFO - 감정 헤드 파라미터: 6,708,575 (6.71M)
2025-08-12 22:31:53,886 - RedHeart.UnifiedTrainingV2 - INFO - ✅ 감정 헤드 로드 성공 (22M)
2025-08-12 22:31:53,886 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: meta_integration_head
2025-08-12 22:31:53,887 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: regret_learning_head
2025-08-12 22:31:53,928 - unified_heads - INFO - 후회 헤드 파라미터: 11,233,289 (11.23M)
2025-08-12 22:31:53,946 - RedHeart.UnifiedTrainingV2 - INFO - ✅ 후회 헤드 로드 성공 (22M)
2025-08-12 22:31:53,946 - RedHeart.UnifiedTrainingV2 - DEBUG - 모듈 로드: semantic_surd_head
2025-08-12 22:31:53,967 - unified_heads - INFO - SURD 헤드 파라미터: 4,992,779 (4.99M)
2025-08-12 22:31:53,980 - RedHeart.UnifiedTrainingV2 - INFO - ✅ SURD 헤드 로드 성공 (16M)
2025-08-12 22:31:53,980 - RedHeart.UnifiedTrainingV2 - INFO - 🎯 학습 필수 모듈 강제 로드 중...
2025-08-12 22:31:53,980 - RedHeart.UnifiedTrainingV2 - INFO -   - regret_analyzer 추가 로드
2025-08-12 22:31:53,980 - RedHeart.UnifiedTrainingV2 - INFO -   - surd_analyzer 추가 로드
2025-08-12 22:31:53,980 - RedHeart.UnifiedTrainingV2 - INFO -   - emotion_head 로드
2025-08-12 22:31:53,981 - RedHeart.UnifiedTrainingV2 - INFO -   - bentham_head 로드
2025-08-12 22:31:53,981 - RedHeart.UnifiedTrainingV2 - INFO -   - regret_head 로드
2025-08-12 22:31:53,981 - RedHeart.UnifiedTrainingV2 - INFO -   - surd_head 로드
2025-08-12 22:31:53,981 - RedHeart.UnifiedTrainingV2 - INFO - ✅ 모델 초기화 완료
2025-08-12 22:31:53,981 - RedHeart.UnifiedTrainingV2 - INFO - 🔧 옵티마이저 초기화 중...
2025-08-12 22:31:53,982 - RedHeart.UnifiedTrainingV2 - INFO -   백본 파라미터 추가됨
2025-08-12 22:31:53,982 - RedHeart.UnifiedTrainingV2 - INFO -   bentham 헤드 파라미터 추가됨
2025-08-12 22:31:53,982 - RedHeart.UnifiedTrainingV2 - INFO -   emotion 헤드 파라미터 추가됨
2025-08-12 22:31:53,983 - RedHeart.UnifiedTrainingV2 - INFO -   regret 헤드 파라미터 추가됨
2025-08-12 22:31:53,983 - RedHeart.UnifiedTrainingV2 - INFO -   surd 헤드 파라미터 추가됨
2025-08-12 22:31:53,983 - RedHeart.UnifiedTrainingV2 - INFO -   dsp 분석기 파라미터 추가됨
2025-08-12 22:31:53,984 - RedHeart.UnifiedTrainingV2 - INFO -   kalman 분석기 파라미터 추가됨
2025-08-12 22:31:53,984 - RedHeart.UnifiedTrainingV2 - INFO - ✅ 옵티마이저 초기화 완료
2025-08-12 22:31:53,985 - RedHeart.UnifiedTrainingV2 - INFO -   - 옵티마이저: AdamW
2025-08-12 22:31:53,985 - RedHeart.UnifiedTrainingV2 - INFO -   - 학습률: 0.0001
2025-08-12 22:31:53,985 - RedHeart.UnifiedTrainingV2 - INFO -   - 스케줄러: CosineAnnealingLR
2025-08-12 22:31:53,985 - RedHeart.UnifiedTrainingV2 - INFO -   - 총 파라미터: 122,395,197
2025-08-12 22:31:53,986 - RedHeart.UnifiedTrainingV2 - INFO -   - 학습 가능 파라미터: 122,395,197
2025-08-12 22:31:53,986 - RedHeart.UnifiedTrainingV2 - INFO - 
📚 Epoch 1/10 시작
2025-08-12 22:31:53,987 - RedHeart.UnifiedTrainingV2 - INFO - 📊 에포크 상세 정보:
2025-08-12 22:31:53,987 - RedHeart.UnifiedTrainingV2 - INFO -   - 총 샘플 수: 2
2025-08-12 22:31:53,988 - RedHeart.UnifiedTrainingV2 - INFO -   - 배치 크기: 4
2025-08-12 22:31:53,988 - RedHeart.UnifiedTrainingV2 - INFO -   - 배치 수: 0
2025-08-12 22:31:53,988 - RedHeart.UnifiedTrainingV2 - ERROR - ❌ 오류 발생: float division by zero
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_training_v2.py", line 535, in run
    train_loss = self.train_epoch(epoch)
                 ^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/unified_training_v2.py", line 361, in train_epoch
    avg_epoch_loss = total_loss / num_batches
                     ~~~~~~~~~~~^~~~~~~~~~~~~
ZeroDivisionError: float division by zero
2025-08-12 22:31:53,990 - RedHeart.UnifiedTrainingV2 - INFO - 
🧹 시스템 정리 중...
2025-08-12 22:31:54,127 - RedHeart.UnifiedTrainingV2 - INFO - ✅ 정리 완료

============================================================
모듈 선택기 요약 - 모드: training
============================================================

📊 메모리 사용량:
  - 총 파라미터: 287,210,742
  - 총 메모리: 1103.1 MB
  - GPU 메모리: 400.0 MB
  - CPU 메모리: 703.1 MB

✅ 활성 모듈 (9개):

  [analyzer]
    - bentham_calculator: 8,330,000 params, 32.0 MB
    - emotion_dsp_simulator: 1,180,000 params, 5.0 MB

  [core]
    - unified_backbone: 104,000,000 params, 400.0 MB

  [filter]
    - kalman_filter: 742 params, 0.1 MB

  [head]
    - bentham_fromm_head: 41,700,000 params, 160.0 MB
    - emotion_empathy_head: 48,600,000 params, 186.0 MB
    - meta_integration_head: 14,000,000 params, 54.0 MB
    - regret_learning_head: 41,700,000 params, 160.0 MB
    - semantic_surd_head: 27,700,000 params, 106.0 MB
============================================================

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_training_v2.py", line 631, in <module>
    main()
  File "/mnt/c/large_project/linux_red_heart/unified_training_v2.py", line 627, in main
    system.run()
  File "/mnt/c/large_project/linux_red_heart/unified_training_v2.py", line 535, in run
    train_loss = self.train_epoch(epoch)
                 ^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/unified_training_v2.py", line 361, in train_epoch
    avg_epoch_loss = total_loss / num_batches
                     ~~~~~~~~~~~^~~~~~~~~~~~~
ZeroDivisionError: float division by zero
[0;34m[INFO][0m 학습 시스템 정리 중...
[0;34m[INFO][0m GPU 메모리 정리...
[0;32m[SUCCESS][0m 정리 완료
