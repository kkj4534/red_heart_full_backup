"""
Sweet Spot Detector - ëª¨ë“ˆë³„ ìµœì  ì—í­ íƒì§€ ì‹œìŠ¤í…œ
ê° ëª¨ë“ˆì´ ìµœê³  ì„±ëŠ¥ì„ ë³´ì´ëŠ” ì—í­ì„ ìë™ìœ¼ë¡œ íƒì§€
"""

import numpy as np
import torch
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import json
import logging
from datetime import datetime
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.signal import find_peaks
import pandas as pd

logger = logging.getLogger(__name__)


class SweetSpotDetector:
    """
    Sweet Spot íƒì§€ ì‹œìŠ¤í…œ
    - ëª¨ë“ˆë³„ ìµœì  ì„±ëŠ¥ ì—í­ íƒì§€
    - ìˆ˜ë ´ íŒ¨í„´ ë¶„ì„
    - ê³¼ì í•© ì‹œì  ê°ì§€
    - ì•ˆì •ì„± í‰ê°€
    """
    
    def __init__(self,
                 window_size: int = 5,
                 stability_threshold: float = 0.01,
                 patience: int = 10,
                 min_epochs: int = 10):
        """
        Args:
            window_size: ì´ë™ í‰ê·  ìœˆë„ìš° í¬ê¸°
            stability_threshold: ì•ˆì •ì„± íŒë‹¨ ì„ê³„ê°’
            patience: ì„±ëŠ¥ ê°œì„  ì—†ì´ ê¸°ë‹¤ë¦¬ëŠ” ì—í­ ìˆ˜
            min_epochs: ìµœì†Œ í•™ìŠµ ì—í­ (ì´ì „ì—ëŠ” Sweet Spot íŒë‹¨ ì•ˆí•¨)
        """
        self.window_size = window_size
        self.stability_threshold = stability_threshold
        self.patience = patience
        self.min_epochs = min_epochs
        
        # ëª¨ë“ˆë³„ ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ (train/val ë¶„ë¦¬)
        self.module_histories = defaultdict(lambda: {
            'train_losses': [],
            'val_losses': [],
            'train_accuracies': [],
            'val_accuracies': [],
            'epochs': [],
            'gradients': [],
            'learning_rates': [],
            'overfitting_scores': [],  # val_loss - train_loss
            'generalization_gaps': []  # val_acc - train_acc
        })
        
        # ëª¨ë“ˆê°„ ìƒí˜¸ì‘ìš© ë©”íŠ¸ë¦­
        self.interaction_metrics = defaultdict(lambda: {
            'synergy_scores': [],  # ëª¨ë“ˆ ì¡°í•© ì‹œë„ˆì§€
            'correlation_matrix': [],  # ëª¨ë“ˆê°„ ì„±ëŠ¥ ìƒê´€ê´€ê³„
            'coupling_strength': [],  # ëª¨ë“ˆê°„ ê²°í•©ë„
            'information_flow': []  # ëª¨ë“ˆê°„ ì •ë³´ íë¦„
        })
        
        # Sweet Spot ì •ë³´
        self.sweet_spots = {}
        self.convergence_points = {}
        self.overfitting_points = {}
        self.interaction_sweet_spots = {}  # ëª¨ë“ˆ ì¡°í•© ìµœì ì 
        
        logger.info("âœ… Sweet Spot Detector ì´ˆê¸°í™”")
        logger.info(f"  - ìœˆë„ìš° í¬ê¸°: {window_size}")
        logger.info(f"  - ì•ˆì •ì„± ì„ê³„ê°’: {stability_threshold}")
        logger.info(f"  - Patience: {patience}")
    
    def update(self, 
               epoch: int,
               train_module_metrics: Dict[str, Dict[str, float]],
               val_module_metrics: Dict[str, Dict[str, float]],
               learning_rate: float = None):
        """
        ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ë° Sweet Spot íƒì§€ (train/val ë¶„ë¦¬)
        
        Args:
            epoch: í˜„ì¬ ì—í­
            train_module_metrics: í•™ìŠµ ëª¨ë“ˆë³„ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
            val_module_metrics: ê²€ì¦ ëª¨ë“ˆë³„ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
            learning_rate: í˜„ì¬ í•™ìŠµë¥ 
        """
        # ëª¨ë“  ëª¨ë“ˆ ì´ë¦„ ìˆ˜ì§‘
        all_modules = set(train_module_metrics.keys()) | set(val_module_metrics.keys())
        
        for module_name in all_modules:
            history = self.module_histories[module_name]
            train_metrics = train_module_metrics.get(module_name, {})
            val_metrics = val_module_metrics.get(module_name, {})
            
            # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            history['epochs'].append(epoch)
            history['train_losses'].append(train_metrics.get('loss', 0))
            history['val_losses'].append(val_metrics.get('loss', 0))
            history['train_accuracies'].append(train_metrics.get('accuracy', 0))
            history['val_accuracies'].append(val_metrics.get('accuracy', 0))
            
            # ê³¼ì í•© ì ìˆ˜ ê³„ì‚° (val_loss - train_loss)
            overfitting_score = val_metrics.get('loss', 0) - train_metrics.get('loss', 0)
            history['overfitting_scores'].append(overfitting_score)
            
            # ì¼ë°˜í™” ê°­ ê³„ì‚° (train_acc - val_acc)
            generalization_gap = train_metrics.get('accuracy', 0) - val_metrics.get('accuracy', 0)
            history['generalization_gaps'].append(generalization_gap)
            
            if 'gradient_norm' in train_metrics:
                history['gradients'].append(train_metrics['gradient_norm'])
            
            if learning_rate:
                history['learning_rates'].append(learning_rate)
            
            # Sweet Spot íƒì§€ (ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìŒ“ì¸ í›„)
            if epoch >= self.min_epochs:
                self._detect_sweet_spot(module_name, epoch)
                self._detect_convergence(module_name, epoch)
                self._detect_overfitting_improved(module_name, epoch)
        
        # ëª¨ë“ˆê°„ ìƒí˜¸ì‘ìš© ë¶„ì„
        if epoch >= self.min_epochs:
            self._analyze_module_interactions(epoch, all_modules)
    
    def _detect_sweet_spot(self, module_name: str, epoch: int):
        """ëª¨ë“ˆë³„ Sweet Spot íƒì§€ (train/val ê· í˜• ê³ ë ¤)"""
        history = self.module_histories[module_name]
        val_losses = history['val_losses']
        train_losses = history['train_losses']
        
        if len(val_losses) < self.window_size:
            return
        
        # ìµœê·¼ ìœˆë„ìš°ì˜ ì†ì‹¤
        recent_val_losses = val_losses[-self.window_size:]
        recent_train_losses = train_losses[-self.window_size:]
        recent_overfitting = history['overfitting_scores'][-self.window_size:]
        
        # ì¡°ê±´ 1: ë‚®ì€ ê²€ì¦ ì†ì‹¤
        avg_val_loss = np.mean(recent_val_losses)
        avg_train_loss = np.mean(recent_train_losses)
        
        # ì¡°ê±´ 2: ì•ˆì •ì„± (ë‚®ì€ ë¶„ì‚°)
        val_std = np.std(recent_val_losses)
        is_stable = val_std < self.stability_threshold
        
        # ì¡°ê±´ 3: ìˆ˜ë ´ (ì†ì‹¤ ê°ì†Œìœ¨ì´ ë‚®ìŒ)
        if len(val_losses) >= self.window_size * 2:
            prev_window = val_losses[-self.window_size*2:-self.window_size]
            improvement = (np.mean(prev_window) - avg_val_loss) / (np.mean(prev_window) + 1e-10)
            is_converged = abs(improvement) < 0.01  # 1% ë¯¸ë§Œ ê°œì„ 
        else:
            is_converged = False
        
        # ì¡°ê±´ 4: ê³¼ì í•© ì œì–´
        avg_overfitting = np.mean(recent_overfitting)
        is_not_overfitting = avg_overfitting < 0.1  # 10% ë¯¸ë§Œ ì°¨ì´
        
        # Sweet Spot íŒë‹¨
        if is_stable and is_not_overfitting and (is_converged or avg_val_loss < 0.1):
            # ì´ì „ Sweet Spotë³´ë‹¤ ë‚˜ì€ì§€ í™•ì¸
            if module_name not in self.sweet_spots or \
               avg_val_loss < self.sweet_spots[module_name]['val_loss']:
                
                self.sweet_spots[module_name] = {
                    'epoch': epoch,
                    'val_loss': avg_val_loss,
                    'train_loss': avg_train_loss,
                    'loss': avg_val_loss,  # í˜¸í™˜ì„± ìœ ì§€
                    'std': val_std,
                    'stable': is_stable,
                    'converged': is_converged,
                    'overfitting_score': avg_overfitting
                }
                
                logger.info(f"  ğŸ¯ Sweet Spot ë°œê²¬: {module_name}")
                logger.info(f"     - ì—í­: {epoch}")
                logger.info(f"     - Val Loss: {avg_val_loss:.4f} (Â±{val_std:.4f})")
                logger.info(f"     - Overfitting: {avg_overfitting:.4f}")
    
    def _detect_convergence(self, module_name: str, epoch: int):
        """ìˆ˜ë ´ ì‹œì  íƒì§€ (val_loss ê¸°ì¤€)"""
        history = self.module_histories[module_name]
        val_losses = history['val_losses']
        
        if len(val_losses) < self.patience:
            return
        
        # ìµœê·¼ patience ì—í­ ë™ì•ˆì˜ ê°œì„  í™•ì¸
        recent_val_losses = val_losses[-self.patience:]
        best_recent = min(recent_val_losses)
        
        # ê°œì„ ì´ ê±°ì˜ ì—†ìœ¼ë©´ ìˆ˜ë ´ìœ¼ë¡œ íŒë‹¨
        improvements = []
        for i in range(1, len(recent_val_losses)):
            if recent_val_losses[i-1] > 0:
                improvement = (recent_val_losses[i-1] - recent_val_losses[i]) / recent_val_losses[i-1]
                improvements.append(improvement)
        
        avg_improvement = np.mean(improvements) if improvements else 0
        
        if abs(avg_improvement) < 0.001:  # 0.1% ë¯¸ë§Œ ê°œì„ 
            if module_name not in self.convergence_points:
                self.convergence_points[module_name] = {
                    'epoch': epoch,
                    'val_loss': best_recent,
                    'train_loss': history['train_losses'][-1] if history['train_losses'] else 0,
                    'improvement_rate': avg_improvement
                }
                logger.info(f"  ğŸ“Š ìˆ˜ë ´ ê°ì§€: {module_name} @ epoch {epoch}")
    
    def _detect_overfitting_improved(self, module_name: str, epoch: int):
        """ê°œì„ ëœ ê³¼ì í•© ì‹œì  íƒì§€ (train/val ê°­ ê¸°ë°˜)"""
        history = self.module_histories[module_name]
        val_losses = history['val_losses']
        train_losses = history['train_losses']
        overfitting_scores = history['overfitting_scores']
        
        if len(val_losses) < self.window_size * 2:
            return
        
        # ìµœê·¼ ìœˆë„ìš°ì˜ ê³¼ì í•© ì ìˆ˜
        recent_overfitting = np.mean(overfitting_scores[-self.window_size:])
        prev_overfitting = np.mean(overfitting_scores[-self.window_size*2:-self.window_size])
        
        # ê²€ì¦ ì†ì‹¤ ì¦ê°€ í™•ì¸
        recent_val = np.mean(val_losses[-self.window_size:])
        prev_val = np.mean(val_losses[-self.window_size*2:-self.window_size])
        val_increase = (recent_val - prev_val) / (prev_val + 1e-10)
        
        # í•™ìŠµ ì†ì‹¤ì€ ê³„ì† ê°ì†Œí•˜ëŠ”ì§€ í™•ì¸
        recent_train = np.mean(train_losses[-self.window_size:])
        prev_train = np.mean(train_losses[-self.window_size*2:-self.window_size])
        train_decrease = (prev_train - recent_train) / (prev_train + 1e-10)
        
        # ê³¼ì í•© ì¡°ê±´: val loss ì¦ê°€ & train loss ê°ì†Œ & ê³¼ì í•© ì ìˆ˜ ì¦ê°€
        if (val_increase > 0.02 and  # val loss 2% ì´ìƒ ì¦ê°€
            train_decrease > 0.01 and  # train lossëŠ” ê³„ì† ê°ì†Œ
            recent_overfitting > prev_overfitting * 1.2):  # ê³¼ì í•© ì ìˆ˜ 20% ì¦ê°€
            
            if module_name not in self.overfitting_points:
                self.overfitting_points[module_name] = {
                    'epoch': epoch - self.window_size,  # ê³¼ì í•© ì‹œì‘ ì‹œì 
                    'val_increase': val_increase,
                    'train_decrease': train_decrease,
                    'overfitting_score': recent_overfitting
                }
                logger.warning(f"  âš ï¸ ê³¼ì í•© ê°ì§€: {module_name} @ epoch {epoch - self.window_size}")
                logger.warning(f"     - Val ì¦ê°€: {val_increase:.2%}, Train ê°ì†Œ: {train_decrease:.2%}")
    
    def _analyze_module_interactions(self, epoch: int, module_names: set):
        """ëª¨ë“ˆê°„ ìƒí˜¸ì‘ìš© ë¶„ì„"""
        import itertools
        
        # ëª¨ë“ˆ ìŒë³„ ìƒê´€ê´€ê³„ ê³„ì‚°
        correlation_matrix = {}
        synergy_scores = {}
        
        module_list = list(module_names)
        for mod1, mod2 in itertools.combinations(module_list, 2):
            if mod1 not in self.module_histories or mod2 not in self.module_histories:
                continue
                
            # ìµœê·¼ ì†ì‹¤ê°’ë“¤ì˜ ìƒê´€ê´€ê³„
            losses1 = self.module_histories[mod1]['val_losses'][-self.window_size:]
            losses2 = self.module_histories[mod2]['val_losses'][-self.window_size:]
            
            if len(losses1) == len(losses2) and len(losses1) > 1:
                correlation = np.corrcoef(losses1, losses2)[0, 1]
                correlation_matrix[f"{mod1}-{mod2}"] = correlation
                
                # ì‹œë„ˆì§€ ì ìˆ˜: ìŒì˜ ìƒê´€ê´€ê³„ëŠ” ë³´ì™„ì , ì–‘ì˜ ìƒê´€ê´€ê³„ëŠ” ì˜ì¡´ì 
                if correlation < -0.3:  # ë³´ì™„ì  ê´€ê³„
                    synergy_scores[f"{mod1}-{mod2}"] = 1.0 - abs(correlation)
                elif correlation > 0.7:  # ê°•í•œ ì˜ì¡´ ê´€ê³„
                    synergy_scores[f"{mod1}-{mod2}"] = correlation * 0.5
                else:  # ë…ë¦½ì  ê´€ê³„
                    synergy_scores[f"{mod1}-{mod2}"] = 0.7
        
        # ì „ì²´ ëª¨ë“ˆ ì¡°í•©ì˜ ì‹œë„ˆì§€ ê³„ì‚°
        if synergy_scores:
            avg_synergy = np.mean(list(synergy_scores.values()))
            
            # ìƒí˜¸ì‘ìš© ë©”íŠ¸ë¦­ ì €ì¥
            self.interaction_metrics[epoch] = {
                'synergy_scores': synergy_scores,
                'correlation_matrix': correlation_matrix,
                'avg_synergy': avg_synergy,
                'module_count': len(module_list)
            }
            
            # Sweet Spot ì¡°í•© ì°¾ê¸°
            if avg_synergy > 0.7 and epoch not in self.interaction_sweet_spots:
                self.interaction_sweet_spots[epoch] = {
                    'synergy': avg_synergy,
                    'best_pairs': sorted(synergy_scores.items(), 
                                        key=lambda x: x[1], reverse=True)[:3]
                }
                logger.info(f"  ğŸ”— ëª¨ë“ˆ ìƒí˜¸ì‘ìš© Sweet Spot @ epoch {epoch}")
                logger.info(f"     - í‰ê·  ì‹œë„ˆì§€: {avg_synergy:.3f}")
    
    def get_optimal_epochs(self) -> Dict[str, int]:
        """
        ê° ëª¨ë“ˆì˜ ìµœì  ì—í­ ë°˜í™˜
        
        Returns:
            ëª¨ë“ˆë³„ ìµœì  ì—í­ ë”•ì…”ë„ˆë¦¬
        """
        optimal_epochs = {}
        
        for module_name in self.module_histories.keys():
            # Sweet Spotì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
            if module_name in self.sweet_spots:
                optimal_epochs[module_name] = self.sweet_spots[module_name]['epoch']
            # ìˆ˜ë ´ì ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
            elif module_name in self.convergence_points:
                optimal_epochs[module_name] = self.convergence_points[module_name]['epoch']
            # ê³¼ì í•© ì§ì „ ì‚¬ìš©
            elif module_name in self.overfitting_points:
                optimal_epochs[module_name] = max(1, self.overfitting_points[module_name]['epoch'] - 1)
            # ê¸°ë³¸ê°’: ìµœì € ê²€ì¦ ì†ì‹¤ ì—í­
            else:
                val_losses = self.module_histories[module_name]['val_losses']
                if val_losses:
                    optimal_epochs[module_name] = val_losses.index(min(val_losses)) + 1
        
        return optimal_epochs
    
    def get_module_status(self, module_name: str) -> Dict[str, Any]:
        """
        íŠ¹ì • ëª¨ë“ˆì˜ í˜„ì¬ ìƒíƒœ ë°˜í™˜
        
        Args:
            module_name: ëª¨ë“ˆ ì´ë¦„
            
        Returns:
            ëª¨ë“ˆ ìƒíƒœ ì •ë³´
        """
        if module_name not in self.module_histories:
            return {'status': 'not_found'}
        
        history = self.module_histories[module_name]
        # train/val ë¶„ë¦¬ëœ ì†ì‹¤ ì²˜ë¦¬
        train_losses = history.get('train_losses', [])
        val_losses = history.get('val_losses', [])
        
        # validation lossë¥¼ ì£¼ìš” ì§€í‘œë¡œ ì‚¬ìš© (ê³¼ì í•© ë°©ì§€)
        primary_losses = val_losses if val_losses else train_losses
        
        status = {
            'total_epochs': len(history['epochs']),
            'current_train_loss': train_losses[-1] if train_losses else None,
            'current_val_loss': val_losses[-1] if val_losses else None,
            'best_train_loss': min(train_losses) if train_losses else None,
            'best_val_loss': min(val_losses) if val_losses else None,
            'best_epoch': val_losses.index(min(val_losses)) + 1 if val_losses else 
                         (train_losses.index(min(train_losses)) + 1 if train_losses else None),
            'overfitting_score': (val_losses[-1] - train_losses[-1]) if (val_losses and train_losses) else None
        }
        
        # Sweet Spot ì •ë³´
        if module_name in self.sweet_spots:
            status['sweet_spot'] = self.sweet_spots[module_name]
        
        # ìˆ˜ë ´ ì •ë³´
        if module_name in self.convergence_points:
            status['convergence'] = self.convergence_points[module_name]
        
        # ê³¼ì í•© ì •ë³´
        if module_name in self.overfitting_points:
            status['overfitting'] = self.overfitting_points[module_name]
        
        return status
    
    def plot_module_analysis(self, module_name: str, save_path: Optional[str] = None):
        """
        ëª¨ë“ˆ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
        
        Args:
            module_name: ëª¨ë“ˆ ì´ë¦„
            save_path: ì €ì¥ ê²½ë¡œ (Noneì´ë©´ í‘œì‹œë§Œ)
        """
        if module_name not in self.module_histories:
            logger.warning(f"ëª¨ë“ˆ {module_name}ì˜ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        history = self.module_histories[module_name]
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # 1. ì†ì‹¤ ê³¡ì„  (train/val ë¶„ë¦¬)
        ax = axes[0, 0]
        if history.get('train_losses'):
            ax.plot(history['epochs'], history['train_losses'], 'b-', label='Train Loss', alpha=0.7)
        if history.get('val_losses'):
            ax.plot(history['epochs'], history['val_losses'], 'r-', label='Val Loss', alpha=0.7)
        
        # Sweet Spot í‘œì‹œ
        if module_name in self.sweet_spots:
            spot = self.sweet_spots[module_name]
            ax.axvline(x=spot['epoch'], color='g', linestyle='--', label=f"Sweet Spot (epoch {spot['epoch']})")
        
        # ìˆ˜ë ´ì  í‘œì‹œ
        if module_name in self.convergence_points:
            conv = self.convergence_points[module_name]
            ax.axvline(x=conv['epoch'], color='orange', linestyle='--', label=f"Convergence (epoch {conv['epoch']})")
        
        # ê³¼ì í•© ì‹œì  í‘œì‹œ
        if module_name in self.overfitting_points:
            overfit = self.overfitting_points[module_name]
            ax.axvline(x=overfit['epoch'], color='r', linestyle='--', label=f"Overfitting (epoch {overfit['epoch']})")
        
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss')
        ax.set_title(f'{module_name} - Loss Curve')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. ì •í™•ë„ ê³¡ì„  (ìˆëŠ” ê²½ìš°)
        ax = axes[0, 1]
        if history['accuracies']:
            ax.plot(history['epochs'], history['accuracies'], 'g-', alpha=0.7)
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Accuracy')
            ax.set_title(f'{module_name} - Accuracy Curve')
            ax.grid(True, alpha=0.3)
        
        # 3. ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ (ìˆëŠ” ê²½ìš°)
        ax = axes[1, 0]
        if history['gradients']:
            ax.plot(history['epochs'][:len(history['gradients'])], 
                   history['gradients'], 'r-', alpha=0.7)
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Gradient Norm')
            ax.set_title(f'{module_name} - Gradient Norm')
            ax.set_yscale('log')
            ax.grid(True, alpha=0.3)
        
        # 4. ì†ì‹¤ ë³€í™”ìœ¨ (validation ê¸°ì¤€)
        ax = axes[1, 1]
        val_losses = history.get('val_losses', [])
        train_losses = history.get('train_losses', [])
        primary_losses = val_losses if val_losses else train_losses
        
        if len(primary_losses) > 1:
            loss_changes = np.diff(primary_losses)
            ax.plot(history['epochs'][1:], loss_changes, 'b-', alpha=0.7)
            ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Loss Change')
            ax.set_title(f'{module_name} - Loss Change Rate')
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Sweet Spot Analysis: {module_name}', fontsize=14)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=100, bbox_inches='tight')
            logger.info(f"ğŸ“Š ë¶„ì„ í”Œë¡¯ ì €ì¥: {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def _mann_kendall_test(self, data: List[float]) -> Dict:
        """Mann-Kendall íŠ¸ë Œë“œ í…ŒìŠ¤íŠ¸"""
        n = len(data)
        s = 0
        
        for i in range(n-1):
            for j in range(i+1, n):
                s += np.sign(data[j] - data[i])
        
        # Calculate variance
        var_s = n * (n - 1) * (2 * n + 5) / 18
        
        if s > 0:
            z = (s - 1) / np.sqrt(var_s)
        elif s < 0:
            z = (s + 1) / np.sqrt(var_s)
        else:
            z = 0
        
        return {'statistic': z, 's': s}
    
    def _cusum_detection(self, data: List[float], threshold: float = None) -> List[int]:
        """CUSUM ë³€í™”ì  íƒì§€"""
        if threshold is None:
            threshold = np.std(data) * 2
        
        mean = np.mean(data)
        cusum_pos = np.zeros(len(data))
        cusum_neg = np.zeros(len(data))
        changes = []
        
        for i in range(1, len(data)):
            cusum_pos[i] = max(0, cusum_pos[i-1] + data[i] - mean - threshold/2)
            cusum_neg[i] = max(0, cusum_neg[i-1] + mean - data[i] - threshold/2)
            
            if cusum_pos[i] > threshold or cusum_neg[i] > threshold:
                changes.append(i)
                cusum_pos[i] = 0
                cusum_neg[i] = 0
        
        return changes
    
    def statistical_plateau_detection(self, losses: List[float]) -> Dict:
        """Statistical Plateau Detection using Mann-Kendall and CUSUM"""
        if len(losses) < 5:
            return {'detected': False}
        
        # Mann-Kendall Trend Test
        mk_result = self._mann_kendall_test(losses)
        
        # CUSUM Change Detection
        cusum_changes = self._cusum_detection(losses)
        
        # Find plateau region
        plateau_start = None
        plateau_end = None
        
        # Plateau: íŠ¸ë Œë“œê°€ ì—†ê³  ë³€í™”ì ì´ ì—†ëŠ” êµ¬ê°„
        for i in range(len(losses) - 5):
            window = losses[i:i+5]
            window_trend = self._mann_kendall_test(window)
            
            if abs(window_trend['statistic']) < 0.5:  # No significant trend
                if plateau_start is None:
                    plateau_start = i
                plateau_end = i + 5
        
        if plateau_start is not None:
            plateau_center = (plateau_start + plateau_end) // 2
            plateau_mean = np.mean(losses[plateau_start:plateau_end])
            plateau_std = np.std(losses[plateau_start:plateau_end])
            
            return {
                'detected': True,
                'start': plateau_start,
                'end': plateau_end,
                'center': plateau_center,
                'mean_loss': plateau_mean,
                'std': plateau_std,
                'mk_statistic': mk_result['statistic'],
                'cusum_changes': cusum_changes
            }
        
        return {'detected': False}
    
    def calculate_task_metrics(self, module: str, metrics: Dict) -> Dict:
        """ëª¨ë“ˆë³„ Task-Specific ë©”íŠ¸ë¦­ ê³„ì‚°"""
        task_scores = {}
        
        if 'head' in module or module == 'heads':
            # í—¤ë“œ í†µí•© ì ìˆ˜
            task_scores['emotion_score'] = np.mean(metrics.get('emotion_f1', [0]))
            task_scores['bentham_score'] = 1.0 - np.mean(metrics.get('bentham_rmse', [1.0]))
            task_scores['regret_score'] = np.mean(metrics.get('regret_accuracy', [0]))
            task_scores['surd_score'] = np.mean(metrics.get('surd_pid_acc', [0]))
            task_scores['combined'] = np.mean(list(task_scores.values()))
            
        elif 'analyzer' in module:
            # Analyzer íŠ¹í™” ë©”íŠ¸ë¦­ (validation ìš°ì„ )
            val_losses = metrics.get('val_losses', [])
            train_losses = metrics.get('train_losses', [])
            losses = val_losses if val_losses else train_losses
            task_scores['stability'] = 1.0 / (1.0 + np.std(losses if losses else [1.0]))
            task_scores['convergence'] = self._calculate_convergence_rate(losses)
            
        elif 'kalman' in module or 'dsp' in module:
            # DSP/Kalman íŠ¹í™” ë©”íŠ¸ë¦­
            task_scores['tracking_accuracy'] = 1.0 - np.mean(metrics.get('tracking_error', [1.0]))
            task_scores['filter_stability'] = 1.0 / (1.0 + np.std(metrics.get('filter_output', [1.0])))
        
        else:
            # ê¸°ë³¸ ë©”íŠ¸ë¦­
            val_losses = metrics.get('val_losses', [])
            train_losses = metrics.get('train_losses', [])
            losses = val_losses if val_losses else train_losses
            task_scores['accuracy'] = np.mean(metrics.get('val_accuracies', metrics.get('accuracies', [0])))
            task_scores['loss_improvement'] = self._calculate_improvement(losses)
        
        return task_scores
    
    def _calculate_convergence_rate(self, losses: List[float]) -> float:
        """ìˆ˜ë ´ ì†ë„ ê³„ì‚°"""
        if len(losses) < 2:
            return 0.0
        
        improvements = []
        for i in range(1, len(losses)):
            if losses[i-1] > 0:
                improvement = (losses[i-1] - losses[i]) / losses[i-1]
                improvements.append(improvement)
        
        return np.mean(improvements) if improvements else 0.0
    
    def _calculate_improvement(self, values: List[float]) -> float:
        """ê°œì„ ë„ ê³„ì‚°"""
        if len(values) < 2:
            return 0.0
        
        initial = np.mean(values[:3]) if len(values) >= 3 else values[0]
        final = np.mean(values[-3:]) if len(values) >= 3 else values[-1]
        
        if initial > 0:
            return (initial - final) / initial
        return 0.0
    
    def mcda_analysis(self, module: str, metrics: Dict) -> Dict:
        """Multi-Criteria Decision Analysis"""
        
        # ê¸°ì¤€ë³„ ì ìˆ˜ ê³„ì‚° (validation ìš°ì„ )
        val_losses = metrics.get('val_losses', [])
        train_losses = metrics.get('train_losses', [])
        val_accs = metrics.get('val_accuracies', [])
        train_accs = metrics.get('train_accuracies', [])
        
        losses = val_losses if val_losses else train_losses
        accuracies = val_accs if val_accs else train_accs
        
        criteria = {
            'loss': 1.0 - np.array(losses if losses else [1.0]),  # Lower is better
            'accuracy': np.array(accuracies if accuracies else [0]),
            'stability': self._calculate_stability_scores(metrics),
            'gradient_health': self._calculate_gradient_health(metrics)
        }
        
        # ì •ê·œí™” (0-1 ë²”ìœ„)
        normalized = {}
        for key, values in criteria.items():
            if len(values) > 0 and np.std(values) > 0:
                normalized[key] = (values - np.min(values)) / (np.max(values) - np.min(values))
            else:
                normalized[key] = values
        
        # ê°€ì¤‘ì¹˜
        weights = {
            'loss': 0.30,
            'accuracy': 0.40,
            'stability': 0.15,
            'gradient_health': 0.15
        }
        
        # MCDA ì ìˆ˜ ê³„ì‚°
        mcda_scores = np.zeros(len(metrics.get('epochs', [])))
        for key, weight in weights.items():
            if key in normalized and len(normalized[key]) == len(mcda_scores):
                mcda_scores += weight * normalized[key]
        
        # ìµœì  epoch ì°¾ê¸°
        best_epoch_idx = np.argmax(mcda_scores) if len(mcda_scores) > 0 else 0
        
        return {
            'scores': mcda_scores.tolist(),
            'best_epoch_idx': int(best_epoch_idx),
            'best_epoch': metrics.get('epochs', [])[best_epoch_idx] if best_epoch_idx < len(metrics.get('epochs', [])) else -1,
            'best_score': float(mcda_scores[best_epoch_idx]) if len(mcda_scores) > 0 else 0.0,
            'weights': weights
        }
    
    def _calculate_stability_scores(self, metrics: Dict) -> np.ndarray:
        """ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚°"""
        val_losses = metrics.get('val_losses', [])
        train_losses = metrics.get('train_losses', [])
        losses = val_losses if val_losses else train_losses
        if len(losses) < 3:
            return np.zeros(len(losses))
        
        stability_scores = []
        for i in range(len(losses)):
            start = max(0, i-2)
            end = min(len(losses), i+3)
            window = losses[start:end]
            
            # ë‚®ì€ ë¶„ì‚° = ë†’ì€ ì•ˆì •ì„±
            stability = 1.0 / (1.0 + np.std(window))
            stability_scores.append(stability)
        
        return np.array(stability_scores)
    
    def _calculate_gradient_health(self, metrics: Dict) -> np.ndarray:
        """Gradient Health ì ìˆ˜ ê³„ì‚°"""
        grad_norms = metrics.get('gradients', [])
        if not grad_norms:
            return np.zeros(len(metrics.get('epochs', [])))
        
        health_scores = []
        for norm in grad_norms:
            # Gradientê°€ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ë¶ˆê±´ì „
            if norm > 0:
                if 0.001 < norm < 10.0:  # ê±´ì „í•œ ë²”ìœ„
                    health = 1.0
                elif norm < 0.001:  # Vanishing
                    health = norm / 0.001
                else:  # Exploding
                    health = 10.0 / norm
            else:
                health = 0.0
            health_scores.append(health)
        
        return np.array(health_scores)
    
    def ensemble_voting(self, module: str, analyses: Dict) -> Dict:
        """ì—¬ëŸ¬ ë¶„ì„ ê¸°ë²•ì˜ ì•™ìƒë¸” íˆ¬í‘œ"""
        candidates = {}
        
        # ê° ê¸°ë²•ì˜ ì¶”ì²œ ìˆ˜ì§‘
        if analyses.get('plateau', {}).get('detected'):
            candidates['plateau'] = analyses['plateau']['center']
        
        if 'best_epoch_idx' in analyses.get('mcda', {}):
            candidates['mcda'] = analyses['mcda']['best_epoch_idx']
        
        # Task metric ìµœê³ ì 
        task_scores = analyses.get('task_scores', {})
        if task_scores and 'combined' in task_scores:
            candidates['task'] = task_scores.get('best_idx', 0)
        
        # Minimum loss (validation ìš°ì„ )
        module_history = self.module_histories.get(module, {})
        val_losses = module_history.get('val_losses', [])
        train_losses = module_history.get('train_losses', [])
        losses = val_losses if val_losses else train_losses
        if losses:
            candidates['min_loss'] = np.argmin(losses)
        
        # íˆ¬í‘œ ì§‘ê³„
        if not candidates:
            return {'selected_epoch': -1, 'confidence': 0.0}
        
        # ê°€ì¥ ë§ì€ í‘œë¥¼ ë°›ì€ epoch
        vote_counts = Counter(candidates.values())
        winner, votes = vote_counts.most_common(1)[0]
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = votes / len(candidates) if candidates else 0.0
        
        epochs = self.module_histories.get(module, {}).get('epochs', [])
        
        return {
            'candidates': candidates,
            'selected_epoch_idx': int(winner),
            'selected_epoch': epochs[winner] if winner < len(epochs) else -1,
            'votes': votes,
            'total_voters': len(candidates),
            'confidence': float(confidence)
        }
    
    def analyze_all(self, output_dir: str = 'analysis_results') -> Dict:
        """
        í•™ìŠµ ì™„ë£Œ í›„ ì „ì²´ ë¶„ì„ ì‹¤í–‰
        
        Args:
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ¯ Sweet Spot ì¢…í•© ë¶„ì„ ì‹œì‘")
        logger.info("=" * 70)
        
        # ë””ë²„ê·¸: ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ í™•ì¸
        logger.debug("ğŸ“Š ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ í™•ì¸:")
        for module_name, history in self.module_histories.items():
            train_losses = history.get('train_losses', [])
            val_losses = history.get('val_losses', [])
            
            if train_losses or val_losses:
                if val_losses:
                    logger.debug(f"  - {module_name}: {len(val_losses)}ê°œ ì—í­, "
                               f"Val: ì²«={val_losses[0]:.4f}, ë§ˆì§€ë§‰={val_losses[-1]:.4f}")
                if train_losses:
                    logger.debug(f"    Train: ì²«={train_losses[0]:.4f}, ë§ˆì§€ë§‰={train_losses[-1]:.4f}")
        
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True, parents=True)
        
        analysis_results = {}
        
        # ëª¨ë“ˆë³„ ë¶„ì„
        for module_name in self.module_histories.keys():
            logger.info(f"\nğŸ” ë¶„ì„ ì¤‘: {module_name}")
            
            metrics = self.module_histories[module_name]
            analyses = {}
            
            # 1. Statistical Plateau Detection (validation ìš°ì„ )
            val_losses = metrics.get('val_losses', [])
            train_losses = metrics.get('train_losses', [])
            losses = val_losses if val_losses else train_losses
            analyses['plateau'] = self.statistical_plateau_detection(losses)
            
            # 2. Task-Specific Metrics
            task_scores = self.calculate_task_metrics(module_name, metrics)
            analyses['task_scores'] = task_scores
            
            # 3. MCDA
            analyses['mcda'] = self.mcda_analysis(module_name, metrics)
            
            # 4. Ensemble Voting
            analyses['voting'] = self.ensemble_voting(module_name, analyses)
            
            # ì¢…í•©
            result = {
                'module': module_name,
                'metrics': metrics,
                'analyses': analyses,
                'recommendation': {
                    'epoch_idx': analyses['voting']['selected_epoch_idx'],
                    'epoch': analyses['voting']['selected_epoch'],
                    'confidence': analyses['voting']['confidence'],
                    'reasoning': self._generate_reasoning(module_name, analyses)
                }
            }
            
            analysis_results[module_name] = result
        
        # ì‹œê°í™” ìƒì„±
        self._generate_visualizations(analysis_results, output_path)
        
        # ê²°ê³¼ ì €ì¥
        self._save_analysis_results(analysis_results, output_path)
        
        logger.info("\n" + "=" * 70)
        logger.info("âœ… Sweet Spot ë¶„ì„ ì™„ë£Œ!")
        logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_path}")
        logger.info("=" * 70)
        
        # ìš”ì•½ ì¶œë ¥
        print("\nğŸ“Š Sweet Spot Recommendations:")
        print("-" * 50)
        for module, result in analysis_results.items():
            rec = result['recommendation']
            print(f"{module:20s}: Epoch {rec['epoch']:3d} (Confidence: {rec['confidence']:.1%})")
        print("-" * 50)
        
        return analysis_results
    
    def _generate_reasoning(self, module: str, analyses: Dict) -> List[str]:
        """ì¶”ì²œ ê·¼ê±° ìƒì„±"""
        reasons = []
        
        if analyses.get('plateau', {}).get('detected'):
            plateau = analyses['plateau']
            reasons.append(f"Plateau êµ¬ê°„ íƒì§€ (Epoch {plateau['start']}-{plateau['end']})")
        
        if analyses.get('mcda', {}).get('best_score', 0) > 0.8:
            reasons.append(f"MCDA ì ìˆ˜ ìš°ìˆ˜ ({analyses['mcda']['best_score']:.3f})")
        
        if analyses.get('voting', {}).get('confidence', 0) > 0.6:
            reasons.append(f"ë†’ì€ íˆ¬í‘œ ì‹ ë¢°ë„ ({analyses['voting']['confidence']:.1%})")
        
        task_scores = analyses.get('task_scores', {})
        if task_scores.get('combined', 0) > 0.7:
            reasons.append(f"Task ë©”íŠ¸ë¦­ ìš°ìˆ˜ ({task_scores['combined']:.3f})")
        
        return reasons
    
    def _generate_visualizations(self, analysis_results: Dict, output_path: Path):
        """ì‹œê°í™” ìƒì„±"""
        logger.info("\nğŸ“ˆ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        viz_dir = output_path / 'visualizations'
        viz_dir.mkdir(exist_ok=True)
        
        for module, result in analysis_results.items():
            self._plot_module_analysis(module, result, viz_dir)
        
        # ì¢…í•© íˆíŠ¸ë§µ
        self._plot_summary_heatmap(analysis_results, viz_dir)
    
    def _plot_module_analysis(self, module: str, result: Dict, viz_dir: Path):
        """ëª¨ë“ˆë³„ ë¶„ì„ ì‹œê°í™”"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle(f'{module} Sweet Spot Analysis', fontsize=16)
            
            metrics = result['metrics']
            analyses = result['analyses']
            
            # 1. Loss curve with plateau
            ax = axes[0, 0]
            epochs = metrics.get('epochs', [])
            val_losses = metrics.get('val_losses', [])
            train_losses = metrics.get('train_losses', [])
            losses = val_losses if val_losses else train_losses
            
            if epochs and losses:
                ax.plot(epochs, losses, 'b-', label='Training Loss')
                
                if analyses.get('plateau', {}).get('detected'):
                    plateau = analyses['plateau']
                    ax.axvspan(epochs[plateau['start']], epochs[plateau['end']], 
                              alpha=0.3, color='green', label='Plateau')
                    ax.axvline(epochs[plateau['center']], color='red', 
                              linestyle='--', label='Plateau Center')
            
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Loss')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # 2. MCDA Scores
            ax = axes[0, 1]
            mcda_scores = analyses.get('mcda', {}).get('scores', [])
            
            if epochs and mcda_scores:
                ax.plot(epochs[:len(mcda_scores)], mcda_scores, 'g-', label='MCDA Score')
                best_idx = analyses.get('mcda', {}).get('best_epoch_idx', 0)
                if best_idx < len(epochs) and best_idx < len(mcda_scores):
                    ax.scatter(epochs[best_idx], mcda_scores[best_idx], 
                              color='red', s=100, label='Best MCDA')
            
            ax.set_xlabel('Epoch')
            ax.set_ylabel('MCDA Score')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # 3. Accuracies
            ax = axes[1, 0]
            accuracies = metrics.get('accuracies', [])
            
            if epochs and accuracies:
                ax.plot(epochs[:len(accuracies)], accuracies, label='Accuracy')
            
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Accuracy')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # 4. Voting Results
            ax = axes[1, 1]
            voting = analyses.get('voting', {})
            
            if voting.get('candidates'):
                candidates = list(voting['candidates'].keys())
                values = list(voting['candidates'].values())
                colors = ['green' if v == voting['selected_epoch_idx'] else 'blue' for v in values]
                ax.bar(candidates, values, color=colors)
                ax.set_xlabel('Analysis Method')
                ax.set_ylabel('Recommended Epoch Index')
                ax.set_title(f"Final: Epoch {voting.get('selected_epoch', -1)} (Confidence: {voting.get('confidence', 0):.1%})")
            
            plt.tight_layout()
            plt.savefig(viz_dir / f'{module}_analysis.png', dpi=150)
            plt.close()
            
        except Exception as e:
            logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨ ({module}): {e}")
    
    def _plot_summary_heatmap(self, analysis_results: Dict, viz_dir: Path):
        """ì¢…í•© íˆíŠ¸ë§µ"""
        try:
            modules = []
            recommended_epochs = []
            confidences = []
            
            for module, result in analysis_results.items():
                modules.append(module)
                recommended_epochs.append(result['recommendation']['epoch'])
                confidences.append(result['recommendation']['confidence'])
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # Epoch recommendations
            ax1.barh(modules, recommended_epochs, color='steelblue')
            ax1.set_xlabel('Recommended Epoch')
            ax1.set_title('Sweet Spot Epochs by Module')
            ax1.grid(True, alpha=0.3)
            
            # Confidence scores
            ax2.barh(modules, confidences, color='coral')
            ax2.set_xlabel('Confidence Score')
            ax2.set_title('Recommendation Confidence')
            ax2.set_xlim([0, 1])
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(viz_dir / 'summary_sweetspots.png', dpi=150)
            plt.close()
            
        except Exception as e:
            logger.warning(f"ì¢…í•© íˆíŠ¸ë§µ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _save_analysis_results(self, analysis_results: Dict, output_path: Path):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        # JSON ì €ì¥
        json_path = output_path / 'sweet_spot_analysis.json'
        with open(json_path, 'w') as f:
            json.dump(analysis_results, f, indent=2, default=str)
        logger.info(f"ğŸ“ JSON ê²°ê³¼ ì €ì¥: {json_path}")
        
        # Markdown ë¦¬í¬íŠ¸ ìƒì„±
        self._generate_markdown_report(analysis_results, output_path)
    
    def _generate_markdown_report(self, analysis_results: Dict, output_path: Path):
        """Markdown í˜•ì‹ ë¦¬í¬íŠ¸ ìƒì„±"""
        report_path = output_path / 'sweet_spot_report.md'
        
        with open(report_path, 'w') as f:
            f.write("# ğŸ¯ Sweet Spot Analysis Report\n\n")
            f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Summary table
            f.write("## ğŸ“Š Summary\n\n")
            f.write("| Module | Recommended Epoch | Confidence | Key Reasoning |\n")
            f.write("|--------|------------------|------------|---------------|\n")
            
            for module, result in analysis_results.items():
                rec = result['recommendation']
                reasons = ', '.join(rec['reasoning'][:2]) if rec['reasoning'] else 'N/A'
                f.write(f"| {module} | {rec['epoch']} | {rec['confidence']:.1%} | {reasons} |\n")
            
            # Detailed analysis
            f.write("\n## ğŸ” Detailed Analysis\n\n")
            
            for module, result in analysis_results.items():
                f.write(f"### Module: {module}\n\n")
                
                analyses = result['analyses']
                
                # Plateau
                if analyses.get('plateau', {}).get('detected'):
                    plateau = analyses['plateau']
                    f.write(f"**Plateau Detection:**\n")
                    f.write(f"- Range: Epoch {plateau['start']}-{plateau['end']}\n")
                    f.write(f"- Center: Epoch {plateau['center']}\n")
                    f.write(f"- Mean Loss: {plateau['mean_loss']:.4f} (Â±{plateau['std']:.4f})\n\n")
                else:
                    f.write("**Plateau Detection:** Not detected\n\n")
                
                # MCDA
                mcda = analyses.get('mcda', {})
                f.write(f"**MCDA Analysis:**\n")
                f.write(f"- Best Epoch: {mcda.get('best_epoch', -1)}\n")
                f.write(f"- Best Score: {mcda.get('best_score', 0):.3f}\n\n")
                
                # Voting
                voting = analyses.get('voting', {})
                f.write(f"**Ensemble Voting:**\n")
                f.write(f"- Selected: Epoch {voting.get('selected_epoch', -1)}\n")
                f.write(f"- Confidence: {voting.get('confidence', 0):.1%}\n")
                f.write(f"- Votes: {voting.get('votes', 0)}/{voting.get('total_voters', 0)}\n\n")
                
                f.write("---\n\n")
            
            # Threshold recommendations
            f.write("## ğŸ¯ Recommended Thresholds for Automation\n\n")
            f.write("```python\n")
            f.write("# Based on empirical analysis\n")
            f.write("thresholds = {\n")
            
            # Calculate empirical thresholds
            all_plateau_stds = []
            for result in analysis_results.values():
                if result['analyses'].get('plateau', {}).get('detected'):
                    all_plateau_stds.append(result['analyses']['plateau']['std'])
            
            if all_plateau_stds:
                f.write(f"    'plateau_variance': {np.mean(all_plateau_stds):.4f},\n")
            else:
                f.write(f"    'plateau_variance': 0.01,  # Default\n")
            
            f.write("    'stability_window': 5,\n")
            f.write("    'mcda_weights': {\n")
            f.write("        'loss': 0.30,\n")
            f.write("        'accuracy': 0.40,\n")
            f.write("        'stability': 0.15,\n")
            f.write("        'gradient_health': 0.15\n")
            f.write("    },\n")
            
            # Average confidence
            avg_confidence = np.mean([r['recommendation']['confidence'] 
                                     for r in analysis_results.values()])
            f.write(f"    'min_confidence': {avg_confidence * 0.8:.2f}\n")
            f.write("}\n```\n\n")
            
            # Next steps
            f.write("## ğŸ“ Next Steps\n\n")
            f.write("1. Review the recommendations above\n")
            f.write("2. Manually combine modules using recommended epochs\n")
            f.write("3. Evaluate combined model performance\n")
            f.write("4. Adjust thresholds based on results\n")
            f.write("5. Enable automated sweet spot detection\n")
        
        logger.info(f"ğŸ“„ Markdown ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
    
    def export_analysis(self, output_dir: str = "training/sweet_spot_analysis"):
        """
        ì „ì²´ ë¶„ì„ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. JSON í˜•ì‹ìœ¼ë¡œ ì „ì²´ ë°ì´í„° ì €ì¥
        analysis_data = {
            'timestamp': timestamp,
            'sweet_spots': self.sweet_spots,
            'convergence_points': self.convergence_points,
            'overfitting_points': self.overfitting_points,
            'optimal_epochs': self.get_optimal_epochs(),
            'module_summaries': {}
        }
        
        for module_name in self.module_histories.keys():
            analysis_data['module_summaries'][module_name] = self.get_module_status(module_name)
        
        json_file = output_dir / f"sweet_spot_analysis_{timestamp}.json"
        with open(json_file, 'w') as f:
            json.dump(analysis_data, f, indent=2)
        
        logger.info(f"ğŸ“Š Sweet Spot ë¶„ì„ ê²°ê³¼ ì €ì¥: {json_file}")
        
        # 2. ê° ëª¨ë“ˆë³„ í”Œë¡¯ ìƒì„±
        plots_dir = output_dir / "plots"
        plots_dir.mkdir(exist_ok=True)
        
        for module_name in self.module_histories.keys():
            plot_file = plots_dir / f"{module_name}_{timestamp}.png"
            self.plot_module_analysis(module_name, str(plot_file))
        
        # 3. ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        report_file = output_dir / f"sweet_spot_report_{timestamp}.txt"
        with open(report_file, 'w') as f:
            f.write("=" * 60 + "\n")
            f.write("Sweet Spot Analysis Report\n")
            f.write(f"Generated: {timestamp}\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("Optimal Epochs by Module:\n")
            f.write("-" * 30 + "\n")
            for module, epoch in self.get_optimal_epochs().items():
                f.write(f"  {module}: Epoch {epoch}\n")
            
            f.write("\n")
            f.write("Sweet Spots Detected:\n")
            f.write("-" * 30 + "\n")
            for module, info in self.sweet_spots.items():
                f.write(f"  {module}:\n")
                f.write(f"    - Epoch: {info['epoch']}\n")
                f.write(f"    - Loss: {info['loss']:.4f} (Â±{info['std']:.4f})\n")
                f.write(f"    - Stable: {info['stable']}\n")
                f.write(f"    - Converged: {info['converged']}\n")
            
            f.write("\n")
            f.write("Convergence Points:\n")
            f.write("-" * 30 + "\n")
            for module, info in self.convergence_points.items():
                f.write(f"  {module}: Epoch {info['epoch']} (Loss: {info['loss']:.4f})\n")
            
            if self.overfitting_points:
                f.write("\n")
                f.write("âš ï¸ Overfitting Warnings:\n")
                f.write("-" * 30 + "\n")
                for module, info in self.overfitting_points.items():
                    f.write(f"  {module}: Started at epoch {info['epoch']}\n")
        
        logger.info(f"ğŸ“„ Sweet Spot ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        
        return {
            'json_file': str(json_file),
            'report_file': str(report_file),
            'plots_dir': str(plots_dir)
        }