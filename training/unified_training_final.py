#!/usr/bin/env python3
"""
Red Heart AI ìµœì¢… í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ
730M íŒŒë¼ë¯¸í„° ëª¨ë¸ì˜ 60 ì—í­ í•™ìŠµ with Advanced Techniques
"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import numpy as np
import logging
import argparse
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import gc
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ì²­í¬ ì„ë² ë”© ì§€ì› ì¶”ê°€
from embedding_chunker import EmbeddingChunkManager

# ì»¤ìŠ¤í…€ ëª¨ë“ˆ ì„í¬íŠ¸
from training.enhanced_checkpoint_manager import EnhancedCheckpointManager
from training.lr_sweep_optimizer import LRSweepOptimizer
from training.sweet_spot_detector import SweetSpotDetector
from training.parameter_crossover_system import ParameterCrossoverSystem
from training.oom_handler import OOMHandler
from training.advanced_training_techniques import AdvancedTrainingManager

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from config import ADVANCED_CONFIG, get_device
from data_loader import PreprocessedDataLoader
from sentence_transformer_singleton import get_sentence_transformer

# ì‹¤ì œ ëª¨ë¸ ëª¨ë“ˆë“¤
from unified_backbone import RedHeartUnifiedBackbone
from unified_heads import EmotionHead, BenthamHead, RegretHead, SURDHead
from analyzer_neural_modules import create_neural_analyzers
from advanced_analyzer_wrappers import create_advanced_analyzer_wrappers
from phase_neural_networks import Phase0ProjectionNet, Phase2CommunityNet, HierarchicalEmotionIntegrator
try:
    from emotion_dsp_simulator import EmotionDSPSimulator, DynamicKalmanFilter
except ImportError:
    EmotionDSPSimulator = None
    DynamicKalmanFilter = None

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('RedHeart.UnifiedTrainingFinal')


class UnifiedTrainingConfig:
    """í†µí•© í•™ìŠµ ì„¤ì •"""
    
    def __init__(self):
        # ëª¨ë¸ ì„¤ì • (730M íŒŒë¼ë¯¸í„°)
        self.model_params = 730_000_000
        self.hidden_dim = 1280
        self.num_layers = 18
        self.num_heads = 20
        
        # í•™ìŠµ ì„¤ì • (50 ì—í­ ì œí•œ - í¬ë¡œìŠ¤ì˜¤ë²„ ìµœì í™”)
        self.total_epochs = 50
        self.micro_batch_size = 2  # ì•ˆì •ì„±ì„ ìœ„í•´ 2ë¡œ ì‹œì‘
        self.gradient_accumulation = 32  # ìœ íš¨ ë°°ì¹˜ = 64
        self.base_lr = 1e-4
        
        # LR ìŠ¤ìœ• ì„¤ì • (ë…ë¦½ ì‹¤í–‰)
        self.lr_sweep_enabled = False  # ë³¸ í•™ìŠµì—ì„œëŠ” ë¹„í™œì„±í™”
        self.lr_sweep_range = (1e-5, 1e-2)
        self.lr_sweep_points = 5
        
        # ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
        self.checkpoint_interval = 1  # ë§¤ ì—í­ë§ˆë‹¤ ì €ì¥
        self.checkpoint_dir = "training/checkpoints_final"
        
        # Advanced Training
        self.enable_label_smoothing = True
        self.enable_rdrop = True
        self.enable_ema = True
        self.enable_llrd = True
        self.label_smoothing = 0.1
        self.rdrop_alpha = 1.0
        self.ema_decay = 0.999
        
        # OOM í•¸ë“¤ë§
        self.enable_oom_handler = True
        self.memory_threshold = 0.85
        self.min_batch_size = 1
        
        # Sweet Spot & Crossover
        self.enable_sweet_spot = True
        self.enable_crossover = True
        self.crossover_strategy = 'selective'
        
        # ë°ì´í„° ì„¤ì •
        self.data_dir = "for_learn_dataset"
        self.validation_split = 0.1
        self.num_workers = 4
        
        # ë¡œê¹…
        self.log_interval = 10
        self.verbose = False  # ìƒì„¸ ì¶œë ¥ ì„¤ì •
        self.val_interval = 100


class UnifiedModel(nn.Module):
    """
    Red Heart AI 730M í†µí•© ëª¨ë¸
    
    âš ï¸ ì˜ë„ì  ìˆœí™˜ ì°¸ì¡° ì•„í‚¤í…ì²˜:
    - Neural Analyzersì™€ ì–‘ë°©í–¥ ì°¸ì¡° (GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ê³µìœ )
    - Advanced Wrappersì™€ ìƒí˜¸ ì˜ì¡´ (ë™ì¼ ì„ë² ë”© ê³µê°„ í™œìš©)
    - ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ë‚´ í…ì„œ ì§ì ‘ ì „ë‹¬ì„ ìœ„í•œ ëª¨ë†€ë¦¬ì‹ ì„¤ê³„
    - 8GB GPU ì œì•½ í•˜ì—ì„œ 730M íŒŒë¼ë¯¸í„° ì‹¤ì‹œê°„ ì¶”ë¡  ìµœì í™”
    
    ìˆœí™˜ ì°¸ì¡° íŒ¨í„´:
    UnifiedModel â†â†’ Neural Analyzers
          â†“â†‘
    Advanced Wrappers â†â†’ EmotionEthicsRegretCircuit
    """
    
    def __init__(self, config: UnifiedTrainingConfig, device=None):
        super().__init__()
        self.config = config
        self.device = device if device else torch.device('cpu')
        
        # ë°±ë³¸ ì„¤ì •
        backbone_config = {
            'input_dim': 768,
            'd_model': 896,
            'num_layers': 8,
            'num_heads': 14,
            'feedforward_dim': 3584,
            'dropout': 0.1,
            'task_dim': 896
        }
        
        # ë°±ë³¸ ì´ˆê¸°í™” (90.6M)
        self.backbone = RedHeartUnifiedBackbone(backbone_config)
        
        # í—¤ë“œ ì´ˆê¸°í™” (153M)
        self.emotion_head = EmotionHead(input_dim=896)
        self.bentham_head = BenthamHead(input_dim=896)
        self.regret_head = RegretHead(input_dim=896) 
        self.surd_head = SURDHead(input_dim=896)
        
        # ì‹ ê²½ë§ ë¶„ì„ê¸° (368M) - nn.ModuleDictë¡œ ê°ì‹¸ì„œ parameters()ì— í¬í•¨ë˜ë„ë¡
        analyzers_dict = create_neural_analyzers(input_dim=896)
        self.neural_analyzers = nn.ModuleDict(analyzers_dict)
        # ê° analyzerë¥¼ deviceë¡œ ì´ë™
        if self.device and self.device != torch.device('cpu'):
            self.neural_analyzers = self.neural_analyzers.to(self.device)
        
        # Advanced ë¶„ì„ê¸° ë˜í¼ (112M) - translator ì´ˆê¸°í™” í›„ ìƒì„±
        self.advanced_wrappers = None  # ë‚˜ì¤‘ì— ì´ˆê¸°í™”
        
        # ë¶„ì„ê¸° ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„±
        self.analyzers = {}
        
        # Phase ë„¤íŠ¸ì›Œí¬ (4.3M)
        self.phase0_net = Phase0ProjectionNet(input_dim=896)
        self.phase2_net = Phase2CommunityNet(input_dim=768)  # phase2_input_projectionì´ 128->768ë¡œ ë³€í™˜
        self.hierarchical_integrator = HierarchicalEmotionIntegrator(input_dim=896)
        
        # Phase2 ì…ë ¥ íˆ¬ì˜ ë ˆì´ì–´ (896ì„ 7ê°œë¡œ ë‚˜ëˆˆ í›„ ê°ê°ì„ 768ë¡œ íˆ¬ì˜)
        self.phase2_input_projection = nn.Linear(128, 768)  # 896/7=128
        
        # DSP & ì¹¼ë§Œ í•„í„° (2.3M)
        if EmotionDSPSimulator is not None:
            self.dsp_simulator = EmotionDSPSimulator({'hidden_dim': 384})
            self.kalman_filter = DynamicKalmanFilter(state_dim=7)
        else:
            self.dsp_simulator = None
            self.kalman_filter = None
        
    def forward(self, x, task='emotion', return_all=False):
        """ìˆœì „íŒŒ - ëª¨ë“  ëª¨ë“ˆ ì‚¬ìš© (730M ì „ì²´)
        
        Args:
            x: ì…ë ¥ í…ì„œ
            task: í˜„ì¬ í•™ìŠµ ì¤‘ì¸ íƒœìŠ¤í¬
            return_all: ëª¨ë“  ì¶œë ¥ ë°˜í™˜ ì—¬ë¶€ (í•™ìŠµ ì‹œ True)
            
        Returns:
            return_all=False: í•´ë‹¹ íƒœìŠ¤í¬ì˜ ì¶œë ¥ í…ì„œ
            return_all=True: dict with 'head_output', 'neural_output', 'wrapper_output'
        """
        # ì…ë ¥ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ (í•„ìš”ì‹œ)
        if x.device != self.backbone.parameters().__next__().device:
            x = x.to(self.backbone.parameters().__next__().device)
        
        # ë°±ë³¸ ì²˜ë¦¬ (90.6M)
        backbone_outputs = self.backbone(x, task=task)
        
        # íƒœìŠ¤í¬ë³„ íŠ¹ì§• ì¶”ì¶œ
        if task in backbone_outputs:
            features = backbone_outputs[task]
        else:
            features = torch.stack(list(backbone_outputs.values())).mean(dim=0)
        
        outputs = {}
        
        # 1. í—¤ë“œ ì¶œë ¥ (153M)
        if task == 'emotion':
            head_output = self.emotion_head(features)
            if isinstance(head_output, dict):
                head_output = head_output.get('emotions', head_output.get('emotion_logits', list(head_output.values())[0]))
        elif task == 'bentham':
            head_output = self.bentham_head(features)
            if isinstance(head_output, dict):
                head_output = head_output.get('bentham_scores', list(head_output.values())[0])
        elif task == 'regret':
            head_output = self.regret_head(features)
            if isinstance(head_output, dict):
                head_output = head_output.get('regret_score', list(head_output.values())[0])
        elif task == 'surd':
            head_output = self.surd_head(features)
            if isinstance(head_output, dict):
                head_output = head_output.get('surd_values', head_output.get('surd_scores', list(head_output.values())[0]))
        else:
            head_output = self.emotion_head(features)
            if isinstance(head_output, dict):
                head_output = head_output.get('emotions', head_output.get('emotion_logits', list(head_output.values())[0]))
        
        outputs['head'] = head_output
        
        # 2. Neural Analyzers ì¶œë ¥ (368.2M)
        if self.neural_analyzers and task in self.neural_analyzers:
            # ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± ì²˜ë¦¬ (MEDIUM ëª¨ë“œì—ì„œ CPU/GPU í˜¼ì¬)
            analyzer = self.neural_analyzers[task]
            analyzer_device = next(analyzer.parameters()).device
            if features.device != analyzer_device:
                features_for_analyzer = features.to(analyzer_device)
            else:
                features_for_analyzer = features
            
            neural_output = analyzer(features_for_analyzer)
            if isinstance(neural_output, dict):
                # dictë©´ ì²« ë²ˆì§¸ í…ì„œ ì¶”ì¶œ
                neural_output = list(neural_output.values())[0] if neural_output else None
            if neural_output is not None:
                # ì¶œë ¥ì„ ì›ë˜ features ë””ë°”ì´ìŠ¤ë¡œ ë˜ëŒë¦¼ (í›„ì† ì²˜ë¦¬ë¥¼ ìœ„í•´)
                if neural_output.device != features.device:
                    neural_output = neural_output.to(features.device)
                outputs['neural'] = neural_output
        
        # 3. Advanced Wrappers ì¶œë ¥ (112M) - ì´ˆê¸°í™”ëœ ê²½ìš°ë§Œ
        # advanced_wrappers í‚¤ ë§¤í•‘ (advanced_emotion, advanced_bentham ë“±)
        wrapper_key = f'advanced_{task}' if not task.startswith('advanced_') else task
        
        # ë””ë²„ê¹…: advanced_wrappers íƒ€ì…ê³¼ í‚¤ í™•ì¸
        import logging  # ëª¨ë“ˆ ë ˆë²¨ import ëŒ€ì‹  forward ë©”ì„œë“œ ì „ì²´ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡
        if self.advanced_wrappers:
            logger = logging.getLogger('UnifiedModel.Debug')
            logger.info(f"ğŸ” advanced_wrappers íƒ€ì…: {type(self.advanced_wrappers)}")
            logger.info(f"ğŸ” advanced_wrappers í‚¤ë“¤: {list(self.advanced_wrappers.keys()) if hasattr(self.advanced_wrappers, 'keys') else 'keys() ì—†ìŒ'}")
            logger.info(f"ğŸ” ì°¾ëŠ” wrapper_key: {wrapper_key}")
            
            if wrapper_key in self.advanced_wrappers:
                wrapper = self.advanced_wrappers[wrapper_key]
                logger.info(f"ğŸ” wrapper íƒ€ì…: {type(wrapper)}")
                
                # wrapperê°€ Noneì´ê±°ë‚˜ dictì¸ ê²½ìš° ì²˜ë¦¬
                if wrapper is None:
                    logger.error(f"âŒ {wrapper_key} wrapperê°€ Noneì…ë‹ˆë‹¤")
                elif not isinstance(wrapper, nn.Module):
                    logger.error(f"âŒ {wrapper_key} wrapperê°€ nn.Moduleì´ ì•„ë‹™ë‹ˆë‹¤: {type(wrapper)}")
                    # dictì¸ ê²½ìš° ë‚´ë¶€ êµ¬ì¡° í™•ì¸
                    if isinstance(wrapper, dict):
                        logger.error(f"   dict ë‚´ìš©: {list(wrapper.keys()) if wrapper else 'ë¹ˆ dict'}")
                else:
                    # ì •ìƒ ì²˜ë¦¬ - nn.Moduleì¸ ê²½ìš°ë§Œ
                    wrapper_device = next(wrapper.parameters()).device
                    if features.device != wrapper_device:
                        features_for_wrapper = features.to(wrapper_device)
                    else:
                        features_for_wrapper = features
                    
                    wrapper_output = wrapper(features_for_wrapper)
                    logger.info(f"ğŸ” wrapper ì¶œë ¥ íƒ€ì…: {type(wrapper_output)}")
                    
                    # ì¬ê·€ì  êµ¬ì¡° ë¶„ì„ í•¨ìˆ˜
                    def analyze_deep_structure(obj, prefix="", max_depth=5, current_depth=0):
                        """ê°ì²´ì˜ ì •í™•í•œ êµ¬ì¡°ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì™„ì „íˆ ë¶„ì„"""
                        if current_depth >= max_depth:
                            logger.info(f"{prefix}[ìµœëŒ€ ê¹Šì´ ë„ë‹¬]")
                            return None
                        
                        if isinstance(obj, torch.Tensor):
                            logger.info(f"{prefix}âœ… Tensor: shape={list(obj.shape)}, dtype={obj.dtype}, device={obj.device}")
                            return obj
                        elif isinstance(obj, dict):
                            logger.info(f"{prefix}ğŸ“¦ Dict[{len(obj)} keys]: {list(obj.keys())}")
                            tensor_found = None
                            for k, v in obj.items():
                                logger.info(f"{prefix}  [{k}]:")
                                result = analyze_deep_structure(v, prefix + "    ", max_depth, current_depth + 1)
                                if result is not None and isinstance(result, torch.Tensor) and tensor_found is None:
                                    tensor_found = result
                            return tensor_found
                        elif isinstance(obj, (list, tuple)):
                            type_name = 'List' if isinstance(obj, list) else 'Tuple'
                            logger.info(f"{prefix}ğŸ“‹ {type_name}[{len(obj)} items]")
                            tensor_found = None
                            for i, item in enumerate(obj[:3]):  # ìµœëŒ€ 3ê°œë§Œ
                                logger.info(f"{prefix}  [{i}]:")
                                result = analyze_deep_structure(item, prefix + "    ", max_depth, current_depth + 1)
                                if result is not None and isinstance(result, torch.Tensor) and tensor_found is None:
                                    tensor_found = result
                            if len(obj) > 3:
                                logger.info(f"{prefix}  ... ({len(obj)-3} more items)")
                            return tensor_found
                        elif hasattr(obj, '__dict__'):
                            logger.info(f"{prefix}ğŸ”§ Object({type(obj).__name__}): attrs={list(obj.__dict__.keys())[:5]}")
                            return None
                        else:
                            logger.info(f"{prefix}ğŸ“ {type(obj).__name__}: {str(obj)[:100]}")
                            return None
                    
                    # ê¹Šì´ ìˆëŠ” êµ¬ì¡° ë¶„ì„ ë° í…ì„œ ì¶”ì¶œ
                    logger.info("ğŸ” === ì™„ì „í•œ êµ¬ì¡° ë¶„ì„ ì‹œì‘ ===")
                    extracted_tensor = analyze_deep_structure(wrapper_output, "  ")
                    logger.info("ğŸ” === êµ¬ì¡° ë¶„ì„ ì™„ë£Œ ===")
                    
                    # ì¶”ì¶œëœ í…ì„œ ì‚¬ìš©
                    if extracted_tensor is not None and isinstance(extracted_tensor, torch.Tensor):
                        logger.info(f"âœ… í…ì„œ ì¶”ì¶œ ì„±ê³µ: shape={list(extracted_tensor.shape)}")
                        wrapper_output = extracted_tensor
                        
                        # í…ì„œì¸ì§€ ìµœì¢… í™•ì¸ í›„ ë°”ë¡œ ì²˜ë¦¬
                        if wrapper_output.device != features.device:
                            wrapper_output = wrapper_output.to(features.device)
                        outputs['advanced'] = wrapper_output
                        logger.info(f"âœ… outputs['advanced'] ì„¤ì • ì™„ë£Œ: {type(outputs['advanced'])}, shape={outputs['advanced'].shape}")
                    else:
                        logger.error(f"âŒ í…ì„œ ì¶”ì¶œ ì‹¤íŒ¨ - wrapper_output êµ¬ì¡°ì—ì„œ í…ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        # ì‹¤íŒ¨ ì‹œ advanced í‚¤ë¥¼ ì„¤ì •í•˜ì§€ ì•ŠìŒ (í”„ë¡œì íŠ¸ ê·œì¹™: fallback ê¸ˆì§€)
            else:
                logger.warning(f"âš ï¸ {wrapper_key} í‚¤ê°€ advanced_wrappersì— ì—†ìŠµë‹ˆë‹¤")
        else:
            logger = logging.getLogger('UnifiedModel.Debug')
            logger.info(f"â„¹ï¸ advanced_wrappersê°€ None ë˜ëŠ” ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {self.advanced_wrappers}")
        
        # 4. Phase Networks (4.3M)
        if hasattr(self, 'phase0_net') and self.phase0_net:
            # ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± ì²˜ë¦¬
            phase0_device = next(self.phase0_net.parameters()).device
            if features.device != phase0_device:
                features_for_phase0 = features.to(phase0_device)
                phase0_out = self.phase0_net(features_for_phase0)
                phase0_out = phase0_out.to(features.device)
            else:
                phase0_out = self.phase0_net(features)
            outputs['phase0'] = phase0_out
        
        # 5. DSP & Kalman (2.3M)
        if hasattr(self, 'dsp_simulator') and self.dsp_simulator and task == 'emotion':
            # DSPëŠ” emotion íƒœìŠ¤í¬ì—ì„œë§Œ ì‚¬ìš©
            # ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± ì²˜ë¦¬
            dsp_device = next(self.dsp_simulator.parameters()).device
            
            # DSPëŠ” featuresë¥¼ ë°›ì•„ì•¼ í•¨ (hidden_dim=384), head_output(1x7)ì´ ì•„ë‹˜
            # featuresëŠ” ë°±ë³¸ ì¶œë ¥ (batch, task_dim=896)ì´ë¯€ë¡œ í”„ë¡œì ì…˜ í•„ìš”
            if not hasattr(self, 'dsp_projection'):
                self.dsp_projection = nn.Linear(features.shape[-1], 384).to(dsp_device)
            
            if features.device != dsp_device:
                features_for_dsp = features.to(dsp_device)
                dsp_input = self.dsp_projection(features_for_dsp)
                dsp_out = self.dsp_simulator.forward(dsp_input)
                # dsp_outì€ dictì´ë¯€ë¡œ ê° í…ì„œë¥¼ ê°œë³„ì ìœ¼ë¡œ ì´ë™
                if isinstance(dsp_out, dict):
                    for key, tensor in dsp_out.items():
                        if isinstance(tensor, torch.Tensor):
                            dsp_out[key] = tensor.to(features.device)
                elif isinstance(dsp_out, torch.Tensor):
                    dsp_out = dsp_out.to(features.device)
            else:
                dsp_input = self.dsp_projection(features)
                dsp_out = self.dsp_simulator.forward(dsp_input)
            outputs['dsp'] = dsp_out
        
        # return_allì´ë©´ ëª¨ë“  ì¶œë ¥ ë°˜í™˜ (í•™ìŠµ ì‹œ ì‚¬ìš©)
        if return_all:
            return outputs
        else:
            # ê¸°ë³¸: head ì¶œë ¥ë§Œ ë°˜í™˜
            return head_output
    
    # ==================== I/O ë¶„ë¦¬ë¥¼ ìœ„í•œ ë¹„ë™ê¸° ì²˜ë¦¬ ë©”ì„œë“œ ====================
    
    async def process_async(self, task_message):
        """TaskMessageë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
        
        Args:
            task_message: TaskMessage ê°ì²´ ë˜ëŠ” í˜¸í™˜ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ResultMessage ê°ì²´
        """
        import asyncio
        import time
        from concurrent.futures import ThreadPoolExecutor
        
        # TaskMessageì—ì„œ ë°ì´í„° ì¶”ì¶œ
        if hasattr(task_message, 'data'):
            data = task_message.data
            task_type = getattr(task_message, 'task_type', 'emotion')
            task_id = getattr(task_message, 'task_id', None)
        else:
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì „ë‹¬ëœ ê²½ìš°
            data = task_message
            task_type = data.get('task_type', 'emotion')
            task_id = data.get('task_id', None)
        
        start_time = time.time()
        
        try:
            # ë¹„ë™ê¸° ì‹¤í–‰ì„ ìœ„í•œ executor (ì—†ìœ¼ë©´ ìƒì„±)
            if not hasattr(self, '_executor'):
                self._executor = ThreadPoolExecutor(max_workers=2)
            
            # forward ë©”ì„œë“œë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self._executor,
                self._process_sync,
                data,
                task_type
            )
            
            processing_time = time.time() - start_time
            
            # ResultMessage ìƒì„± (data_structures.py ì˜ì¡´ì„± ì²´í¬)
            try:
                from data_structures import ResultMessage
                return ResultMessage(
                    task_id=task_id or f"unified_{int(time.time()*1000)}",
                    module='unified_model',
                    task_type=task_type,
                    status='success',
                    data=result,
                    processing_time=processing_time
                )
            except ImportError:
                # data_structuresê°€ ì—†ìœ¼ë©´ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
                return {
                    'task_id': task_id or f"unified_{int(time.time()*1000)}",
                    'module': 'unified_model',
                    'task_type': task_type,
                    'status': 'success',
                    'data': result,
                    'processing_time': processing_time
                }
                
        except Exception as e:
            logger.error(f"ë¹„ë™ê¸° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            # ì—ëŸ¬ ResultMessage ë°˜í™˜
            try:
                from data_structures import ResultMessage
                return ResultMessage(
                    task_id=task_id or 'error',
                    module='unified_model',
                    task_type=task_type,
                    status='error',
                    data={},
                    error=str(e)
                )
            except ImportError:
                return {
                    'task_id': task_id or 'error',
                    'module': 'unified_model',
                    'task_type': task_type,
                    'status': 'error',
                    'data': {},
                    'error': str(e)
                }
    
    def _process_sync(self, data, task_type='emotion'):
        """ë™ê¸° ì²˜ë¦¬ í—¬í¼ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ìš©)
        
        Args:
            data: ì…ë ¥ ë°ì´í„° (í…ìŠ¤íŠ¸ ë˜ëŠ” ì„ë² ë”©)
            task_type: ì²˜ë¦¬í•  íƒœìŠ¤í¬ íƒ€ì…
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
        if isinstance(data, str):
            # í…ìŠ¤íŠ¸ì¸ ê²½ìš° ì„ë² ë”© ë³€í™˜ í•„ìš”
            embeddings = self._text_to_embedding(data)
        elif isinstance(data, dict):
            # ë”•ì…”ë„ˆë¦¬ì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
            if 'embeddings' in data:
                embeddings = data['embeddings']
            elif 'text' in data:
                embeddings = self._text_to_embedding(data['text'])
            else:
                raise ValueError("ì…ë ¥ ë°ì´í„°ì— 'embeddings' ë˜ëŠ” 'text'ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        else:
            # ì´ë¯¸ í…ì„œì¸ ê²½ìš°
            embeddings = data
        
        # í…ì„œë¡œ ë³€í™˜
        if not isinstance(embeddings, torch.Tensor):
            embeddings = torch.tensor(embeddings, dtype=torch.float32)
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (í•„ìš”ì‹œ)
        if embeddings.dim() == 1:
            embeddings = embeddings.unsqueeze(0)
        elif embeddings.dim() == 2 and embeddings.shape[0] != 1:
            # (seq_len, hidden_dim) -> (1, hidden_dim)ìœ¼ë¡œ í‰ê· 
            embeddings = embeddings.mean(dim=0, keepdim=True)
        
        # ë””ë°”ì´ìŠ¤ ì´ë™
        device = next(self.parameters()).device
        embeddings = embeddings.to(device)
        
        # forward ì‹¤í–‰ (return_all=Trueë¡œ ëª¨ë“  ì¶œë ¥ ë°›ê¸°)
        with torch.no_grad():
            outputs = self.forward(embeddings, task=task_type, return_all=True)
        
        # ê²°ê³¼ í›„ì²˜ë¦¬ (í…ì„œë¥¼ íŒŒì´ì¬ íƒ€ì…ìœ¼ë¡œ)
        result = {}
        for key, value in outputs.items():
            if isinstance(value, torch.Tensor):
                # CPUë¡œ ì´ë™ í›„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                value = value.cpu()
                if value.dim() == 0:
                    result[key] = value.item()
                else:
                    result[key] = value.tolist()
            elif isinstance(value, dict):
                # ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬
                result[key] = {}
                for k, v in value.items():
                    if isinstance(v, torch.Tensor):
                        v = v.cpu()
                        result[key][k] = v.tolist() if v.dim() > 0 else v.item()
                    else:
                        result[key][k] = v
            else:
                result[key] = value
        
        return result
    
    def _text_to_embedding(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸
            
        Returns:
            ì„ë² ë”© ë²¡í„°
        """
        try:
            # SentenceTransformer ì‚¬ìš©
            from sentence_transformer_singleton import get_sentence_transformer
            encoder = get_sentence_transformer()
            embeddings = encoder.encode(text, convert_to_tensor=False)
            return embeddings
        except ImportError:
            # í´ë°±: ëœë¤ ì„ë² ë”© (í…ŒìŠ¤íŠ¸ìš©)
            logger.warning("SentenceTransformerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ. ëœë¤ ì„ë² ë”© ì‚¬ìš©")
            return torch.randn(768)
    
    async def process_batch_async(self, task_messages):
        """ë°°ì¹˜ TaskMessageë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
        
        Args:
            task_messages: TaskMessage ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ResultMessage ë¦¬ìŠ¤íŠ¸
        """
        import asyncio
        
        # ë³‘ë ¬ ì²˜ë¦¬
        tasks = [self.process_async(msg) for msg in task_messages]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜ [{i}]: {result}")
                # ì—ëŸ¬ ê²°ê³¼ ìƒì„±
                try:
                    from data_structures import ResultMessage
                    error_result = ResultMessage(
                        task_id=f"batch_error_{i}",
                        module='unified_model',
                        task_type='unknown',
                        status='error',
                        data={},
                        error=str(result)
                    )
                except ImportError:
                    error_result = {
                        'task_id': f"batch_error_{i}",
                        'module': 'unified_model',
                        'task_type': 'unknown',
                        'status': 'error',
                        'data': {},
                        'error': str(result)
                    }
                processed_results.append(error_result)
            else:
                processed_results.append(result)
        
        return processed_results
    
    def cleanup_executor(self):
        """Executor ì •ë¦¬ (ì¢…ë£Œ ì‹œ í˜¸ì¶œ)"""
        if hasattr(self, '_executor'):
            self._executor.shutdown(wait=True)
            delattr(self, '_executor')


class UnifiedTrainer:
    """í†µí•© í•™ìŠµ ê´€ë¦¬ì"""
    
    def __init__(self, config: UnifiedTrainingConfig):
        self.config = config
        self.device = get_device()
        self.verbose = config.verbose  # V2ì™€ ë™ì¼í•˜ê²Œ verbose ì„¤ì •
        
        logger.info("=" * 70)
        logger.info("Red Heart AI ìµœì¢… í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        logger.info(f"  - ëª¨ë¸ í¬ê¸°: {config.model_params/1e6:.0f}M íŒŒë¼ë¯¸í„°")
        logger.info(f"  - ì´ ì—í­: {config.total_epochs}")
        logger.info(f"  - ë°°ì¹˜ ì‚¬ì´ì¦ˆ: {config.micro_batch_size} (GA={config.gradient_accumulation})")
        logger.info(f"  - ë””ë°”ì´ìŠ¤: {self.device}")
        logger.info("=" * 70)
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._initialize_components()
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_model()
        
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        self._initialize_dataloaders()
        
        # ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
        self._initialize_optimizer()
        
        # ë©”íŠ¸ë¦­ ì¶”ì 
        self.global_step = 0
        self.current_epoch = 0
        self.best_loss = float('inf')
        self.no_param_update = False  # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ í”Œë˜ê·¸
        
    def _initialize_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì €
        self.checkpoint_manager = EnhancedCheckpointManager(
            checkpoint_dir=self.config.checkpoint_dir,
            max_checkpoints=30,
            save_interval=self.config.checkpoint_interval
        )
        
        # LR ìŠ¤ìœ• ì˜µí‹°ë§ˆì´ì €
        if self.config.lr_sweep_enabled:
            self.lr_sweep = LRSweepOptimizer(
                base_lr=self.config.base_lr,
                sweep_range=self.config.lr_sweep_range,
                num_sweep_points=self.config.lr_sweep_points
            )
        
        # Sweet Spot íƒì§€ê¸°
        if self.config.enable_sweet_spot:
            self.sweet_spot_detector = SweetSpotDetector(
                window_size=5,
                stability_threshold=0.01,
                patience=10
            )
        
        # Parameter Crossover
        if self.config.enable_crossover:
            self.crossover_system = ParameterCrossoverSystem(
                crossover_strategy=self.config.crossover_strategy,
                blend_ratio=0.7
            )
        
        # OOM í•¸ë“¤ëŸ¬
        if self.config.enable_oom_handler:
            self.oom_handler = OOMHandler(
                initial_batch_size=self.config.micro_batch_size,
                min_batch_size=self.config.min_batch_size,
                gradient_accumulation=self.config.gradient_accumulation,
                memory_threshold=self.config.memory_threshold
            )
        
        # Advanced Training Manager
        self.training_manager = AdvancedTrainingManager(
            enable_label_smoothing=self.config.enable_label_smoothing,
            enable_rdrop=self.config.enable_rdrop,
            enable_ema=self.config.enable_ema,
            enable_llrd=self.config.enable_llrd,
            label_smoothing=self.config.label_smoothing,
            rdrop_alpha=self.config.rdrop_alpha,
            ema_decay=self.config.ema_decay
        )
        
        logger.info("âœ… ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_model(self):
        """ëª¨ë¸ ì´ˆê¸°í™” - v2 ë°©ì‹ ì°¨ìš© (ìˆœì°¨ì  GPU ë¡œë“œ)"""
        logger.info("ğŸ”§ ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘ (ìˆœì°¨ì  GPU ë¡œë“œ ë°©ì‹)...")
        
        # ì‹¤ì œ 730M ëª¨ë¸ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤ ì „ë‹¬)
        self.model = UnifiedModel(self.config, device=self.device)
        
        # GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
        if self.device.type == 'cuda':
            gpu_mem_before = torch.cuda.memory_allocated() / (1024**3)
            logger.info(f"  ì´ˆê¸° GPU ë©”ëª¨ë¦¬: {gpu_mem_before:.2f}GB")
        
        # ìˆœì°¨ì ìœ¼ë¡œ ì»´í¬ë„ŒíŠ¸ë¥¼ GPUë¡œ ì´ë™ (7GBê¹Œì§€ í™œìš©)
        # 1. ë°±ë³¸ (90.6M) - í•­ìƒ GPU
        self.model.backbone = self.model.backbone.to(self.device)
        logger.info(f"  âœ… ë°±ë³¸ GPU ë¡œë“œ (90.6M)")
        
        # 2. ëª¨ë“  í—¤ë“œ (153M) - GPUì— ìœ ì§€ (ì´ì „ì—” í•„ìš”ì‹œë§Œ ë¡œë“œ)
        self.model.emotion_head = self.model.emotion_head.to(self.device)
        logger.info(f"  âœ… ê°ì • í—¤ë“œ GPU ë¡œë“œ (38.3M)")
        
        self.model.bentham_head = self.model.bentham_head.to(self.device)
        logger.info(f"  âœ… ë²¤ë‹´ í—¤ë“œ GPU ë¡œë“œ (38.3M)")
        
        self.model.regret_head = self.model.regret_head.to(self.device)
        logger.info(f"  âœ… í›„íšŒ í—¤ë“œ GPU ë¡œë“œ (38.3M)")
        
        self.model.surd_head = self.model.surd_head.to(self.device)
        logger.info(f"  âœ… SURD í—¤ë“œ GPU ë¡œë“œ (38.3M)")
        
        # 3. Translator ëª¨ë“ˆ ì´ˆê¸°í™” (Advanced ë¶„ì„ê¸° ì˜ì¡´ì„±)
        logger.info("  ğŸ”„ Translator ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")
        try:
            from config import get_system_module, register_system_module
            existing_translator = get_system_module('translator')
            if existing_translator is None:
                from local_translator import LocalTranslator
                translator = LocalTranslator()
                register_system_module('translator', translator)
                logger.info("  âœ… LocalTranslator ì´ˆê¸°í™” ë° ì „ì—­ ë“±ë¡ ì™„ë£Œ")
            else:
                logger.info("  â„¹ï¸ Translatorê°€ ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.error(f"  âŒ Translator ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.warning("     Advanced Emotion Wrapperê°€ ì œí•œë©ë‹ˆë‹¤")
        
        # Translator ì´ˆê¸°í™” í›„ Advanced Wrappers ìƒì„±
        if self.model.advanced_wrappers is None:
            logger.info("  ğŸ”§ Advanced Wrappers ìƒì„± ì¤‘...")
            from advanced_analyzer_wrappers import create_advanced_analyzer_wrappers
            wrappers_dict = create_advanced_analyzer_wrappers()
            # nn.ModuleDictë¡œ ê°ì‹¸ì„œ parameters()ì— í¬í•¨ë˜ë„ë¡
            self.model.advanced_wrappers = nn.ModuleDict(wrappers_dict) if wrappers_dict else None
            
            # Advanced Wrappers íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸
            wrapper_params = 0
            if self.model.advanced_wrappers:
                for name, wrapper in self.model.advanced_wrappers.items():
                    if hasattr(wrapper, 'parameters'):
                        params = sum(p.numel() for p in wrapper.parameters())
                        wrapper_params += params
            logger.info(f"  âœ… Advanced Wrappers ìƒì„± ì™„ë£Œ ({wrapper_params/1e6:.1f}M)")
        
        # 4. Neural Analyzers (368M) - GPU ì—¬ìœ  ìˆìœ¼ë©´ ë¡œë“œ  
        if hasattr(self.model, 'neural_analyzers') and self.model.neural_analyzers:
            try:
                for name, analyzer in self.model.neural_analyzers.items():
                    self.model.neural_analyzers[name] = analyzer.to(self.device)
                    logger.info(f"  âœ… {name} ë¶„ì„ê¸° GPU ë¡œë“œ")
            except RuntimeError as e:
                if 'out of memory' in str(e).lower():
                    logger.warning(f"  âš ï¸ Neural AnalyzersëŠ” ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ CPU ìœ ì§€")
                else:
                    raise
        
        # 5. Advanced Wrappers (112M) - GPU ì—¬ìœ  ìˆìœ¼ë©´ ë¡œë“œ
        if hasattr(self.model, 'advanced_wrappers') and self.model.advanced_wrappers:
            try:
                for name, wrapper in self.model.advanced_wrappers.items():
                    self.model.advanced_wrappers[name] = wrapper.to(self.device)
                    logger.info(f"  âœ… {name} Wrapper GPU ë¡œë“œ")
            except RuntimeError as e:
                if 'out of memory' in str(e).lower():
                    logger.warning(f"  âš ï¸ Advanced WrappersëŠ” ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ CPU ìœ ì§€")
                else:
                    raise
        
        # 6. Phase Networks (4.3M) - ì‘ìœ¼ë‹ˆê¹Œ GPUë¡œ
        if hasattr(self.model, 'phase0_net') and self.model.phase0_net:
            self.model.phase0_net = self.model.phase0_net.to(self.device)
            logger.info(f"  âœ… Phase0 ë„¤íŠ¸ì›Œí¬ GPU ë¡œë“œ")
        
        if hasattr(self.model, 'phase2_net') and self.model.phase2_net:
            self.model.phase2_net = self.model.phase2_net.to(self.device)
            logger.info(f"  âœ… Phase2 ë„¤íŠ¸ì›Œí¬ GPU ë¡œë“œ")
        
        if hasattr(self.model, 'hierarchical_integrator') and self.model.hierarchical_integrator:
            self.model.hierarchical_integrator = self.model.hierarchical_integrator.to(self.device)
            logger.info(f"  âœ… Hierarchical Integrator GPU ë¡œë“œ")
        
        # 7. DSP & Kalman (2.3M) - ì‘ìœ¼ë‹ˆê¹Œ GPUë¡œ
        if hasattr(self.model, 'dsp_simulator') and self.model.dsp_simulator:
            self.model.dsp_simulator = self.model.dsp_simulator.to(self.device)
            logger.info(f"  âœ… DSP Simulator GPU ë¡œë“œ")
        
        if hasattr(self.model, 'kalman_filter') and self.model.kalman_filter:
            self.model.kalman_filter = self.model.kalman_filter.to(self.device)
            logger.info(f"  âœ… Kalman Filter GPU ë¡œë“œ")
        
        # Phase2 ì…ë ¥ íˆ¬ì˜ ë ˆì´ì–´ GPU ì´ë™
        if hasattr(self.model, 'phase2_input_projection'):
            self.model.phase2_input_projection = self.model.phase2_input_projection.to(self.device)
            logger.info(f"  âœ… Phase2 Input Projection GPU ë¡œë“œ")
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        if self.device.type == 'cuda':
            gpu_mem_after = torch.cuda.memory_allocated() / (1024**3)
            logger.info(f"  ìµœì¢… GPU ë©”ëª¨ë¦¬: {gpu_mem_after:.2f}GB (ì¦ê°€: {gpu_mem_after - gpu_mem_before:.2f}GB)")
            
            # ì „ì²´ GPU ë©”ëª¨ë¦¬ ì •ë³´
            total_gpu = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            logger.info(f"  GPU ì‚¬ìš©ë¥ : {gpu_mem_after/total_gpu*100:.1f}% / {total_gpu:.1f}GB")
        
        # ë¶„ì„ê¸° ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
        if hasattr(self.model, 'neural_analyzers') and self.model.neural_analyzers:
            for name, analyzer in self.model.neural_analyzers.items():
                self.model.analyzers[f"neural_{name}"] = analyzer
        
        if hasattr(self.model, 'advanced_wrappers') and self.model.advanced_wrappers:
            for name, wrapper in self.model.advanced_wrappers.items():
                self.model.analyzers[f"advanced_{name}"] = wrapper
        
        # Advanced Training ì´ˆê¸°í™”
        self.training_manager.initialize(
            model=self.model,
            num_classes=6,
            base_lr=self.config.base_lr
        )
        
        # íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸ (v2ì²˜ëŸ¼ ê° ì»´í¬ë„ŒíŠ¸ë³„ë¡œ ê³„ì‚°)
        total_params = 0
        
        # ë°±ë³¸
        backbone_params = sum(p.numel() for p in self.model.backbone.parameters())
        total_params += backbone_params
        logger.info(f"  ë°±ë³¸: {backbone_params/1e6:.1f}M")
        
        # í—¤ë“œë“¤
        head_params = 0
        for name in ['emotion_head', 'bentham_head', 'regret_head', 'surd_head']:
            if hasattr(self.model, name):
                head = getattr(self.model, name)
                params = sum(p.numel() for p in head.parameters())
                head_params += params
                logger.info(f"  {name}: {params/1e6:.1f}M")
        total_params += head_params
        
        # Neural Analyzers
        if hasattr(self.model, 'neural_analyzers') and self.model.neural_analyzers:
            analyzer_params = 0
            for name, analyzer in self.model.neural_analyzers.items():
                params = sum(p.numel() for p in analyzer.parameters())
                analyzer_params += params
            total_params += analyzer_params
            logger.info(f"  Neural Analyzers: {analyzer_params/1e6:.1f}M")
        
        # Advanced Wrappers
        if hasattr(self.model, 'advanced_wrappers') and self.model.advanced_wrappers:
            wrapper_params = 0
            for name, wrapper in self.model.advanced_wrappers.items():
                if hasattr(wrapper, 'parameters'):
                    params = sum(p.numel() for p in wrapper.parameters())
                    wrapper_params += params
            total_params += wrapper_params
            logger.info(f"  Advanced Wrappers: {wrapper_params/1e6:.1f}M")
        
        # Phase Networks
        phase_params = 0
        for name in ['phase0_net', 'phase2_net', 'hierarchical_integrator']:
            if hasattr(self.model, name) and getattr(self.model, name) is not None:
                net = getattr(self.model, name)
                params = sum(p.numel() for p in net.parameters())
                phase_params += params
        if phase_params > 0:
            total_params += phase_params
            logger.info(f"  Phase Networks: {phase_params/1e6:.1f}M")
        
        # DSP & Kalman
        dsp_kalman_params = 0
        if hasattr(self.model, 'dsp_simulator') and self.model.dsp_simulator:
            dsp_kalman_params += sum(p.numel() for p in self.model.dsp_simulator.parameters())
        if hasattr(self.model, 'kalman_filter') and self.model.kalman_filter:
            dsp_kalman_params += sum(p.numel() for p in self.model.kalman_filter.parameters())
        if dsp_kalman_params > 0:
            total_params += dsp_kalman_params
            logger.info(f"  DSP & Kalman: {dsp_kalman_params/1e6:.1f}M")
        
        logger.info(f"âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: ì´ {total_params/1e6:.1f}M íŒŒë¼ë¯¸í„°")
        
        # 730M íƒ€ê²Ÿ í™•ì¸
        target_params = 730e6
        if abs(total_params - target_params) > 10e6:  # 10M ì´ìƒ ì°¨ì´ë‚˜ë©´ ê²½ê³ 
            logger.warning(f"âš ï¸ íŒŒë¼ë¯¸í„° ê°œìˆ˜ ë¶ˆì¼ì¹˜!")
            logger.warning(f"   ëª©í‘œ: {target_params/1e6:.1f}M")
            logger.warning(f"   ì‹¤ì œ: {total_params/1e6:.1f}M")
            logger.warning(f"   ì°¨ì´: {(total_params - target_params)/1e6:.1f}M")
            
            # ìƒì„¸ ë¶„ì„
            logger.warning("ğŸ“Š ëª¨ë“ˆë³„ íŒŒë¼ë¯¸í„° ë¶„ì„:")
            all_params_dict = {}
            for name, module in self.model.named_children():
                if hasattr(module, 'parameters'):
                    params = sum(p.numel() for p in module.parameters())
                    if params > 0:
                        all_params_dict[name] = params/1e6
                        logger.warning(f"   - {name}: {params/1e6:.1f}M")
            
            # íŒŒë¼ë¯¸í„°ê°€ í•™ìŠµì— ì°¸ì—¬í•˜ëŠ”ì§€ í™•ì¸
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            logger.warning(f"   í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params/1e6:.1f}M")
            
            # íŒŒë¼ë¯¸í„°ê°€ optimizerì— ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
            optimizer_params = sum(p.numel() for group in self.optimizer.param_groups for p in group['params'])
            logger.warning(f"   Optimizer íŒŒë¼ë¯¸í„°: {optimizer_params/1e6:.1f}M")
        else:
            logger.info(f"âœ… ëª©í‘œ íŒŒë¼ë¯¸í„° ìˆ˜ ë‹¬ì„±: {total_params/1e6:.1f}M â‰ˆ 730M")
        
        # ëª¨ë“ˆ ìš”ì•½ ë¡œê·¸ ì¶œë ¥
        self._log_module_summary()
    
    def _log_module_summary(self):
        """ëª¨ë“ˆ ìš”ì•½ ë¡œê·¸ ì¶œë ¥"""
        logger.info("\nğŸ“Š ëª¨ë“ˆ êµ¬ì„± ìš”ì•½:")
        logger.info("=" * 60)
        
        # ì£¼ìš” ì»´í¬ë„ŒíŠ¸
        logger.info("ğŸ“Œ ì£¼ìš” ì»´í¬ë„ŒíŠ¸:")
        components = [
            ('ë°±ë³¸', self.model.backbone),
            ('ê°ì • í—¤ë“œ', self.model.emotion_head),
            ('ë²¤ë‹´ í—¤ë“œ', self.model.bentham_head),
            ('í›„íšŒ í—¤ë“œ', self.model.regret_head),
            ('SURD í—¤ë“œ', self.model.surd_head)
        ]
        
        for name, module in components:
            if module:
                params = sum(p.numel() for p in module.parameters())
                logger.info(f"  - {name:20s}: {params/1e6:8.2f}M íŒŒë¼ë¯¸í„°")
        
        # ë¶„ì„ê¸°ë“¤
        if self.model.analyzers:
            logger.info("\nğŸ“Œ ë¶„ì„ê¸° ëª¨ë“ˆ:")
            for name, analyzer in self.model.analyzers.items():
                params = sum(p.numel() for p in analyzer.parameters())
                logger.info(f"  - {name:24s}: {params/1e6:8.2f}M íŒŒë¼ë¯¸í„°")
        
        # Advanced Training ìƒíƒœ
        logger.info("\nğŸ“Œ Advanced Training ê¸°ë²•:")
        logger.info(f"  - Label Smoothing: {'âœ…' if self.config.enable_label_smoothing else 'âŒ'}")
        logger.info(f"  - R-Drop: {'âœ…' if self.config.enable_rdrop else 'âŒ'}")
        logger.info(f"  - EMA: {'âœ…' if self.config.enable_ema else 'âŒ'}")
        logger.info(f"  - LLRD: {'âœ…' if self.config.enable_llrd else 'âŒ'}")
        logger.info(f"  - Sweet Spot Detection: {'âœ…' if self.config.enable_sweet_spot else 'âŒ'}")
        logger.info(f"  - Parameter Crossover: {'âœ…' if self.config.enable_crossover else 'âŒ'}")
        
        logger.info("=" * 60)
    
    def _initialize_dataloaders(self):
        """ë°ì´í„° ë¡œë” ì´ˆê¸°í™” (ì²­í¬ ë°©ì‹ ìš°ì„ )"""
        
        # ì²­í¬ ì„ë² ë”© ê°•ì œ ì‚¬ìš©
        embeddings_dir = Path("claude_api_preprocessing/embedded")
        embeddings_dir.mkdir(parents=True, exist_ok=True)
        
        # ì²­í¬ ë§¤ë‹ˆì € ìƒì„±
        chunk_manager = EmbeddingChunkManager(str(embeddings_dir))
        logger.info(f"ğŸ§± ì²­í¬ ëª¨ë“œ í™œì„±í™” - {embeddings_dir}")
        
        # ê¸°ì¡´ ì²­í¬ê°€ ìˆëŠ”ì§€ í™•ì¸
        if (embeddings_dir / "metadata.json").exists():
            logger.info("ğŸ“¦ ê¸°ì¡´ ì²­í¬ ì„ë² ë”© ë¡œë“œ")
            stats = chunk_manager.get_statistics()
            logger.info(f"  - ì²­í¬ ìˆ˜: {stats['total_chunks']}ê°œ")
            logger.info(f"  - ì „ì²´ ë°ì´í„°: {stats['total_items']:,}ê°œ")
            logger.info(f"  - ì„ë² ë”© ì™„ë£Œ: {stats['total_embedded']:,}ê°œ ({stats['embedding_ratio']*100:.1f}%)")
            
            # ì²­í¬ì—ì„œ ë°ì´í„° ë¡œë“œ
            data = []
            metadata = chunk_manager.load_metadata()
            for chunk_info in metadata['chunks']:
                chunk_data = chunk_manager.load_chunk(chunk_info['chunk_idx'])
                data.extend(chunk_data)
            
            logger.info(f"  - ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ ì•„ì´í…œ")
            preprocessed_path = None  # ì²­í¬ ì‚¬ìš© ì‹œ ê²½ë¡œ ì—†ìŒ
            
        else:
            # ì²­í¬ê°€ ì—†ìœ¼ë©´ ì›ë³¸ íŒŒì¼ì—ì„œ ë¡œë“œ
            logger.info("ğŸ“‚ ì²­í¬ê°€ ì—†ìŒ - ì›ë³¸ ë°ì´í„° ë¡œë“œ")
            preprocessed_path = Path("claude_api_preprocessing/claude_preprocessed_complete.json")
            
            if not preprocessed_path.exists():
                # ëŒ€ì²´ ê²½ë¡œ ì‹œë„
                preprocessed_path = Path("for_learn_dataset/claude_preprocessed_complete.json")
                if not preprocessed_path.exists():
                    logger.error(f"ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {preprocessed_path}")
                    raise FileNotFoundError(f"ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
            # ë‹¨ì¼ ì„ë² ë”© íŒŒì¼ì€ ì ˆëŒ€ ì½ì§€ ì•ŠìŒ - ì›ë³¸ ë°ì´í„°ë§Œ ë¡œë“œ
            logger.info(f"ğŸ“‚ ì›ë³¸ ë°ì´í„° ë¡œë“œ: {preprocessed_path}")
            logger.info("âš ï¸ ë‹¨ì¼ ì„ë² ë”© íŒŒì¼ì€ ë¬´ì‹œí•˜ê³  ì²­í¬ ë°©ì‹ ì‚¬ìš©")
            with open(preprocessed_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        
        # ìƒ˜í”Œ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ)
        if hasattr(self.config, 'max_samples') and self.config.max_samples:
            data = data[:self.config.max_samples]
        
        # ë°ì´í„°ì…‹ í´ë˜ìŠ¤
        class RedHeartDataset(Dataset):
            def __init__(self, data_list, preprocessed_path=None, chunk_manager=None):
                self.data = data_list
                self.preprocessed_path = preprocessed_path
                self.chunk_manager = chunk_manager  # ì²­í¬ ë§¤ë‹ˆì €
                self.embedding_manager = None  # ì§€ì—° ì´ˆê¸°í™”
                self.embeddings_modified = False  # ì„ë² ë”© ìˆ˜ì • ì—¬ë¶€ ì¶”ì 
                self.use_chunks = chunk_manager is not None
                
                # label ë§¤í•‘ (v2ì—ì„œ ì²˜ëŸ¼ TargetMapper ëŒ€ì‹  ì§ì ‘ ì²˜ë¦¬)
                self.label_to_idx = {
                    'AUTHOR': 0,
                    'EVERYBODY': 1,
                    'INFO': 2,
                    'NOBODY': 3,
                    'OTHER': 4
                }
                # ê°ì • ë§¤í•‘ (emotions dictì—ì„œ ì¶”ì¶œ)
                self.emotion_keys = ['joy', 'anger', 'surprise', 'disgust', 'sadness', 'shame', 'fear']
                
                # ì„ë² ë”© ìƒíƒœ í™•ì¸
                self._check_embeddings()
                
            def __len__(self):
                return len(self.data)
            
            def __getitem__(self, idx):
                item = self.data[idx]
                # ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = item.get('text', '') + ' ' + item.get('title', '')
                
                # í…ìŠ¤íŠ¸ ì„ë² ë”©ì€ ì‚¬ì „ ì²˜ë¦¬ëœ ë°ì´í„°ì—ì„œ ì‚¬ìš©
                # preprocessed ë°ì´í„°ì— ì´ë¯¸ embeddingì´ ìˆìœ¼ë©´ ì‚¬ìš©
                if 'embedding' in item:
                    text_embedding = torch.tensor(item['embedding'], dtype=torch.float32)
                    # 100x768 í¬ê¸°ë¡œ ì¡°ì •
                    if text_embedding.shape[0] < 100:
                        # íŒ¨ë”©
                        pad_size = 100 - text_embedding.shape[0]
                        text_embedding = torch.cat([text_embedding, torch.zeros(pad_size, 768)], dim=0)
                    elif text_embedding.shape[0] > 100:
                        # ìë¥´ê¸°
                        text_embedding = text_embedding[:100]
                else:
                    # ì„ë² ë”©ì´ ì—†ìœ¼ë©´ SentenceTransformerë¡œ ìƒì„±
                    if self.embedding_manager is None:
                        try:
                            self.embedding_manager = get_sentence_transformer(
                                'sentence-transformers/all-MiniLM-L6-v2',
                                device='cuda' if torch.cuda.is_available() else 'cpu',
                                cache_folder=os.path.expanduser('~/.cache/huggingface/hub')
                            )
                        except Exception as e:
                            logger.error(f"âŒ SentenceTransformer ë¡œë“œ ì‹¤íŒ¨: {e}")
                            logger.error("ì„ë² ë”© ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì¢…ë£Œ.")
                            raise RuntimeError(f"SentenceTransformer í•„ìˆ˜ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    
                    if self.embedding_manager:
                        try:
                            # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
                            embedding = self.embedding_manager.encode(text[:512])  # ìµœëŒ€ 512ì
                            text_embedding = torch.tensor(embedding, dtype=torch.float32)
                            
                            # 100x768 í˜•íƒœë¡œ í™•ì¥ (ë¬¸ì¥ì„ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ)
                            if text_embedding.dim() == 1:
                                text_embedding = text_embedding.unsqueeze(0)
                            
                            # 384ì°¨ì›ì„ 768ì°¨ì›ìœ¼ë¡œ íŒ¨ë”© (all-MiniLM-L6-v2ëŠ” 384ì°¨ì› ì¶œë ¥)
                            if text_embedding.shape[-1] == 384:
                                padding = torch.zeros(text_embedding.shape[0], 384, dtype=torch.float32)
                                text_embedding = torch.cat([text_embedding, padding], dim=-1)  # (1, 768)
                            
                            # 100ê°œ í† í°ìœ¼ë¡œ í™•ì¥
                            text_embedding = text_embedding.repeat(100, 1)
                            
                            # ìƒì„±ëœ ì„ë² ë”©ì„ ë°ì´í„°ì— ì €ì¥
                            self.data[idx]['embedding'] = text_embedding.numpy().tolist()
                            self.embeddings_modified = True
                            
                        except Exception as e:
                            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                            logger.error(f"í…ìŠ¤íŠ¸: {text[:50]}...")
                            raise RuntimeError(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                    else:
                        logger.error("âŒ SentenceTransformer ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        raise RuntimeError("SentenceTransformer ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
                
                # label ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜
                label_str = item.get('label', 'OTHER')
                label_idx = self.label_to_idx.get(label_str, 4)  # ê¸°ë³¸ê°’ 4 (OTHER)
                
                # emotions dictì—ì„œ ê°ì • ë²¡í„° ì¶”ì¶œ
                emotions = item.get('emotions', {})
                if isinstance(emotions, dict):
                    # 7ê°œ ê¸°ë³¸ ê°ì • ì¶”ì¶œ
                    emotion_vector = [emotions.get(key, 0.0) for key in self.emotion_keys]
                    # ê°€ì¥ ë†’ì€ ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ë¼ë²¨ë¡œ
                    emotion_label = torch.argmax(torch.tensor(emotion_vector)).item()
                else:
                    emotion_label = 0  # ê¸°ë³¸ê°’
                
                # bentham_scores ì²˜ë¦¬ (dict -> 10ì°¨ì› ë²¡í„°)
                bentham_keys = [
                    'intensity', 'duration', 'certainty', 'propinquity',
                    'purity', 'extent', 'fecundity', 'remoteness', 
                    'succession', 'utility'
                ]
                
                bentham_scores = item.get('bentham_scores', {})
                if isinstance(bentham_scores, dict):
                    # dictì—ì„œ ê°’ ì¶”ì¶œ (ì—†ìœ¼ë©´ 0.5 ê¸°ë³¸ê°’)
                    bentham_vector = [bentham_scores.get(key, 0.5) for key in bentham_keys]
                else:
                    # dictê°€ ì•„ë‹ˆë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                    bentham_vector = [0.5] * 10
                
                return {
                    'input': text_embedding,
                    'emotion_label': torch.tensor(emotion_label, dtype=torch.long),
                    'bentham_label': torch.tensor(bentham_vector, dtype=torch.float),
                    'regret_label': torch.tensor(item.get('regret_factor', 0.0), dtype=torch.float),
                    'surd_label': torch.tensor(label_idx, dtype=torch.long)  # labelì„ SURDì—ë„ ì‚¬ìš©
                }
            
            def _check_embeddings(self):
                """ì„ë² ë”© ìƒíƒœ í™•ì¸"""
                total_items = len(self.data)
                items_with_embedding = sum(1 for item in self.data if 'embedding' in item)
                items_without_embedding = total_items - items_with_embedding
                
                logger.info(f"ğŸ“Š ì„ë² ë”© ìƒíƒœ:")
                logger.info(f"  - ì „ì²´ ë°ì´í„°: {total_items}ê°œ")
                logger.info(f"  - ì„ë² ë”© ìˆìŒ: {items_with_embedding}ê°œ ({items_with_embedding/total_items*100:.1f}%)")
                logger.info(f"  - ì„ë² ë”© ì—†ìŒ: {items_without_embedding}ê°œ ({items_without_embedding/total_items*100:.1f}%)")
                
                if items_without_embedding > 0:
                    logger.warning(f"âš ï¸ {items_without_embedding}ê°œ í•­ëª©ì— ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤. ìë™ ìƒì„±ë©ë‹ˆë‹¤.")
            
            def save_embeddings(self):
                """ìƒì„±ëœ ì„ë² ë”©ì„ ì €ì¥ (ì²­í¬ ë°©ì‹ ìš°ì„ )"""
                if not self.embeddings_modified:
                    return
                
                if self.use_chunks and self.chunk_manager:
                    # ì²­í¬ ë°©ì‹ìœ¼ë¡œ ì €ì¥
                    try:
                        self.chunk_manager.create_chunks_from_embedded_data(self.data, rebuild=not self.chunk_manager.metadata_file.exists())
                        logger.info(f"âœ… ì„ë² ë”©ì´ ì²­í¬ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")
                        self.embeddings_modified = False
                    except Exception as e:
                        logger.error(f"ì²­í¬ ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨: {e}")
                else:
                    # ì²­í¬ ë§¤ë‹ˆì €ê°€ ì—†ëŠ” ê²½ìš° ê²½ê³ 
                    logger.warning("âš ï¸ ì²­í¬ ë§¤ë‹ˆì €ê°€ ì—†ì–´ ì„ë² ë”©ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì²­í¬ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
        val_size = int(len(data) * self.config.validation_split)
        train_data = data[val_size:]
        val_data = data[:val_size]
        
        # ë°ì´í„°ì…‹ ìƒì„± (preprocessed_pathì™€ chunk_manager ì „ë‹¬)
        train_dataset = RedHeartDataset(train_data, preprocessed_path, chunk_manager)
        val_dataset = RedHeartDataset(val_data, preprocessed_path, chunk_manager)
        
        # ë°ì´í„°ì…‹ í¬ê¸° ì €ì¥
        train_size = len(train_dataset)
        val_size_actual = len(val_dataset)
        
        self.train_loader = DataLoader(
            train_dataset,
            batch_size=self.config.micro_batch_size,
            shuffle=True,
            num_workers=self.config.num_workers,
            pin_memory=True
        )
        
        self.val_loader = DataLoader(
            val_dataset,
            batch_size=self.config.micro_batch_size,
            shuffle=False,
            num_workers=self.config.num_workers,
            pin_memory=True
        )
        
        logger.info(f"âœ… ë°ì´í„° ë¡œë” ì´ˆê¸°í™”: Train={train_size}, Val={val_size_actual}")
    
    def _initialize_optimizer(self):
        """ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”"""
        # LLRD ì‚¬ìš© ì‹œ
        if self.config.enable_llrd:
            self.optimizer = self.training_manager.get_optimizer(
                self.model,
                lr=self.config.base_lr,
                weight_decay=0.01
            )
        else:
            self.optimizer = torch.optim.AdamW(
                self.model.parameters(),
                lr=self.config.base_lr,
                weight_decay=0.01
            )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬
        total_steps = len(self.train_loader) * self.config.total_epochs
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer,
            T_0=total_steps // 10,
            T_mult=2,
            eta_min=self.config.base_lr * 0.01
        )
        
        logger.info("âœ… ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def run_lr_sweep(self):
        """LR ìŠ¤ìœ• ì‹¤í–‰"""
        if not self.config.lr_sweep_enabled:
            return
        
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ” Learning Rate Sweep ì‹œì‘...")
        logger.info("=" * 70)
        
        # ê°„ë‹¨í•œ ì†ì‹¤ í•¨ìˆ˜
        criterion = nn.CrossEntropyLoss()
        
        # ìŠ¤ìœ• ì‹¤í–‰
        sweep_results = self.lr_sweep.run_sweep(
            model=self.model,
            train_loader=self.train_loader,
            val_loader=self.val_loader,
            criterion=criterion,
            device=self.device
        )
        
        # ìµœì  LRë¡œ ì˜µí‹°ë§ˆì´ì € ì¬ì´ˆê¸°í™”
        self.config.base_lr = self.lr_sweep.best_lr
        self._initialize_optimizer()
        
        logger.info(f"âœ… ìµœì  LR ì„ íƒ: {self.config.base_lr:.1e}")
    
    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """í•œ ì—í­ í•™ìŠµ"""
        self.model.train()
        epoch_losses = []
        module_metrics = {}
        batch_gradients = {}  # ëª¨ë“  ë°°ì¹˜ì˜ gradient norm ì €ì¥
        total_batches = len(self.train_loader)
        completed_batches = 0
        
        for batch_idx, batch in enumerate(self.train_loader):
            # OOM í•¸ë“¤ë§
            if self.config.enable_oom_handler:
                self.oom_handler.log_memory_stats(self.global_step, 'train')
            
            # Forward pass
            try:
                loss, metrics = self._forward_step(batch)
            except RuntimeError as e:
                if 'out of memory' in str(e).lower():
                    if self.oom_handler.handle_oom(e):
                        # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì • í›„ ì¬ì‹œë„
                        self.train_loader = self.oom_handler.adjust_dataloader(self.train_loader)
                        continue
                    else:
                        raise
                else:
                    raise
            
            # Backward pass (Gradient Accumulation)
            loss = loss / self.config.gradient_accumulation
            loss.backward()
            
            # ë§¤ ë°°ì¹˜ë§ˆë‹¤ gradient norm ê³„ì‚° (accumulation ì—¬ë¶€ì™€ ë¬´ê´€)
            with torch.no_grad():
                # ì „ì²´ ëª¨ë¸ì˜ gradient norm
                total_grad_norm = 0.0
                for p in self.model.parameters():
                    if p.grad is not None:
                        param_norm = p.grad.data.norm(2).item()
                        total_grad_norm += param_norm ** 2
                total_grad_norm = total_grad_norm ** 0.5
                
                # ëª¨ë“ˆë³„ gradient norm ê³„ì‚°
                for name, module in self.model.named_children():
                    module_grad_norm = 0.0
                    for p in module.parameters():
                        if p.grad is not None:
                            param_norm = p.grad.data.norm(2).item()
                            module_grad_norm += param_norm ** 2
                    module_grad_norm = module_grad_norm ** 0.5
                    
                    if module_grad_norm > 0:
                        if f'{name}_grad_norm' not in batch_gradients:
                            batch_gradients[f'{name}_grad_norm'] = []
                        batch_gradients[f'{name}_grad_norm'].append(module_grad_norm)
                        metrics[f'{name}_grad_norm'] = module_grad_norm
                
                if total_grad_norm > 0:
                    if 'total_grad_norm' not in batch_gradients:
                        batch_gradients['total_grad_norm'] = []
                    batch_gradients['total_grad_norm'].append(total_grad_norm)
                    metrics['total_grad_norm'] = total_grad_norm
            
            # Gradient Accumulation
            if (batch_idx + 1) % self.config.gradient_accumulation == 0:
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                # Optimizer step (íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ í”Œë˜ê·¸ í™•ì¸)
                if not self.no_param_update:
                    # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ì „ ê°’ ì €ì¥ (ìƒ˜í”Œë§)
                    param_before = {}
                    if batch_idx == 0 or batch_idx % 100 == 0:  # ì²« ë°°ì¹˜ì™€ 100ë°°ì¹˜ë§ˆë‹¤ ì²´í¬
                        for name, module in self.model.named_children():
                            if hasattr(module, 'parameters'):
                                # ì²« ë²ˆì§¸ íŒŒë¼ë¯¸í„°ë§Œ ìƒ˜í”Œë§
                                for p in module.parameters():
                                    if p.requires_grad and p.grad is not None:
                                        param_before[name] = p.data.clone().mean().item()
                                        break
                    
                    self.optimizer.step()
                    self.scheduler.step()
                    
                    # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ í›„ í™•ì¸
                    if param_before:
                        param_updated = []
                        param_not_updated = []
                        for name, module in self.model.named_children():
                            if name in param_before:
                                for p in module.parameters():
                                    if p.requires_grad and p.grad is not None:
                                        param_after = p.data.mean().item()
                                        if abs(param_after - param_before[name]) > 1e-8:
                                            param_updated.append(name)
                                        else:
                                            param_not_updated.append(name)
                                        break
                        
                        if param_updated:
                            logger.debug(f"  âœ… íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ë¨ (batch {batch_idx}): {', '.join(param_updated)}")
                        if param_not_updated:
                            logger.warning(f"  âš ï¸ íŒŒë¼ë¯¸í„° ë¯¸ì—…ë°ì´íŠ¸ (batch {batch_idx}): {', '.join(param_not_updated)}")
                    
                    # EMA update
                    self.training_manager.step()
                else:
                    # ê²€ì¦ ëª¨ë“œ: ê·¸ë¼ë””ì–¸íŠ¸ë§Œ ê³„ì‚°í•˜ê³  ì—…ë°ì´íŠ¸ëŠ” ê±´ë„ˆëœ€
                    logger.debug("  [ê²€ì¦] íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ê±´ë„ˆëœ€")
                
                self.optimizer.zero_grad()
                self.global_step += 1
            
            epoch_losses.append(loss.item() * self.config.gradient_accumulation)
            
            # ë¡œê¹…
            if batch_idx % self.config.log_interval == 0:
                avg_loss = np.mean(epoch_losses[-self.config.log_interval:])
                # ì „ì²´ param_groupsì˜ LR ì •ë³´ ìˆ˜ì§‘
                lrs = [group['lr'] for group in self.optimizer.param_groups]
                avg_lr = np.mean(lrs)
                # ì£¼ìš” ë ˆì´ì–´ LR í‘œì‹œ (ì²« ë²ˆì§¸, ì¤‘ê°„, ë§ˆì§€ë§‰)
                if len(lrs) > 1:
                    lr_info = f"LR: {avg_lr:.1e} (layers: [{lrs[0]:.1e}, {lrs[len(lrs)//2]:.1e}, {lrs[-1]:.1e}])"
                else:
                    lr_info = f"LR: {avg_lr:.1e}"
                logger.info(f"  [Epoch {epoch}][{batch_idx}/{len(self.train_loader)}] "
                          f"Loss: {avg_loss:.4f}, {lr_info}")
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            for key, value in metrics.items():
                if key not in module_metrics:
                    module_metrics[key] = []
                module_metrics[key].append(value)
            
            completed_batches += 1
        
        # ë°°ì¹˜ ë£¨í”„ ì™„ë£Œ í™•ì¸
        if completed_batches != total_batches:
            logger.error(f"  âš ï¸ ì—í­ {epoch} ë¶ˆì™„ì „ ì¢…ë£Œ: {completed_batches}/{total_batches} ë°°ì¹˜ë§Œ ì²˜ë¦¬ë¨")
            logger.error(f"     ë§ˆì§€ë§‰ ì²˜ë¦¬ ë°°ì¹˜ ì¸ë±ìŠ¤: {completed_batches - 1}")
        else:
            logger.info(f"  âœ… ì—í­ {epoch} ì™„ë£Œ: {completed_batches}/{total_batches} ë°°ì¹˜ ëª¨ë‘ ì²˜ë¦¬")
        
        # gradient norm í‰ê·  ì¶”ê°€ (ëª¨ë“  ë°°ì¹˜ì˜ í‰ê· )
        for key, values in batch_gradients.items():
            module_metrics[key] = values
        
        # ì—í­ í‰ê· 
        avg_metrics = {k: np.mean(v) for k, v in module_metrics.items()}
        avg_metrics['loss'] = np.mean(epoch_losses)
        avg_metrics['completed_batches'] = completed_batches
        avg_metrics['total_batches'] = total_batches
        
        return avg_metrics
    
    def validate(self) -> Dict[str, float]:
        """ê²€ì¦"""
        self.model.eval()
        val_losses = []
        module_metrics = {}
        
        with torch.no_grad():
            # EMA ì ìš©
            if self.config.enable_ema:
                self.training_manager.apply_ema()
            
            for batch in self.val_loader:
                loss, metrics = self._forward_step(batch)
                val_losses.append(loss.item())
                
                for key, value in metrics.items():
                    if key not in module_metrics:
                        module_metrics[key] = []
                    module_metrics[key].append(value)
            
            # EMA ë³µì›
            if self.config.enable_ema:
                self.training_manager.restore_ema()
        
        # í‰ê· 
        avg_metrics = {k: np.mean(v) for k, v in module_metrics.items()}
        avg_metrics['val_loss'] = np.mean(val_losses)
        
        return avg_metrics
    
    def _forward_step(self, batch: Dict) -> Tuple[torch.Tensor, Dict]:
        """
        í•™ìŠµ ìŠ¤í… - V2ì˜ 3ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ë³µì›
        1. FORWARD: ë°ì´í„° â†’ ë°±ë³¸ â†’ í—¤ë“œ
        2. COMPUTE: ì†ì‹¤ ê³„ì‚° + Neural Analyzers + DSP/Kalman
        3. UPDATE: ì—­ì „íŒŒ + ìµœì í™”
        """
        batch_idx = self.global_step % 100  # ë¡œê¹…ìš©
        
        # ========== STAGE 1: FORWARD ==========
        if self.verbose and batch_idx < 3:
            logger.info("    [STAGE 1] Forward Pass ì‹œì‘")
        
        # ë°ì´í„° ì¤€ë¹„ - ì…ë ¥ ì¶”ì¶œ
        inputs = batch['input'].to(self.device)
        
        # ë°±ë³¸ í†µê³¼
        backbone_outputs = self.model.backbone(inputs, return_all_tasks=True)
        features = backbone_outputs.get('emotion', inputs)  # 896ì°¨ì›
        
        if self.verbose and batch_idx < 3:
            logger.info(f"      - ë°±ë³¸ ì¶œë ¥ shape: {features.shape}")
            logger.info(f"      - ë°±ë³¸ ì¶œë ¥ í‚¤: {list(backbone_outputs.keys())}")
        
        # ========== STAGE 2: COMPUTE LOSSES ==========
        if self.verbose and batch_idx < 3:
            logger.info("    [STAGE 2] Compute Loss")
        
        # í—¤ë“œ ì†ì‹¤ ê³„ì‚°
        head_losses = []
        individual_losses = {}  # ê°œë³„ ì†ì‹¤ ì €ì¥ìš©
        individual_accs = {}    # ê°œë³„ ì •í™•ë„ ì €ì¥ìš©
        
        # ê°ì • í—¤ë“œ
        if hasattr(self.model, 'emotion_head'):
            emotion_output = self.model.emotion_head(features)
            emotion_pred = emotion_output['emotions'] if isinstance(emotion_output, dict) else emotion_output
            emotion_target = batch['emotion_label'].to(self.device)
            emotion_loss = self.model.emotion_head.compute_loss(emotion_pred, emotion_target)
            head_losses.append(emotion_loss)
            individual_losses['emotion_loss'] = emotion_loss.item()
            # accuracy ê³„ì‚° (classification task)
            emotion_acc = (emotion_pred.argmax(dim=-1) == emotion_target).float().mean().item()
            individual_accs['emotion_acc'] = emotion_acc
            if self.verbose and batch_idx < 3:
                logger.info(f"      - ê°ì • ì†ì‹¤: {emotion_loss.item():.6f}, ì •í™•ë„: {emotion_acc:.4f}")
        
        # ë²¤ë‹´ í—¤ë“œ
        if hasattr(self.model, 'bentham_head'):
            bentham_output = self.model.bentham_head(features)
            bentham_pred = bentham_output['bentham_scores'] if isinstance(bentham_output, dict) else bentham_output
            bentham_target = batch['bentham_label'].to(self.device)
            bentham_loss = self.model.bentham_head.compute_loss(bentham_pred, bentham_target)
            head_losses.append(bentham_loss)
            individual_losses['bentham_loss'] = bentham_loss.item()
            # accuracy ê³„ì‚° (regression task - ë™ì  threshold ê¸°ë°˜)
            # í•™ìŠµ ì§„í–‰ì— ë”°ë¼ ì ì§„ì ìœ¼ë¡œ ì—„ê²©í•œ ê¸°ì¤€ ì ìš©
            dynamic_threshold = 0.3 if self.current_epoch <= 5 else 0.25 if self.current_epoch <= 15 else 0.2 if self.current_epoch <= 30 else 0.15
            bentham_acc = ((bentham_pred - bentham_target).abs() < dynamic_threshold).float().mean().item()
            individual_accs['bentham_acc'] = bentham_acc
            if self.verbose and batch_idx < 3:
                logger.info(f"      - ë²¤ë‹´ ì†ì‹¤: {bentham_loss.item():.6f}, ì •í™•ë„: {bentham_acc:.4f}")
        
        # í›„íšŒ í—¤ë“œ
        if hasattr(self.model, 'regret_head'):
            regret_output = self.model.regret_head(features)
            regret_pred = regret_output['regret_score'] if isinstance(regret_output, dict) else regret_output
            regret_target = batch['regret_label'].to(self.device)
            regret_loss = self.model.regret_head.compute_loss(regret_pred, regret_target)
            head_losses.append(regret_loss)
            individual_losses['regret_loss'] = regret_loss.item()
            # accuracy ê³„ì‚° (regression task - ë™ì  threshold ê¸°ë°˜)
            # í•™ìŠµ ì§„í–‰ì— ë”°ë¼ ì ì§„ì ìœ¼ë¡œ ì—„ê²©í•œ ê¸°ì¤€ ì ìš©
            dynamic_threshold = 0.3 if self.current_epoch <= 5 else 0.25 if self.current_epoch <= 15 else 0.2 if self.current_epoch <= 30 else 0.15
            regret_acc = ((regret_pred - regret_target).abs() < dynamic_threshold).float().mean().item()
            individual_accs['regret_acc'] = regret_acc
            if self.verbose and batch_idx < 3:
                logger.info(f"      - í›„íšŒ ì†ì‹¤: {regret_loss.item():.6f}, ì •í™•ë„: {regret_acc:.4f}")
        
        # SURD í—¤ë“œ
        if hasattr(self.model, 'surd_head'):
            surd_output = self.model.surd_head(features)
            surd_pred = surd_output['surd_values'] if isinstance(surd_output, dict) else surd_output
            
            # SURD íƒ€ê²Ÿì„ ì‹¤ì œ ë°ì´í„°ì—ì„œ ê³„ì‚°
            batch_size = surd_pred.shape[0]
            surd_target = torch.zeros((batch_size, 4), device=self.device)
            
            # Synergy: ê°ì • ë‹¤ì–‘ì„± (ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜)
            if 'emotion_label' in batch:
                emotion_probs = F.one_hot(batch['emotion_label'].to(self.device), num_classes=7).float()
                emotion_entropy = -(emotion_probs * (emotion_probs + 1e-10).log()).sum(dim=1)
                surd_target[:, 0] = emotion_entropy / np.log(7)  # ì •ê·œí™”
            
            # Unique: ë ˆì´ë¸” ê³ ìœ ì„± (one-hot ì¸ì½”ë”©)
            if 'surd_label' in batch:
                label_unique = F.one_hot(batch['surd_label'].to(self.device), num_classes=5).float()
                surd_target[:, 1] = label_unique.max(dim=1)[0]  # ìµœëŒ€ê°’ = 1.0
            
            # Redundant: ë²¤ë‹´ ìƒê´€ë„ (í‰ê· ê³¼ ë¶„ì‚°)
            if 'bentham_label' in batch:
                bentham = batch['bentham_label'].to(self.device)
                bentham_mean = bentham.mean(dim=1)
                bentham_std = bentham.std(dim=1) + 1e-10
                surd_target[:, 2] = 1.0 - (bentham_std / (bentham_mean + 1e-10)).clamp(0, 1)
            
            # Deterministic: í›„íšŒ ê²°ì •ì„± (ì ˆëŒ€ê°’)
            if 'regret_label' in batch:
                regret = batch['regret_label'].to(self.device)
                if regret.dim() == 1:
                    regret = regret.unsqueeze(1)
                surd_target[:, 3] = regret.abs().squeeze()
            
            surd_loss = self.model.surd_head.compute_loss(surd_pred, surd_target)
            head_losses.append(surd_loss)
            individual_losses['surd_loss'] = surd_loss.item()
            # accuracy ê³„ì‚° (multi-dimensional regression - ë™ì  threshold ê¸°ë°˜)
            # í•™ìŠµ ì§„í–‰ì— ë”°ë¼ ì ì§„ì ìœ¼ë¡œ ì—„ê²©í•œ ê¸°ì¤€ ì ìš©
            # SURDëŠ” 4ì°¨ì›ì´ë¯€ë¡œ ì•½ê°„ ë” ì™„í™”ëœ ê¸°ì¤€ ì ìš©
            dynamic_threshold = 0.35 if self.current_epoch <= 5 else 0.3 if self.current_epoch <= 15 else 0.25 if self.current_epoch <= 30 else 0.2
            surd_acc = ((surd_pred - surd_target).abs() < dynamic_threshold).float().mean().item()
            individual_accs['surd_acc'] = surd_acc
            if self.verbose and batch_idx < 3:
                logger.info(f"      - SURD ì†ì‹¤: {surd_loss.item():.6f}, ì •í™•ë„: {surd_acc:.4f}")
        
        # ========== STAGE 2: NEURAL ANALYZERS ==========
        if self.verbose and batch_idx < 3:
            logger.info("    [STAGE 2] Neural Analyzer Processing")
        
        analyzer_losses = []
        analyzer_accuracies = []  # ëˆ„ë½ëœ ì´ˆê¸°í™” ì¶”ê°€
        dsp_output = None
        neural_emotion_output = None
        
        # Neural Emotion Analyzer ì²˜ë¦¬ (ë¨¼ì €)
        if hasattr(self.model, 'neural_analyzers') and 'emotion' in self.model.neural_analyzers:
            try:
                emotion_analyzer = self.model.neural_analyzers['emotion']
                neural_emotion_output = emotion_analyzer(features)
                
                if 'emotion_logits' in neural_emotion_output:
                    target = batch['emotion_label'].to(self.device)
                    if target.dim() == 1:
                        target = F.one_hot(target, num_classes=7).float()
                    emotion_loss = F.cross_entropy(neural_emotion_output['emotion_logits'], target)
                    analyzer_losses.append(emotion_loss)
                    if self.verbose and batch_idx < 3:
                        logger.info(f"      - neural_emotion ì†ì‹¤: {emotion_loss.item():.6f}")
            except Exception as e:
                logger.error(f"    âŒ neural_emotion ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # Phase0 Network ì²˜ë¦¬
        if hasattr(self.model, 'phase0_net') and self.model.phase0_net:
            try:
                phase0_output = self.model.phase0_net(features)
                # Phase0ì€ 7ì°¨ì› ê°ì • ì¶œë ¥ - ê°ì • ë ˆì´ë¸”ê³¼ ë¹„êµ
                if 'emotion_label' in batch and phase0_output.shape[-1] == 7:
                    # ê°ì • ë ˆì´ë¸”ê³¼ ë¹„êµ
                    emotion_target = batch['emotion_label'].to(self.device)
                    phase0_loss = F.cross_entropy(phase0_output, emotion_target)
                else:
                    # ê°ì • ë ˆì´ë¸”ì´ ì—†ìœ¼ë©´ ìê¸° ìì‹ ê³¼ì˜ ì¼ê´€ì„± ì†ì‹¤
                    phase0_loss = F.mse_loss(phase0_output, phase0_output.detach().mean(dim=0).expand_as(phase0_output))
                
                analyzer_losses.append(phase0_loss)
                individual_losses['phase0_loss'] = phase0_loss.item()
                # Phase0 accuracy
                if 'emotion_label' in batch and phase0_output.shape[-1] == 7:
                    phase0_acc = (phase0_output.argmax(dim=-1) == emotion_target).float().mean().item()
                else:
                    phase0_acc = max(0, 1.0 - phase0_loss.item())
                individual_accs['phase0_acc'] = phase0_acc
                if self.verbose and batch_idx < 3:
                    logger.info(f"      - Phase0 ì†ì‹¤: {phase0_loss.item():.6f}, ì •í™•ë„: {phase0_acc:.4f}")
            except Exception as e:
                logger.warning(f"    âš ï¸ Phase0 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # Phase2 Network ì²˜ë¦¬ - featuresë¥¼ ì—¬ëŸ¬ "ê´€ì "ìœ¼ë¡œ ë¶„í• 
        phase2_output = None
        if hasattr(self.model, 'phase2_net') and self.model.phase2_net:
            try:
                # 896ì°¨ì›ì„ ì—¬ëŸ¬ "ê°œì¸"ì˜ ê´€ì ìœ¼ë¡œ ì¬í•´ì„
                # 896 = 128 * 7 (7ê°œì˜ ê°ì • ê´€ì )
                # ê° 128ì°¨ì›ì„ 768ì°¨ì›ìœ¼ë¡œ íˆ¬ì˜
                batch_size = features.shape[0]
                
                # featuresë¥¼ 7ê°œ ì²­í¬ë¡œ ë¶„í• 
                num_individuals = 7  # 7ê°€ì§€ ê°ì • ì°¨ì›
                chunk_size = features.shape[-1] // num_individuals  # 896 // 7 = 128
                
                # [batch_size, 896] -> [batch_size, 7, 128]
                individuals = features.view(batch_size, num_individuals, chunk_size)
                
                # ê° ê°œì¸ì„ 768ì°¨ì›ìœ¼ë¡œ íˆ¬ì˜ (Phase2 LSTM ì…ë ¥ ì°¨ì›)
                individuals_768 = self.model.phase2_input_projection(individuals)  # [batch_size, 7, 768]
                
                # Phase2ë¡œ ê³µë™ì²´ íŒ¨í„´ ì¶”ì¶œ
                phase2_output = self.model.phase2_net(individuals_768, cultural_context='global')
                
                # Phase2ëŠ” 10ì°¨ì› ì»¤ë®¤ë‹ˆí‹° íŒ¨í„´ ì¶œë ¥
                # ê³µë™ì²´ ì¼ê´€ì„± ì†ì‹¤: ê°™ì€ ë°°ì¹˜ëŠ” ë¹„ìŠ·í•œ ê³µë™ì²´ íŒ¨í„´ì„ ê°€ì ¸ì•¼ í•¨
                community_center = phase2_output.mean(dim=0, keepdim=True)
                phase2_loss = F.mse_loss(phase2_output, community_center.expand_as(phase2_output)) * 0.5
                
                analyzer_losses.append(phase2_loss)
                individual_losses['phase2_loss'] = phase2_loss.item()
                phase2_acc = max(0, 1.0 - phase2_loss.item())
                individual_accs['phase2_acc'] = phase2_acc
                
                if self.verbose and batch_idx < 3:
                    logger.info(f"      - Phase2 ì†ì‹¤: {phase2_loss.item():.6f}, í’ˆì§ˆ: {phase2_acc:.4f}")
            except Exception as e:
                logger.warning(f"    âš ï¸ Phase2 ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # Hierarchical Integrator ì²˜ë¦¬ (Phase0, Phase2 ì¶œë ¥ í™œìš©)
        if hasattr(self.model, 'hierarchical_integrator') and self.model.hierarchical_integrator:
            try:
                # Phase0, Phase2 ì¶œë ¥ ìˆ˜ì§‘ (ìˆìœ¼ë©´)
                phase0_output = None
                phase2_output = None
                
                # Phase0 ì¶œë ¥ì´ ìˆìœ¼ë©´ í™œìš©
                if hasattr(self.model, 'phase0_net') and self.model.phase0_net:
                    try:
                        phase0_temp = self.model.phase0_net(features)
                        if phase0_temp.shape[-1] == 7:
                            phase0_output = phase0_temp
                    except:
                        pass
                
                # Phase2 ì¶œë ¥ì´ ìˆìœ¼ë©´ í™œìš©
                if hasattr(self.model, 'phase2_net') and self.model.phase2_net:
                    try:
                        phase2_temp = self.model.phase2_net(features, 'global')
                        if phase2_temp.shape[-1] <= 10:
                            phase2_output = phase2_temp
                    except:
                        pass
                
                # ê³„ì¸µì  í†µí•© ì²˜ë¦¬
                hierarchical_output = self.model.hierarchical_integrator(
                    features, 
                    phase0_out=phase0_output,
                    phase2_out=phase2_output
                )
                
                # Hierarchicalì€ integrationì´ë¯€ë¡œ consistency loss ì‚¬ìš©
                hierarchical_loss = F.mse_loss(hierarchical_output, features) * 0.3
                analyzer_losses.append(hierarchical_loss)
                individual_losses['hierarchical_loss'] = hierarchical_loss.item()
                # Hierarchical accuracy (integration quality)
                hierarchical_acc = max(0, 1.0 - hierarchical_loss.item())
                individual_accs['hierarchical_acc'] = hierarchical_acc
                if self.verbose and batch_idx < 3:
                    logger.info(f"      - Hierarchical ì†ì‹¤: {hierarchical_loss.item():.6f}, í’ˆì§ˆ: {hierarchical_acc:.4f}")
            except Exception as e:
                logger.warning(f"    âš ï¸ Hierarchical ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # DSP Simulator ì²˜ë¦¬
        if hasattr(self.model, 'dsp_simulator') and self.model.dsp_simulator:
            try:
                # DSPëŠ” 384ì°¨ì› ì…ë ¥ í•„ìš”
                if not hasattr(self, 'dsp_projection'):
                    self.dsp_projection = torch.nn.Linear(features.shape[-1], 384).to(self.device)
                
                dsp_input = self.dsp_projection(features)
                dsp_output = self.model.dsp_simulator(dsp_input)
                
                # DSP loss ê³„ì‚° (ê°ì • ì‹œë®¬ë ˆì´ì…˜ loss)
                if 'emotion_label' in batch:
                    dsp_target = F.one_hot(batch['emotion_label'].to(self.device), num_classes=7).float()
                    if isinstance(dsp_output, dict) and 'final_emotions' in dsp_output:
                        dsp_pred = dsp_output['final_emotions']
                    else:
                        dsp_pred = dsp_output
                    
                    # DSP ì¶œë ¥ì„ 7ì°¨ì›ìœ¼ë¡œ ë§¤í•‘
                    if dsp_pred.shape[-1] != 7:
                        if not hasattr(self, 'dsp_emotion_projection'):
                            self.dsp_emotion_projection = torch.nn.Linear(dsp_pred.shape[-1], 7).to(self.device)
                        dsp_pred = self.dsp_emotion_projection(dsp_pred)
                    
                    dsp_loss = F.cross_entropy(dsp_pred, dsp_target)
                    analyzer_losses.append(dsp_loss)
                    individual_losses['dsp_loss'] = dsp_loss.item()
                    
                    # DSP accuracy
                    dsp_acc = (dsp_pred.argmax(dim=-1) == batch['emotion_label'].to(self.device)).float().mean().item()
                    individual_accs['dsp_acc'] = dsp_acc
                    
                if self.verbose and batch_idx < 3:
                    logger.info(f"      - DSP ì†ì‹¤: {dsp_loss.item():.6f}, ì •í™•ë„: {dsp_acc:.4f}")
            except Exception as e:
                logger.warning(f"    âš ï¸ DSP ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # Kalman Filter ì²˜ë¦¬ (neural_emotion + DSP í•„ìš”)
        if hasattr(self.model, 'kalman_filter') and self.model.kalman_filter and \
           dsp_output is not None and neural_emotion_output is not None:
            try:
                traditional_emotions = neural_emotion_output.get('emotion_logits', None)
                dsp_emotions = dsp_output.get('final_emotions', None) if isinstance(dsp_output, dict) else dsp_output
                
                if traditional_emotions is not None and dsp_emotions is not None:
                    kalman_output = self.model.kalman_filter(
                        traditional_emotions=traditional_emotions,
                        dsp_emotions=dsp_emotions
                    )
                    
                    # Kalman filter loss (ìœµí•©ëœ ê°ì •ê³¼ íƒ€ê²Ÿ ë¹„êµ)
                    if 'emotion_label' in batch:
                        kalman_target = F.one_hot(batch['emotion_label'].to(self.device), num_classes=7).float()
                        if isinstance(kalman_output, dict) and 'fused_emotions' in kalman_output:
                            kalman_pred = kalman_output['fused_emotions']
                        else:
                            kalman_pred = kalman_output
                        
                        # Kalman ì¶œë ¥ ì •ê·œí™”
                        if kalman_pred.shape[-1] != 7:
                            if not hasattr(self, 'kalman_projection'):
                                self.kalman_projection = torch.nn.Linear(kalman_pred.shape[-1], 7).to(self.device)
                            kalman_pred = self.kalman_projection(kalman_pred)
                        
                        kalman_loss = F.cross_entropy(kalman_pred, kalman_target) * 0.5
                        analyzer_losses.append(kalman_loss)
                        individual_losses['kalman_loss'] = kalman_loss.item()
                        
                        # Kalman accuracy
                        kalman_acc = (kalman_pred.argmax(dim=-1) == batch['emotion_label'].to(self.device)).float().mean().item()
                        individual_accs['kalman_acc'] = kalman_acc
                        
                    if self.verbose and batch_idx < 3:
                        logger.info(f"      - Kalman ì†ì‹¤: {kalman_loss.item():.6f}, ì •í™•ë„: {kalman_acc:.4f}")
            except Exception as e:
                logger.warning(f"    âš ï¸ Kalman ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # ë‚˜ë¨¸ì§€ Neural Analyzers ì²˜ë¦¬
        if hasattr(self.model, 'neural_analyzers'):
            for name, analyzer in self.model.neural_analyzers.items():
                if name == 'emotion':  # ì´ë¯¸ ì²˜ë¦¬í•¨
                    continue
                    
                try:
                    analyzer_output = analyzer(features)
                    
                    # ê° analyzerë³„ ì†ì‹¤ ê³„ì‚°
                    if 'bentham' in name and 'bentham_scores' in analyzer_output:
                        target = batch['bentham_label'].to(self.device)
                        analyzer_loss = F.mse_loss(analyzer_output['bentham_scores'], target)
                        analyzer_losses.append(analyzer_loss)
                        
                        # Analyzer accuracy ê³„ì‚° (regression - ë™ì  ì„ê³€4ê°’)
                        with torch.no_grad():
                            # ì—í­ì— ë”°ë¼ ì„ê³€4ê°’ ì¡°ì ˆ
                            dynamic_threshold = 0.3 if self.current_epoch <= 5 else 0.25 if self.current_epoch <= 15 else 0.2 if self.current_epoch <= 30 else 0.15
                            analyzer_acc = ((analyzer_output['bentham_scores'] - target).abs() < dynamic_threshold).float().mean().item()
                            analyzer_accuracies.append(analyzer_acc)
                        
                        if self.verbose and batch_idx < 3:
                            logger.info(f"      - {name} ì†ì‹¤: {analyzer_loss.item():.6f}, ì •í™•ë„: {analyzer_acc:.4f}")
                    
                    elif 'regret' in name and 'regret_score' in analyzer_output:
                        target = batch['regret_label'].to(self.device)
                        analyzer_loss = F.smooth_l1_loss(analyzer_output['regret_score'], target)
                        analyzer_losses.append(analyzer_loss)
                        
                        # Analyzer accuracy ê³„ì‚° (regression - ë™ì  ì„ê³€4ê°’)
                        with torch.no_grad():
                            dynamic_threshold = 0.3 if self.current_epoch <= 5 else 0.25 if self.current_epoch <= 15 else 0.2 if self.current_epoch <= 30 else 0.15
                            analyzer_acc = ((analyzer_output['regret_score'] - target).abs() < dynamic_threshold).float().mean().item()
                            analyzer_accuracies.append(analyzer_acc)
                        
                        if self.verbose and batch_idx < 3:
                            logger.info(f"      - {name} ì†ì‹¤: {analyzer_loss.item():.6f}, ì •í™•ë„: {analyzer_acc:.4f}")
                    
                    elif 'surd' in name and 'surd_scores' in analyzer_output:
                        # SURD analyzerë„ 4ì°¨ì› íƒ€ê²Ÿ í•„ìš”
                        batch_size = analyzer_output['surd_scores'].shape[0]
                        target = torch.zeros((batch_size, 4), device=self.device)
                        
                        # ì‹¤ì œ ë°ì´í„°ë¡œ SURD ê³„ì‚° (ìœ„ì™€ ë™ì¼)
                        if 'emotion_label' in batch:
                            emotion_probs = F.one_hot(batch['emotion_label'].to(self.device), num_classes=7).float()
                            emotion_entropy = -(emotion_probs * (emotion_probs + 1e-10).log()).sum(dim=1)
                            target[:, 0] = emotion_entropy / np.log(7)
                        
                        if 'surd_label' in batch:
                            label_unique = F.one_hot(batch['surd_label'].to(self.device), num_classes=5).float()
                            target[:, 1] = label_unique.max(dim=1)[0]
                        
                        if 'bentham_label' in batch:
                            bentham = batch['bentham_label'].to(self.device)
                            bentham_mean = bentham.mean(dim=1)
                            bentham_std = bentham.std(dim=1) + 1e-10
                            target[:, 2] = 1.0 - (bentham_std / (bentham_mean + 1e-10)).clamp(0, 1)
                        
                        if 'regret_label' in batch:
                            regret = batch['regret_label'].to(self.device)
                            if regret.dim() == 1:
                                regret = regret.unsqueeze(1)
                            target[:, 3] = regret.abs().squeeze()
                        
                        analyzer_loss = F.mse_loss(analyzer_output['surd_scores'], target)
                        analyzer_losses.append(analyzer_loss)
                        if self.verbose and batch_idx < 3:
                            logger.info(f"      - {name} ì†ì‹¤: {analyzer_loss.item():.6f}")
                    
                except Exception as e:
                    if hasattr(self.config, 'debug') and self.config.debug:
                        logger.error(f"    {name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    else:
                        logger.error(f"    {name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # Advanced Wrappers ì²˜ë¦¬
        wrapper_losses = []
        wrapper_accuracies = []
        if hasattr(self.model, 'advanced_wrappers') and self.model.advanced_wrappers:
            if self.verbose and batch_idx < 3:
                logger.info("    [Advanced Wrappers] ì²˜ë¦¬ ì‹œì‘")
            
            for name, wrapper in self.model.advanced_wrappers.items():
                try:
                    wrapper_output = wrapper(features)
                    
                    # Advanced wrapper ì†ì‹¤ ê³„ì‚°
                    if isinstance(wrapper_output, dict):
                        wrapper_loss = 0
                        wrapper_acc_list = []
                        
                        # ê° íƒœìŠ¤í¬ë³„ ì†ì‹¤ ê³„ì‚°
                        if 'emotion' in wrapper_output:
                            target = batch.get('emotion_target', batch.get('emotions', None))
                            if target is not None:
                                target = target.to(self.device)
                                loss = F.mse_loss(wrapper_output['emotion'], target)
                                wrapper_loss += loss
                                acc = 1.0 - torch.mean(torch.abs(wrapper_output['emotion'] - target)).item()
                                wrapper_acc_list.append(acc)
                        
                        if 'bentham' in wrapper_output:
                            target = batch.get('bentham_target', batch.get('bentham', None))
                            if target is not None:
                                target = target.to(self.device)
                                loss = F.mse_loss(wrapper_output['bentham'], target)
                                wrapper_loss += loss
                                acc = 1.0 - torch.mean(torch.abs(wrapper_output['bentham'] - target)).item()
                                wrapper_acc_list.append(acc)
                        
                        if wrapper_loss > 0:
                            wrapper_losses.append(wrapper_loss)
                            individual_losses[f'advanced_{name}_loss'] = wrapper_loss.item()
                            
                            if wrapper_acc_list:
                                avg_acc = np.mean(wrapper_acc_list)
                                wrapper_accuracies.append(avg_acc)
                                individual_accs[f'advanced_{name}_acc'] = avg_acc
                            
                            if self.verbose and batch_idx < 3:
                                logger.info(f"      - Advanced {name} ì†ì‹¤: {wrapper_loss.item():.6f}, ì •í™•ë„: {avg_acc:.4f}")
                        
                except Exception as e:
                    if self.config.debug:
                        logger.error(f"    Advanced {name} wrapper ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # ì „ì²´ ì†ì‹¤ í†µí•© (í—¤ë“œ 60%, Analyzer 25%, Advanced 15%)
        all_losses = head_losses + analyzer_losses + wrapper_losses
        
        if all_losses:
            if head_losses and analyzer_losses and wrapper_losses:
                head_loss = sum(head_losses) / len(head_losses)
                analyzer_loss = sum(analyzer_losses) / len(analyzer_losses)
                wrapper_loss = sum(wrapper_losses) / len(wrapper_losses)
                loss = 0.6 * head_loss + 0.25 * analyzer_loss + 0.15 * wrapper_loss
                if self.verbose and batch_idx < 3:
                    logger.info(f"      - í—¤ë“œ ì†ì‹¤: {head_loss.item():.6f}")
                    logger.info(f"      - ë¶„ì„ê¸° ì†ì‹¤: {analyzer_loss.item():.6f}")
                    logger.info(f"      - Advanced ì†ì‹¤: {wrapper_loss.item():.6f}")
                    logger.info(f"      - ì „ì²´ ì†ì‹¤: {loss.item():.6f}")
            elif head_losses and analyzer_losses:
                head_loss = sum(head_losses) / len(head_losses)
                analyzer_loss = sum(analyzer_losses) / len(analyzer_losses)
                loss = 0.7 * head_loss + 0.3 * analyzer_loss
                if self.verbose and batch_idx < 3:
                    logger.info(f"      - í—¤ë“œ ì†ì‹¤: {head_loss.item():.6f}")
                    logger.info(f"      - ë¶„ì„ê¸° ì†ì‹¤: {analyzer_loss.item():.6f}")
                    logger.info(f"      - ì „ì²´ ì†ì‹¤: {loss.item():.6f}")
            else:
                loss = sum(all_losses) / len(all_losses)
        else:
            # NO FALLBACK - ì†ì‹¤ì´ ì—†ìœ¼ë©´ ì—ëŸ¬
            raise RuntimeError("ì†ì‹¤ ê³„ì‚° ì‹¤íŒ¨: í—¤ë“œë‚˜ ë¶„ì„ê¸°ê°€ ì†ì‹¤ì„ ìƒì„±í•˜ì§€ ëª»í•¨")
        
        # ë©”íŠ¸ë¦­ - ê°œë³„ ëª¨ë“ˆ ì†ì‹¤ í¬í•¨
        metrics = {
            'loss': loss.item(),
            'train_loss': loss.item(),  # ì „ì²´ ì†ì‹¤ (backward í˜¸í™˜)
            'head_losses': len(head_losses),
            'analyzer_losses': len(analyzer_losses),
            'total_losses': len(all_losses)
        }
        
        # ê°œë³„ í—¤ë“œ ì†ì‹¤ ë° ì •í™•ë„ ì¶”ê°€
        metrics.update(individual_losses)
        metrics.update(individual_accs)
        
        # ë°±ë³¸ ì†ì‹¤ (ì „ì²´ ì†ì‹¤ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •)
        metrics['backbone_loss'] = loss.item()
        metrics['backbone_acc'] = 0.0  # ë°±ë³¸ì€ ë³„ë„ accuracy ì—†ìŒ
        
        # Neural Analyzer ì†ì‹¤ ë° ì •í™•ë„
        if analyzer_losses:
            metrics['analyzer_loss'] = sum(al.item() for al in analyzer_losses) / len(analyzer_losses)
            # ì‹¤ì œ analyzer accuracy ê³„ì‚° (í‰ê· )
            metrics['analyzer_acc'] = np.mean(analyzer_accuracies) if analyzer_accuracies else 0.0
        else:
            metrics['analyzer_loss'] = 0.0
            metrics['analyzer_acc'] = 0.0
        
        # ì „ì²´ accuracy ê³„ì‚° (ê°€ì¤‘ í‰ê· )
        # ê° íƒœìŠ¤í¬ì˜ ì¤‘ìš”ë„: emotion(30%), bentham(25%), regret(20%), surd(15%), analyzer(10%)
        weighted_acc = 0.0
        weights_sum = 0.0
        
        task_weights = {
            'emotion_acc': 0.30,
            'bentham_acc': 0.25,
            'regret_acc': 0.20,
            'surd_acc': 0.15,
            'analyzer_acc': 0.10
        }
        
        for task, weight in task_weights.items():
            if task in metrics and metrics[task] > 0:
                weighted_acc += metrics[task] * weight
                weights_sum += weight
        
        # train/val ë©”íŠ¸ë¦­
        metrics['train_loss'] = loss.item()
        metrics['train_acc'] = weighted_acc / weights_sum if weights_sum > 0 else 0.0
        metrics['val_loss'] = loss.item()  # validate()ì—ì„œ ë®ì–´ì”Œì›Œì§
        metrics['val_acc'] = metrics['train_acc']  # validate()ì—ì„œ ë®ì–´ì”Œì›Œì§
        
        # ëª¨ë“ˆ ìƒí˜¸ì‘ìš© ë©”íŠ¸ë¦­ ê³„ì‚° (ì‹¤ì œ êµ¬í˜„)
        with torch.no_grad():
            # 1. ëª¨ë“ˆ ê°„ ì†ì‹¤ ìƒê´€ê´€ê³„
            if len(individual_losses) > 1:
                loss_values = list(individual_losses.values())
                if len(loss_values) >= 2:
                    # ì†ì‹¤ ê°„ ìƒê´€ì„± ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ - ë…ë¦½ì ì¸ í•™ìŠµ)
                    loss_tensor = torch.tensor(loss_values)
                    loss_std = loss_tensor.std().item()
                    loss_mean = loss_tensor.mean().item()
                    metrics['module_loss_variance'] = loss_std
                    metrics['module_loss_mean'] = loss_mean
                    # ë³€ë™ê³„ìˆ˜ (Coefficient of Variation)
                    metrics['module_loss_cv'] = loss_std / (loss_mean + 1e-10)
            
            # 2. ëª¨ë“ˆ ê°„ ì •í™•ë„ ì‹œë„ˆì§€
            if len(individual_accs) > 1:
                acc_values_list = list(individual_accs.values())
                if len(acc_values_list) >= 2:
                    acc_tensor = torch.tensor(acc_values_list)
                    # ì •í™•ë„ ê°„ ì¼ê´€ì„± (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
                    acc_std = acc_tensor.std().item()
                    acc_mean = acc_tensor.mean().item()
                    metrics['module_acc_consistency'] = 1.0 - (acc_std / (acc_mean + 1e-10))
                    
                    # ì‹œë„ˆì§€ ì ìˆ˜: ì „ì²´ ì •í™•ë„ê°€ ê°œë³„ í‰ê· ë³´ë‹¤ ë†’ìœ¼ë©´ ì–‘ì˜ ì‹œë„ˆì§€
                    synergy_score = metrics['train_acc'] - acc_mean
                    metrics['module_synergy_score'] = synergy_score
            
            # 3. Head-Analyzer ìƒí˜¸ì‘ìš©
            if analyzer_accuracies and len(individual_accs) > 0:
                head_acc_mean = np.mean(list(individual_accs.values()))
                analyzer_acc_mean = np.mean(analyzer_accuracies)
                # Headì™€ Analyzer ê°„ ì„±ëŠ¥ ê²©ì°¨ (ì‘ì„ìˆ˜ë¡ ê· í˜•ì )
                metrics['head_analyzer_gap'] = abs(head_acc_mean - analyzer_acc_mean)
                # ìƒí˜¸ ë³´ì™„ ì§€ìˆ˜
                metrics['head_analyzer_complement'] = min(head_acc_mean, analyzer_acc_mean) / (max(head_acc_mean, analyzer_acc_mean) + 1e-10)
        
        return loss, metrics
    
    def train(self):
        """ì „ì²´ í•™ìŠµ ì‹¤í–‰"""
        logger.info("\n" + "=" * 70)
        logger.info("ğŸš€ í•™ìŠµ ì‹œì‘")
        logger.info("=" * 70)
        
        # LR ìŠ¤ìœ• ì‹¤í–‰
        self.run_lr_sweep()
        
        # 60 ì—í­ í•™ìŠµ (ì¬ê°œ ì‹œ current_epochë¶€í„°)
        start_epoch = self.current_epoch + 1 if self.current_epoch > 0 else 1
        for epoch in range(start_epoch, self.config.total_epochs + 1):
            self.current_epoch = epoch
            
            logger.info(f"\nğŸ“Œ Epoch {epoch}/{self.config.total_epochs}")
            
            # í•™ìŠµ
            try:
                train_metrics = self.train_epoch(epoch)
            except Exception as e:
                logger.error(f"  âŒ ì—í­ {epoch} í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
                train_metrics = {'train_loss': float('inf')}
            
            # ê²€ì¦ ì‹¤í–‰ ì¡°ê±´ (ì„¤ì • ê°€ëŠ¥)
            should_validate = False
            if hasattr(self.config, 'val_interval'):
                # val_intervalì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ í•´ë‹¹ ê°„ê²©ìœ¼ë¡œ ê²€ì¦
                should_validate = (epoch % self.config.val_interval == 0)
            else:
                # ê¸°ë³¸ ë¡œì§: í…ŒìŠ¤íŠ¸ ëª¨ë“œë‚˜ ì‘ì€ ì—í­ ìˆ˜ì¼ ë•ŒëŠ” ìì£¼ ê²€ì¦
                if self.config.total_epochs <= 5:
                    should_validate = True  # ëª¨ë“  ì—í­ì—ì„œ ê²€ì¦
                elif self.config.total_epochs <= 20:
                    should_validate = (epoch % 2 == 0)  # ì§ìˆ˜ ì—í­ë§ˆë‹¤
                else:
                    should_validate = (epoch % 5 == 0) or (epoch == self.config.total_epochs)  # 5 ì—í­ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰
            
            if should_validate:
                val_metrics = self.validate()
                logger.info(f"  Validation Loss: {val_metrics['val_loss']:.4f}")
            else:
                val_metrics = {}
            
            # ë©”íŠ¸ë¦­ í†µí•© ë° ëª¨ë“ˆë³„ ê·¸ë£¹í™” (train/val ë¶„ë¦¬)
            all_metrics = {**train_metrics, **val_metrics}
            
            # í•™ìŠµ ëª¨ë“ˆë³„ ë©”íŠ¸ë¦­
            train_module_metrics = {
                'backbone': {
                    'loss': train_metrics.get('backbone_loss', train_metrics.get('train_loss', 0)),
                    'accuracy': train_metrics.get('backbone_acc', 0),
                    'gradient_norm': train_metrics.get('backbone_grad_norm', 0)
                },
                'emotion_head': {
                    'loss': train_metrics.get('emotion_loss', train_metrics.get('train_loss', 0)),
                    'accuracy': train_metrics.get('emotion_acc', 0),
                    'gradient_norm': train_metrics.get('emotion_grad_norm', 0)
                },
                'bentham_head': {
                    'loss': train_metrics.get('bentham_loss', train_metrics.get('train_loss', 0)),
                    'accuracy': train_metrics.get('bentham_acc', 0),
                    'gradient_norm': train_metrics.get('bentham_grad_norm', 0)
                },
                'regret_head': {
                    'loss': train_metrics.get('regret_loss', train_metrics.get('train_loss', 0)),
                    'accuracy': train_metrics.get('regret_acc', 0),
                    'gradient_norm': train_metrics.get('regret_grad_norm', 0)
                },
                'surd_head': {
                    'loss': train_metrics.get('surd_loss', train_metrics.get('train_loss', 0)),
                    'accuracy': train_metrics.get('surd_acc', 0),
                    'gradient_norm': train_metrics.get('surd_grad_norm', 0)
                },
                'neural_analyzers': {
                    'loss': train_metrics.get('analyzer_loss', train_metrics.get('train_loss', 0)),
                    'accuracy': train_metrics.get('analyzer_acc', 0),
                    'gradient_norm': train_metrics.get('analyzer_grad_norm', 0)
                },
                'system': {
                    'loss': train_metrics.get('train_loss', 0),
                    'accuracy': train_metrics.get('train_acc', 0),
                    'gradient_norm': train_metrics.get('total_grad_norm', 0)
                }
            }
            
            # ê²€ì¦ ëª¨ë“ˆë³„ ë©”íŠ¸ë¦­ (val_metricsê°€ ìˆì„ ë•Œë§Œ)
            if val_metrics:
                val_module_metrics = {
                    'backbone': {
                        'loss': val_metrics.get('backbone_loss', val_metrics.get('val_loss', 0)),
                        'accuracy': val_metrics.get('backbone_acc', val_metrics.get('val_acc', 0))
                    },
                    'emotion_head': {
                        'loss': val_metrics.get('emotion_loss', val_metrics.get('val_loss', 0)),
                        'accuracy': val_metrics.get('emotion_acc', val_metrics.get('val_acc', 0))
                    },
                    'bentham_head': {
                        'loss': val_metrics.get('bentham_loss', val_metrics.get('val_loss', 0)),
                        'accuracy': val_metrics.get('bentham_acc', val_metrics.get('val_acc', 0))
                    },
                    'regret_head': {
                        'loss': val_metrics.get('regret_loss', val_metrics.get('val_loss', 0)),
                        'accuracy': val_metrics.get('regret_acc', val_metrics.get('val_acc', 0))
                    },
                    'surd_head': {
                        'loss': val_metrics.get('surd_loss', val_metrics.get('val_loss', 0)),
                        'accuracy': val_metrics.get('surd_acc', val_metrics.get('val_acc', 0))
                    },
                    'neural_analyzers': {
                        'loss': val_metrics.get('analyzer_loss', val_metrics.get('val_loss', 0)),
                        'accuracy': val_metrics.get('analyzer_acc', val_metrics.get('val_acc', 0))
                    },
                    'system': {
                        'loss': val_metrics.get('val_loss', 0),
                        'accuracy': val_metrics.get('val_acc', 0)
                    }
                }
            else:
                # ê²€ì¦ì´ ì—†ëŠ” ì—í­ì€ train ë©”íŠ¸ë¦­ì„ ë³µì‚¬ (í˜¸í™˜ì„±)
                val_module_metrics = train_module_metrics.copy()
            
            # ë””ë²„ê·¸: ë©”íŠ¸ë¦­ ê²€ì¦
            if epoch == 1 and self.verbose:
                logger.info("\n  ğŸ“Š ë©”íŠ¸ë¦­ ê²€ì¦ (Epoch 1):")
                logger.info("  [Train]")
                for module_name, metrics in train_module_metrics.items():
                    logger.info(f"    - {module_name}: loss={metrics['loss']:.4f}, acc={metrics['accuracy']:.4f}")
                if val_metrics:
                    logger.info("  [Validation]")
                    for module_name, metrics in val_module_metrics.items():
                        logger.info(f"    - {module_name}: loss={metrics['loss']:.4f}, acc={metrics['accuracy']:.4f}")
            
            # Sweet Spot ì—…ë°ì´íŠ¸ (train/val ë¶„ë¦¬)
            if self.config.enable_sweet_spot:
                self.sweet_spot_detector.update(
                    epoch=epoch,
                    train_module_metrics=train_module_metrics,
                    val_module_metrics=val_module_metrics,
                    learning_rate=self.optimizer.param_groups[0]['lr']
                )
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint_path = self.checkpoint_manager.save_checkpoint(
                epoch=epoch,
                model=self.model,
                optimizer=self.optimizer,
                scheduler=self.scheduler,
                metrics=all_metrics,
                lr=self.optimizer.param_groups[0]['lr']
            )
            
            # Crossover ì‹œìŠ¤í…œì— ì²´í¬í¬ì¸íŠ¸ ì¶”ê°€
            if checkpoint_path and self.config.enable_crossover:
                self.crossover_system.add_checkpoint(
                    epoch=epoch,
                    checkpoint_path=checkpoint_path,
                    module_metrics=all_metrics
                )
            
            # ìµœê³  ì„±ëŠ¥ ê°±ì‹ 
            if 'loss' in all_metrics and all_metrics['loss'] < self.best_loss:
                self.best_loss = all_metrics['loss']
                logger.info(f"  ğŸ† ìµœê³  ì„±ëŠ¥ ê°±ì‹ : {self.best_loss:.4f}")
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ í™•ì¸ ë° ë§ˆì§€ë§‰ ì—í­ ê°•ì œ ì €ì¥
            if epoch == self.config.total_epochs:
                # ë§ˆì§€ë§‰ ì—í­ì€ ë¬´ì¡°ê±´ ì €ì¥
                if checkpoint_path is None:
                    logger.info("  ğŸ“Œ ë§ˆì§€ë§‰ ì—í­ ì²´í¬í¬ì¸íŠ¸ ê°•ì œ ì €ì¥...")
                    checkpoint_path = self.checkpoint_manager.save_checkpoint(
                        epoch=epoch,
                        model=self.model,
                        optimizer=self.optimizer,
                        scheduler=self.scheduler,
                        metrics=all_metrics,
                        lr=self.optimizer.param_groups[0]['lr']
                    )
                else:
                    logger.info(f"  âœ… ë§ˆì§€ë§‰ ì—í­ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ë¨: {checkpoint_path}")
        
        logger.info("\n" + "=" * 70)
        logger.info(f"âœ… {self.config.total_epochs} ì—í­ í•™ìŠµ ì™„ë£Œ!")
        logger.info("=" * 70)
        
        # ìµœì¢… ì²˜ë¦¬
        self._finalize_training()
    
    def _finalize_training(self):
        """í•™ìŠµ ë§ˆë¬´ë¦¬ ì²˜ë¦¬"""
        logger.info("\nğŸ”§ ìµœì¢… ì²˜ë¦¬ ì‹œì‘...")
        
        # Sweet Spot ì¢…í•© ë¶„ì„ ì‹¤í–‰
        optimal_epochs = {}
        if self.config.enable_sweet_spot:
            logger.info("\nğŸ¯ Sweet Spot ì¢…í•© ë¶„ì„ ì‹œì‘...")
            try:
                # 5ê°€ì§€ ê³ ê¸‰ ë¶„ì„ ê¸°ë²• ì ìš©
                analysis_results = self.sweet_spot_detector.analyze_all(
                    output_dir='training/sweet_spot_analysis'
                )
                
                # analyze_allì˜ ì¶”ì²œ ì—í­ì„ ì§ì ‘ ì‚¬ìš©
                for module, result in analysis_results.items():
                    rec = result['recommendation']
                    optimal_epochs[module] = rec['epoch']
                    logger.info(f"    - {module}: Epoch {rec['epoch']} (ì‹ ë¢°ë„: {rec['confidence']:.1%})")
                
                logger.info(f"  ğŸ“Š ëª¨ë“ˆë³„ ìµœì  ì—í­: {optimal_epochs}")
                    
            except Exception as e:
                logger.error(f"Sweet Spot ë¶„ì„ ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ ë©”ì„œë“œ ì‚¬ìš© (fallback)
                optimal_epochs = self.sweet_spot_detector.get_optimal_epochs()
                logger.info(f"  ğŸ“Š ê¸°ë³¸ ë¶„ì„ ìµœì  ì—í­: {optimal_epochs}")
        
        # Parameter Crossover ì‹¤í–‰
        if self.config.enable_crossover and self.config.enable_sweet_spot:
            logger.info("\nğŸ§¬ Parameter Crossover ì‹¤í–‰...")
            
            crossover_model = self.crossover_system.perform_crossover(
                model=self.model,
                optimal_epochs=optimal_epochs
            )
            
            # Crossover ëª¨ë¸ ì €ì¥
            crossover_path = Path(self.config.checkpoint_dir) / "crossover_final.pth"
            self.crossover_system.save_crossover_result(
                model=crossover_model,
                save_path=str(crossover_path),
                metadata={'optimal_epochs': optimal_epochs}
            )
            logger.info(f"  ğŸ’¾ Crossover ëª¨ë¸ ì €ì¥: {crossover_path}")
        
        # í•™ìŠµ ê³¡ì„  ë‚´ë³´ë‚´ê¸°
        curves_file = self.checkpoint_manager.export_training_curves()
        logger.info(f"  ğŸ“ˆ í•™ìŠµ ê³¡ì„  ì €ì¥: {curves_file}")
        
        # OOM í†µê³„ ì €ì¥
        if self.config.enable_oom_handler:
            oom_stats = self.oom_handler.save_stats()
            logger.info(f"  ğŸ“Š OOM í†µê³„ ì €ì¥: {oom_stats}")
        
        # ì„ë² ë”©ì€ ì´ë¯¸ ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ - ì¶”ê°€ ì €ì¥ ë¶ˆí•„ìš”
        # save_embeddings ë©”ì„œë“œê°€ ì—†ìœ¼ë¯€ë¡œ ì œê±°
        
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        logger.info("=" * 70)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="Red Heart AI ìµœì¢… í†µí•© í•™ìŠµ")
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ')
    parser.add_argument('--epochs', type=int, default=60, help='í•™ìŠµ ì—í­')
    parser.add_argument('--batch-size', type=int, default=2, help='ë°°ì¹˜ ì‚¬ì´ì¦ˆ')
    parser.add_argument('--lr', type=float, default=1e-4, help='í•™ìŠµë¥ ')
    parser.add_argument('--resume', type=str, help='ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ')
    parser.add_argument('--no-param-update', action='store_true', help='íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ê±´ë„ˆë›°ê¸° (ê²€ì¦ìš©)')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ')
    parser.add_argument('--verbose', action='store_true', help='ìƒì„¸ ë¡œê¹…')
    parser.add_argument('--samples', type=int, help='í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ìˆ˜ (ì—í­ ìˆ˜ë¡œ ì‚¬ìš©)')
    
    args = parser.parse_args()
    
    # ì„¤ì • ìƒì„±
    config = UnifiedTrainingConfig()
    
    # argsì—ì„œ ì„¤ì • ì ìš©
    config.verbose = args.verbose
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if args.test:
        if args.samples:
            config.total_epochs = args.samples
            logger.info(f"âš ï¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {args.samples} ì—í­ ì‹¤í–‰")
        else:
            config.total_epochs = 2
            logger.info("âš ï¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: 2 ì—í­ë§Œ ì‹¤í–‰")
    else:
        config.total_epochs = args.epochs
    
    config.micro_batch_size = args.batch_size
    config.base_lr = args.lr
    
    # ë””ë²„ê·¸/ìƒì„¸ ë¡œê¹… ì„¤ì •
    if args.debug or args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        config.log_interval = 1  # ë§¤ ìŠ¤í…ë§ˆë‹¤ ë¡œê¹…
        config.val_interval = 10  # ë” ìì£¼ ê²€ì¦
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° ì‹¤í–‰
    trainer = UnifiedTrainer(config)
    trainer.no_param_update = args.no_param_update  # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ í”Œë˜ê·¸
    
    if args.no_param_update:
        logger.warning("âš ï¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ë¹„í™œì„±í™” - ê²€ì¦ ëª¨ë“œ")
    
    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
    if args.resume:
        checkpoint = trainer.checkpoint_manager.load_checkpoint(args.resume)
        
        # ëª¨ë“ˆë³„ë¡œ ì €ì¥ëœ stateë¥¼ í”Œë«í•˜ê²Œ ë³€í™˜
        model_state = checkpoint['model_state']
        if isinstance(model_state, dict) and 'backbone' in model_state:
            # ì¬ê·€ì ìœ¼ë¡œ ì¤‘ì²©ëœ dictë¥¼ í”Œë« êµ¬ì¡°ë¡œ ë³€í™˜
            def flatten_state_dict(state_dict, prefix=''):
                flat = {}
                for key, value in state_dict.items():
                    new_key = f"{prefix}.{key}" if prefix else key
                    if isinstance(value, dict):
                        # ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
                        flat.update(flatten_state_dict(value, new_key))
                    else:
                        flat[new_key] = value
                return flat
            
            flat_state = flatten_state_dict(model_state)
            # strict=Falseë¡œ ë¶€ë¶„ ë¡œë“œ í—ˆìš© (í–¥í›„ ëª¨ë“ˆ ì¶”ê°€/ë³€ê²½ ëŒ€ì‘)
            missing, unexpected = trainer.model.load_state_dict(flat_state, strict=False)
            logger.info(f"âœ… ëª¨ë“ˆë³„ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (ëª¨ë“ˆ: {list(model_state.keys())})")
            if missing:
                logger.warning(f"âš ï¸ ëˆ„ë½ëœ í‚¤: {len(missing)}ê°œ")
            if unexpected:
                logger.warning(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected)}ê°œ")
        else:
            # ì´ë¯¸ í”Œë«í•œ êµ¬ì¡°ë©´ ê·¸ëŒ€ë¡œ ë¡œë“œ
            trainer.model.load_state_dict(model_state)
            logger.info(f"âœ… ì¼ë°˜ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ")
        
        if 'optimizer_state' in checkpoint:
            trainer.optimizer.load_state_dict(checkpoint['optimizer_state'])
        if 'scheduler_state' in checkpoint and checkpoint['scheduler_state']:
            trainer.scheduler.load_state_dict(checkpoint['scheduler_state'])
        trainer.current_epoch = checkpoint['epoch']
        logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ: Epoch {trainer.current_epoch}")
        logger.info(f"   - ë‹¤ìŒ ì—í­ë¶€í„° í•™ìŠµ: {trainer.current_epoch + 1}")
    
    # í•™ìŠµ ì‹¤í–‰
    trainer.train()


if __name__ == "__main__":
    main()