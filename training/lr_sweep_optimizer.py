"""
Learning Rate Sweep ìµœì í™” ì‹œìŠ¤í…œ
5ê°œ LR ê°’ìœ¼ë¡œ ìŠ¤ìœ•í•˜ì—¬ ìµœì  í•™ìŠµë¥  ìë™ íƒìƒ‰
"""

import torch
import torch.nn as nn
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

logger = logging.getLogger(__name__)


class LRSweepOptimizer:
    """
    Learning Rate Sweep ìµœì í™” ì‹œìŠ¤í…œ
    - 5ê°œ LR ê°’ìœ¼ë¡œ ì²´ê³„ì  íƒìƒ‰
    - ê° LRë¡œ ì§§ì€ í•™ìŠµ ì‹¤í–‰
    - ìˆ˜ë ´ ì†ë„ì™€ ì•ˆì •ì„± í‰ê°€
    - ìµœì  LR ìë™ ì„ íƒ
    """
    
    def __init__(self, 
                 base_lr: float = 1e-4,
                 sweep_range: Tuple[float, float] = (1e-5, 1e-2),
                 num_sweep_points: int = 5,
                 sweep_epochs: int = 3,
                 sweep_steps_per_epoch: int = 100):
        """
        Args:
            base_lr: ê¸°ë³¸ í•™ìŠµë¥ 
            sweep_range: ìŠ¤ìœ• ë²”ìœ„ (min, max)
            num_sweep_points: ìŠ¤ìœ• í¬ì¸íŠ¸ ê°œìˆ˜ (ê¸°ë³¸ 5ê°œ)
            sweep_epochs: ê° LRë‹¹ í…ŒìŠ¤íŠ¸ ì—í­ ìˆ˜
            sweep_steps_per_epoch: ì—í­ë‹¹ ìŠ¤í… ìˆ˜
        """
        self.base_lr = base_lr
        self.sweep_range = sweep_range
        self.num_sweep_points = num_sweep_points
        self.sweep_epochs = sweep_epochs
        self.sweep_steps_per_epoch = sweep_steps_per_epoch
        
        # ìŠ¤ìœ•í•  LR ê°’ë“¤ ìƒì„± (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        self.lr_candidates = np.logspace(
            np.log10(sweep_range[0]), 
            np.log10(sweep_range[1]), 
            num_sweep_points
        )
        
        # ê²°ê³¼ ì €ì¥
        self.sweep_results = {}
        self.best_lr = None
        self.sweep_history = []
        
        logger.info(f"âœ… LR Sweep Optimizer ì´ˆê¸°í™”")
        logger.info(f"  - ìŠ¤ìœ• ë²”ìœ„: {sweep_range[0]:.1e} ~ {sweep_range[1]:.1e}")
        logger.info(f"  - í…ŒìŠ¤íŠ¸ LR ê°’: {[f'{lr:.1e}' for lr in self.lr_candidates]}")
        logger.info(f"  - ê° LRë‹¹ {sweep_epochs} ì—í­ í…ŒìŠ¤íŠ¸")
    
    def run_sweep(self, 
                  model: nn.Module,
                  train_loader: Any,
                  val_loader: Any,
                  criterion: nn.Module,
                  device: torch.device) -> Dict[str, Any]:
        """
        LR ìŠ¤ìœ• ì‹¤í–‰
        
        Args:
            model: í•™ìŠµí•  ëª¨ë¸
            train_loader: í•™ìŠµ ë°ì´í„° ë¡œë”
            val_loader: ê²€ì¦ ë°ì´í„° ë¡œë”
            criterion: ì†ì‹¤ í•¨ìˆ˜
            device: í•™ìŠµ ë””ë°”ì´ìŠ¤
            
        Returns:
            ìŠ¤ìœ• ê²°ê³¼ ë° ìµœì  LR
        """
        logger.info("ğŸ” LR Sweep ì‹œì‘...")
        
        for idx, lr in enumerate(self.lr_candidates):
            logger.info(f"\n[{idx+1}/{self.num_sweep_points}] LR={lr:.1e} í…ŒìŠ¤íŠ¸")
            
            # ëª¨ë¸ ì´ˆê¸° ìƒíƒœ ì €ì¥ (ê° LR í…ŒìŠ¤íŠ¸ë§ˆë‹¤ ì´ˆê¸°í™”)
            initial_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}
            
            # ì´ LRë¡œ í•™ìŠµ ì‹¤í–‰
            sweep_result = self._run_single_sweep(
                model, train_loader, val_loader, criterion, device, lr
            )
            
            # ê²°ê³¼ ì €ì¥
            self.sweep_results[lr] = sweep_result
            
            # ëª¨ë¸ ìƒíƒœ ë³µì›
            model.load_state_dict(initial_state)
            
            # ê²°ê³¼ ë¡œê¹…
            logger.info(f"  - ìµœì¢… train loss: {sweep_result['final_train_loss']:.4f}")
            logger.info(f"  - ìµœì¢… val loss: {sweep_result['final_val_loss']:.4f}")
            logger.info(f"  - ìˆ˜ë ´ ì†ë„: {sweep_result['convergence_speed']:.4f}")
            logger.info(f"  - ì•ˆì •ì„± ì ìˆ˜: {sweep_result['stability_score']:.4f}")
        
        # ìµœì  LR ì„ íƒ
        self.best_lr = self._select_best_lr()
        
        # ê²°ê³¼ ìš”ì•½
        summary = self._generate_sweep_summary()
        
        # ì‹œê°í™” ìƒì„±
        self._plot_sweep_results()
        
        return summary
    
    def _run_single_sweep(self,
                         model: nn.Module,
                         train_loader: Any,
                         val_loader: Any,
                         criterion: nn.Module,
                         device: torch.device,
                         lr: float) -> Dict[str, Any]:
        """ë‹¨ì¼ LRë¡œ ìŠ¤ìœ• ì‹¤í–‰"""
        # ì˜µí‹°ë§ˆì´ì € ìƒì„±
        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
        
        # ë©”íŠ¸ë¦­ ì¶”ì 
        train_losses = []
        val_losses = []
        lr_history = []
        
        # í•™ìŠµ ì‹¤í–‰
        for epoch in range(self.sweep_epochs):
            # Training
            model.train()
            epoch_train_losses = []
            
            for step, batch in enumerate(train_loader):
                if step >= self.sweep_steps_per_epoch:
                    break
                
                # Forward pass
                loss = self._compute_loss(model, batch, criterion, device)
                
                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                epoch_train_losses.append(loss.item())
                lr_history.append(lr)
            
            avg_train_loss = np.mean(epoch_train_losses)
            train_losses.append(avg_train_loss)
            
            # Validation
            model.eval()
            epoch_val_losses = []
            
            with torch.no_grad():
                for step, batch in enumerate(val_loader):
                    if step >= 50:  # ê²€ì¦ì€ 50 ìŠ¤í…ë§Œ
                        break
                    
                    loss = self._compute_loss(model, batch, criterion, device)
                    epoch_val_losses.append(loss.item())
            
            avg_val_loss = np.mean(epoch_val_losses)
            val_losses.append(avg_val_loss)
            
            logger.debug(f"    Epoch {epoch+1}: train={avg_train_loss:.4f}, val={avg_val_loss:.4f}")
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        convergence_speed = self._calculate_convergence_speed(train_losses)
        stability_score = self._calculate_stability_score(train_losses, val_losses)
        
        return {
            'lr': lr,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'final_train_loss': train_losses[-1],
            'final_val_loss': val_losses[-1],
            'convergence_speed': convergence_speed,
            'stability_score': stability_score,
            'lr_history': lr_history
        }
    
    def _compute_loss(self, model: nn.Module, batch: Any, criterion: nn.Module, device: torch.device) -> torch.Tensor:
        """ì†ì‹¤ ê³„ì‚° (ê°„ë‹¨í•œ ì˜ˆì œ)"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” batch êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”
        if isinstance(batch, dict):
            inputs = batch.get('input', batch.get('text', None))
            targets = batch.get('target', batch.get('label', None))
        else:
            inputs, targets = batch
        
        if inputs is None or targets is None:
            # ë”ë¯¸ ì†ì‹¤ ë°˜í™˜ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
            return torch.tensor(1.0, requires_grad=True, device=device)
        
        inputs = inputs.to(device)
        targets = targets.to(device)
        
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        
        return loss
    
    def _calculate_convergence_speed(self, losses: List[float]) -> float:
        """ìˆ˜ë ´ ì†ë„ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ë¹ ë¥¸ ìˆ˜ë ´)"""
        if len(losses) < 2:
            return float('inf')
        
        # ì†ì‹¤ ê°ì†Œìœ¨ ê³„ì‚°
        improvements = []
        for i in range(1, len(losses)):
            if losses[i-1] > 0:
                improvement = (losses[i-1] - losses[i]) / losses[i-1]
                improvements.append(improvement)
        
        if not improvements:
            return 0.0
        
        # í‰ê·  ê°œì„ ìœ¨ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        avg_improvement = np.mean(improvements)
        
        # ìˆ˜ë ´ ì†ë„ ì ìˆ˜ (0~1, ë†’ì„ìˆ˜ë¡ ë¹ ë¦„)
        convergence_speed = min(1.0, max(0.0, avg_improvement * 10))
        
        return convergence_speed
    
    def _calculate_stability_score(self, train_losses: List[float], val_losses: List[float]) -> float:
        """ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚° (ë†’ì„ìˆ˜ë¡ ì•ˆì •ì )"""
        # ì†ì‹¤ì˜ í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì 
        train_std = np.std(train_losses) if len(train_losses) > 1 else 0
        val_std = np.std(val_losses) if len(val_losses) > 1 else 0
        
        # Overfitting ì²´í¬ (val lossê°€ train lossë³´ë‹¤ í¬ê²Œ ì¦ê°€í•˜ëŠ”ì§€)
        if len(train_losses) > 0 and len(val_losses) > 0:
            overfitting_gap = val_losses[-1] - train_losses[-1]
        else:
            overfitting_gap = 0
        
        # ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚° (0~1, ë†’ì„ìˆ˜ë¡ ì•ˆì •ì )
        stability = 1.0 / (1.0 + train_std + val_std + max(0, overfitting_gap))
        
        return min(1.0, stability)
    
    def _select_best_lr(self) -> float:
        """ìµœì  LR ì„ íƒ"""
        best_score = -float('inf')
        best_lr = self.base_lr
        
        for lr, result in self.sweep_results.items():
            # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ìˆ˜ë ´ ì†ë„ì™€ ì•ˆì •ì„±ì˜ ê· í˜•)
            score = (
                0.4 * result['convergence_speed'] +  # ìˆ˜ë ´ ì†ë„ 40%
                0.3 * result['stability_score'] +     # ì•ˆì •ì„± 30%
                0.3 * (1.0 / (1.0 + result['final_val_loss']))  # ìµœì¢… ì„±ëŠ¥ 30%
            )
            
            if score > best_score:
                best_score = score
                best_lr = lr
        
        logger.info(f"\nğŸ† ìµœì  LR ì„ íƒ: {best_lr:.1e}")
        logger.info(f"   - ì¢…í•© ì ìˆ˜: {best_score:.4f}")
        
        return best_lr
    
    def _generate_sweep_summary(self) -> Dict[str, Any]:
        """ìŠ¤ìœ• ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        summary = {
            'best_lr': self.best_lr,
            'sweep_timestamp': datetime.now().isoformat(),
            'lr_candidates': self.lr_candidates.tolist(),
            'results': {}
        }
        
        for lr, result in self.sweep_results.items():
            summary['results'][f"{lr:.1e}"] = {
                'final_train_loss': result['final_train_loss'],
                'final_val_loss': result['final_val_loss'],
                'convergence_speed': result['convergence_speed'],
                'stability_score': result['stability_score']
            }
        
        # ê²°ê³¼ ì €ì¥
        output_dir = Path("training/lr_sweep_results")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"lr_sweep_{timestamp}.json"
        
        with open(output_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        logger.info(f"ğŸ“Š ìŠ¤ìœ• ê²°ê³¼ ì €ì¥: {output_file}")
        
        return summary
    
    def _plot_sweep_results(self):
        """ìŠ¤ìœ• ê²°ê³¼ ì‹œê°í™”"""
        try:
            import matplotlib
            matplotlib.use('Agg')  # GUI ì—†ëŠ” í™˜ê²½ ëŒ€ë¹„
            
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            
            # 1. ê° LRë³„ í•™ìŠµ ê³¡ì„ 
            ax = axes[0, 0]
            for lr, result in self.sweep_results.items():
                ax.plot(result['train_losses'], label=f'LR={lr:.1e}', alpha=0.7)
            ax.set_xlabel('Epoch')
            ax.set_ylabel('Training Loss')
            ax.set_title('Training Loss by Learning Rate')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            # 2. ê²€ì¦ ì†ì‹¤ ë¹„êµ
            ax = axes[0, 1]
            lrs = list(self.sweep_results.keys())
            val_losses = [r['final_val_loss'] for r in self.sweep_results.values()]
            ax.bar(range(len(lrs)), val_losses)
            ax.set_xticks(range(len(lrs)))
            ax.set_xticklabels([f'{lr:.1e}' for lr in lrs], rotation=45)
            ax.set_ylabel('Final Validation Loss')
            ax.set_title('Final Validation Loss Comparison')
            ax.grid(True, alpha=0.3)
            
            # 3. ìˆ˜ë ´ ì†ë„ vs ì•ˆì •ì„±
            ax = axes[1, 0]
            convergence_speeds = [r['convergence_speed'] for r in self.sweep_results.values()]
            stability_scores = [r['stability_score'] for r in self.sweep_results.values()]
            
            ax.scatter(convergence_speeds, stability_scores, s=100)
            for i, lr in enumerate(lrs):
                ax.annotate(f'{lr:.1e}', 
                           (convergence_speeds[i], stability_scores[i]),
                           xytext=(5, 5), textcoords='offset points')
            
            ax.set_xlabel('Convergence Speed')
            ax.set_ylabel('Stability Score')
            ax.set_title('Convergence vs Stability Trade-off')
            ax.grid(True, alpha=0.3)
            
            # 4. ì¢…í•© ì ìˆ˜
            ax = axes[1, 1]
            scores = []
            for lr, result in self.sweep_results.items():
                score = (
                    0.4 * result['convergence_speed'] +
                    0.3 * result['stability_score'] +
                    0.3 * (1.0 / (1.0 + result['final_val_loss']))
                )
                scores.append(score)
            
            bars = ax.bar(range(len(lrs)), scores)
            # ìµœê³  ì ìˆ˜ ë§‰ëŒ€ ê°•ì¡°
            best_idx = scores.index(max(scores))
            bars[best_idx].set_color('green')
            
            ax.set_xticks(range(len(lrs)))
            ax.set_xticklabels([f'{lr:.1e}' for lr in lrs], rotation=45)
            ax.set_ylabel('Combined Score')
            ax.set_title('Overall Performance Score')
            ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ì €ì¥
            output_dir = Path("training/lr_sweep_results")
            output_dir.mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            plot_file = output_dir / f"lr_sweep_plot_{timestamp}.png"
            plt.savefig(plot_file, dpi=100, bbox_inches='tight')
            plt.close()
            
            logger.info(f"ğŸ“ˆ ì‹œê°í™” ì €ì¥: {plot_file}")
            
        except Exception as e:
            logger.warning(f"ì‹œê°í™” ìƒì„± ì‹¤íŒ¨: {e}")
    
    def get_scheduler(self, optimizer: torch.optim.Optimizer, 
                     total_steps: int) -> torch.optim.lr_scheduler._LRScheduler:
        """
        ìµœì  LR ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
        
        Args:
            optimizer: ì˜µí‹°ë§ˆì´ì €
            total_steps: ì „ì²´ í•™ìŠµ ìŠ¤í… ìˆ˜
            
        Returns:
            í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        """
        if self.best_lr is None:
            raise ValueError("ë¨¼ì € run_sweep()ë¥¼ ì‹¤í–‰í•˜ì—¬ ìµœì  LRì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤")
        
        # Cosine Annealing with Warm Restarts
        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer,
            T_0=total_steps // 10,  # ì²« ë²ˆì§¸ ì¬ì‹œì‘ ì£¼ê¸°
            T_mult=2,  # ì£¼ê¸° ë°°ìˆ˜
            eta_min=self.best_lr * 0.01  # ìµœì†Œ LR
        )
        
        logger.info(f"ğŸ“… ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±: CosineAnnealingWarmRestarts")
        logger.info(f"   - ì´ˆê¸° LR: {self.best_lr:.1e}")
        logger.info(f"   - ìµœì†Œ LR: {self.best_lr * 0.01:.1e}")
        
        return scheduler