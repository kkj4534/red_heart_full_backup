#!/usr/bin/env python3
"""
10ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ í•™ìŠµ
10 Samples Test Training
"""

import sys
import time
from pathlib import Path
import torch

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from training.hybrid_distributed_trainer import HybridDistributedTrainer, HybridConfig
from training.results_analyzer import TrainingResultsAnalyzer

def main():
    """10ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ í•™ìŠµ ì‹¤í–‰"""
    print("ğŸ§ª Red Heart XAI - 10ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ í•™ìŠµ")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    config = HybridConfig(
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™”
        test_mode=True,
        test_samples=10,
        
        # ëª¨ë¸ ì„¤ì • (ê³µê²©ì  ê³ ì„±ëŠ¥ 70GB)
        target_params=4_300_000_000,    # 43ì–µ íŒŒë¼ë¯¸í„° (í˜„ì‹¤ì  70GB)
        gpu_memory_gb=8.0,
        cpu_memory_gb=70.0,             # WSL ê³µê²©ì  ë©”ëª¨ë¦¬ í™œìš©
        
        # í•™ìŠµ ì„¤ì • (ê³µê²©ì  ê³ ì„±ëŠ¥)
        regrets_per_step=7,             # ì›ë˜ ì„¤ì • ë³µì› (ìµœê³  í’ˆì§ˆ)
        bentham_calculations_per_regret=3,  # ì›ë˜ ì„¤ì • ë³µì› (ì •í™•ë„ ê·¹ëŒ€í™”)
        epochs=3,                       # 3ìˆœíšŒ ìœ ì§€
        batch_size=12,                  # ëŒ€í˜• ë°°ì¹˜ (ì²˜ë¦¬ëŸ‰ ì¦ê°€)
        micro_batch_size=3,             # ë©”ëª¨ë¦¬ ì—¬ìœ ë¡œ ì¦ê°€
        
        # ë¶„ì‚° ì„¤ì • (ê³µê²©ì  ë³‘ë ¬í™”)
        num_workers=8,                  # ìµœëŒ€ CPU í™œìš©
        gpu_layers_ratio=0.6,           # ê· í˜•ì¡íŒ GPU/CPU ë¶„í• 
        overlap_computation=True,
        use_cpu_offload=True,           # CPU ì˜¤í”„ë¡œë“œ í™œì„±í™”
        enable_memory_monitoring=True,  # ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
        
        # ìµœì í™” ì„¤ì •
        use_mixed_precision=True,
        gradient_accumulation_steps=4,   # ëŒ€í˜• ë°°ì¹˜ë¡œ ì¡°ì •
        use_gradient_checkpointing=True, # ë©”ëª¨ë¦¬ ì ˆì•½
        use_parameter_sharing=True,     # íŒŒë¼ë¯¸í„° ê³µìœ 
        
        # ë¡œê¹… ì„¤ì • (ìì£¼)
        log_every_n_steps=1,            # ëª¨ë“  ìŠ¤í… ë¡œê¹…
        save_checkpoint_every=2,        # 2ìŠ¤í…ë§ˆë‹¤ ì €ì¥
        max_storage_gb=10.0             # í…ŒìŠ¤íŠ¸ìš© ì‘ì€ ìš©ëŸ‰
    )
    
    print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì„¤ì •:")
    print(f"   - ìƒ˜í”Œ ìˆ˜: {config.test_samples}ê°œ")
    print(f"   - ëª¨ë¸ íŒŒë¼ë¯¸í„°: {config.target_params:,}ê°œ")
    print(f"   - í›„íšŒ/ìŠ¤í…: {config.regrets_per_step}")
    print(f"   - ë²¤ë‹´/í›„íšŒ: {config.bentham_calculations_per_regret}")
    print(f"   - ì´ ë²¤ë‹´/ìŠ¤í…: {config.regrets_per_step * config.bentham_calculations_per_regret}")
    print(f"   - ì—í¬í¬: {config.epochs}")
    print(f"   - ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
    print("=" * 60)
    
    # ì‹œê°„ ì¸¡ì • ì‹œì‘
    total_start_time = time.time()
    
    try:
        # í…ŒìŠ¤íŠ¸ í•™ìŠµê¸° ìƒì„±
        trainer = HybridDistributedTrainer(config)
        
        # í•™ìŠµ ì‹¤í–‰
        print("ğŸ¯ 10ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ í•™ìŠµ ì‹œì‘...")
        print(f"â±ï¸  ì‹œì‘ ì‹œê°„: {time.strftime('%H:%M:%S')}")
        
        report, checkpoint_path = trainer.train()
        
        total_time = time.time() - total_start_time
        
        print("\n" + "=" * 60)
        print("ğŸ‰ 10ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   - ì´ í•™ìŠµ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time/60:.2f}ë¶„)")
        print(f"   - ì´ í›„íšŒ: {sum(trainer.training_stats['regret_count']):,}")
        print(f"   - ì´ ë²¤ë‹´ ê³„ì‚°: {sum(trainer.training_stats['bentham_count']):,}")
        print(f"   - ì´ ìŠ¤í…: {len(trainer.training_stats['total_loss'])}")
        print(f"   - ìŠ¤í…ë‹¹ í‰ê·  ì‹œê°„: {total_time / len(trainer.training_stats['total_loss']):.2f}ì´ˆ")
        print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
        
        # ì†ì‹¤ ê°œì„  ë¶„ì„
        losses = trainer.training_stats['total_loss']
        if len(losses) > 2:
            initial_loss = losses[0]
            final_loss = losses[-1]
            improvement = ((initial_loss - final_loss) / initial_loss * 100) if initial_loss > 0 else 0
            print(f"ğŸ“ˆ ì†ì‹¤ ê°œì„ : {improvement:.2f}% ({initial_loss:.6f} â†’ {final_loss:.6f})")
        
        # ì „ì²´ í•™ìŠµ ì‹œê°„ ì˜ˆì¸¡
        samples_per_second = config.test_samples / total_time
        full_samples = 28882  # ì „ì²´ ë°ì´í„°
        predicted_full_time = full_samples / samples_per_second
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ì „ì²´ í•™ìŠµ ì‹œê°„ ì˜ˆì¸¡:")
        print(f"   - ìƒ˜í”Œ ì²˜ë¦¬ ì†ë„: {samples_per_second:.2f} ìƒ˜í”Œ/ì´ˆ")
        print(f"   - ì „ì²´ ë°ì´í„°: {full_samples:,}ê°œ")
        print(f"   - ì˜ˆìƒ ì „ì²´ ì‹œê°„: {predicted_full_time:.0f}ì´ˆ ({predicted_full_time/3600:.2f}ì‹œê°„)")
        print(f"   - 3ì—í¬í¬ ì˜ˆìƒ: {predicted_full_time * 3 / 3600:.2f}ì‹œê°„")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.max_memory_allocated() / 1024**3
            print(f"   - ìµœëŒ€ GPU ë©”ëª¨ë¦¬: {gpu_memory:.2f}GB")
        
        print("=" * 60)
        
        # í•™ìŠµ í’ˆì§ˆ í‰ê°€
        if improvement > 1:
            print("âœ… í•™ìŠµ íš¨ê³¼ í™•ì¸: ì†ì‹¤ì´ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤!")
        elif improvement > 0:
            print("âš ï¸ ë¯¸ë¯¸í•œ í•™ìŠµ íš¨ê³¼: ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âŒ í•™ìŠµ íš¨ê³¼ ì—†ìŒ: ì„¤ì • ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if predicted_full_time < 24 * 3600:  # 24ì‹œê°„ ì´ë‚´
            print("âœ… ì „ì²´ í•™ìŠµ ì‹œê°„ ì ì ˆ: í•˜ë£¨ ë‚´ ì™„ë£Œ ê°€ëŠ¥")
        elif predicted_full_time < 72 * 3600:  # 72ì‹œê°„ ì´ë‚´
            print("âš ï¸ ì „ì²´ í•™ìŠµ ì‹œê°„ ê¸¸ìŒ: 2-3ì¼ ì†Œìš” ì˜ˆìƒ")
        else:
            print("âŒ ì „ì²´ í•™ìŠµ ì‹œê°„ ê³¼ë‹¤: ìµœì í™” í•„ìš”")
        
        # ê²°ê³¼ ë¶„ì„ ë° ë¬¸ì„œ ìƒì„±
        print("\nğŸ“Š ê²°ê³¼ ë¶„ì„ ì¤‘...")
        analyzer = TrainingResultsAnalyzer(project_root)
        
        # ë¦¬í¬íŠ¸ ê²½ë¡œ ì°¾ê¸°
        report_files = list((project_root / 'training' / 'hybrid_outputs' / 'reports').glob('hybrid_training_report_*.json'))
        if report_files:
            latest_report = max(report_files, key=lambda x: x.stat().st_mtime)
            analysis_results = analyzer.analyze_and_generate_docs(latest_report)
            print(f"ğŸ“„ ë¶„ì„ ë¦¬í¬íŠ¸: {analysis_results['markdown_report']}")
        
        print(f"\nğŸŠ 10ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì„±ê³µ! ğŸŠ")
        if predicted_full_time < 12 * 3600:  # 12ì‹œê°„ ì´ë‚´ë¼ë©´
            print("ğŸš€ ì „ì²´ í•™ìŠµ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
            print("python3 training/start_hybrid_training.py ë¡œ ì „ì²´ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”.")
        else:
            print("âš ï¸ ì „ì²´ í•™ìŠµ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì„¤ì • ì¡°ì •ì„ ê²€í† í•˜ì„¸ìš”.")
        
        return True, {
            'total_time': total_time,
            'samples_per_second': samples_per_second,
            'predicted_full_time_hours': predicted_full_time / 3600,
            'improvement_percent': improvement if len(losses) > 2 else 0,
            'total_steps': len(trainer.training_stats['total_loss']),
            'total_regrets': sum(trainer.training_stats['regret_count']),
            'total_benthams': sum(trainer.training_stats['bentham_count'])
        }
        
    except Exception as e:
        print(f"\nâŒ 10ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False, None

if __name__ == "__main__":
    success, results = main()
    
    if success and results:
        print(f"\nâ±ï¸ í•µì‹¬ ê²°ê³¼:")
        print(f"   - í…ŒìŠ¤íŠ¸ ì‹œê°„: {results['total_time']:.1f}ì´ˆ")
        print(f"   - ì „ì²´ ì˜ˆìƒ: {results['predicted_full_time_hours']:.1f}ì‹œê°„")
        print(f"   - ì†ì‹¤ ê°œì„ : {results['improvement_percent']:.1f}%")
    
    sys.exit(0 if success else 1)