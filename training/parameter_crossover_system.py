"""
Parameter Crossover System
ì„œë¡œ ë‹¤ë¥¸ ì—í­ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ëª¨ë¸ ìƒì„±
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import json
import logging
from datetime import datetime
from collections import defaultdict
import copy

logger = logging.getLogger(__name__)


class ParameterCrossoverSystem:
    """
    íŒŒë¼ë¯¸í„° êµì°¨ ì‹œìŠ¤í…œ
    - ëª¨ë“ˆë³„ ìµœì  ì—í­ì˜ íŒŒë¼ë¯¸í„° ì„ íƒ
    - ê°€ì¤‘ì¹˜ í‰ê· í™” ë° ì•™ìƒë¸”
    - ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ìµœì í™”
    - íŒŒë¼ë¯¸í„° ë³´ê°„
    """
    
    def __init__(self,
                 crossover_strategy: str = 'selective',
                 blend_ratio: float = 0.7,
                 mutation_rate: float = 0.01):
        """
        Args:
            crossover_strategy: êµì°¨ ì „ëµ ('selective', 'weighted', 'genetic', 'interpolate')
            blend_ratio: ë¸”ë Œë”© ë¹„ìœ¨ (ì£¼ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜)
            mutation_rate: ìœ ì „ ì•Œê³ ë¦¬ì¦˜ì˜ ë³€ì´ìœ¨
        """
        self.crossover_strategy = crossover_strategy
        self.blend_ratio = blend_ratio
        self.mutation_rate = mutation_rate
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ì†Œ
        self.checkpoint_pool = {}
        self.module_best_epochs = {}
        
        # êµì°¨ ê²°ê³¼
        self.crossover_results = []
        self.best_combination = None
        
        logger.info("âœ… Parameter Crossover System ì´ˆê¸°í™”")
        logger.info(f"  - ì „ëµ: {crossover_strategy}")
        logger.info(f"  - ë¸”ë Œë“œ ë¹„ìœ¨: {blend_ratio}")
    
    def add_checkpoint(self, 
                      epoch: int,
                      checkpoint_path: str,
                      module_metrics: Dict[str, float]):
        """
        ì²´í¬í¬ì¸íŠ¸ í’€ì— ì¶”ê°€
        
        Args:
            epoch: ì—í­ ë²ˆí˜¸
            checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
            module_metrics: ëª¨ë“ˆë³„ ë©”íŠ¸ë¦­
        """
        self.checkpoint_pool[epoch] = {
            'path': checkpoint_path,
            'metrics': module_metrics
        }
        
        # ëª¨ë“ˆë³„ ìµœê³  ì„±ëŠ¥ ì—í­ ì—…ë°ì´íŠ¸
        for module_name, metric_value in module_metrics.items():
            if module_name not in self.module_best_epochs or \
               metric_value < self.module_best_epochs[module_name]['metric']:
                self.module_best_epochs[module_name] = {
                    'epoch': epoch,
                    'metric': metric_value
                }
    
    def perform_crossover(self,
                         model: nn.Module,
                         optimal_epochs: Dict[str, int],
                         validation_fn: Optional[Any] = None) -> nn.Module:
        """
        íŒŒë¼ë¯¸í„° êµì°¨ ìˆ˜í–‰
        
        Args:
            model: ê¸°ë³¸ ëª¨ë¸ êµ¬ì¡°
            optimal_epochs: ëª¨ë“ˆë³„ ìµœì  ì—í­
            validation_fn: ê²€ì¦ í•¨ìˆ˜ (ì„ íƒì )
            
        Returns:
            êµì°¨ëœ ìµœì¢… ëª¨ë¸
        """
        logger.info("ğŸ§¬ Parameter Crossover ì‹œì‘...")
        logger.info(f"  - ìµœì  ì—í­: {optimal_epochs}")
        
        if self.crossover_strategy == 'selective':
            return self._selective_crossover(model, optimal_epochs)
        elif self.crossover_strategy == 'weighted':
            return self._weighted_crossover(model, optimal_epochs)
        elif self.crossover_strategy == 'genetic':
            return self._genetic_crossover(model, optimal_epochs, validation_fn)
        elif self.crossover_strategy == 'interpolate':
            return self._interpolate_crossover(model, optimal_epochs)
        else:
            raise ValueError(f"Unknown crossover strategy: {self.crossover_strategy}")
    
    def _selective_crossover(self, 
                           model: nn.Module,
                           optimal_epochs: Dict[str, int]) -> nn.Module:
        """
        ì„ íƒì  êµì°¨: ê° ëª¨ë“ˆë§ˆë‹¤ ìµœì  ì—í­ì˜ íŒŒë¼ë¯¸í„° ì„ íƒ
        ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°©ì‹ìœ¼ë¡œ state_dictë§Œ êµì²´
        """
        logger.info("  ğŸ“Œ ì„ íƒì  êµì°¨ ìˆ˜í–‰ ì¤‘...")
        
        # í˜„ì¬ ëª¨ë¸ì˜ state_dict ì €ì¥ (deepcopy ëŒ€ì‹ )
        current_state = model.state_dict()
        crossover_state = {}  # ìƒˆë¡œìš´ state_dict êµ¬ì„±
        
        # ê¸°ë³¸ì ìœ¼ë¡œ í˜„ì¬ stateë¥¼ ë³µì‚¬
        for key, value in current_state.items():
            crossover_state[key] = value.clone()
        
        # ëª¨ë“ˆë³„ë¡œ ìµœì  ì—í­ì˜ íŒŒë¼ë¯¸í„° ë¡œë“œ
        for module_name, optimal_epoch in optimal_epochs.items():
            if optimal_epoch not in self.checkpoint_pool:
                logger.warning(f"    âš ï¸ ì—í­ {optimal_epoch}ì˜ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤: {module_name}")
                continue
            
            checkpoint_path = self.checkpoint_pool[optimal_epoch]['path']
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            
            # ëª¨ë“ˆë³„ state_dict ì¶”ì¶œ
            if 'model_state' in checkpoint:
                checkpoint_state = checkpoint['model_state']
            elif 'model' in checkpoint:
                checkpoint_state = checkpoint['model']
            else:
                checkpoint_state = checkpoint
            
            # í•´ë‹¹ ëª¨ë“ˆì˜ íŒŒë¼ë¯¸í„°ë§Œ ì—…ë°ì´íŠ¸
            updated_keys = []
            
            # Special case 1: neural_analyzers dict ì²˜ë¦¬
            if module_name == 'neural_analyzers' and module_name in checkpoint_state:
                neural_states = checkpoint_state[module_name]
                if isinstance(neural_states, dict):
                    # nested dict êµ¬ì¡° ì²˜ë¦¬
                    for analyzer_name, analyzer_state in neural_states.items():
                        if isinstance(analyzer_state, dict):
                            for param_key, param_value in analyzer_state.items():
                                full_key = f"neural_analyzers.{analyzer_name}.{param_key}"
                                if full_key in crossover_state:
                                    crossover_state[full_key] = param_value.cpu() if torch.is_tensor(param_value) else param_value
                                    updated_keys.append(full_key)
                    if not updated_keys:
                        # í‚¤ê°€ ì•ˆë§ìœ¼ë©´ ë‹¤ë¥¸ í˜•ì‹ ì‹œë„ (dict of dictì´ ì•„ë‹Œ ê²½ìš°)
                        for key, value in neural_states.items():
                            if torch.is_tensor(value):
                                # ì§ì ‘ ë§¤í•‘ ì‹œë„
                                crossover_state[f"neural_analyzers.{key}"] = value.cpu()
                                updated_keys.append(f"neural_analyzers.{key}")
            
            # Special case 2: system ì²˜ë¦¬ (í†µí•© íŒŒë¼ë¯¸í„°)
            elif module_name == 'system' and module_name in checkpoint_state:
                system_state = checkpoint_state[module_name]
                if isinstance(system_state, dict) and 'meta' not in system_state:
                    # systemì˜ ë°±ë³¸ í†µí•© ë ˆì´ì–´ ì²˜ë¦¬
                    for sub_module, sub_state in system_state.items():
                        if sub_module != 'meta' and isinstance(sub_state, dict):
                            for key, value in sub_state.items():
                                # backbone.final_norm ë“±ì˜ ì‹¤ì œ í‚¤ë¡œ ë§¤í•‘
                                if 'backbone_final_norm' in sub_module:
                                    full_key = f"backbone.final_norm.{key}"
                                elif 'backbone_output_projection' in sub_module:
                                    full_key = f"backbone.output_projection.{key}"
                                else:
                                    full_key = f"{sub_module}.{key}"
                                
                                if full_key in crossover_state:
                                    crossover_state[full_key] = value.cpu() if torch.is_tensor(value) else value
                                    updated_keys.append(full_key)
            
            # ì¼ë°˜ì ì¸ ê²½ìš°: checkpoint_stateê°€ ëª¨ë“ˆë³„ë¡œ ì €ì¥ëœ ê²½ìš°
            elif module_name in checkpoint_state:
                module_state = checkpoint_state[module_name]
                # ëª¨ë“ˆì˜ state_dictë¥¼ crossover_stateì— ì¶”ê°€
                for key, value in module_state.items():
                    full_key = f"{module_name}.{key}"
                    if full_key in crossover_state:
                        # CPUì—ì„œ ì‘ì—… (ì´ë¯¸ CPUì— ìˆì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ)
                        crossover_state[full_key] = value.cpu() if torch.is_tensor(value) else value
                        updated_keys.append(full_key)
            else:
                # ì „ì²´ state_dictê°€ í”Œë«í•˜ê²Œ ì €ì¥ëœ ê²½ìš° (ê¸°ì¡´ ë°©ì‹)
                module_prefix = f"{module_name}."
                for key, value in checkpoint_state.items():
                    if key.startswith(module_prefix):
                        if key in crossover_state:
                            # CPUì—ì„œ ì‘ì—… (ì´ë¯¸ CPUì— ìˆì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ)
                            crossover_state[key] = value.cpu() if torch.is_tensor(value) else value
                            updated_keys.append(key)
            
            if updated_keys:
                logger.info(f"    âœ“ {module_name}: ì—í­ {optimal_epoch}ì—ì„œ {len(updated_keys)}ê°œ íŒŒë¼ë¯¸í„° ë¡œë“œ")
            else:
                logger.warning(f"    âš ï¸ {module_name}: ë§¤ì¹­ë˜ëŠ” íŒŒë¼ë¯¸í„° ì—†ìŒ")
        
        # ìƒˆë¡œìš´ state_dictë¥¼ ëª¨ë¸ì— ë¡œë“œ
        try:
            model.load_state_dict(crossover_state, strict=False)
            logger.info("  âœ… Parameter Crossover ì™„ë£Œ")
        except Exception as e:
            logger.error(f"  âŒ State dict ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë˜ state ë³µì›
            model.load_state_dict(current_state)
            logger.info("  â†©ï¸ ì›ë˜ stateë¡œ ë³µì›ë¨")
        
        return model
    
    def _weighted_crossover(self,
                          model: nn.Module,
                          optimal_epochs: Dict[str, int]) -> nn.Module:
        """
        ê°€ì¤‘ í‰ê·  êµì°¨: ì—¬ëŸ¬ ì—í­ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì¤‘ í‰ê· 
        """
        logger.info("  ğŸ“Š ê°€ì¤‘ í‰ê·  êµì°¨ ìˆ˜í–‰ ì¤‘...")
        
        crossover_model = copy.deepcopy(model)
        
        # ê° ëª¨ë“ˆë³„ë¡œ ì²˜ë¦¬
        for module_name in optimal_epochs.keys():
            if not hasattr(crossover_model, module_name):
                continue
            
            module = getattr(crossover_model, module_name)
            
            # ìµœì  ì—í­ ì£¼ë³€ì˜ ì²´í¬í¬ì¸íŠ¸ ìˆ˜ì§‘
            optimal_epoch = optimal_epochs[module_name]
            nearby_epochs = [
                e for e in range(max(1, optimal_epoch - 2), optimal_epoch + 3)
                if e in self.checkpoint_pool
            ]
            
            if not nearby_epochs:
                continue
            
            # ê°€ì¤‘ì¹˜ ê³„ì‚° (ìµœì  ì—í­ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
            weights = []
            state_dicts = []
            
            for epoch in nearby_epochs:
                distance = abs(epoch - optimal_epoch)
                weight = 1.0 / (1.0 + distance)  # ê±°ë¦¬ì— ë°˜ë¹„ë¡€
                weights.append(weight)
                
                checkpoint = torch.load(self.checkpoint_pool[epoch]['path'], map_location='cpu')
                if 'model_state' in checkpoint and module_name in checkpoint['model_state']:
                    state_dicts.append(checkpoint['model_state'][module_name])
            
            if not state_dicts:
                continue
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            weights = np.array(weights)
            weights = weights / weights.sum()
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            averaged_state = {}
            for key in state_dicts[0].keys():
                averaged_state[key] = sum(
                    w * sd[key] for w, sd in zip(weights, state_dicts)
                )
            
            module.load_state_dict(averaged_state)
            logger.info(f"    âœ“ {module_name}: {len(nearby_epochs)}ê°œ ì—í­ ê°€ì¤‘ í‰ê· ")
        
        return crossover_model
    
    def _genetic_crossover(self,
                         model: nn.Module,
                         optimal_epochs: Dict[str, int],
                         validation_fn: Optional[Any] = None) -> nn.Module:
        """
        ìœ ì „ ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ êµì°¨
        """
        logger.info("  ğŸ§¬ ìœ ì „ ì•Œê³ ë¦¬ì¦˜ êµì°¨ ìˆ˜í–‰ ì¤‘...")
        
        population_size = 10
        generations = 5
        
        # ì´ˆê¸° ê°œì²´êµ° ìƒì„±
        population = []
        for _ in range(population_size):
            individual = self._create_random_combination(model, optimal_epochs)
            population.append(individual)
        
        # ì§„í™” ê³¼ì •
        for gen in range(generations):
            # ì í•©ë„ í‰ê°€
            if validation_fn:
                fitness_scores = [validation_fn(ind) for ind in population]
            else:
                # ë”ë¯¸ ì í•©ë„ (ì‹¤ì œë¡œëŠ” ê²€ì¦ ì†ì‹¤ ë“± ì‚¬ìš©)
                fitness_scores = [np.random.random() for _ in population]
            
            # ì„ íƒ (ìƒìœ„ 50%)
            sorted_indices = np.argsort(fitness_scores)[:population_size // 2]
            parents = [population[i] for i in sorted_indices]
            
            # êµì°¨ ë° ë³€ì´
            offspring = []
            for i in range(0, len(parents) - 1, 2):
                child1, child2 = self._crossover_individuals(parents[i], parents[i+1])
                child1 = self._mutate_individual(child1)
                child2 = self._mutate_individual(child2)
                offspring.extend([child1, child2])
            
            # ë‹¤ìŒ ì„¸ëŒ€
            population = parents + offspring
            
            logger.info(f"    Generation {gen+1}: Best fitness = {min(fitness_scores):.4f}")
        
        # ìµœê³  ê°œì²´ ì„ íƒ
        if validation_fn:
            fitness_scores = [validation_fn(ind) for ind in population]
            best_idx = np.argmin(fitness_scores)
        else:
            best_idx = 0
        
        return population[best_idx]
    
    def _interpolate_crossover(self,
                             model: nn.Module,
                             optimal_epochs: Dict[str, int]) -> nn.Module:
        """
        ë³´ê°„ ê¸°ë°˜ êµì°¨: ì—í­ ê°„ íŒŒë¼ë¯¸í„°ë¥¼ ë¶€ë“œëŸ½ê²Œ ë³´ê°„
        """
        logger.info("  ğŸ”„ ë³´ê°„ êµì°¨ ìˆ˜í–‰ ì¤‘...")
        
        crossover_model = copy.deepcopy(model)
        
        for module_name, optimal_epoch in optimal_epochs.items():
            if not hasattr(crossover_model, module_name):
                continue
            
            module = getattr(crossover_model, module_name)
            
            # ë³´ê°„í•  ë‘ ì²´í¬í¬ì¸íŠ¸ ì„ íƒ
            if optimal_epoch > 1 and (optimal_epoch - 1) in self.checkpoint_pool:
                epoch1 = optimal_epoch - 1
                epoch2 = optimal_epoch
            elif optimal_epoch < 60 and (optimal_epoch + 1) in self.checkpoint_pool:
                epoch1 = optimal_epoch
                epoch2 = optimal_epoch + 1
            else:
                continue
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            cp1 = torch.load(self.checkpoint_pool[epoch1]['path'], map_location='cpu')
            cp2 = torch.load(self.checkpoint_pool[epoch2]['path'], map_location='cpu')
            
            if 'model_state' not in cp1 or 'model_state' not in cp2:
                continue
            
            if module_name not in cp1['model_state'] or module_name not in cp2['model_state']:
                continue
            
            state1 = cp1['model_state'][module_name]
            state2 = cp2['model_state'][module_name]
            
            # ì„ í˜• ë³´ê°„
            interpolated_state = {}
            alpha = 0.5  # ë³´ê°„ ë¹„ìœ¨
            
            for key in state1.keys():
                interpolated_state[key] = (1 - alpha) * state1[key] + alpha * state2[key]
            
            module.load_state_dict(interpolated_state)
            logger.info(f"    âœ“ {module_name}: ì—í­ {epoch1}-{epoch2} ë³´ê°„")
        
        return crossover_model
    
    def _create_random_combination(self,
                                  model: nn.Module,
                                  optimal_epochs: Dict[str, int]) -> nn.Module:
        """ëœë¤ íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±"""
        individual = copy.deepcopy(model)
        
        for module_name in optimal_epochs.keys():
            # ëœë¤í•˜ê²Œ ì—í­ ì„ íƒ
            available_epochs = list(self.checkpoint_pool.keys())
            if available_epochs:
                random_epoch = np.random.choice(available_epochs)
                
                checkpoint = torch.load(
                    self.checkpoint_pool[random_epoch]['path'],
                    map_location='cpu'
                )
                
                if hasattr(individual, module_name) and 'model_state' in checkpoint:
                    if module_name in checkpoint['model_state']:
                        module = getattr(individual, module_name)
                        try:
                            module.load_state_dict(checkpoint['model_state'][module_name])
                        except:
                            pass
        
        return individual
    
    def _crossover_individuals(self,
                             parent1: nn.Module,
                             parent2: nn.Module) -> Tuple[nn.Module, nn.Module]:
        """ë‘ ê°œì²´ êµì°¨"""
        child1 = copy.deepcopy(parent1)
        child2 = copy.deepcopy(parent2)
        
        # ëª¨ë“ˆë³„ë¡œ 50% í™•ë¥ ë¡œ êµí™˜
        for name, module in parent1.named_modules():
            if np.random.random() < 0.5:
                # child1ì€ parent2ì˜ ëª¨ë“ˆì„, child2ëŠ” parent1ì˜ ëª¨ë“ˆì„ ë°›ìŒ
                if hasattr(child1, name) and hasattr(parent2, name):
                    child1_module = getattr(child1, name)
                    parent2_module = getattr(parent2, name)
                    child1_module.load_state_dict(parent2_module.state_dict())
                
                if hasattr(child2, name) and hasattr(parent1, name):
                    child2_module = getattr(child2, name)
                    parent1_module = getattr(parent1, name)
                    child2_module.load_state_dict(parent1_module.state_dict())
        
        return child1, child2
    
    def _mutate_individual(self, individual: nn.Module) -> nn.Module:
        """ê°œì²´ ë³€ì´"""
        for name, param in individual.named_parameters():
            if np.random.random() < self.mutation_rate:
                # ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
                noise = torch.randn_like(param) * 0.01
                param.data.add_(noise)
        
        return individual
    
    def save_crossover_result(self,
                            model: nn.Module,
                            save_path: str,
                            metadata: Optional[Dict] = None):
        """
        êµì°¨ ê²°ê³¼ ì €ì¥
        
        Args:
            model: êµì°¨ëœ ëª¨ë¸
            save_path: ì €ì¥ ê²½ë¡œ
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        """
        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        checkpoint = {
            'model_state_dict': model.state_dict(),
            'crossover_strategy': self.crossover_strategy,
            'blend_ratio': self.blend_ratio,
            'module_best_epochs': self.module_best_epochs,
            'timestamp': datetime.now().isoformat()
        }
        
        if metadata:
            checkpoint['metadata'] = metadata
        
        torch.save(checkpoint, save_path)
        logger.info(f"ğŸ’¾ Crossover ëª¨ë¸ ì €ì¥: {save_path}")
        
        # ë©”íƒ€ë°ì´í„° ë³„ë„ ì €ì¥
        meta_file = save_path.with_suffix('.json')
        with open(meta_file, 'w') as f:
            json.dump({
                'crossover_strategy': self.crossover_strategy,
                'module_best_epochs': self.module_best_epochs,
                'timestamp': checkpoint['timestamp'],
                'metadata': metadata or {}
            }, f, indent=2)
    
    def analyze_crossover_impact(self,
                                original_model: nn.Module,
                                crossover_model: nn.Module) -> Dict[str, Any]:
        """
        êµì°¨ ì „í›„ ëª¨ë¸ ë¹„êµ ë¶„ì„
        
        Args:
            original_model: ì›ë³¸ ëª¨ë¸
            crossover_model: êµì°¨ëœ ëª¨ë¸
            
        Returns:
            ë¶„ì„ ê²°ê³¼
        """
        analysis = {
            'parameter_changes': {},
            'magnitude_changes': {},
            'similarity_scores': {}
        }
        
        for name, param in original_model.named_parameters():
            if name in dict(crossover_model.named_parameters()):
                original_param = param.data
                crossover_param = dict(crossover_model.named_parameters())[name].data
                
                # íŒŒë¼ë¯¸í„° ë³€í™”ëŸ‰
                change = (crossover_param - original_param).abs().mean().item()
                analysis['parameter_changes'][name] = change
                
                # í¬ê¸° ë³€í™”
                original_norm = original_param.norm().item()
                crossover_norm = crossover_param.norm().item()
                magnitude_change = (crossover_norm - original_norm) / original_norm if original_norm > 0 else 0
                analysis['magnitude_changes'][name] = magnitude_change
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                if original_param.numel() > 1:
                    original_flat = original_param.flatten()
                    crossover_flat = crossover_param.flatten()
                    cosine_sim = torch.nn.functional.cosine_similarity(
                        original_flat.unsqueeze(0),
                        crossover_flat.unsqueeze(0)
                    ).item()
                    analysis['similarity_scores'][name] = cosine_sim
        
        # ìš”ì•½ í†µê³„
        analysis['summary'] = {
            'avg_parameter_change': np.mean(list(analysis['parameter_changes'].values())),
            'avg_magnitude_change': np.mean(list(analysis['magnitude_changes'].values())),
            'avg_similarity': np.mean(list(analysis['similarity_scores'].values()))
        }
        
        logger.info("ğŸ“Š Crossover Impact Analysis:")
        logger.info(f"  - í‰ê·  íŒŒë¼ë¯¸í„° ë³€í™”: {analysis['summary']['avg_parameter_change']:.4f}")
        logger.info(f"  - í‰ê·  í¬ê¸° ë³€í™”: {analysis['summary']['avg_magnitude_change']:.4f}")
        logger.info(f"  - í‰ê·  ìœ ì‚¬ë„: {analysis['summary']['avg_similarity']:.4f}")
        
        return analysis