#!/usr/bin/env python3
"""
ëª¨ë¸ ìºì‹œ ìƒíƒœ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
Verify Model Cache Status Script

ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ë“¤ì´ ì‹¤ì œë¡œ ì˜¤í”„ë¼ì¸ì—ì„œ ë¡œë“œ ê°€ëŠ¥í•œì§€ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import os
import sys
import logging
from pathlib import Path
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def setup_offline_mode():
    """ê°•ë ¥í•œ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •"""
    offline_env = {
        'TRANSFORMERS_OFFLINE': '1',
        'HF_HUB_OFFLINE': '1', 
        'HF_DATASETS_OFFLINE': '1',
        'HF_HUB_DISABLE_TELEMETRY': '1',
        'DISABLE_TELEMETRY': '1',
        'TOKENIZERS_PARALLELISM': 'false'
    }
    
    for key, value in offline_env.items():
        os.environ[key] = value
        print(f"   ğŸ”’ {key}={value}")

def check_cache_directories():
    """ìºì‹œ ë””ë ‰í† ë¦¬ ìƒíƒœ í™•ì¸"""
    print("\n" + "=" * 50)
    print("ğŸ“‚ ìºì‹œ ë””ë ‰í† ë¦¬ ìƒíƒœ í™•ì¸")
    print("=" * 50)
    
    cache_paths = [
        Path.home() / '.cache' / 'huggingface' / 'hub',
        Path.home() / '.cache' / 'huggingface' / 'transformers', 
        Path.home() / '.cache' / 'torch' / 'sentence_transformers',
        Path.home() / '.cache' / 'huggingface' / 'datasets'
    ]
    
    for cache_path in cache_paths:
        if cache_path.exists():
            # íŒŒì¼ ê°œìˆ˜ì™€ ì´ í¬ê¸° ê³„ì‚°
            files = list(cache_path.rglob('*'))
            file_count = len([f for f in files if f.is_file()])
            total_size = sum(f.stat().st_size for f in files if f.is_file())
            size_mb = total_size / (1024 * 1024)
            
            print(f"   âœ… {cache_path}")
            print(f"      ğŸ“„ íŒŒì¼ ìˆ˜: {file_count:,}ê°œ")
            print(f"      ğŸ’¾ í¬ê¸°: {size_mb:.1f} MB")
            
            # ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸ (hub ìºì‹œì¸ ê²½ìš°)
            if cache_path.name == 'hub':
                model_dirs = [d for d in cache_path.iterdir() if d.is_dir() and d.name.startswith('models--')]
                print(f"      ğŸ¤– ëª¨ë¸ ë””ë ‰í† ë¦¬: {len(model_dirs)}ê°œ")
                for model_dir in sorted(model_dirs):
                    model_name = model_dir.name.replace('models--', '').replace('--', '/')
                    print(f"         - {model_name}")
        else:
            print(f"   âŒ {cache_path} (ì¡´ì¬í•˜ì§€ ì•ŠìŒ)")

def test_transformers_models():
    """Transformers ëª¨ë¸ë“¤ ê°œë³„ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 50)
    print("ğŸ¤– Transformers ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    models_to_test = [
        ("Helsinki-NLP/opus-mt-ko-en", "ë²ˆì—­ ëª¨ë¸"),
        ("j-hartmann/emotion-english-distilroberta-base", "ê°ì • ë¶„ì„ ëª¨ë¸"),
        ("jhgan/ko-sroberta-multitask", "í•œêµ­ì–´ ë¬¸ì¥ ì„ë² ë”©"),
        ("beomi/KcELECTRA-base-v2022", "í•œêµ­ì–´ ELECTRA")
    ]
    
    results = {}
    
    for model_name, description in models_to_test:
        print(f"\nğŸ”„ í…ŒìŠ¤íŠ¸ ì¤‘: {model_name} ({description})")
        start_time = time.time()
        
        try:
            if "opus-mt" in model_name:
                # ë²ˆì—­ ëª¨ë¸ í…ŒìŠ¤íŠ¸
                from transformers import MarianTokenizer, MarianMTModel
                tokenizer = MarianTokenizer.from_pretrained(model_name, local_files_only=True)
                model = MarianMTModel.from_pretrained(model_name, local_files_only=True)
                
                # ê°„ë‹¨í•œ ë²ˆì—­ í…ŒìŠ¤íŠ¸
                inputs = tokenizer("ì•ˆë…•í•˜ì„¸ìš”", return_tensors="pt")
                outputs = model.generate(**inputs)
                translated = tokenizer.decode(outputs[0], skip_special_tokens=True)
                
                print(f"   âœ… ë¡œë”© ì„±ê³µ - ë²ˆì—­ ê²°ê³¼: '{translated}'")
                results[model_name] = "ì„±ê³µ"
                
            elif "emotion" in model_name:
                # ê°ì • ë¶„ì„ ëª¨ë¸ í…ŒìŠ¤íŠ¸
                from transformers import AutoTokenizer, AutoModelForSequenceClassification
                tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=True)
                model = AutoModelForSequenceClassification.from_pretrained(model_name, local_files_only=True)
                
                # ê°„ë‹¨í•œ ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸
                inputs = tokenizer("I am happy today", return_tensors="pt")
                outputs = model(**inputs)
                predictions = outputs.logits.argmax(dim=-1)
                
                print(f"   âœ… ë¡œë”© ì„±ê³µ - ì˜ˆì¸¡ ê²°ê³¼: {predictions.item()}")
                results[model_name] = "ì„±ê³µ"
                
            else:
                # ì¼ë°˜ ëª¨ë¸ í…ŒìŠ¤íŠ¸
                from transformers import AutoTokenizer, AutoModel
                tokenizer = AutoTokenizer.from_pretrained(model_name, local_files_only=True)
                model = AutoModel.from_pretrained(model_name, local_files_only=True)
                
                # ê°„ë‹¨í•œ ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
                inputs = tokenizer("í…ŒìŠ¤íŠ¸ ë¬¸ì¥", return_tensors="pt")
                outputs = model(**inputs)
                
                print(f"   âœ… ë¡œë”© ì„±ê³µ - ì„ë² ë”© í¬ê¸°: {outputs.last_hidden_state.shape}")
                results[model_name] = "ì„±ê³µ"
            
            elapsed = time.time() - start_time
            print(f"   â±ï¸ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
            
        except Exception as e:
            print(f"   âŒ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            logger.error(f"ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {model_name} - {e}")
            results[model_name] = f"ì‹¤íŒ¨: {str(e)}"
    
    return results

def test_sentence_transformers():
    """SentenceTransformers ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 50)  
    print("ğŸ”¤ SentenceTransformers ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    sentence_models = [
        "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        "jhgan/ko-sroberta-multitask"
    ]
    
    results = {}
    
    try:
        from sentence_transformers import SentenceTransformer
        
        for model_name in sentence_models:
            print(f"\nğŸ”„ í…ŒìŠ¤íŠ¸ ì¤‘: {model_name}")
            start_time = time.time()
            
            try:
                # local_files_only ì˜µì…˜ìœ¼ë¡œ ë¡œë“œ ì‹œë„
                model = SentenceTransformer(model_name, device='cpu')
                
                # ê°„ë‹¨í•œ ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
                test_sentences = ["ì•ˆë…•í•˜ì„¸ìš”", "Hello world"]
                embeddings = model.encode(test_sentences)
                
                print(f"   âœ… ë¡œë”© ì„±ê³µ")
                print(f"      ğŸ“Š ì„ë² ë”© ì°¨ì›: {embeddings.shape[1]}")
                print(f"      ğŸ“„ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ìˆ˜: {len(test_sentences)}")
                
                elapsed = time.time() - start_time
                print(f"   â±ï¸ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
                
                results[model_name] = "ì„±ê³µ"
                
            except Exception as e:
                print(f"   âŒ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                results[model_name] = f"ì‹¤íŒ¨: {str(e)}"
        
    except ImportError as e:
        print(f"âŒ sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ: {e}")
        return {"sentence-transformers": f"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜: {e}"}
    
    return results

def test_subprocess_mode():
    """Subprocess ëª¨ë“œì—ì„œ sentence-transformers í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 50)
    print("ğŸ”„ Subprocess ëª¨ë“œ SentenceTransformers í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # sentence_transformer_singleton ì‚¬ìš© í…ŒìŠ¤íŠ¸
        from sentence_transformer_singleton import get_sentence_transformer
        
        print("ğŸ”„ sentence_transformer_singletonì„ í†µí•œ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸...")
        
        # ë‹¤êµ­ì–´ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
        print(f"   í…ŒìŠ¤íŠ¸ ëª¨ë¸: {model_name}")
        
        start_time = time.time()
        model = get_sentence_transformer(model_name)
        
        # ê°„ë‹¨í•œ ì¸ì½”ë”© í…ŒìŠ¤íŠ¸
        result = model.encode(["í…ŒìŠ¤íŠ¸ ë¬¸ì¥", "Test sentence"])
        elapsed = time.time() - start_time
        
        print(f"   âœ… Subprocess ëª¨ë“œ ì„±ê³µ")
        print(f"      ğŸ“Š ì„ë² ë”© í˜•íƒœ: {result.shape if hasattr(result, 'shape') else type(result)}")
        print(f"   â±ï¸ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
        
        return "ì„±ê³µ"
        
    except Exception as e:
        print(f"   âŒ Subprocess ëª¨ë“œ ì‹¤íŒ¨: {str(e)}")
        logger.error(f"Subprocess ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return f"ì‹¤íŒ¨: {str(e)}"

def main():
    """ë©”ì¸ ê²€ì¦ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ” Red Heart AI ëª¨ë¸ ìºì‹œ ìƒíƒœ ê²€ì¦")
    print("=" * 60)
    
    # 1. ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •
    print("\nğŸ”’ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •:")
    setup_offline_mode()
    
    # 2. ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸
    check_cache_directories()
    
    # 3. Transformers ëª¨ë¸ í…ŒìŠ¤íŠ¸
    transformers_results = test_transformers_models()
    
    # 4. SentenceTransformers ëª¨ë¸ í…ŒìŠ¤íŠ¸
    sentence_results = test_sentence_transformers()
    
    # 5. Subprocess ëª¨ë“œ í…ŒìŠ¤íŠ¸
    subprocess_result = test_subprocess_mode()
    
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    print("\nğŸ¤– Transformers ëª¨ë¸:")
    for model, result in transformers_results.items():
        status = "âœ…" if result == "ì„±ê³µ" else "âŒ"
        print(f"   {status} {model.split('/')[-1]}: {result}")
    
    print("\nğŸ”¤ SentenceTransformers ëª¨ë¸:")
    for model, result in sentence_results.items():
        status = "âœ…" if result == "ì„±ê³µ" else "âŒ"
        model_short = model.split('/')[-1]
        print(f"   {status} {model_short}: {result}")
    
    print(f"\nğŸ”„ Subprocess ëª¨ë“œ: {'âœ…' if subprocess_result == 'ì„±ê³µ' else 'âŒ'} {subprocess_result}")
    
    # ì „ì²´ ì„±ê³µ ì—¬ë¶€ íŒë‹¨
    all_transformers_ok = all(r == "ì„±ê³µ" for r in transformers_results.values())
    all_sentence_ok = all(r == "ì„±ê³µ" for r in sentence_results.values())
    subprocess_ok = subprocess_result == "ì„±ê³µ"
    
    if all_transformers_ok and all_sentence_ok and subprocess_ok:
        print("\nğŸ‰ ëª¨ë“  ëª¨ë¸ì´ ì˜¤í”„ë¼ì¸ì—ì„œ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!")
        print("   unified-test ì‹¤í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return 0
    else:
        print("\nâš ï¸ ì¼ë¶€ ëª¨ë¸ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        print("   ë¬¸ì œ í•´ê²° í›„ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)