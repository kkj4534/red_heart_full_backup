#!/usr/bin/env python3
"""
_tokenize ë©”ì„œë“œ ë””ë²„ê¹…
"""

import sys
import torch
import logging
import asyncio
sys.path.append('/mnt/c/large_project/linux_red_heart')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s'
)

from main_unified import UnifiedInferenceSystem, InferenceConfig, MemoryMode

async def debug_tokenize():
    """_tokenize ë©”ì„œë“œ ë””ë²„ê¹…"""
    print("="*60)
    print("ğŸ” _tokenize ë©”ì„œë“œ ë””ë²„ê¹…")
    print("="*60)
    
    # ì„¤ì •
    config = InferenceConfig(
        memory_mode=MemoryMode.LIGHT,
        auto_memory_mode=False,
        device='cuda' if torch.cuda.is_available() else 'cpu',
        verbose=True
    )
    
    print("\n1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
    system = UnifiedInferenceSystem(config)
    await system.initialize()
    
    print("\n2. _tokenize ë©”ì„œë“œ ì§ì ‘ í˜¸ì¶œ...")
    text = "ì¹œêµ¬ê°€ ì–´ë ¤ìš´ ìƒí™©ì— ì²˜í–ˆì„ ë•Œ ì–´ë–»ê²Œ ë„ì™€ì•¼ í• ê¹Œ?"
    print(f"   ì…ë ¥ í…ìŠ¤íŠ¸: '{text}'")
    print(f"   ë‹¨ì–´ ìˆ˜: {len(text.split())}")
    
    # _tokenize ì§ì ‘ í˜¸ì¶œ
    inputs = system._tokenize(text)
    
    print(f"\n3. _tokenize ê²°ê³¼:")
    for key, value in inputs.items():
        if isinstance(value, torch.Tensor):
            print(f"   - {key}: shape={value.shape}, dtype={value.dtype}")
            print(f"     ì²« 5ê°œ ê°’: {value.flatten()[:5].tolist()}")
        else:
            print(f"   - {key}: {value}")
    
    print("\n4. UnifiedModel í˜¸ì¶œ í…ŒìŠ¤íŠ¸...")
    try:
        with torch.no_grad():
            outputs = system.unified_model(
                x=inputs['embeddings'],
                task='emotion',
                return_all=True
            )
        print("   âœ… UnifiedModel í˜¸ì¶œ ì„±ê³µ!")
        print(f"   ì¶œë ¥ í‚¤: {outputs.keys() if isinstance(outputs, dict) else type(outputs)}")
    except Exception as e:
        print(f"   âŒ UnifiedModel í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*60)
    print("âœ… ë””ë²„ê¹… ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(debug_tokenize())