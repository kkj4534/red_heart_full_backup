## 3. 연구 방법 및 내용

### 3.1 시스템 설계의 현실적 제약과 결정

#### 3.1.1 730M 파라미터 규모 결정 과정

730M이라는 숫자는 거창한 실험의 결과가 아니다. 500M-800M 범위면 8GB GPU에서 어떻게든 돌릴 수 있을 것으로 추정했고, 그 중간값 정도를 선택한 것이다. 더 큰 모델은 메모리 부족으로 실행조차 안 되고, 더 작은 모델은 성능이 너무 떨어질 것 같았다.

실제로 8GB VRAM 제약을 고려한 이유는 두 가지다. 첫째, 클라우드 GPU는 시간당 비용이 비싸서 실험 중 문제가 생기면 금전적 리스크가 크다. 둘째, 최종적으로는 로컬에서도 돌릴 수 있어야 실용성이 있다. 대부분의 개인이나 소규모 연구실이 보유한 GPU가 RTX 3070/4060 수준(8GB)이기 때문이다.

#### 3.1.2 모듈별 파라미터 할당의 실제 이유

**백본 (90.6M)**: 작게 잡은 이유는 단순하다. 백본은 임베딩을 변환하는 역할이라 크게 복잡한 처리가 필요 없다고 판단했다. BERT 임베딩(768차원)을 내부 표현(896차원)으로 바꾸는 정도면 충분하다.

**헤드 모듈 (각 38.3M)**: 솔직히 정밀하게 계산한 건 아니다. 4개 헤드에 150M 정도 할당하고 균등 분배했다. 헤드는 그저 데이터를 다음 단계로 넘기는 라우터 역할이라 크기가 성능에 미치는 영향이 적을 것으로 봤다.

**Neural Analyzers (368M)**: 전체의 절반을 차지하는데, 이건 의도적이다. 여기가 실제 "학습"이 일어나는 핵심이다. 딥러닝의 특성상 파라미터가 많아야 복잡한 패턴을 학습할 수 있다. 특히 윤리적 판단같은 추상적 개념은 더욱 그렇다.

**Advanced Wrappers (112M)**: 사실 처음 설계에는 없었다. 구현하다 보니 Neural Analyzer 출력이 너무 raw해서 후처리가 필요했고, 급하게 추가한 것이다. 그래서 "Advanced"라는 거창한 이름과 달리 실제로는 후처리 레이어에 가깝다.

**EmotionDSP (2.3M)**: 작은 이유는 학습할 게 거의 없기 때문이다. 주파수 매핑(50-350Hz)이나 ADSR 엔벨로프는 음향공학에서 가져온 수식이라 파라미터로 학습하는 게 아니다. 그저 감정을 음파처럼 모델링하면 시간적 변화를 추적하기 쉬울 것 같아서 시도한 휴리스틱 접근이다.

#### 3.1.3 3단계 처리 구조의 실용적 의도

시스템은 실제로 3단계 처리 구조를 갖는다:

**1단계 - 헤드 (빠르지만 부정확)**
응답 시간이 중요한 경우를 위한 빠른 경로다. 정확도는 떨어지지만 100ms 이내에 결과를 낼 수 있다. 프로토타입이나 데모에서 쓸 수 있다.

**2단계 - Neural Analyzer (정확하지만 불투명)**
실제 학습이 일어나는 곳이다. 블랙박스지만 데이터 특성을 가장 잘 포착한다. SCRUPLES 데이터셋의 복잡한 윤리적 뉘앙스를 학습하려면 이런 딥러닝 접근이 필수다.

**3단계 - Advanced Analyzer (투명하지만 복잡)**
해석 가능성을 위한 레이어다. 벤담의 10차원 변수처럼 명시적으로 추적 가능한 계산을 수행한다. 의료나 법률 분야처럼 "왜"를 설명해야 하는 경우에 필요하다.

#### 3.1.4 Claude API 사용의 현실적 이유

데이터 라벨링에 Claude 3.5 API를 쓴 건 순전히 비용 때문이다. 사람이 10,000개 샘플을 라벨링하면:
- 샘플당 5분 × 10,000개 = 833시간
- 시급 15,000원 기준 = 1,250만원

Claude API는:
- 샘플당 0.002달러 × 10,000개 = 20달러 (약 2.6만원)
- Prompt Caching으로 90% 절감 = 실제 2,600원

품질은 사람보다 떨어지지만(temperature 때문에 일관성도 완벽하지 않음), MVP에는 충분하다. 중~중상 정도 품질이면 프로토타입 학습에는 문제없다.

#### 3.1.5 ModuleBridgeCoordinator의 진짜 목적

비동기 처리가 주목적처럼 보이지만, 실제로는 OOM(Out of Memory) 방지가 핵심이다. 

8GB VRAM은 생각보다 작다. 모든 모듈을 동시에 로드하면 메모리가 터진다. ModuleBridgeCoordinator는:
1. 메모리 사용량을 실시간 모니터링
2. 85% 넘으면 비의존적 모듈들을 언로드
3. 순차 처리로 전환하여 메모리 스왑
4. OOM 없이 전체 파이프라인 완주

속도는 느려지지만 적어도 실행은 된다. 이게 없으면 8GB GPU에서는 학습조차 못 한다.

---

이제 3.1을 현실적으로 다시 썼습니다. 미화 없이 실제 의도와 제약을 솔직하게 설명했습니다. 

다음 섹션도 이 톤으로 진행할까요?