# Red Heart AI 320M 파라미터 정밀 배분 계획

## 📊 현재 모듈별 실제 파라미터 분석

### 기존 구현된 모듈들의 실제 크기:
| 모듈 | 현재 크기 | 주요 구성 | 핵심 기능 |
|------|-----------|-----------|-----------|
| `advanced_emotion_analyzer.py` | ~5M | MoE 4전문가, LSTM(128,64), KcELECTRA | 다국어 감정 분석 |
| `advanced_bentham_calculator.py` | ~2.5M | Linear(50→256→256→128→64→6), MoE 4윤리전문가 | 공리주의 3.0 |
| `advanced_regret_analyzer.py` | ~3M | Linear(768→512→256→64→1) × 3네트워크 | GPU 가속 후회 |
| `advanced_surd_analyzer.py` | ~2M | Linear(768→128→64→32) + 3헤드 | 인과관계 분석 |
| `emotion_dsp_simulator.py` | ~1.18M | Conv1d + Linear 복합 구조, hidden_dim=256 | DSP 감정 시뮬레이션 |

**현재 총합**: ~13.68M (목표 320M의 4.3%)

---

## 🎯 320M 정밀 재배분 계획

### 1. **공유 백본 (40M - 12.5%)**
```python
class RedHeartUnifiedBackbone:
    # 입력 임베딩 레이어
    - input_projection: Linear(768 → 1024) = 0.79M
    
    # 트랜스포머 인코더 (6층)
    - transformer_layers × 6:
        * self_attention(1024, 16heads) = 4.2M × 6 = 25.2M
        * feedforward(1024 → 4096 → 1024) = 8.4M × 6 = 50.4M
        * layer_norm × 2 = 0.004M × 6 = 0.024M
    
    # 태스크 분기 프로젝션
    - emotion_proj: Linear(1024 → 768) = 0.79M
    - bentham_proj: Linear(1024 → 768) = 0.79M
    - regret_proj: Linear(1024 → 768) = 0.79M
    - surd_proj: Linear(1024 → 768) = 0.79M
    
    총합: 40M (실제로는 너무 큼, 조정 필요)
```

**조정된 백본 (40M)**:
```python
- input_projection: Linear(768 → 512) = 0.39M
- transformer_layers × 4:
    * self_attention(512, 8heads) = 1.05M × 4 = 4.2M
    * feedforward(512 → 2048 → 512) = 2.1M × 4 = 8.4M
- task_projections × 4: Linear(512 → 384) = 0.79M
총합: ~15M (효율적)
```

### 2. **태스크별 전문 헤드 (180M - 56.3%)**

#### 감정 헤드 (50M)
```python
- base_emotion: 기존 5M 유지
- deep_emotion_layers × 6:
    * Linear(384 → 768 → 384) = 0.59M × 6 = 3.5M
- MoE expansion (8 experts): 
    * expert_networks × 8: Linear(384 → 256 → 7) = 0.8M × 8 = 6.4M
- cultural_adaptation:
    * korean_emotion: Linear(384 → 256 → 3) = 0.2M (정/한/체면)
- hierarchical_phases × 3:
    * phase_networks: Linear(384 → 256 → 128 → 7) = 0.4M × 3 = 1.2M
- attention_layers × 4:
    * multi_head_attention(384, 8heads) = 0.59M × 4 = 2.36M
총합: ~45M
```

#### 벤담 헤드 (45M)
```python
- base_bentham: 기존 2.5M 유지
- ethical_reasoning × 6층:
    * Linear(384 → 512 → 384) = 0.59M × 6 = 3.5M
- MoE ethics (공리주의/의무론/덕윤리/돌봄윤리):
    * expert × 4: Linear(384 → 512 → 256 → 10) = 1.2M × 4 = 4.8M
- cultural_weights × 6:
    * weight_layers: Linear(384 → 256 → 6) = 0.2M × 6 = 1.2M
- legal_risk_assessment × 5도메인:
    * domain_networks: Linear(384 → 128 → 1) = 0.1M × 5 = 0.5M
- temporal_analysis:
    * LSTM(384, 256) × 2layers = 1.8M
총합: ~42M
```

#### 후회 헤드 (45M)
```python
- base_regret: 기존 3M 유지
- deep_regret_layers × 6:
    * Linear(384 → 512 → 384) = 0.59M × 6 = 3.5M
- scenario_networks × 3 (낙관/중도/비관):
    * scenario: Linear(384 → 512 → 256 → 1) = 1M × 3 = 3M
- counterfactual_reasoning:
    * GRU(384, 256) × 2layers = 1.5M
    * attention(256, 8heads) = 0.52M
- uncertainty_quantification:
    * dropout_networks × 5: Linear(384 → 256 → 1) = 0.2M × 5 = 1M
- temporal_propagation:
    * LSTM(384, 256) × 2layers = 1.8M
총합: ~42M
```

#### SURD 헤드 (40M)
```python
- base_surd: 기존 2M 유지
- causal_inference × 4층:
    * Linear(384 → 512 → 384) = 0.59M × 4 = 2.36M
- information_decomposition:
    * PID_networks × 4: Linear(384 → 256 → 64) = 0.3M × 4 = 1.2M
- graph_neural_network:
    * GCN layers × 3: 0.8M × 3 = 2.4M
- mutual_info_estimation:
    * kraskov_networks × 3: Linear(384 → 256 → 128 → 1) = 0.4M × 3 = 1.2M
- attention_mechanism:
    * self_attention(384, 8heads) × 2 = 1.18M
총합: ~38M

**헤드 총합**: 45 + 42 + 42 + 38 = 167M

### 3. **고급 분석기 강화 (90M - 28.1%)**

#### 감정 분석기 강화 (25M)
- 기존 5M 구조 유지
- 생체신호 처리 네트워크 추가: 5M
- 멀티모달 융합 레이어: 5M  
- 시계열 감정 추적: 5M
- 문화적 뉘앙스 감지: 5M

#### 벤담 분석기 강화 (25M)
- 기존 2.5M 구조 유지
- 심층 윤리 추론 네트워크: 7M
- 사회적 영향 평가: 5M
- 장기적 결과 예측: 5M
- 문화간 윤리 비교: 5.5M

#### 후회 분석기 강화 (25M)
- 기존 3M 구조 유지
- 반사실적 시뮬레이션: 7M
- 시간축 후회 전파: 5M
- 의사결정 트리 분석: 5M
- 베이지안 후회 추론: 5M

#### SURD 분석기 강화 (15M)
- 기존 2M 구조 유지
- 심층 인과 추론: 5M
- 정보이론 분해: 4M
- 네트워크 효과 분석: 4M

**분석기 총합**: 25 + 25 + 25 + 15 = 90M

### 4. **보조 모듈 (10M - 3.1%)**
- DSP 시뮬레이터: 8M (강화)
- 칼만 필터: 2M

---

## 📈 최종 배분 요약

| 구성요소 | 파라미터 | 비율 | 역할 |
|----------|----------|------|------|
| **공유 백본** | 15M | 4.7% | 공통 특징 추출 |
| **태스크 헤드** | 167M | 52.2% | 태스크별 특화 학습 |
| **고급 분석기** | 90M | 28.1% | 심층 분석 및 추론 |
| **보조 모듈** | 10M | 3.1% | 신호처리 및 필터링 |
| **예비** | 38M | 11.9% | 추가 확장 여유 |
| **총합** | 320M | 100% | |

## 💡 핵심 설계 원칙

1. **백본 최소화 (15M)**: 과도한 공유 표현보다 태스크별 특화 중시
2. **헤드 극대화 (167M)**: 각 태스크의 전문성과 정확도 최우선
3. **분석기 강화 (90M)**: 기존 모듈 재사용하며 심층 기능 추가
4. **균형잡힌 배분**: 감정/벤담/후회는 균등, SURD는 약간 적게

## 🔧 구현 우선순위

1. **Phase 1**: unified_backbone.py 생성 (15M)
2. **Phase 2**: 4개 헤드 구현 (167M)
3. **Phase 3**: 분석기 강화 레이어 추가 (90M)
4. **Phase 4**: 통합 및 최적화