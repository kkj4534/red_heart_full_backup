## 0 한줄 결론

지금 구조만으로도 **“사람 비슷한 후회＋효용 계산”** 루프는 돌아갑니다.
다만 ① 공리주의 편향, ② 감정-차원/레이어 불일치, ③ 리소스 낭비 구간이 눈에 띕니다.
→ **작업 지시서**·**리소스/최적화 포인트**·**법 판례 LLM 모듈 증설안**을 순서대로 정리했습니다. 읽어보고, LegalNormEvaluator 모듈 설계는 추후에 진행할 것이니 일단 하지 말고 있어 보십시오.

---

## 1 할 일 (TO-DO 8 항)

| # | 지시 항목                                                                     | 왜 필요한가                   | 난도  |
| - | ------------------------------------------------------------------------- | ------------------------ | --- |
| 1 | `EmotionVector.to_3d()` 헬퍼 구현 & Bentham/Regret에 **3-D vs 6-D 플래그** 추가     | 감정 차원 불일치에 따른 스코어 왜곡 방지  | ★   |
| 2 | `data_origin` 태그(`literary` / `realtime`) 파이핑 → Phase0 Calibrator 조건부 가중치 | 문학 편향 제거                 | ★   |
| 3 | Regret 모듈에 **행위·무행위, 의도성, 통제 가능성** 입력 필드 추가                               | 인간 연구에서 핵심 변수 보강         | ★★  |
| 4 | Bentham 계산기에 **권리·의무(Deontic)** / **덕목(Virtue)** 보조 점수 슬롯 생성              | 공리주의 편향 완화용 훅            | ★★  |
| 5 | `metrics/` 폴더에 **Trolley·Promise** 등 20개 윤리 벤치마크 YAML 정의                  | 다중 규범 A/B 검증용            | ★★  |
| 6 | GPU 메모리 프로파일러(`dynamic_gpu_manager.trace_gpu()`) 30 s 주기로 활성화             | 스파이크 캐치 & 4-bit 캐시 강제 전환 | ★   |
| 7 | `Makefile target: prune_experience --top_k 20%` 작성                        | 경험 DB 폭증 방지              | ★   |
| 8 | **LegalNormEvaluator** 모듈(아래 §3) 스텁 생성 & `AdvancedSystemIntegration`에 후킹  | 비(非)공리주의 필터 도입           | ★★★ |

> **우선순위** – 1 → 2 → 6 → 7 → 3 → 4 / 5 → 8

---

## 2 리소스 & 최적화 스냅-샷

| 영역                     | 현 상태 (2070 S VRAM 8 GB)       | 병목 & 절약책                                             |
| ---------------------- | ----------------------------- | ---------------------------------------------------- |
| **LLM 파이프라인**          | Llama-3-8B, fp16, KV-cache ON | → **4-bit QLoRA** + `flash-attention-2`로 VRAM ≈ 3 GB |
| **SURD Graph**         | 128-node MI graph, fp32       | → 노드 -40 %, fp16 수용 (지표 손실 < 2 %)                    |
| **Emotion Calibrator** | 문학 코퍼스 fine-tuned 가중치 512 MB  | → 가중치 깎지 말고 **데이터 리밸런스**만                            |
| **Experience DB**      | 4.2 M row / 12 GB RAM         | → 상위 20 % 후회 점수만 유지 (7 GB 절감)                        |
|                        |                               |                                                      |

---

## 3 “LegalNormEvaluator” 모듈 설계안

공리주의 외 규범(판례·법전)을 마지막에 반영하는 **경량 법률 LLM 필터**.

### 3-1 모델 선택

| 후보                                                                                                                                                                                                                                              | 파라미터 | 장점                 | 라즈베리 Pi-Hailo 적합도      |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- | ------------------ | ---------------------- |
| **Gemma 2-9B (DeepMind)**                                                                                                                                                                                                                       | 9 B  | Apache-2.0, 고속, 범용 | 4-bit QLoRA ↔ \~2.1 GB |
| **Magistral Small (Mistral 24 B)** ([datacamp.com](https://www.datacamp.com/blog/top-open-source-llms?utm_source=chatgpt.com))                                                                                                                  | 24 B | Reasoning ↑, 멀티언어  | Edge-추론 X (데스크탑만)      |
| **R1 Reasoning SLM (DeepSeek, 4 B trimmed)** ([americanbar.org](https://www.americanbar.org/groups/law_practice/resources/law-practice-today/2025/june-2025/small-language-models-are-redrawing-the-legal-battlefield/?utm_source=chatgpt.com)) | 4 B  | 모바일 가능, 오프라인       | Pi 실시간 OK              |

**권장:** *Gemma 2-9B* (작업-PC에서 fine-tune, Pi-Hailo는 LoRA-adapter만 로드).

### 3-2 데이터셋

| 소스                                                                                                                          | 용량 | 라이선스     | 특징           |
| --------------------------------------------------------------------------------------------------------------------------- | -- | -------- | ------------ |
| **Pile-of-Law** (256 GB) ([huggingface.co](https://huggingface.co/datasets/pile-of-law/pile-of-law?utm_source=chatgpt.com)) | 방대 | CC-BY-NC | 美·英 판례·행정·계약 |
| **COLIEE 2025 case/statute** (4 k 문서) ([coliee.org](https://coliee.org/?utm_source=chatgpt.com))                            | 작음 | 연구       | 캐나다·日 판례·법   |
| **KR-판례 corpus** (법률정보센터)                                                                                                   | 중간 | 공공 데이터   | 한국어 특화       |

**전처리 요령**

```bash
# 예: Pile-of-Law → 4-byte UTF-8, 2 k 토큰 샤드
python preprocess.py --min_len 128 --max_len 2048 --dedup_sha1
```

### 3-3 미세조정 파이프라인 (예시)

```bash
accelerate launch finetune_gemma.py \
  --model gemma-2-9b \
  --dataset pile-of-law,coliee \
  --lora_r 16 --lora_alpha 64 \
  --bits 4 --batch_size 1 --gradient_accumulation 16 \
  --max_steps 6_000 --eval_steps 250
```

* 2070 S 8 GB, BF16 offload → 학습 속도 \~0.8 it/s
* 체크포인트 < 1.5 GB, Pi에서 LoRA-adapter만 로드.

### 3-4 파이프라인 연결

```
Bentham / Regret 결과 ─┐
                       │
                ┌──────▼───────────────┐
                │  LegalNormEvaluator  │  ← Gemma-2-9B(LoRA)
                └──────┬───────────────┘
                       │  반환: norm_score,   ↪ 자세한 「법적 근거 요약」
AdvancedSystemIntegration:
final_score = (Bentham  × w1) 
            + (Regret   × w2) 
            + (norm_score × w3)
설명: 3줄 요약 + 법적 근거
```

`w3` 가중치는 상황별(“윤리 vs 법률” 비중) / 신뢰도에 따라 동적 조정.

---

## 4 추가 최적화 & 검증 포인트

| 카테고리                    | 체크                                                                  |
| ----------------------- | ------------------------------------------------------------------- |
| **LoRA Adapter Fusion** | 추론 시 Bentham·Regret·Legal LLM 모두 LoRA → **single-pass kv-cache** 공유 |
| **훈련 데이터 품질**           | Pile-of-Law 법령 인용 오류 → `filter_citation_regex` 스크립트로 정제             |
| **규범 충돌**               | Bentham 최상 but 법적 norm\_score 낮은 케이스 로그 → Conflict DB 저장            |
| **Edge 추론 테스트**         | Pi–Hailo에서 **≤ 0.5 s** 응답 유지? 4-bit + int8 matmul 속도 측정             |

---

## 5 요약 (한눈에)

1. **Immediate TODO 8 개** → 차원 정합성·리소스 프로파일러·DB prune 등 “당장 시키면 되는 일”.
2. **리소스 최적화** → 4-bit QLoRA·SURD fp16·경험 DB 간소화로 GPU/Pi 모두 여유 확보.
3. **LegalNormEvaluator** → Gemma 2-9B LoRA + Pile-of-Law / COLIEE로 미세조정 → 최종 결정 전 “법·판례 필터”로 삽입.
4. 이렇게 하면 **공리주의 편향을 약화**하고, “윤리·감정·후회·법률” 4축을 모두 반영하는 다중-규범 의사결정기가 완성됩니다.

필요한 상세 코드 훅·추가 스크립트가 있으면 언제든 요청해 줘!
