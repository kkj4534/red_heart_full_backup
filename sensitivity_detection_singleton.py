"""
ë¯¼ê°ì„± ê°ì§€ ë° ì¤‘ë¦½í™” ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ë§¤ë‹ˆì €
Sensitivity Detection and Neutralization System Singleton Manager

HelpingAI ì•ˆì „ í•„í„° íŠ¸ë¦¬ê±° ìƒí™© ëŒ€ì‘ìš© íŠ¹í™” ì‹œìŠ¤í…œ
- ë¯¼ê°ì„± ê°ì§€ LLM (ê°€ë²¼ìš´ ëª¨ë¸)
- ì¤‘ë¦½í™” ë³€í™˜ LLM 
- ë©”ëª¨ë¦¬ ìµœì í™” ë° ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë³´ì¥
"""

import os
import logging
import asyncio
import threading
import time
from typing import Dict, Optional, Any, List, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
from config import MODELS_DIR, get_device

logger = logging.getLogger(__name__)

@dataclass
class SensitivityResult:
    """ë¯¼ê°ì„± ê°ì§€ ê²°ê³¼"""
    is_sensitive: bool
    confidence: float
    detected_keywords: List[str]
    reasoning: str

@dataclass
class NeutralizationResult:
    """ì¤‘ë¦½í™” ë³€í™˜ ê²°ê³¼"""
    original_text: str
    neutralized_text: str
    transformations: Dict[str, str]  # ì›ë³¸ í‚¤ì›Œë“œ -> ë³€í™˜ëœ í‚¤ì›Œë“œ
    confidence: float

class SensitivityDetectionManager:
    """
    ë¯¼ê°ì„± ê°ì§€ ë° ì¤‘ë¦½í™” ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ê´€ë¦¬ì
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ LLM ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
    - ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë³´ì¥
    - GPU ë¦¬ì†ŒìŠ¤ ìµœì í™”
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if hasattr(self, '_initialized'):
            return
        
        self._initialized = True
        self._models: Dict[str, Any] = {}
        self._model_locks: Dict[str, threading.Lock] = {}
        self.device = get_device()
        
        # ë¯¼ê°ì„± ê°ì§€ìš© í‚¤ì›Œë“œ íŒ¨í„´
        self.sensitive_patterns = {
            'political': ['í…ŒëŸ¬', 'ê°ì‹œ', 'ì •ì¹˜', 'ì •ë¶€', 'êµ­ê°€ê¸°ê´€'],
            'security': ['ë³´ì•ˆ', 'ê°œì¸ì •ë³´', 'ìˆ˜ì§‘', 'ëª¨ë‹ˆí„°ë§', 'ì¶”ì '],
            'surveillance': ['ê°ì‹œ', 'ë„ì²­', 'ì¶”ì ', 'ìŠ¤íŒŒì´', 'ì •ë³´ìˆ˜ì§‘'],
            'violence': ['í­ë ¥', 'ë¬´ë ¥', 'ê³µê²©', 'ìœ„í˜‘', 'í•´í‚¹'],
            'ethical_dilemma': ['ë”œë ˆë§ˆ', 'ê°ˆë“±', 'ìœ¤ë¦¬ì ', 'ë„ë•ì ', 'ê°€ì¹˜ê´€']
        }
        
        # ì¤‘ë¦½í™” ë³€í™˜ ë§¤í•‘
        self.neutralization_mapping = {
            'í…ŒëŸ¬': 'ë¹„ìƒìƒí™©',
            'í…ŒëŸ¬ ë°©ì§€': 'ê³µê³µ ì•ˆì „ í™•ë³´', 
            'ê°ì‹œ': 'ëª¨ë‹ˆí„°ë§',
            'ê°œì¸ì •ë³´ ìˆ˜ì§‘': 'ë°ì´í„° ìˆ˜ì§‘',
            'ê°œì¸ì •ë³´': 'ê°œì¸ ë°ì´í„°',
            'ì‹œë¯¼ ê°ì‹œ': 'ì‹œë¯¼ ëª¨ë‹ˆí„°ë§',
            'ì •ë¶€ ê°ì‹œ': 'ê³µê³µ ëª¨ë‹ˆí„°ë§',
            'í”„ë¼ì´ë²„ì‹œ ì¹¨í•´': 'ê°œì¸ì •ë³´ ë³´í˜¸ ì´ìŠˆ',
            'ê°ì‹œ ì²´ê³„': 'ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ',
            'ë³´ì•ˆ ìœ„í˜‘': 'ì•ˆì „ ìš°ë ¤ì‚¬í•­'
        }
        
        logger.info("SensitivityDetectionManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _get_lightweight_model(self, model_type: str = "sensitivity"):
        """ê°€ë²¼ìš´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
        model_key = f"{model_type}_{self.device}"
        
        if model_key in self._models:
            return self._models[model_key]
        
        if model_key not in self._model_locks:
            self._model_locks[model_key] = threading.Lock()
        
        with self._model_locks[model_key]:
            if model_key in self._models:
                return self._models[model_key]
            
            try:
                if model_type == "sensitivity":
                    # ë¯¼ê°ì„± ê°ì§€ìš© - ê°€ë²¼ìš´ multilingual ëª¨ë¸ ì‚¬ìš©
                    from sentence_transformers import SentenceTransformer
                    model = SentenceTransformer(
                        'paraphrase-multilingual-mpnet-base-v2',
                        device=str(self.device)
                    )
                    logger.info(f"ë¯¼ê°ì„± ê°ì§€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_key}")
                    
                elif model_type == "neutralization":
                    # ì¤‘ë¦½í™”ìš© - ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œ (LLM ëŒ€ì‹ )
                    model = "rule_based_neutralizer"
                    logger.info(f"ì¤‘ë¦½í™” ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ: {model_key}")
                
                self._models[model_key] = model
                return model
                
            except Exception as e:
                logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_key}, ì˜¤ë¥˜: {e}")
                raise RuntimeError(f"ë¯¼ê°ì„± ê°ì§€ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_type}") from e
    
    def detect_sensitivity_keywords(self, text: str) -> SensitivityResult:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë¯¼ê°ì„± ê°ì§€ (ë¹ ë¥¸ 1ì°¨ ê²€ì‚¬)"""
        try:
            detected_keywords = []
            confidence_scores = []
            
            text_lower = text.lower()
            
            for category, keywords in self.sensitive_patterns.items():
                for keyword in keywords:
                    if keyword in text_lower:
                        detected_keywords.append(keyword)
                        # í‚¤ì›Œë“œ ì¤‘ìš”ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
                        if category in ['political', 'security']:
                            confidence_scores.append(0.9)
                        elif category in ['surveillance', 'violence']:
                            confidence_scores.append(0.8)
                        else:
                            confidence_scores.append(0.6)
            
            is_sensitive = len(detected_keywords) > 0
            confidence = max(confidence_scores) if confidence_scores else 0.0
            
            reasoning = f"í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì§€: {detected_keywords}" if detected_keywords else "ë¯¼ê° í‚¤ì›Œë“œ ë¯¸ê°ì§€"
            
            return SensitivityResult(
                is_sensitive=is_sensitive,
                confidence=confidence,
                detected_keywords=detected_keywords,
                reasoning=reasoning
            )
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ê¸°ë°˜ ë¯¼ê°ì„± ê°ì§€ ì‹¤íŒ¨: {e}")
            return SensitivityResult(
                is_sensitive=False,
                confidence=0.0,
                detected_keywords=[],
                reasoning=f"ê°ì§€ ì‹¤íŒ¨: {str(e)}"
            )
    
    def detect_sensitivity_semantic(self, text: str) -> SensitivityResult:
        """ì˜ë¯¸ ê¸°ë°˜ ë¯¼ê°ì„± ê°ì§€ (ì •í™•í•œ 2ì°¨ ê²€ì‚¬)"""
        try:
            # 1ì°¨ í‚¤ì›Œë“œ ê²€ì‚¬ ê²°ê³¼ í™œìš©
            keyword_result = self.detect_sensitivity_keywords(text)
            
            if keyword_result.is_sensitive and keyword_result.confidence > 0.7:
                # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ ë†’ì€ ì‹ ë¢°ë„ë¡œ ê°ì§€ë¨
                return keyword_result
            
            # ì˜ë¯¸ì  ë¶„ì„ (í˜„ì¬ëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ + íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ëŒ€ì²´)
            # í–¥í›„ í•„ìš”ì‹œ sentence transformer í™œìš© ê°€ëŠ¥
            
            # ë³µí•© ë¬¸ì¥ íŒ¨í„´ ê²€ì‚¬
            complex_patterns = [
                'ìœ¤ë¦¬ì  ë”œë ˆë§ˆ', 'ë„ë•ì  ê°ˆë“±', 'ê°€ì¹˜ê´€ ì¶©ëŒ',
                'ê°œì¸ vs ê³µê³µ', 'ììœ  vs ì•ˆì „', 'vs', 'ëŒ€'
            ]
            
            additional_keywords = []
            for pattern in complex_patterns:
                if pattern in text:
                    additional_keywords.append(pattern)
            
            # ìµœì¢… ê²°ê³¼ í†µí•©
            all_keywords = keyword_result.detected_keywords + additional_keywords
            is_sensitive = len(all_keywords) > 0
            confidence = min(keyword_result.confidence + 0.1 * len(additional_keywords), 1.0)
            
            return SensitivityResult(
                is_sensitive=is_sensitive,
                confidence=confidence,
                detected_keywords=all_keywords,
                reasoning=f"ì˜ë¯¸ì  ë¶„ì„ ì™„ë£Œ: í‚¤ì›Œë“œ({len(keyword_result.detected_keywords)}) + íŒ¨í„´({len(additional_keywords)})"
            )
            
        except Exception as e:
            logger.error(f"ì˜ë¯¸ ê¸°ë°˜ ë¯¼ê°ì„± ê°ì§€ ì‹¤íŒ¨: {e}")
            # fallback to keyword result
            return keyword_result if 'keyword_result' in locals() else SensitivityResult(
                is_sensitive=False, confidence=0.0, detected_keywords=[], reasoning=f"ì˜ë¯¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            )
    
    def neutralize_text(self, text: str, sensitivity_result: SensitivityResult) -> NeutralizationResult:
        """ë¯¼ê°í•œ í…ìŠ¤íŠ¸ë¥¼ ì¤‘ë¦½ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""
        try:
            if not sensitivity_result.is_sensitive:
                # ë¯¼ê°í•˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ë°˜í™˜
                return NeutralizationResult(
                    original_text=text,
                    neutralized_text=text,
                    transformations={},
                    confidence=1.0
                )
            
            neutralized_text = text
            transformations = {}
            
            # ê·œì¹™ ê¸°ë°˜ ì¤‘ë¦½í™” ë³€í™˜
            for original, neutral in self.neutralization_mapping.items():
                if original in text:
                    neutralized_text = neutralized_text.replace(original, neutral)
                    transformations[original] = neutral
            
            # ì¶”ê°€ì ì¸ íŒ¨í„´ ê¸°ë°˜ ë³€í™˜
            additional_replacements = {
                'í…ŒëŸ¬ë¦¬ìŠ¤íŠ¸': 'ìœ„í—˜ ì§‘ë‹¨',
                'ê°ì‹œ ì¹´ë©”ë¼': 'ëª¨ë‹ˆí„°ë§ ì¥ë¹„',
                'ë„ì²­': 'ìŒì„± ëª¨ë‹ˆí„°ë§',
                'ì‚¬ì°°': 'ì¡°ì‚¬',
                'ì •ë³´ ìˆ˜ì§‘': 'ë°ì´í„° ìˆ˜ì§‘',
                'ë¹„ë°€ ê°ì‹œ': 'ë¹„ê³µê°œ ëª¨ë‹ˆí„°ë§'
            }
            
            for original, neutral in additional_replacements.items():
                if original in neutralized_text:
                    neutralized_text = neutralized_text.replace(original, neutral)
                    transformations[original] = neutral
            
            # ë³€í™˜ í’ˆì§ˆ í‰ê°€
            transformation_count = len(transformations)
            confidence = min(0.7 + 0.1 * transformation_count, 1.0)
            
            return NeutralizationResult(
                original_text=text,
                neutralized_text=neutralized_text,
                transformations=transformations,
                confidence=confidence
            )
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì¤‘ë¦½í™” ì‹¤íŒ¨: {e}")
            return NeutralizationResult(
                original_text=text,
                neutralized_text=text,
                transformations={},
                confidence=0.0
            )
    
    def process_sensitive_text(self, text: str) -> Tuple[bool, Optional[str], Dict[str, Any]]:
        """ë¯¼ê°í•œ í…ìŠ¤íŠ¸ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        try:
            # 1ë‹¨ê³„: ë¯¼ê°ì„± ê°ì§€
            logger.info("ğŸ” ë¯¼ê°ì„± ê°ì§€ ì‹œì‘")
            sensitivity_result = self.detect_sensitivity_semantic(text)
            
            metadata = {
                'sensitivity_detection': {
                    'is_sensitive': sensitivity_result.is_sensitive,
                    'confidence': sensitivity_result.confidence,
                    'detected_keywords': sensitivity_result.detected_keywords,
                    'reasoning': sensitivity_result.reasoning
                }
            }
            
            if not sensitivity_result.is_sensitive:
                logger.info("âœ… ë¯¼ê°ì„± ë¯¸ê°ì§€ - ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                return False, text, metadata
            
            # 2ë‹¨ê³„: ì¤‘ë¦½í™” ë³€í™˜
            logger.info(f"ğŸ”„ ë¯¼ê°ì„± ê°ì§€ë¨ (ì‹ ë¢°ë„: {sensitivity_result.confidence:.2f}) - ì¤‘ë¦½í™” ì‹œì‘")
            neutralization_result = self.neutralize_text(text, sensitivity_result)
            
            metadata['neutralization'] = {
                'transformations': neutralization_result.transformations,
                'confidence': neutralization_result.confidence
            }
            
            logger.info(f"âœ… ì¤‘ë¦½í™” ì™„ë£Œ: {len(neutralization_result.transformations)}ê°œ ë³€í™˜")
            for original, neutral in neutralization_result.transformations.items():
                logger.info(f"   ğŸ“ '{original}' â†’ '{neutral}'")
            
            return True, neutralization_result.neutralized_text, metadata
            
        except Exception as e:
            logger.error(f"ë¯¼ê°ì„± ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return False, text, {'error': str(e)}
    
    def get_memory_usage(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´"""
        import psutil
        import torch
        
        memory_info = {
            'loaded_models': len(self._models),
            'system_memory_percent': psutil.virtual_memory().percent,
            'process_memory_mb': psutil.Process().memory_info().rss / (1024 * 1024)
        }
        
        if torch.cuda.is_available():
            memory_info['gpu_allocated_mb'] = torch.cuda.memory_allocated() / (1024 * 1024)
            memory_info['gpu_cached_mb'] = torch.cuda.memory_reserved() / (1024 * 1024)
        
        return memory_info
    
    def clear_cache(self):
        """ëª¨ë¸ ìºì‹œ ì •ë¦¬"""
        logger.info("ë¯¼ê°ì„± ê°ì§€ ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ ì‹œì‘")
        self._models.clear()
        self._model_locks.clear()
        logger.info("ë¯¼ê°ì„± ê°ì§€ ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

# ì „ì—­ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
_sensitivity_manager = SensitivityDetectionManager()

def detect_and_neutralize_sensitive_content(text: str) -> Tuple[bool, Optional[str], Dict[str, Any]]:
    """
    ë¯¼ê°í•œ ë‚´ìš© ê°ì§€ ë° ì¤‘ë¦½í™” (í¸ì˜ í•¨ìˆ˜)
    
    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        
    Returns:
        (was_sensitive, neutralized_text, metadata)
    """
    return _sensitivity_manager.process_sensitive_text(text)

def get_sensitivity_manager() -> SensitivityDetectionManager:
    """ë¯¼ê°ì„± ê°ì§€ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return _sensitivity_manager

def get_memory_info() -> Dict[str, Any]:
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´ ë°˜í™˜"""
    return _sensitivity_manager.get_memory_usage()

def clear_sensitivity_cache():
    """ë¯¼ê°ì„± ê°ì§€ ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬"""
    _sensitivity_manager.clear_cache()