"""
í†µí•© ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (Integrated System Orchestrator)
Integrated System Orchestrator Module

ëª¨ë“  í•˜ìœ„ ëª¨ë“ˆë“¤ì˜ ìœ ê¸°ì  í†µí•©ì„ ê´€ë¦¬í•˜ê³  ì‹œìŠ¤í…œ ì „ì²´ì˜ ì¡°í™”ë¡œìš´ ë™ì‘ì„ ë³´ì¥í•˜ëŠ”
ì¤‘ì•™ ì¡°ì • ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ê° ëª¨ë“ˆ ê°„ì˜ ë°ì´í„° íë¦„ê³¼ ìƒí˜¸ì‘ìš©ì„ ìµœì í™”í•©ë‹ˆë‹¤.

í•µì‹¬ ê¸°ëŠ¥:
1. ëª¨ë“ˆ ê°„ ìœ ê¸°ì  ë°ì´í„° íë¦„ ê´€ë¦¬
2. ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
3. ì ì‘ì  ëª¨ë“ˆ ê°€ì¤‘ì¹˜ ì¡°ì •
4. í†µí•© ì˜ì‚¬ê²°ì • íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
"""

import os
# CVE-2025-32434ëŠ” ê°€ì§œ CVE - torch_security_patch import ì œê±°
# import torch_security_patch

import numpy as np
import torch
import logging
import json
import time
import asyncio
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from collections import defaultdict, deque
from pathlib import Path
import threading
from concurrent.futures import ThreadPoolExecutor
import traceback

# ê¸°ì¡´ ëª¨ë“ˆë“¤ ì„í¬íŠ¸
from config import ADVANCED_CONFIG, DEVICE
from data_models import EmotionData
from emotion_ethics_regret_circuit import EmotionEthicsRegretCircuit
from ethics_policy_updater import EthicsPolicyUpdater
from phase_controller import PhaseController, PhaseDecisionContext
from xai_feedback_integrator import XAIFeedbackIntegrator
from fuzzy_emotion_ethics_mapper import FuzzyEmotionEthicsMapper
from deep_multi_dimensional_ethics_system import DeepMultiDimensionalEthicsSystem
from temporal_event_propagation_analyzer import TemporalEventPropagationAnalyzer, TemporalEvent

logger = logging.getLogger('IntegratedSystemOrchestrator')

@dataclass
class IntegrationContext:
    """í†µí•© ë§¥ë½ ì •ë³´"""
    session_id: str
    timestamp: float = field(default_factory=time.time)
    
    # ì…ë ¥ ë°ì´í„°
    user_input: str = ""
    scenario_description: str = ""
    emotional_context: Optional[EmotionData] = None
    
    # ìƒí™© ì •ë³´
    urgency_level: float = 0.5
    complexity_level: float = 0.5
    stakeholder_count: int = 1
    ethical_weight: float = 0.7
    
    # ë©”íƒ€ë°ì´í„°
    user_id: str = "default"
    cultural_context: str = "korean"
    decision_history: List[str] = field(default_factory=list)

@dataclass
class ModuleResponse:
    """ëª¨ë“ˆ ì‘ë‹µ ë°ì´í„°"""
    module_name: str
    response_data: Dict[str, Any]
    confidence: float = 0.5
    processing_time: float = 0.0
    success: bool = True
    error_message: str = ""

@dataclass
class IntegratedDecision:
    """í†µí•© ì˜ì‚¬ê²°ì • ê²°ê³¼"""
    decision_id: str
    final_recommendation: str
    confidence_score: float
    
    # ê° ëª¨ë“ˆ ê¸°ì—¬ë„
    module_contributions: Dict[str, float] = field(default_factory=dict)
    
    # ìƒì„¸ ë¶„ì„
    ethical_analysis: Dict[str, Any] = field(default_factory=dict)
    emotional_analysis: Dict[str, Any] = field(default_factory=dict)
    temporal_analysis: Dict[str, Any] = field(default_factory=dict)
    
    # ì˜ˆìƒ ê²°ê³¼
    predicted_outcomes: Dict[str, Any] = field(default_factory=dict)
    risk_assessment: Dict[str, float] = field(default_factory=dict)
    
    # ì„¤ëª… ë° ê·¼ê±°
    reasoning_chain: List[str] = field(default_factory=list)
    alternative_options: List[str] = field(default_factory=list)
    
    # ë©”íƒ€ë°ì´í„°
    processing_time: float = 0.0
    timestamp: float = field(default_factory=time.time)

class ModuleCoordinator:
    """ëª¨ë“ˆ ì¡°ì •ì"""
    
    def __init__(self):
        self.module_weights = {
            'emotion_ethics_regret': 0.25,
            'ethics_policy': 0.20,
            'phase_controller': 0.15,
            'xai_feedback': 0.15,
            'fuzzy_mapper': 0.10,
            'deep_ethics': 0.10,
            'temporal_analyzer': 0.05
        }
        
        # ì ì‘ì  ê°€ì¤‘ì¹˜ ì¡°ì • íŒŒë¼ë¯¸í„°
        self.adaptation_rate = 0.05
        self.performance_history = defaultdict(deque)
        self.correlation_matrix = np.eye(len(self.module_weights))
        
    def adjust_weights_based_on_performance(self, performance_data: Dict[str, float]):
        """ì„±ëŠ¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“ˆ ê°€ì¤‘ì¹˜ ì¡°ì •"""
        
        for module_name, performance in performance_data.items():
            if module_name in self.module_weights:
                # ì„±ëŠ¥ì´ ì¢‹ìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¦ê°€, ë‚˜ì˜ë©´ ê°ì†Œ
                adjustment = (performance - 0.5) * self.adaptation_rate
                self.module_weights[module_name] = np.clip(
                    self.module_weights[module_name] + adjustment,
                    0.05, 0.4  # ìµœì†Œ 5%, ìµœëŒ€ 40%
                )
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(self.module_weights.values())
        for module_name in self.module_weights:
            self.module_weights[module_name] /= total_weight
    
    def get_current_weights(self) -> Dict[str, float]:
        """í˜„ì¬ ëª¨ë“ˆ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        return self.module_weights.copy()
    
    def calculate_module_synergy(self, module_responses: Dict[str, ModuleResponse]) -> float:
        """ëª¨ë“ˆ ê°„ ì‹œë„ˆì§€ ê³„ì‚°"""
        
        if len(module_responses) < 2:
            return 0.5
        
        # ëª¨ë“ˆ ê°„ ì¼ì¹˜ë„ ê³„ì‚°
        agreements = []
        confidences = [resp.confidence for resp in module_responses.values()]
        
        # ì‹ ë¢°ë„ ì¼ì¹˜ì„±
        confidence_variance = np.var(confidences)
        confidence_agreement = 1.0 / (1.0 + confidence_variance)
        agreements.append(confidence_agreement)
        
        # ê²°ë¡  ì¼ì¹˜ì„± (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì˜ë¯¸ ë¶„ì„ì´ í•„ìš”
        response_similarities = []
        responses = list(module_responses.values())
        
        for i in range(len(responses)):
            for j in range(i+1, len(responses)):
                # ì‹ ë¢°ë„ ê¸°ë°˜ ìœ ì‚¬ì„± (ì‹¤ì œë¡œëŠ” ë‚´ìš© ë¶„ì„ í•„ìš”)
                similarity = 1.0 - abs(responses[i].confidence - responses[j].confidence)
                response_similarities.append(similarity)
        
        if response_similarities:
            content_agreement = np.mean(response_similarities)
            agreements.append(content_agreement)
        
        return np.mean(agreements)

class IntegratedSystemOrchestrator:
    """í†µí•© ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self):
        self.logger = logger
        
        # í•˜ìœ„ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”
        self.modules = {}
        self.module_coordinator = ModuleCoordinator()
        
        # ìŠ¤ë ˆë“œ í’€
        self.thread_pool = ThreadPoolExecutor(max_workers=8)
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_decisions': 0,
            'successful_decisions': 0,
            'average_processing_time': 0.0,
            'module_performance': defaultdict(list),
            'integration_quality': deque(maxlen=100)
        }
        
        # í•™ìŠµ ë°ì´í„°
        self.decision_history = deque(maxlen=1000)
        self.feedback_history = deque(maxlen=500)
        
        # ìƒíƒœ ê´€ë¦¬
        self.system_status = "initializing"
        self.last_health_check = time.time()
        
        # ì´ˆê¸°í™”
        self._initialize_modules()
        
        self.logger.info("í†µí•© ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_modules(self):
        """í•˜ìœ„ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”"""
        try:
            # ê° ëª¨ë“ˆ ì´ˆê¸°í™” (ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ)
            try:
                self.modules['emotion_ethics_regret'] = EmotionEthicsRegretCircuit()
                self.logger.info("ê°ì •-ìœ¤ë¦¬-í›„íšŒ íšŒë¡œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"ê°ì •-ìœ¤ë¦¬-í›„íšŒ íšŒë¡œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            try:
                self.modules['ethics_policy'] = EthicsPolicyUpdater()
                self.logger.info("ìœ¤ë¦¬ ì •ì±… ì¡°ì •ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"ìœ¤ë¦¬ ì •ì±… ì¡°ì •ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            try:
                self.modules['phase_controller'] = PhaseController()
                self.logger.info("í˜ì´ì¦ˆ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"í˜ì´ì¦ˆ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            try:
                self.modules['xai_feedback'] = XAIFeedbackIntegrator()
                self.logger.info("XAI í”¼ë“œë°± í†µí•©ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"XAI í”¼ë“œë°± í†µí•©ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            try:
                self.modules['fuzzy_mapper'] = FuzzyEmotionEthicsMapper()
                self.logger.info("í¼ì§€ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"í¼ì§€ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            try:
                self.modules['deep_ethics'] = DeepMultiDimensionalEthicsSystem()
                self.logger.info("ì‹¬ì¸µ ìœ¤ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"ì‹¬ì¸µ ìœ¤ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            try:
                self.modules['temporal_analyzer'] = TemporalEventPropagationAnalyzer()
                self.logger.info("ì‹œê³„ì—´ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"ì‹œê³„ì—´ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            if self.modules:
                self.system_status = "ready"
                self.logger.info(f"{len(self.modules)}ê°œ ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self.system_status = "degraded"
                self.logger.warning("ëª¨ë“  ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨")
                
        except Exception as e:
            self.logger.error(f"ëª¨ë“ˆ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            self.system_status = "error"
    
    async def process_decision_request(self, context: IntegrationContext) -> IntegratedDecision:
        """í†µí•© ì˜ì‚¬ê²°ì • ìš”ì²­ ì²˜ë¦¬"""
        
        start_time = time.time()
        decision_id = f"decision_{int(start_time)}_{context.session_id}"
        
        try:
            # 1. ëª¨ë“  ëª¨ë“ˆì—ì„œ ë³‘ë ¬ë¡œ ë¶„ì„ ìˆ˜í–‰
            module_responses = await self._gather_module_responses(context)
            
            # 2. í˜ì´ì¦ˆ ì»¨íŠ¸ë¡¤ëŸ¬ë¡œ í˜„ì¬ ìƒí™©ì— ë§ëŠ” í˜ì´ì¦ˆ ê²°ì •
            optimal_phase = await self._determine_optimal_phase(context, module_responses)
            
            # 3. í˜ì´ì¦ˆë³„ ê°€ì¤‘ì¹˜ ì¡°ì •
            phase_adjusted_weights = await self._adjust_weights_for_phase(optimal_phase, context)
            
            # 4. ëª¨ë“ˆ ì‘ë‹µ í†µí•©
            integrated_result = await self._integrate_module_responses(
                module_responses, phase_adjusted_weights, context
            )
            
            # 5. ìµœì¢… ì˜ì‚¬ê²°ì • ìƒì„±
            final_decision = await self._generate_final_decision(
                integrated_result, context, decision_id
            )
            
            # 6. ì‹œê³„ì—´ ì´ë²¤íŠ¸ ë“±ë¡
            await self._register_decision_event(final_decision, context)
            
            # 7. ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            await self._update_performance_stats(final_decision, processing_time, module_responses)
            
            self.logger.info(f"ì˜ì‚¬ê²°ì • ì™„ë£Œ: {decision_id} ({processing_time:.3f}ì´ˆ)")
            return final_decision
            
        except Exception as e:
            self.logger.error(f"ì˜ì‚¬ê²°ì • ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            self.logger.error(traceback.format_exc())
            
            # í´ë°± ì˜ì‚¬ê²°ì •
            return IntegratedDecision(
                decision_id=decision_id,
                final_recommendation="ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µì…ë‹ˆë‹¤. ë” ì‹ ì¤‘í•œ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                confidence_score=0.1,
                processing_time=time.time() - start_time,
                reasoning_chain=["system_error_fallback"]
            )
    
    async def _gather_module_responses(self, context: IntegrationContext) -> Dict[str, ModuleResponse]:
        """ëª¨ë“  ëª¨ë“ˆì—ì„œ ë³‘ë ¬ë¡œ ì‘ë‹µ ìˆ˜ì§‘"""
        
        tasks = []
        available_modules = {}
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“ˆë“¤ì— ëŒ€í•´ ë¹„ë™ê¸° íƒœìŠ¤í¬ ìƒì„±
        for module_name, module_instance in self.modules.items():
            if hasattr(module_instance, 'analyze') or hasattr(module_instance, 'process'):
                task = asyncio.create_task(
                    self._query_module_async(module_name, module_instance, context)
                )
                tasks.append(task)
                available_modules[module_name] = task
        
        # ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
        if tasks:
            responses = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì •ë¦¬
            module_responses = {}
            for i, (module_name, task) in enumerate(available_modules.items()):
                if i < len(responses):
                    response = responses[i]
                    if isinstance(response, Exception):
                        # ì˜ˆì™¸ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ
                        module_responses[module_name] = ModuleResponse(
                            module_name=module_name,
                            response_data={},
                            confidence=0.1,
                            success=False,
                            error_message=str(response)
                        )
                    else:
                        module_responses[module_name] = response
            
            return module_responses
        
        return {}
    
    async def _query_module_async(
        self, 
        module_name: str, 
        module_instance: Any, 
        context: IntegrationContext
    ) -> ModuleResponse:
        """ê°œë³„ ëª¨ë“ˆ ë¹„ë™ê¸° ì¡°íšŒ"""
        
        start_time = time.time()
        
        try:
            # ëª¨ë“ˆë³„ íŠ¹í™” ì¡°íšŒ ë¡œì§
            if module_name == 'emotion_ethics_regret':
                result = await self._query_emotion_ethics_regret(module_instance, context)
            
            elif module_name == 'ethics_policy':
                result = await self._query_ethics_policy(module_instance, context)
            
            elif module_name == 'phase_controller':
                result = await self._query_phase_controller(module_instance, context)
            
            elif module_name == 'xai_feedback':
                result = await self._query_xai_feedback(module_instance, context)
            
            elif module_name == 'fuzzy_mapper':
                result = await self._query_fuzzy_mapper(module_instance, context)
            
            elif module_name == 'deep_ethics':
                result = await self._query_deep_ethics(module_instance, context)
            
            elif module_name == 'temporal_analyzer':
                result = await self._query_temporal_analyzer(module_instance, context)
            
            else:
                result = {'analysis': 'generic_module_response', 'confidence': 0.5}
            
            processing_time = time.time() - start_time
            
            return ModuleResponse(
                module_name=module_name,
                response_data=result,
                confidence=result.get('confidence', 0.5),
                processing_time=processing_time,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"ëª¨ë“ˆ {module_name} ì¡°íšŒ ì˜¤ë¥˜: {e}")
            
            return ModuleResponse(
                module_name=module_name,
                response_data={},
                confidence=0.1,
                processing_time=processing_time,
                success=False,
                error_message=str(e)
            )
    
    async def _query_emotion_ethics_regret(self, module, context: IntegrationContext) -> Dict[str, Any]:
        """ê°ì •-ìœ¤ë¦¬-í›„íšŒ íšŒë¡œ ì¡°íšŒ"""
        
        # ëª¨ë“ˆì´ ì´ˆê¸°í™”ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ê³  ê¸°ë³¸ ì‘ë‹µ ìƒì„±
        return {
            'emotion_analysis': {
                'primary_emotion': 'concern',
                'intensity': context.urgency_level,
                'stability': 0.7
            },
            'ethics_score': context.ethical_weight,
            'regret_prediction': 0.3,
            'recommendation': 'balanced_ethical_approach',
            'confidence': 0.8
        }
    
    async def _query_ethics_policy(self, module, context: IntegrationContext) -> Dict[str, Any]:
        """ìœ¤ë¦¬ ì •ì±… ì¡°ì •ê¸° ì¡°íšŒ"""
        
        return {
            'policy_recommendations': {
                'care_harm': 0.8,
                'fairness_cheating': 0.7,
                'loyalty_betrayal': 0.6,
                'authority_subversion': 0.5,
                'sanctity_degradation': 0.6
            },
            'cultural_adjustments': {
                'hierarchy_respect': 0.7,
                'group_harmony': 0.8,
                'long_term_thinking': 0.9
            },
            'confidence': 0.75
        }
    
    async def _query_phase_controller(self, module, context: IntegrationContext) -> Dict[str, Any]:
        """í˜ì´ì¦ˆ ì»¨íŠ¸ë¡¤ëŸ¬ ì¡°íšŒ"""
        
        # í˜ì´ì¦ˆ ê²°ì • ë§¥ë½ ìƒì„±
        phase_context = PhaseDecisionContext(
            scenario_complexity=context.complexity_level,
            uncertainty_level=1.0 - context.complexity_level,  # ë³µì¡í• ìˆ˜ë¡ ë¶ˆí™•ì‹¤
            time_pressure=context.urgency_level,
            stakeholder_count=context.stakeholder_count,
            ethical_weight=context.ethical_weight
        )
        
        # ì‹¤ì œ ëª¨ë“ˆ ë©”ì„œë“œ í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        return {
            'optimal_phase': 'execution' if context.urgency_level > 0.7 else 'learning',
            'phase_confidence': 0.8,
            'recommended_parameters': {
                'exploration_rate': 0.3 if context.urgency_level > 0.7 else 0.8,
                'safety_threshold': 0.8 if context.urgency_level > 0.7 else 0.5,
                'ethical_strictness': context.ethical_weight
            },
            'confidence': 0.85
        }
    
    async def _query_xai_feedback(self, module, context: IntegrationContext) -> Dict[str, Any]:
        """XAI í”¼ë“œë°± í†µí•©ê¸° ì¡°íšŒ"""
        
        return {
            'explainability_score': 0.7,
            'feature_importance': {
                'ethical_weight': 0.3,
                'urgency_level': 0.25,
                'complexity_level': 0.2,
                'stakeholder_count': 0.15,
                'cultural_context': 0.1
            },
            'interpretation_quality': 0.8,
            'user_understanding_prediction': 0.75,
            'confidence': 0.7
        }
    
    async def _query_fuzzy_mapper(self, module, context: IntegrationContext) -> Dict[str, Any]:
        """í¼ì§€ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ ì¡°íšŒ"""
        
        return {
            'fuzzy_emotion_state': {
                'anxiety': 0.6 if context.urgency_level > 0.5 else 0.3,
                'concern': 0.7,
                'determination': 0.5,
                'empathy': 0.8 if context.stakeholder_count > 1 else 0.4
            },
            'ethics_mapping': {
                'care_orientation': 0.8,
                'justice_orientation': 0.7,
                'duty_orientation': 0.6
            },
            'mapping_certainty': 0.75,
            'confidence': 0.8
        }
    
    async def _query_deep_ethics(self, module, context: IntegrationContext) -> Dict[str, Any]:
        """ì‹¬ì¸µ ìœ¤ë¦¬ ì‹œìŠ¤í…œ ì¡°íšŒ"""
        
        return {
            'multi_dimensional_analysis': {
                'utilitarianism_score': 0.7,
                'virtue_ethics_score': 0.8,
                'deontological_score': 0.6,
                'care_ethics_score': 0.9,
                'justice_theory_score': 0.7
            },
            'stakeholder_analysis': {
                'individual_impact': 0.7,
                'community_impact': 0.8,
                'societal_impact': 0.6
            },
            'cultural_considerations': {
                'collectivism_factor': 0.8,
                'hierarchy_factor': 0.7,
                'harmony_factor': 0.9
            },
            'overall_ethics_score': 0.75,
            'confidence': 0.82
        }
    
    async def _query_temporal_analyzer(self, module, context: IntegrationContext) -> Dict[str, Any]:
        """ì‹œê³„ì—´ ë¶„ì„ê¸° ì¡°íšŒ"""
        
        return {
            'temporal_patterns': {
                'short_term_trend': 'stable',
                'medium_term_trend': 'improving',
                'long_term_implications': 'positive'
            },
            'consequence_prediction': {
                'immediate_effects': {'probability': 0.8, 'severity': 0.4},
                'short_term_effects': {'probability': 0.6, 'severity': 0.5},
                'long_term_effects': {'probability': 0.4, 'severity': 0.3}
            },
            'propagation_analysis': {
                'cascade_potential': 0.3,
                'amplification_risk': 0.2,
                'containment_feasibility': 0.8
            },
            'prediction_confidence': 0.7,
            'confidence': 0.72
        }
    
    async def _determine_optimal_phase(
        self, 
        context: IntegrationContext, 
        module_responses: Dict[str, ModuleResponse]
    ) -> str:
        """ìµœì  í˜ì´ì¦ˆ ê²°ì •"""
        
        # í˜ì´ì¦ˆ ì»¨íŠ¸ë¡¤ëŸ¬ ì‘ë‹µì´ ìˆìœ¼ë©´ ì‚¬ìš©
        if 'phase_controller' in module_responses:
            phase_response = module_responses['phase_controller']
            if phase_response.success:
                return phase_response.response_data.get('optimal_phase', 'execution')
        
        # í´ë°± ë¡œì§
        if context.urgency_level > 0.8:
            return 'execution'
        elif context.complexity_level > 0.7:
            return 'learning'
        else:
            return 'reflection'
    
    async def _adjust_weights_for_phase(
        self, 
        phase: str, 
        context: IntegrationContext
    ) -> Dict[str, float]:
        """í˜ì´ì¦ˆë³„ ê°€ì¤‘ì¹˜ ì¡°ì •"""
        
        base_weights = self.module_coordinator.get_current_weights()
        adjusted_weights = base_weights.copy()
        
        if phase == 'learning':
            # í•™ìŠµ í˜ì´ì¦ˆ: íƒìƒ‰ì  ëª¨ë“ˆ ê°•í™”
            adjusted_weights['temporal_analyzer'] *= 1.5
            adjusted_weights['deep_ethics'] *= 1.3
            adjusted_weights['phase_controller'] *= 0.8
        
        elif phase == 'execution':
            # ì‹¤í–‰ í˜ì´ì¦ˆ: ì•ˆì •ì  ëª¨ë“ˆ ê°•í™”
            adjusted_weights['emotion_ethics_regret'] *= 1.3
            adjusted_weights['phase_controller'] *= 1.2
            adjusted_weights['temporal_analyzer'] *= 0.7
        
        elif phase == 'reflection':
            # ë°˜ì„± í˜ì´ì¦ˆ: ë¶„ì„ì  ëª¨ë“ˆ ê°•í™”
            adjusted_weights['deep_ethics'] *= 1.4
            adjusted_weights['xai_feedback'] *= 1.3
            adjusted_weights['fuzzy_mapper'] *= 1.2
        
        # ì •ê·œí™”
        total_weight = sum(adjusted_weights.values())
        for module_name in adjusted_weights:
            adjusted_weights[module_name] /= total_weight
        
        return adjusted_weights
    
    async def _integrate_module_responses(
        self, 
        module_responses: Dict[str, ModuleResponse],
        weights: Dict[str, float],
        context: IntegrationContext
    ) -> Dict[str, Any]:
        """ëª¨ë“ˆ ì‘ë‹µ í†µí•©"""
        
        integrated_result = {
            'confidence_scores': {},
            'recommendations': [],
            'risk_assessments': {},
            'explanations': [],
            'overall_confidence': 0.0
        }
        
        total_weight = 0.0
        weighted_confidence = 0.0
        
        for module_name, response in module_responses.items():
            if not response.success:
                continue
            
            module_weight = weights.get(module_name, 0.0)
            total_weight += module_weight
            weighted_confidence += response.confidence * module_weight
            
            # ëª¨ë“ˆë³„ ì‹ ë¢°ë„ ì €ì¥
            integrated_result['confidence_scores'][module_name] = response.confidence
            
            # ì¶”ì²œì‚¬í•­ ìˆ˜ì§‘
            if 'recommendation' in response.response_data:
                integrated_result['recommendations'].append({
                    'module': module_name,
                    'recommendation': response.response_data['recommendation'],
                    'weight': module_weight
                })
            
            # ìœ„í—˜ í‰ê°€ ìˆ˜ì§‘
            if 'risk_assessment' in response.response_data:
                integrated_result['risk_assessments'][module_name] = response.response_data['risk_assessment']
            
            # ì„¤ëª… ìˆ˜ì§‘
            if 'explanation' in response.response_data:
                integrated_result['explanations'].append({
                    'module': module_name,
                    'explanation': response.response_data['explanation'],
                    'weight': module_weight
                })
        
        # ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
        if total_weight > 0:
            integrated_result['overall_confidence'] = weighted_confidence / total_weight
        
        # ëª¨ë“ˆ ê°„ ì‹œë„ˆì§€ í‰ê°€
        synergy_score = self.module_coordinator.calculate_module_synergy(module_responses)
        integrated_result['synergy_score'] = synergy_score
        
        return integrated_result
    
    async def _generate_final_decision(
        self, 
        integrated_result: Dict[str, Any],
        context: IntegrationContext,
        decision_id: str
    ) -> IntegratedDecision:
        """ìµœì¢… ì˜ì‚¬ê²°ì • ìƒì„±"""
        
        # ìµœì¢… ì¶”ì²œì‚¬í•­ ê²°ì •
        recommendations = integrated_result.get('recommendations', [])
        
        if recommendations:
            # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìµœê³  ì¶”ì²œì‚¬í•­ ì„ íƒ
            best_recommendation = max(recommendations, key=lambda r: r['weight'])
            final_recommendation = best_recommendation['recommendation']
        else:
            final_recommendation = "ì‹ ì¤‘í•œ ê²€í† ì™€ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        base_confidence = integrated_result.get('overall_confidence', 0.5)
        synergy_bonus = integrated_result.get('synergy_score', 0.5) * 0.2
        final_confidence = min(base_confidence + synergy_bonus, 1.0)
        
        # ì¶”ë¡  ì²´ì¸ ìƒì„±
        reasoning_chain = []
        reasoning_chain.append(f"ìƒí™© ë¶„ì„: ê¸´ê¸‰ë„ {context.urgency_level:.2f}, ë³µì¡ë„ {context.complexity_level:.2f}")
        reasoning_chain.append(f"ìœ¤ë¦¬ì  ê°€ì¤‘ì¹˜: {context.ethical_weight:.2f}")
        reasoning_chain.append(f"ëª¨ë“ˆ ì‹ ë¢°ë„: {base_confidence:.3f}")
        reasoning_chain.append(f"ëª¨ë“ˆ ì‹œë„ˆì§€: {integrated_result.get('synergy_score', 0.5):.3f}")
        
        for rec in recommendations[:3]:  # ìƒìœ„ 3ê°œ ì¶”ì²œì‚¬í•­
            reasoning_chain.append(f"{rec['module']}: {rec['recommendation']} (ê°€ì¤‘ì¹˜: {rec['weight']:.3f})")
        
        # ëŒ€ì•ˆ ì˜µì…˜ ìƒì„±
        alternative_options = []
        for rec in recommendations[1:4]:  # 2-4ìœ„ ì¶”ì²œì‚¬í•­
            alternative_options.append(rec['recommendation'])
        
        if not alternative_options:
            alternative_options = [
                "ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ í›„ ì¬í‰ê°€",
                "ì „ë¬¸ê°€ ìë¬¸ ìš”ì²­",
                "ë‹¨ê³„ì  ì ‘ê·¼ ë°©ì‹ ì±„íƒ"
            ]
        
        # ìœ„í—˜ í‰ê°€
        risk_assessment = {}
        for module_name, risks in integrated_result.get('risk_assessments', {}).items():
            if isinstance(risks, dict):
                for risk_type, risk_level in risks.items():
                    if risk_type not in risk_assessment:
                        risk_assessment[risk_type] = []
                    risk_assessment[risk_type].append(risk_level)
        
        # í‰ê·  ìœ„í—˜ë„ ê³„ì‚°
        averaged_risks = {}
        for risk_type, risk_levels in risk_assessment.items():
            averaged_risks[risk_type] = np.mean(risk_levels)
        
        return IntegratedDecision(
            decision_id=decision_id,
            final_recommendation=final_recommendation,
            confidence_score=final_confidence,
            module_contributions={
                module_name: response.confidence * weights.get(module_name, 0.0)
                for module_name, response in integrated_result.get('module_responses', {}).items()
            },
            risk_assessment=averaged_risks,
            reasoning_chain=reasoning_chain,
            alternative_options=alternative_options,
            ethical_analysis=self._extract_ethical_analysis(integrated_result),
            emotional_analysis=self._extract_emotional_analysis(integrated_result),
            temporal_analysis=self._extract_temporal_analysis(integrated_result)
        )
    
    def _extract_ethical_analysis(self, integrated_result: Dict[str, Any]) -> Dict[str, Any]:
        """ìœ¤ë¦¬ì  ë¶„ì„ ì¶”ì¶œ"""
        
        ethical_analysis = {
            'primary_ethical_concerns': [],
            'ethical_frameworks_applied': [],
            'moral_implications': {},
            'cultural_considerations': {}
        }
        
        # ê° ëª¨ë“ˆì˜ ìœ¤ë¦¬ì  ë¶„ì„ ì •ë³´ ìˆ˜ì§‘
        for module_name, response in integrated_result.get('module_responses', {}).items():
            if isinstance(response, ModuleResponse) and response.success:
                data = response.response_data
                
                # ìœ¤ë¦¬ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
                if 'ethics_score' in data:
                    ethical_analysis['moral_implications'][module_name] = data['ethics_score']
                
                if 'multi_dimensional_analysis' in data:
                    ethical_analysis['ethical_frameworks_applied'].append(module_name)
                
                if 'cultural_considerations' in data:
                    ethical_analysis['cultural_considerations'][module_name] = data['cultural_considerations']
        
        return ethical_analysis
    
    def _extract_emotional_analysis(self, integrated_result: Dict[str, Any]) -> Dict[str, Any]:
        """ê°ì •ì  ë¶„ì„ ì¶”ì¶œ"""
        
        emotional_analysis = {
            'primary_emotions': {},
            'emotional_intensity': 0.0,
            'emotional_stability': 0.0,
            'empathy_considerations': {}
        }
        
        # ê°ì • ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
        emotion_data = []
        
        for module_name, response in integrated_result.get('module_responses', {}).items():
            if isinstance(response, ModuleResponse) and response.success:
                data = response.response_data
                
                if 'emotion_analysis' in data:
                    emotion_info = data['emotion_analysis']
                    emotional_analysis['primary_emotions'][module_name] = emotion_info
                    
                    if 'intensity' in emotion_info:
                        emotion_data.append(emotion_info['intensity'])
                
                if 'fuzzy_emotion_state' in data:
                    emotional_analysis['primary_emotions'][module_name] = data['fuzzy_emotion_state']
        
        if emotion_data:
            emotional_analysis['emotional_intensity'] = np.mean(emotion_data)
            emotional_analysis['emotional_stability'] = 1.0 - np.std(emotion_data)
        
        return emotional_analysis
    
    def _extract_temporal_analysis(self, integrated_result: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œê°„ì  ë¶„ì„ ì¶”ì¶œ"""
        
        temporal_analysis = {
            'short_term_implications': {},
            'long_term_implications': {},
            'temporal_risks': {},
            'propagation_potential': 0.0
        }
        
        # ì‹œê°„ì  ë¶„ì„ ì •ë³´ ìˆ˜ì§‘
        for module_name, response in integrated_result.get('module_responses', {}).items():
            if isinstance(response, ModuleResponse) and response.success:
                data = response.response_data
                
                if 'temporal_patterns' in data:
                    temporal_analysis['short_term_implications'][module_name] = data['temporal_patterns']
                
                if 'consequence_prediction' in data:
                    temporal_analysis['long_term_implications'][module_name] = data['consequence_prediction']
                
                if 'propagation_analysis' in data:
                    prop_data = data['propagation_analysis']
                    if 'cascade_potential' in prop_data:
                        temporal_analysis['propagation_potential'] = max(
                            temporal_analysis['propagation_potential'],
                            prop_data['cascade_potential']
                        )
        
        return temporal_analysis
    
    async def _register_decision_event(self, decision: IntegratedDecision, context: IntegrationContext):
        """ì˜ì‚¬ê²°ì •ì„ ì‹œê³„ì—´ ì´ë²¤íŠ¸ë¡œ ë“±ë¡"""
        
        try:
            if 'temporal_analyzer' in self.modules:
                temporal_event = TemporalEvent(
                    event_id=decision.decision_id,
                    timestamp=decision.timestamp,
                    event_type="decision",
                    description=f"Integrated decision: {decision.final_recommendation[:100]}",
                    intensity=decision.confidence_score,
                    scope=context.stakeholder_count / 10.0,  # ì •ê·œí™”
                    reversibility=0.5,  # ê¸°ë³¸ê°’
                    certainty_level=decision.confidence_score,
                    prediction_confidence=decision.confidence_score,
                    primary_actors=[context.user_id],
                    affected_entities=["user", "system"],
                    ethical_implications={
                        'overall_ethics': decision.confidence_score * context.ethical_weight
                    }
                )
                
                # ì‹œê³„ì—´ ë¶„ì„ê¸°ì— ë“±ë¡
                await asyncio.get_event_loop().run_in_executor(
                    self.thread_pool,
                    self.modules['temporal_analyzer'].register_event,
                    temporal_event
                )
                
        except Exception as e:
            self.logger.error(f"ì‹œê³„ì—´ ì´ë²¤íŠ¸ ë“±ë¡ ì˜¤ë¥˜: {e}")
    
    async def _update_performance_stats(
        self, 
        decision: IntegratedDecision,
        processing_time: float,
        module_responses: Dict[str, ModuleResponse]
    ):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        try:
            # ì „ì²´ í†µê³„
            self.performance_stats['total_decisions'] += 1
            
            if decision.confidence_score > 0.7:
                self.performance_stats['successful_decisions'] += 1
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
            total_decisions = self.performance_stats['total_decisions']
            current_avg = self.performance_stats['average_processing_time']
            new_avg = (current_avg * (total_decisions - 1) + processing_time) / total_decisions
            self.performance_stats['average_processing_time'] = new_avg
            
            # ëª¨ë“ˆë³„ ì„±ëŠ¥
            for module_name, response in module_responses.items():
                if response.success:
                    self.performance_stats['module_performance'][module_name].append(response.confidence)
                    
                    # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
                    if len(self.performance_stats['module_performance'][module_name]) > 100:
                        self.performance_stats['module_performance'][module_name] = \
                            self.performance_stats['module_performance'][module_name][-100:]
            
            # í†µí•© í’ˆì§ˆ
            integration_quality = decision.confidence_score
            self.performance_stats['integration_quality'].append(integration_quality)
            
            # ëª¨ë“ˆ ê°€ì¤‘ì¹˜ ì ì‘ì  ì¡°ì •
            module_performance = {}
            for module_name, performances in self.performance_stats['module_performance'].items():
                if performances:
                    module_performance[module_name] = np.mean(performances[-10:])  # ìµœê·¼ 10ê°œ í‰ê· 
            
            if module_performance:
                self.module_coordinator.adjust_weights_based_on_performance(module_performance)
            
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
    
    def get_system_health(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ë°˜í™˜"""
        
        health_data = {
            'system_status': self.system_status,
            'active_modules': len(self.modules),
            'total_decisions': self.performance_stats['total_decisions'],
            'success_rate': 0.0,
            'average_processing_time': self.performance_stats['average_processing_time'],
            'module_weights': self.module_coordinator.get_current_weights(),
            'last_health_check': self.last_health_check
        }
        
        # ì„±ê³µë¥  ê³„ì‚°
        if self.performance_stats['total_decisions'] > 0:
            health_data['success_rate'] = (
                self.performance_stats['successful_decisions'] / 
                self.performance_stats['total_decisions']
            )
        
        # ëª¨ë“ˆë³„ ìƒíƒœ
        module_health = {}
        for module_name, performances in self.performance_stats['module_performance'].items():
            if performances:
                module_health[module_name] = {
                    'average_performance': np.mean(performances),
                    'performance_trend': np.mean(performances[-10:]) - np.mean(performances[-20:-10]) 
                                       if len(performances) >= 20 else 0.0,
                    'total_queries': len(performances)
                }
        
        health_data['module_health'] = module_health
        
        # ìµœê·¼ í†µí•© í’ˆì§ˆ
        if self.performance_stats['integration_quality']:
            health_data['recent_integration_quality'] = np.mean(
                list(self.performance_stats['integration_quality'])[-10:]
            )
        
        self.last_health_check = time.time()
        return health_data
    
    def run_integration_test(self) -> Dict[str, Any]:
        """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        print("ğŸ”§ í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        test_results = {
            'test_timestamp': time.time(),
            'module_tests': {},
            'integration_tests': {},
            'performance_tests': {},
            'overall_status': 'unknown'
        }
        
        try:
            # 1. ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
            print("\nğŸ“‹ ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
            for module_name, module_instance in self.modules.items():
                try:
                    # ê¸°ë³¸ì ì¸ ëª¨ë“ˆ ìƒíƒœ ì²´í¬
                    module_test_result = {
                        'initialized': module_instance is not None,
                        'has_required_methods': True,  # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê²€ì‚¬ í•„ìš”
                        'status': 'healthy'
                    }
                    
                    test_results['module_tests'][module_name] = module_test_result
                    print(f"  âœ… {module_name}: ì •ìƒ")
                    
                except Exception as e:
                    test_results['module_tests'][module_name] = {
                        'initialized': False,
                        'error': str(e),
                        'status': 'error'
                    }
                    print(f"  âŒ {module_name}: ì˜¤ë¥˜ - {e}")
            
            # 2. í†µí•© í…ŒìŠ¤íŠ¸
            print("\nğŸ”— ëª¨ë“ˆ ê°„ í†µí•© í…ŒìŠ¤íŠ¸")
            integration_test_contexts = [
                IntegrationContext(
                    session_id="test_1",
                    user_input="ê°„ë‹¨í•œ ìœ¤ë¦¬ì  ë”œë ˆë§ˆ ìƒí™©",
                    urgency_level=0.3,
                    complexity_level=0.4,
                    ethical_weight=0.8
                ),
                IntegrationContext(
                    session_id="test_2", 
                    user_input="ë³µì¡í•˜ê³  ê¸´ê¸‰í•œ ì˜ì‚¬ê²°ì • ìƒí™©",
                    urgency_level=0.9,
                    complexity_level=0.8,
                    stakeholder_count=5,
                    ethical_weight=0.9
                )
            ]
            
            integration_results = []
            for i, test_context in enumerate(integration_test_contexts):
                try:
                    # ë™ê¸°ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                    start_time = time.time()
                    
                    # ë¹„ë™ê¸° ë©”ì„œë“œë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
                    import asyncio
                    decision = asyncio.run(self.process_decision_request(test_context))
                    
                    processing_time = time.time() - start_time
                    
                    integration_result = {
                        'test_id': f"integration_test_{i+1}",
                        'success': True,
                        'processing_time': processing_time,
                        'confidence_score': decision.confidence_score,
                        'modules_participated': len(decision.module_contributions),
                        'decision_id': decision.decision_id
                    }
                    
                    integration_results.append(integration_result)
                    print(f"  âœ… í†µí•© í…ŒìŠ¤íŠ¸ {i+1}: ì„±ê³µ (ì‹ ë¢°ë„: {decision.confidence_score:.3f})")
                    
                except Exception as e:
                    integration_result = {
                        'test_id': f"integration_test_{i+1}",
                        'success': False,
                        'error': str(e),
                        'processing_time': 0.0
                    }
                    integration_results.append(integration_result)
                    print(f"  âŒ í†µí•© í…ŒìŠ¤íŠ¸ {i+1}: ì‹¤íŒ¨ - {e}")
            
            test_results['integration_tests'] = integration_results
            
            # 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            print("\nâš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
            performance_metrics = {
                'average_processing_time': np.mean([r['processing_time'] for r in integration_results if r['success']]),
                'successful_integrations': sum(1 for r in integration_results if r['success']),
                'total_integrations': len(integration_results),
                'success_rate': sum(1 for r in integration_results if r['success']) / len(integration_results),
                'system_health': self.get_system_health()
            }
            
            test_results['performance_tests'] = performance_metrics
            
            print(f"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {performance_metrics['average_processing_time']:.3f}ì´ˆ")
            print(f"  ì„±ê³µë¥ : {performance_metrics['success_rate']:.1%}")
            print(f"  í™œì„± ëª¨ë“ˆ ìˆ˜: {performance_metrics['system_health']['active_modules']}")
            
            # 4. ì „ì²´ ìƒíƒœ ê²°ì •
            module_success_rate = sum(1 for t in test_results['module_tests'].values() if t.get('status') == 'healthy') / len(test_results['module_tests'])
            integration_success_rate = performance_metrics['success_rate']
            
            if module_success_rate > 0.8 and integration_success_rate > 0.8:
                test_results['overall_status'] = 'excellent'
            elif module_success_rate > 0.6 and integration_success_rate > 0.6:
                test_results['overall_status'] = 'good'
            elif module_success_rate > 0.4 and integration_success_rate > 0.4:
                test_results['overall_status'] = 'acceptable'
            else:
                test_results['overall_status'] = 'needs_improvement'
            
            print(f"\nğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_results['overall_status'].upper()}")
            print(f"   ëª¨ë“ˆ ì„±ê³µë¥ : {module_success_rate:.1%}")
            print(f"   í†µí•© ì„±ê³µë¥ : {integration_success_rate:.1%}")
            
        except Exception as e:
            test_results['overall_status'] = 'error'
            test_results['error'] = str(e)
            print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print("\nâœ… í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return test_results
    
    def save_integration_state(self, filepath: str):
        """í†µí•© ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥"""
        
        state_data = {
            'system_status': self.system_status,
            'active_modules': list(self.modules.keys()),
            'module_weights': self.module_coordinator.get_current_weights(),
            'performance_stats': {
                'total_decisions': self.performance_stats['total_decisions'],
                'successful_decisions': self.performance_stats['successful_decisions'],
                'average_processing_time': self.performance_stats['average_processing_time']
            },
            'health_data': self.get_system_health(),
            'last_updated': time.time()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(state_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"í†µí•© ì‹œìŠ¤í…œ ìƒíƒœë¥¼ {filepath}ì— ì €ì¥ ì™„ë£Œ")


# ë©”ì¸ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Red Heart í†µí•© ì‹œìŠ¤í…œ ì‹œì‘")
    
    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”
    orchestrator = IntegratedSystemOrchestrator()
    
    # ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ì²´í¬
    health = orchestrator.get_system_health()
    print(f"\nğŸ’Š ì‹œìŠ¤í…œ ìƒíƒœ: {health['system_status']}")
    print(f"   í™œì„± ëª¨ë“ˆ: {health['active_modules']}ê°œ")
    print(f"   ì´ ì˜ì‚¬ê²°ì •: {health['total_decisions']}íšŒ")
    
    # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_results = orchestrator.run_integration_test()
    
    # í…ŒìŠ¤íŠ¸ ì˜ˆì œ ì‹¤í–‰
    print("\nğŸ¯ ì‹¤ì œ ì˜ì‚¬ê²°ì • ì˜ˆì œ í…ŒìŠ¤íŠ¸")
    
    example_context = IntegrationContext(
        session_id="example_1",
        user_input="íšŒì‚¬ì—ì„œ ê°œì¸ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìƒˆë¡œìš´ ì •ì±…ì„ ë„ì…í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í¸ì˜ì„±ì€ ë†’ì•„ì§€ì§€ë§Œ í”„ë¼ì´ë²„ì‹œ ìš°ë ¤ê°€ ìˆìŠµë‹ˆë‹¤.",
        scenario_description="ê°œì¸ì •ë³´ ìˆ˜ì§‘ ì •ì±… ë„ì…ì— ëŒ€í•œ ìœ¤ë¦¬ì  íŒë‹¨",
        urgency_level=0.6,
        complexity_level=0.8,
        stakeholder_count=3,
        ethical_weight=0.9
    )
    
    try:
        import asyncio
        decision = asyncio.run(orchestrator.process_decision_request(example_context))
        
        print(f"\nğŸ“‹ ì˜ì‚¬ê²°ì • ê²°ê³¼:")
        print(f"   ê²°ì • ID: {decision.decision_id}")
        print(f"   ì¶”ì²œì‚¬í•­: {decision.final_recommendation}")
        print(f"   ì‹ ë¢°ë„: {decision.confidence_score:.3f}")
        print(f"   ì²˜ë¦¬ ì‹œê°„: {decision.processing_time:.3f}ì´ˆ")
        
        print(f"\nğŸ§  ì¶”ë¡  ê³¼ì •:")
        for i, reasoning in enumerate(decision.reasoning_chain[:5], 1):
            print(f"   {i}. {reasoning}")
        
        if decision.alternative_options:
            print(f"\nğŸ”„ ëŒ€ì•ˆ ì˜µì…˜:")
            for i, option in enumerate(decision.alternative_options[:3], 1):
                print(f"   {i}. {option}")
        
    except Exception as e:
        print(f"âŒ ì˜ˆì œ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    
    # ìµœì¢… ìƒíƒœ ì €ì¥
    try:
        orchestrator.save_integration_state("integration_state.json")
        print(f"\nğŸ’¾ ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ìƒíƒœ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    print("\nğŸ‰ Red Heart í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    return orchestrator


if __name__ == "__main__":
    main()