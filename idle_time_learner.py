#!/usr/bin/env python3
"""
ìœ íœ´ ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ
Idle Time Learning System

ëŒ€í™”ê°€ ì—†ëŠ” ì‹œê°„ì— ìë™ìœ¼ë¡œ ë°°ì¹˜ í•™ìŠµì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import asyncio
import time
import torch
import numpy as np
import logging
from typing import Dict, List, Any, Optional, Deque
from collections import deque
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime, timedelta
import json
import pickle
from pathlib import Path

logger = logging.getLogger('RedHeart.IdleLearner')


class IdleLevel(Enum):
    """ìœ íœ´ ë ˆë²¨ ì •ì˜"""
    ACTIVE = "active"           # í™œë™ ì¤‘ (0-1ë¶„)
    IMMEDIATE = "immediate"     # ì¦‰ì‹œ ì •ë¦¬ (1-10ë¶„)
    SHORT = "short"            # ì§§ì€ ìœ íœ´ (10-30ë¶„)
    MEDIUM = "medium"          # ì¤‘ê°„ ìœ íœ´ (30ë¶„-1ì‹œê°„)
    LONG = "long"              # ê¸´ ìœ íœ´ (1-8ì‹œê°„)
    OVERNIGHT = "overnight"    # ë°¤ìƒ˜ ìœ íœ´ (8ì‹œê°„+)


@dataclass
class RegretMemory:
    """í›„íšŒ ë©”ëª¨ë¦¬ í•­ëª©"""
    timestamp: datetime
    decision: Dict[str, Any]
    actual_outcome: Dict[str, Any]
    predicted_outcome: Dict[str, Any]
    regret_score: float
    context: Dict[str, Any] = field(default_factory=dict)
    learned: bool = False
    
    def to_dict(self) -> Dict:
        return {
            'timestamp': self.timestamp.isoformat(),
            'decision': self.decision,
            'actual_outcome': self.actual_outcome,
            'predicted_outcome': self.predicted_outcome,
            'regret_score': self.regret_score,
            'context': self.context,
            'learned': self.learned
        }


@dataclass
class LearningSession:
    """í•™ìŠµ ì„¸ì…˜ ì •ë³´"""
    session_id: str
    start_time: datetime
    end_time: Optional[datetime] = None
    items_processed: int = 0
    total_items: int = 0
    learning_type: str = "regret"
    status: str = "pending"
    metrics: Dict[str, float] = field(default_factory=dict)


class HierarchicalIdleLearner:
    """ê³„ì¸µì  ìœ íœ´ ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 regret_buffer_size: int = 1000,
                 experience_cache_size: int = 500):
        
        # ìœ íœ´ ì‹œê°„ ì„ê³„ê°’ (ì´ˆ)
        self.idle_thresholds = {
            IdleLevel.IMMEDIATE: 60,      # 1ë¶„
            IdleLevel.SHORT: 600,         # 10ë¶„
            IdleLevel.MEDIUM: 1800,       # 30ë¶„
            IdleLevel.LONG: 3600,         # 1ì‹œê°„
            IdleLevel.OVERNIGHT: 28800    # 8ì‹œê°„
        }
        
        # ìƒíƒœ ì¶”ì 
        self.last_interaction_time = time.time()
        self.is_learning = False
        self.current_idle_level = IdleLevel.ACTIVE
        
        # í›„íšŒ ë²„í¼
        self.regret_buffer: Deque[RegretMemory] = deque(maxlen=regret_buffer_size)
        self.priority_regrets: List[RegretMemory] = []  # ë†’ì€ í›„íšŒ ì ìˆ˜ í•­ëª©
        
        # ê²½í—˜ ìºì‹œ
        self.experience_cache: Deque[Dict] = deque(maxlen=experience_cache_size)
        
        # í•™ìŠµ ì„¸ì…˜ ê¸°ë¡
        self.learning_sessions: List[LearningSession] = []
        self.current_session: Optional[LearningSession] = None
        
        # í•™ìŠµ í†µê³„
        self.stats = {
            'total_sessions': 0,
            'total_items_learned': 0,
            'total_learning_time': 0.0,
            'regret_reduction': [],
            'last_learning': None
        }
        
        # ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬
        self.monitor_task: Optional[asyncio.Task] = None
        
        logger.info("HierarchicalIdleLearner ì´ˆê¸°í™” ì™„ë£Œ")
    
    def record_interaction(self):
        """ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ê¸°ë¡"""
        self.last_interaction_time = time.time()
        self.current_idle_level = IdleLevel.ACTIVE
    
    def add_regret(self, regret_memory: RegretMemory):
        """í›„íšŒ ë©”ëª¨ë¦¬ ì¶”ê°€"""
        self.regret_buffer.append(regret_memory)
        
        # ë†’ì€ í›„íšŒ ì ìˆ˜ëŠ” ìš°ì„ ìˆœìœ„ íì—ë„ ì¶”ê°€
        if regret_memory.regret_score > 0.7:
            self.priority_regrets.append(regret_memory)
            # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
            self.priority_regrets.sort(key=lambda x: x.regret_score, reverse=True)
            # ìƒìœ„ 100ê°œë§Œ ìœ ì§€
            self.priority_regrets = self.priority_regrets[:100]
    
    def add_experience(self, experience: Dict):
        """ê²½í—˜ ì¶”ê°€"""
        experience['timestamp'] = datetime.now()
        self.experience_cache.append(experience)
    
    def get_idle_level(self) -> IdleLevel:
        """í˜„ì¬ ìœ íœ´ ë ˆë²¨ ê³„ì‚°"""
        idle_time = time.time() - self.last_interaction_time
        
        for level in reversed(list(IdleLevel)):
            if level == IdleLevel.ACTIVE:
                continue
            if idle_time >= self.idle_thresholds[level]:
                return level
        
        return IdleLevel.ACTIVE
    
    async def start_monitoring(self):
        """ìœ íœ´ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitor_task is not None:
            logger.warning("ì´ë¯¸ ëª¨ë‹ˆí„°ë§ ì¤‘")
            return
        
        self.monitor_task = asyncio.create_task(self._monitor_and_learn())
        logger.info("ìœ íœ´ ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    async def stop_monitoring(self):
        """ìœ íœ´ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
            self.monitor_task = None
            logger.info("ìœ íœ´ ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    async def _monitor_and_learn(self):
        """ìœ íœ´ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ì ì ˆí•œ ì‹œì ì— í•™ìŠµ ìˆ˜í–‰"""
        
        while True:
            try:
                await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
                
                # í˜„ì¬ ìœ íœ´ ë ˆë²¨ í™•ì¸
                current_level = self.get_idle_level()
                
                # ë ˆë²¨ ë³€ê²½ ì‹œ ë¡œê¹…
                if current_level != self.current_idle_level:
                    logger.info(f"ìœ íœ´ ë ˆë²¨ ë³€ê²½: {self.current_idle_level.value} â†’ {current_level.value}")
                    self.current_idle_level = current_level
                
                # ì´ë¯¸ í•™ìŠµ ì¤‘ì´ë©´ ìŠ¤í‚µ
                if self.is_learning:
                    continue
                
                # ë ˆë²¨ë³„ í•™ìŠµ ìˆ˜í–‰
                if current_level == IdleLevel.IMMEDIATE:
                    # 1-10ë¶„: ìºì‹œ ì •ë¦¬
                    await self._immediate_cleanup()
                
                elif current_level == IdleLevel.SHORT:
                    # 10-30ë¶„: ê²½í—˜ ì •ë¦¬
                    await self._consolidate_experiences()
                
                elif current_level == IdleLevel.MEDIUM:
                    # 30ë¶„-1ì‹œê°„: ë¶€ë¶„ í•™ìŠµ
                    await self._partial_update()
                
                elif current_level == IdleLevel.LONG:
                    # 1ì‹œê°„+: ì „ì²´ ë°°ì¹˜ í•™ìŠµ
                    await self._batch_regret_learning()
                
                elif current_level == IdleLevel.OVERNIGHT:
                    # 8ì‹œê°„+: ëŒ€ê·œëª¨ ì¬í•™ìŠµ
                    await self._deep_retrospective_learning()
                
            except asyncio.CancelledError:
                logger.info("ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì·¨ì†Œë¨")
                break
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ ëŒ€ê¸°
    
    async def _immediate_cleanup(self):
        """ì¦‰ì‹œ ì •ë¦¬ (1-10ë¶„ ìœ íœ´)"""
        logger.info("ğŸ“§ ì¦‰ì‹œ ì •ë¦¬ ì‹œì‘...")
        
        # ì¤‘ë³µ ì œê±°
        unique_regrets = {}
        for regret in self.regret_buffer:
            key = json.dumps(regret.decision, sort_keys=True)
            if key not in unique_regrets or regret.regret_score > unique_regrets[key].regret_score:
                unique_regrets[key] = regret
        
        # ë²„í¼ ì—…ë°ì´íŠ¸
        self.regret_buffer = deque(unique_regrets.values(), maxlen=self.regret_buffer.maxlen)
        
        logger.info(f"   ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(unique_regrets)}ê°œ í•­ëª©")
    
    async def _consolidate_experiences(self):
        """ê²½í—˜ ì •ë¦¬ (10-30ë¶„ ìœ íœ´)"""
        logger.info("ğŸ’¾ ê²½í—˜ ì •ë¦¬ ì‹œì‘...")
        
        if not self.experience_cache:
            return
        
        # ìœ ì‚¬í•œ ê²½í—˜ ê·¸ë£¹í™”
        experience_groups = {}
        for exp in self.experience_cache:
            # ê°„ë‹¨í•œ í•´ì‹œ í‚¤ ìƒì„±
            key = f"{exp.get('emotion', {}).get('dominant', 'unknown')}_{exp.get('bentham', {}).get('intensity', 0):.1f}"
            if key not in experience_groups:
                experience_groups[key] = []
            experience_groups[key].append(exp)
        
        # ê·¸ë£¹ë³„ ëŒ€í‘œ ê²½í—˜ ì¶”ì¶œ
        consolidated = []
        for group in experience_groups.values():
            # í‰ê·  ë˜ëŠ” ê°€ì¥ ìµœê·¼ ê²½í—˜ì„ ëŒ€í‘œë¡œ
            if group:
                consolidated.append(group[-1])  # ê°€ì¥ ìµœê·¼ ê²ƒ
        
        # ìºì‹œ ì—…ë°ì´íŠ¸
        self.experience_cache = deque(consolidated, maxlen=self.experience_cache.maxlen)
        
        logger.info(f"   ê²½í—˜ ì •ë¦¬ ì™„ë£Œ: {len(experience_groups)}ê°œ ê·¸ë£¹ â†’ {len(consolidated)}ê°œ ëŒ€í‘œ")
    
    async def _partial_update(self):
        """ë¶€ë¶„ í•™ìŠµ (30ë¶„-1ì‹œê°„ ìœ íœ´)"""
        logger.info("ğŸ“š ë¶€ë¶„ í•™ìŠµ ì‹œì‘...")
        
        self.is_learning = True
        session = LearningSession(
            session_id=f"partial_{int(time.time())}",
            start_time=datetime.now(),
            learning_type="partial",
            total_items=min(50, len(self.regret_buffer))
        )
        self.current_session = session
        
        try:
            # ìµœê·¼ 50ê°œ í•­ëª©ë§Œ í•™ìŠµ
            items_to_learn = list(self.regret_buffer)[-50:]
            
            for i, regret_item in enumerate(items_to_learn):
                if not regret_item.learned:
                    # ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
                    await self._learn_from_regret(regret_item)
                    regret_item.learned = True
                    session.items_processed += 1
                    
                    # ì£¼ê¸°ì ìœ¼ë¡œ ìœ íœ´ ìƒíƒœ ì²´í¬
                    if i % 10 == 0:
                        if self.get_idle_level() == IdleLevel.ACTIVE:
                            logger.info("   ì‚¬ìš©ì í™œë™ ê°ì§€ - í•™ìŠµ ì¤‘ë‹¨")
                            break
                    
                    await asyncio.sleep(0.1)  # ë¹„ë™ê¸° ì²˜ë¦¬
            
            session.end_time = datetime.now()
            session.status = "completed"
            self.stats['total_items_learned'] += session.items_processed
            
            logger.info(f"   ë¶€ë¶„ í•™ìŠµ ì™„ë£Œ: {session.items_processed}ê°œ í•­ëª©")
            
        except Exception as e:
            logger.error(f"   ë¶€ë¶„ í•™ìŠµ ì‹¤íŒ¨: {e}")
            session.status = "failed"
        finally:
            self.is_learning = False
            self.learning_sessions.append(session)
            self.current_session = None
    
    async def _batch_regret_learning(self):
        """ë°°ì¹˜ í›„íšŒ í•™ìŠµ (1ì‹œê°„+ ìœ íœ´)"""
        logger.info("ğŸ“ ë°°ì¹˜ í›„íšŒ í•™ìŠµ ì‹œì‘...")
        
        self.is_learning = True
        session = LearningSession(
            session_id=f"batch_{int(time.time())}",
            start_time=datetime.now(),
            learning_type="batch",
            total_items=len(self.regret_buffer)
        )
        self.current_session = session
        
        try:
            # ìš°ì„ ìˆœìœ„ í•­ëª©ë¶€í„° í•™ìŠµ
            all_items = self.priority_regrets + list(self.regret_buffer)
            unique_items = {id(item): item for item in all_items}.values()
            
            batch_size = 32
            batches = [list(unique_items)[i:i+batch_size] 
                      for i in range(0, len(unique_items), batch_size)]
            
            for batch_idx, batch in enumerate(batches):
                # ë°°ì¹˜ í•™ìŠµ
                await self._learn_batch(batch)
                session.items_processed += len(batch)
                
                # ìœ íœ´ ìƒíƒœ ì²´í¬
                if self.get_idle_level() == IdleLevel.ACTIVE:
                    logger.info("   ì‚¬ìš©ì í™œë™ ê°ì§€ - ë°°ì¹˜ í•™ìŠµ ì¤‘ë‹¨")
                    break
                
                # ì§„í–‰ìƒí™© ë¡œê¹…
                if batch_idx % 5 == 0:
                    progress = (session.items_processed / session.total_items) * 100
                    logger.info(f"   ì§„í–‰ë¥ : {progress:.1f}% ({session.items_processed}/{session.total_items})")
                
                await asyncio.sleep(1)  # ë°°ì¹˜ ê°„ ëŒ€ê¸°
            
            # í•™ìŠµ í›„ ë²„í¼ ì •ë¦¬
            learned_items = [item for item in self.regret_buffer if item.learned]
            if len(learned_items) > len(self.regret_buffer) * 0.8:
                # 80% ì´ìƒ í•™ìŠµë¨ - ë²„í¼ ì´ˆê¸°í™”
                self.regret_buffer.clear()
                logger.info("   í›„íšŒ ë²„í¼ ì´ˆê¸°í™”")
            
            session.end_time = datetime.now()
            session.status = "completed"
            self.stats['total_sessions'] += 1
            self.stats['total_items_learned'] += session.items_processed
            self.stats['last_learning'] = datetime.now()
            
            logger.info(f"   ë°°ì¹˜ í•™ìŠµ ì™„ë£Œ: {session.items_processed}ê°œ í•­ëª©")
            
        except Exception as e:
            logger.error(f"   ë°°ì¹˜ í•™ìŠµ ì‹¤íŒ¨: {e}")
            session.status = "failed"
        finally:
            self.is_learning = False
            self.learning_sessions.append(session)
            self.current_session = None
    
    async def _deep_retrospective_learning(self):
        """ëŒ€ê·œëª¨ íšŒê³  í•™ìŠµ (8ì‹œê°„+ ìœ íœ´)"""
        logger.info("ğŸŒ™ ëŒ€ê·œëª¨ íšŒê³  í•™ìŠµ ì‹œì‘...")
        
        self.is_learning = True
        session = LearningSession(
            session_id=f"deep_{int(time.time())}",
            start_time=datetime.now(),
            learning_type="deep_retrospective",
            total_items=len(self.regret_buffer) + len(self.experience_cache)
        )
        self.current_session = session
        
        try:
            # 1. ëª¨ë“  í›„íšŒ ì¬í‰ê°€
            logger.info("   1ë‹¨ê³„: í›„íšŒ ì¬í‰ê°€...")
            for regret in self.regret_buffer:
                await self._reevaluate_regret(regret)
                session.items_processed += 1
            
            # 2. ê²½í—˜ íŒ¨í„´ ë¶„ì„
            logger.info("   2ë‹¨ê³„: ê²½í—˜ íŒ¨í„´ ë¶„ì„...")
            patterns = await self._analyze_experience_patterns()
            session.metrics['patterns_found'] = len(patterns)
            
            # 3. ë©”íƒ€ í•™ìŠµ
            logger.info("   3ë‹¨ê³„: ë©”íƒ€ í•™ìŠµ...")
            meta_insights = await self._meta_learning(patterns)
            session.metrics['meta_insights'] = len(meta_insights)
            
            # 4. ì •ì±… ì—…ë°ì´íŠ¸
            logger.info("   4ë‹¨ê³„: ì •ì±… ì—…ë°ì´íŠ¸...")
            await self._update_policies(meta_insights)
            
            session.end_time = datetime.now()
            session.status = "completed"
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            learning_time = (session.end_time - session.start_time).total_seconds()
            self.stats['total_learning_time'] += learning_time
            
            logger.info(f"   ëŒ€ê·œëª¨ íšŒê³  í•™ìŠµ ì™„ë£Œ")
            logger.info(f"   - ì²˜ë¦¬ í•­ëª©: {session.items_processed}")
            logger.info(f"   - ë°œê²¬ íŒ¨í„´: {session.metrics.get('patterns_found', 0)}")
            logger.info(f"   - ë©”íƒ€ ì¸ì‚¬ì´íŠ¸: {session.metrics.get('meta_insights', 0)}")
            logger.info(f"   - ì†Œìš” ì‹œê°„: {learning_time/60:.1f}ë¶„")
            
        except Exception as e:
            logger.error(f"   ëŒ€ê·œëª¨ íšŒê³  í•™ìŠµ ì‹¤íŒ¨: {e}")
            session.status = "failed"
        finally:
            self.is_learning = False
            self.learning_sessions.append(session)
            self.current_session = None
    
    async def _learn_from_regret(self, regret_item: RegretMemory):
        """ë‹¨ì¼ í›„íšŒ í•­ëª©ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        # ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.01)
        
        # í›„íšŒ ì ìˆ˜ ê°ì†Œ (í•™ìŠµ íš¨ê³¼)
        regret_item.regret_score *= 0.9
        self.stats['regret_reduction'].append(regret_item.regret_score)
    
    async def _learn_batch(self, batch: List[RegretMemory]):
        """ë°°ì¹˜ í•™ìŠµ"""
        # ë°°ì¹˜ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.1 * len(batch))
        
        for item in batch:
            item.learned = True
            item.regret_score *= 0.85  # ë°°ì¹˜ í•™ìŠµì´ ë” íš¨ê³¼ì 
    
    async def _reevaluate_regret(self, regret_item: RegretMemory):
        """í›„íšŒ ì¬í‰ê°€"""
        # ì‹œê°„ì´ ì§€ë‚œ í›„íšŒëŠ” ì¤‘ìš”ë„ ê°ì†Œ
        age_days = (datetime.now() - regret_item.timestamp).days
        if age_days > 7:
            regret_item.regret_score *= 0.7
    
    async def _analyze_experience_patterns(self) -> List[Dict]:
        """ê²½í—˜ íŒ¨í„´ ë¶„ì„"""
        patterns = []
        
        # ê°„ë‹¨í•œ íŒ¨í„´ ì¶”ì¶œ ì‹œë®¬ë ˆì´ì…˜
        if len(self.experience_cache) > 10:
            pattern = {
                'type': 'recurring_emotion',
                'confidence': 0.8,
                'description': 'ë°˜ë³µë˜ëŠ” ê°ì • íŒ¨í„´ ë°œê²¬'
            }
            patterns.append(pattern)
        
        return patterns
    
    async def _meta_learning(self, patterns: List[Dict]) -> List[Dict]:
        """ë©”íƒ€ í•™ìŠµ"""
        insights = []
        
        for pattern in patterns:
            insight = {
                'pattern': pattern,
                'learning': f"{pattern['type']}ì— ëŒ€í•œ ê°œì„  ì „ëµ",
                'priority': pattern['confidence']
            }
            insights.append(insight)
        
        return insights
    
    async def _update_policies(self, insights: List[Dict]):
        """ì •ì±… ì—…ë°ì´íŠ¸"""
        # ì •ì±… ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
        for insight in insights:
            logger.debug(f"ì •ì±… ì—…ë°ì´íŠ¸: {insight['learning']}")
    
    def get_status(self) -> Dict:
        """í˜„ì¬ ìƒíƒœ ë°˜í™˜"""
        return {
            'idle_level': self.current_idle_level.value,
            'idle_seconds': time.time() - self.last_interaction_time,
            'is_learning': self.is_learning,
            'current_session': self.current_session.to_dict() if self.current_session else None,
            'regret_buffer_size': len(self.regret_buffer),
            'priority_regrets': len(self.priority_regrets),
            'experience_cache_size': len(self.experience_cache),
            'stats': self.stats
        }
    
    def save_state(self, filepath: Path):
        """ìƒíƒœ ì €ì¥"""
        state = {
            'regret_buffer': [r.to_dict() for r in self.regret_buffer],
            'priority_regrets': [r.to_dict() for r in self.priority_regrets],
            'experience_cache': list(self.experience_cache),
            'stats': self.stats,
            'learning_sessions': [s.__dict__ for s in self.learning_sessions[-100:]]  # ìµœê·¼ 100ê°œ
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(state, f)
        
        logger.info(f"ìƒíƒœ ì €ì¥: {filepath}")
    
    def load_state(self, filepath: Path):
        """ìƒíƒœ ë¡œë“œ"""
        if not filepath.exists():
            logger.warning(f"ìƒíƒœ íŒŒì¼ ì—†ìŒ: {filepath}")
            return
        
        with open(filepath, 'rb') as f:
            state = pickle.load(f)
        
        # ë³µì›
        self.regret_buffer = deque(
            [RegretMemory(**r) for r in state['regret_buffer']], 
            maxlen=self.regret_buffer.maxlen
        )
        self.priority_regrets = [RegretMemory(**r) for r in state['priority_regrets']]
        self.experience_cache = deque(state['experience_cache'], maxlen=self.experience_cache.maxlen)
        self.stats = state['stats']
        
        logger.info(f"ìƒíƒœ ë¡œë“œ: {filepath}")


# ì‚¬ìš© ì˜ˆì œ
async def example_usage():
    """ì‚¬ìš© ì˜ˆì œ"""
    
    # í•™ìŠµê¸° ìƒì„±
    learner = HierarchicalIdleLearner()
    
    # ëª¨ë‹ˆí„°ë§ ì‹œì‘
    await learner.start_monitoring()
    
    # í›„íšŒ ë©”ëª¨ë¦¬ ì¶”ê°€ ì˜ˆì œ
    for i in range(5):
        regret = RegretMemory(
            timestamp=datetime.now(),
            decision={'action': f'decision_{i}'},
            actual_outcome={'result': 'bad'},
            predicted_outcome={'result': 'good'},
            regret_score=0.5 + i * 0.1
        )
        learner.add_regret(regret)
    
    # ê²½í—˜ ì¶”ê°€ ì˜ˆì œ
    for i in range(3):
        experience = {
            'emotion': {'valence': 0.5, 'arousal': 0.3},
            'bentham': {'intensity': 0.6},
            'outcome': 'positive'
        }
        learner.add_experience(experience)
    
    # ìƒí˜¸ì‘ìš© ì‹œë®¬ë ˆì´ì…˜
    print("ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
    for minute in range(10):
        print(f"\në¶„ {minute}:")
        
        # ì²˜ìŒ 2ë¶„ì€ í™œë™
        if minute < 2:
            learner.record_interaction()
            print("  ì‚¬ìš©ì í™œë™ ì¤‘...")
        
        # ìƒíƒœ ì¶œë ¥
        status = learner.get_status()
        print(f"  ìœ íœ´ ë ˆë²¨: {status['idle_level']}")
        print(f"  ìœ íœ´ ì‹œê°„: {status['idle_seconds']:.0f}ì´ˆ")
        print(f"  í•™ìŠµ ì¤‘: {status['is_learning']}")
        
        await asyncio.sleep(1)  # ì‹¤ì œë¡œëŠ” 60ì´ˆ
    
    # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
    await learner.stop_monitoring()
    
    # ìµœì¢… í†µê³„
    print("\nìµœì¢… í†µê³„:")
    print(f"  ì´ ì„¸ì…˜: {learner.stats['total_sessions']}")
    print(f"  í•™ìŠµ í•­ëª©: {learner.stats['total_items_learned']}")
    print(f"  ì´ í•™ìŠµ ì‹œê°„: {learner.stats['total_learning_time']:.1f}ì´ˆ")


if __name__ == '__main__':
    asyncio.run(example_usage())