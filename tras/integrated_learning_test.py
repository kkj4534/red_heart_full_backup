"""
í†µí•©ëœ Red Heart ì‹œìŠ¤í…œ GPU í•™ìŠµ í…ŒìŠ¤íŠ¸
Integrated Red Heart System GPU Learning Test

í˜„ì¬ í†µí•©ëœ ëª¨ë“  ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë°ì´í„°ë¡œ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì§„í–‰
"""

import os
import sys
import json
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import logging
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
import asyncio

# í˜„ì¬ í”„ë¡œì íŠ¸ì˜ í†µí•©ëœ ëª¨ë“ˆë“¤ ì„í¬íŠ¸
try:
    from config import DEVICE, ADVANCED_CONFIG, DATA_DIR
    from data_models import EmotionData, EmotionState, EmotionIntensity
    from emotion_ethics_regret_circuit import EmotionEthicsRegretCircuit, CircuitDecisionContext
    from ethics_policy_updater import EthicsPolicyUpdater, EthicsExperience
    from phase_controller import PhaseController, PhaseDecisionContext, Phase
    from xai_feedback_integrator import XAIFeedbackIntegrator, XAIInterpretation
    from fuzzy_emotion_ethics_mapper import FuzzyEmotionEthicsMapper
    from deep_multi_dimensional_ethics_system import DeepMultiDimensionalEthicsSystem, EthicalDilemma, StakeholderPerspective
    from temporal_event_propagation_analyzer import TemporalEventPropagationAnalyzer, TemporalEvent
    from integrated_system_orchestrator import IntegratedSystemOrchestrator, IntegrationContext
    
    # ì—…ê·¸ë ˆì´ë“œëœ ì‹œìŠ¤í…œ ì„í¬íŠ¸
    from dynamic_gpu_manager import get_gpu_manager, allocate_gpu_memory, optimize_gpu_for_learning
    from robust_logging_system import get_robust_logger, test_session, add_performance_sample
    
    print("âœ… ëª¨ë“  í†µí•© ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")
    print("âœ… ë™ì  GPU ê´€ë¦¬ì ë° ê²¬ê³ í•œ ë¡œê¹… ì‹œìŠ¤í…œ ì—°ë™ ì™„ë£Œ")
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('IntegratedLearningTest')

@dataclass
class LearningConfig:
    """í•™ìŠµ ì„¤ì •"""
    batch_size: int = 8
    learning_rate: float = 0.001
    num_epochs: int = 10
    device: str = str(DEVICE)
    use_gpu: bool = ADVANCED_CONFIG.get('enable_gpu', False)
    validation_split: float = 0.2
    early_stopping_patience: int = 3

@dataclass
class TestResults:
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    accuracy: float
    loss: float
    prediction_error: float
    processing_time: float
    gpu_utilization: float
    memory_usage: float

class IntegratedLearningFramework:
    """í†µí•© í•™ìŠµ í”„ë ˆì„ì›Œí¬ - ì—…ê·¸ë ˆì´ë“œëœ GPU ê´€ë¦¬ ë° ë¡œê¹…"""
    
    def __init__(self, config: LearningConfig):
        self.config = config
        self.logger = logger
        
        # ì—…ê·¸ë ˆì´ë“œëœ GPU ê´€ë¦¬ì ë° ë¡œê¹… ì‹œìŠ¤í…œ ì—°ë™
        self.gpu_manager = get_gpu_manager()
        self.robust_logger = get_robust_logger()
        
        # GPU ìƒíƒœ í™•ì¸ ë° ìµœì í™”
        self.device = torch.device(config.device)
        
        if config.use_gpu and torch.cuda.is_available():
            # GPU í•™ìŠµ ìµœì í™” í™œì„±í™”
            optimization_success = optimize_gpu_for_learning()
            
            gpu_status = self.gpu_manager.get_memory_status()
            self.logger.info(f"ğŸš€ GPU ì‚¬ìš©: {torch.cuda.get_device_name()}")
            self.logger.info(f"ğŸ’¾ ì´ GPU ë©”ëª¨ë¦¬: {gpu_status['total_gb']:.1f}GB")
            self.logger.info(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {gpu_status['available_gb']:.1f}GB")
            self.logger.info(f"âš¡ í•™ìŠµ ìµœì í™”: {'í™œì„±í™”' if optimization_success else 'ì œí•œë¨'}")
            
            self.robust_logger.log("INFO", "GPU_Manager", 
                                 f"GPU í•™ìŠµ í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ - ìµœì í™”: {optimization_success}",
                                 {"gpu_status": gpu_status})
        else:
            self.logger.info("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")
            self.robust_logger.log("INFO", "GPU_Manager", "CPU ëª¨ë“œë¡œ ì‹¤í–‰")
        
        # í†µí•©ëœ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
        self.initialize_components()
        
        # í•™ìŠµ ë°ì´í„° ì €ì¥ì†Œ
        self.training_data = []
        self.validation_data = []
        
        # ì„±ëŠ¥ ì¶”ì  - í–¥ìƒëœ ì¶”ì 
        self.training_history = {
            'loss': [],
            'accuracy': [],
            'gpu_memory': [],
            'processing_time': [],
            'gpu_utilization': [],
            'memory_efficiency': []
        }
    
    def initialize_components(self):
        """í†µí•© ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        self.logger.info("ğŸ—ï¸ í†µí•© ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”...")
        
        try:
            # í•µì‹¬ íšŒë¡œ
            self.emotion_circuit = EmotionEthicsRegretCircuit()
            self.logger.info("âœ… ê°ì •-ìœ¤ë¦¬-í›„íšŒ ì‚¼ê°íšŒë¡œ ì´ˆê¸°í™”")
            
            # ì •ì±… ì—…ë°ì´í„°
            self.policy_updater = EthicsPolicyUpdater()
            self.logger.info("âœ… ìœ¤ë¦¬ ì •ì±… ì—…ë°ì´í„° ì´ˆê¸°í™”")
            
            # í˜ì´ì¦ˆ ì»¨íŠ¸ë¡¤ëŸ¬
            self.phase_controller = PhaseController()
            self.logger.info("âœ… í˜ì´ì¦ˆ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™”")
            
            # XAI í”¼ë“œë°± í†µí•©ê¸°
            self.xai_integrator = XAIFeedbackIntegrator()
            self.logger.info("âœ… XAI í”¼ë“œë°± í†µí•©ê¸° ì´ˆê¸°í™”")
            
            # í¼ì§€ ë§¤í•‘
            self.fuzzy_mapper = FuzzyEmotionEthicsMapper()
            self.logger.info("âœ… í¼ì§€ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ ì´ˆê¸°í™”")
            
            # ë‹¤ì°¨ì› ìœ¤ë¦¬ ì‹œìŠ¤í…œ
            self.ethics_system = DeepMultiDimensionalEthicsSystem()
            self.logger.info("âœ… ë‹¤ì°¨ì› ìœ¤ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
            
            # ì‹œê³„ì—´ ë¶„ì„ê¸°
            self.temporal_analyzer = TemporalEventPropagationAnalyzer()
            self.logger.info("âœ… ì‹œê³„ì—´ ì‚¬ê±´ ì „íŒŒ ë¶„ì„ê¸° ì´ˆê¸°í™”")
            
            # í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
            self.orchestrator = IntegratedSystemOrchestrator()
            self.logger.info("âœ… í†µí•© ì‹œìŠ¤í…œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”")
            
            self.logger.info("ğŸ¯ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            self.logger.error(f"âŒ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def load_training_data(self, data_dir: Path = None) -> int:
        """í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        if data_dir is None:
            data_dir = DATA_DIR / 'decision_logs'
        
        self.logger.info(f"ğŸ“‚ ë°ì´í„° ë¡œë”© ì‹œì‘: {data_dir}")
        
        json_files = list(data_dir.glob("*.json"))
        self.logger.info(f"ğŸ“„ ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ")
        
        loaded_count = 0
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ë°ì´í„° ê²€ì¦ ë° ë³€í™˜
                if self.validate_data_format(data):
                    processed_data = self.preprocess_data(data)
                    self.training_data.append(processed_data)
                    loaded_count += 1
                    
            except Exception as e:
                self.logger.warning(f"âš ï¸ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨ {json_file.name}: {e}")
        
        # í•™ìŠµ/ê²€ì¦ ë¶„í• 
        if self.training_data:
            split_idx = int(len(self.training_data) * (1 - self.config.validation_split))
            self.validation_data = self.training_data[split_idx:]
            self.training_data = self.training_data[:split_idx]
        
        self.logger.info(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: í•™ìŠµ {len(self.training_data)}ê°œ, ê²€ì¦ {len(self.validation_data)}ê°œ")
        return loaded_count
    
    def validate_data_format(self, data: Dict) -> bool:
        """ë°ì´í„° í˜•ì‹ ê²€ì¦"""
        required_fields = ['situation', 'decision', 'actual_outcome']
        return all(field in data for field in required_fields)
    
    def preprocess_data(self, raw_data: Dict) -> Dict:
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        situation = raw_data['situation']
        decision = raw_data['decision']
        outcome = raw_data['actual_outcome']
        
        # ê°ì • ë°ì´í„° ë³€í™˜
        emotion_data = EmotionData(
            primary_emotion=EmotionState[raw_data['emotions']['primary_emotion']],
            intensity=EmotionIntensity[raw_data['emotions']['intensity']],
            valence=raw_data['emotions']['valence'],
            arousal=raw_data['emotions']['arousal'],
            confidence=raw_data['emotions']['confidence']
        )
        
        # ì´í•´ê´€ê³„ì ì¶”ì¶œ
        stakeholders = []
        for person in situation['context']['people_involved']:
            stakeholder = StakeholderPerspective(
                stakeholder_id=person.replace(' ', '_'),
                name=person,
                role='participant',
                power_level=0.5,
                vulnerability=0.5
            )
            stakeholders.append(stakeholder)
        
        # ìœ¤ë¦¬ì  ë”œë ˆë§ˆ êµ¬ì„±
        ethical_dilemma = EthicalDilemma(
            dilemma_id=situation['id'],
            scenario=situation['description'],
            context=situation['context']['location'],
            stakeholders=stakeholders,
            available_options=[opt['text'] for opt in situation['options']]
        )
        
        return {
            'input': {
                'emotion': emotion_data,
                'dilemma': ethical_dilemma,
                'situation': situation,
                'hedonic_values': raw_data['hedonic_values']
            },
            'target': {
                'chosen_option': decision['choice'],
                'hedonic_prediction': decision['predicted_outcome']['hedonic_value'],
                'actual_hedonic': outcome['hedonic_value'],
                'actual_emotion': EmotionState[outcome['primary_emotion']],
                'regret': raw_data.get('regret_data', {}).get('intensity', 0.0)
            }
        }
    
    async def train_integrated_system(self) -> Dict[str, Any]:
        """í†µí•© ì‹œìŠ¤í…œ í•™ìŠµ"""
        self.logger.info("ğŸš€ í†µí•© ì‹œìŠ¤í…œ í•™ìŠµ ì‹œì‘")
        
        start_time = time.time()
        best_loss = float('inf')
        patience_counter = 0
        
        # í•™ìŠµ ë£¨í”„
        for epoch in range(self.config.num_epochs):
            epoch_start = time.time()
            
            # GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
            if self.config.use_gpu:
                torch.cuda.empty_cache()
                initial_memory = torch.cuda.memory_allocated()
            
            # ë°°ì¹˜ í•™ìŠµ
            train_loss, train_accuracy = await self.train_epoch(epoch)
            val_loss, val_accuracy = await self.validate_epoch(epoch)
            
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡
            if self.config.use_gpu:
                memory_used = torch.cuda.memory_allocated() - initial_memory
                self.training_history['gpu_memory'].append(memory_used / 1e6)  # MB
            
            epoch_time = time.time() - epoch_start
            
            # íˆìŠ¤í† ë¦¬ ê¸°ë¡
            self.training_history['loss'].append(train_loss)
            self.training_history['accuracy'].append(train_accuracy)
            self.training_history['processing_time'].append(epoch_time)
            
            self.logger.info(
                f"Epoch {epoch+1}/{self.config.num_epochs} - "
                f"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, "
                f"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, "
                f"Time: {epoch_time:.2f}s"
            )
            
            # Early stopping
            if val_loss < best_loss:
                best_loss = val_loss
                patience_counter = 0
            else:
                patience_counter += 1
                if patience_counter >= self.config.early_stopping_patience:
                    self.logger.info(f"ğŸ›‘ Early stopping at epoch {epoch+1}")
                    break
        
        total_time = time.time() - start_time
        
        # í•™ìŠµ ê²°ê³¼ ìš”ì•½
        results = {
            'total_training_time': total_time,
            'final_train_loss': train_loss,
            'final_train_accuracy': train_accuracy,
            'final_val_loss': val_loss,
            'final_val_accuracy': val_accuracy,
            'best_loss': best_loss,
            'epochs_completed': epoch + 1,
            'training_history': self.training_history
        }
        
        self.logger.info(f"âœ… í•™ìŠµ ì™„ë£Œ - ì´ ì‹œê°„: {total_time:.2f}ì´ˆ, ìµœì¢… ì •í™•ë„: {train_accuracy:.4f}")
        return results
    
    async def train_epoch(self, epoch: int) -> Tuple[float, float]:
        """ì—í¬í¬ í•™ìŠµ"""
        total_loss = 0.0
        total_accuracy = 0.0
        batch_count = 0
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for i in range(0, len(self.training_data), self.config.batch_size):
            batch_data = self.training_data[i:i + self.config.batch_size]
            
            batch_loss, batch_acc = await self.process_batch(batch_data, training=True)
            
            total_loss += batch_loss
            total_accuracy += batch_acc
            batch_count += 1
        
        return total_loss / batch_count, total_accuracy / batch_count
    
    async def validate_epoch(self, epoch: int) -> Tuple[float, float]:
        """ì—í¬í¬ ê²€ì¦"""
        if not self.validation_data:
            return 0.0, 0.0
        
        total_loss = 0.0
        total_accuracy = 0.0
        batch_count = 0
        
        # ê²€ì¦ ë°°ì¹˜ ì²˜ë¦¬
        for i in range(0, len(self.validation_data), self.config.batch_size):
            batch_data = self.validation_data[i:i + self.config.batch_size]
            
            batch_loss, batch_acc = await self.process_batch(batch_data, training=False)
            
            total_loss += batch_loss
            total_accuracy += batch_acc
            batch_count += 1
        
        return total_loss / batch_count, total_accuracy / batch_count
    
    async def process_batch(self, batch_data: List[Dict], training: bool = True) -> Tuple[float, float]:
        """ë°°ì¹˜ ì²˜ë¦¬"""
        batch_losses = []
        batch_accuracies = []
        
        for data_point in batch_data:
            try:
                # í†µí•© ì‹œìŠ¤í…œìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
                prediction = await self.run_integrated_prediction(data_point['input'])
                
                # ì†ì‹¤ ê³„ì‚°
                loss = self.calculate_loss(prediction, data_point['target'])
                
                # ì •í™•ë„ ê³„ì‚°
                accuracy = self.calculate_accuracy(prediction, data_point['target'])
                
                batch_losses.append(loss)
                batch_accuracies.append(accuracy)
                
                # í•™ìŠµ ë‹¨ê³„ì—ì„œ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
                if training:
                    await self.update_system_components(data_point, prediction)
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        return (
            np.mean(batch_losses) if batch_losses else 0.0,
            np.mean(batch_accuracies) if batch_accuracies else 0.0
        )
    
    async def run_integrated_prediction(self, input_data: Dict) -> Dict:
        """í†µí•© ì‹œìŠ¤í…œ ì˜ˆì¸¡ ì‹¤í–‰"""
        
        # 1. ê°ì •-ìœ¤ë¦¬-í›„íšŒ íšŒë¡œ ì²˜ë¦¬
        circuit_context = CircuitDecisionContext(
            scenario_text=input_data['dilemma'].scenario,
            proposed_action="ìœ¤ë¦¬ì  ì˜ì‚¬ê²°ì •",
            self_emotion=input_data['emotion'],
            stakeholders=[s.name for s in input_data['dilemma'].stakeholders]
        )
        
        circuit_result = await self.emotion_circuit.process_ethical_decision(circuit_context)
        
        # 2. ë‹¤ì°¨ì› ìœ¤ë¦¬ ë¶„ì„
        ethics_result = self.ethics_system.comprehensive_ethical_analysis(input_data['dilemma'])
        
        # 3. í¼ì§€ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘
        fuzzy_result = self.fuzzy_mapper.map_emotion_to_ethics(input_data['emotion'])
        
        # 4. ì‹œê³„ì—´ ì´ë²¤íŠ¸ ë“±ë¡ ë° ì˜ˆì¸¡
        temporal_event = TemporalEvent(
            event_id=f"decision_{int(time.time())}",
            timestamp=time.time(),
            event_type="ethical_decision",
            description=input_data['dilemma'].scenario,
            emotion_state=input_data['emotion']
        )
        self.temporal_analyzer.register_event(temporal_event)
        
        # í†µí•© ì˜ˆì¸¡ ê²°ê³¼
        prediction = {
            'ethical_score': circuit_result.final_ethical_score,
            'confidence': circuit_result.confidence,
            'ethics_weights': ethics_result.school_reasonings,
            'fuzzy_mapping': fuzzy_result.ethics_weights,
            'predicted_regret': circuit_result.predicted_regret.get('anticipated_regret', 0.0),
            'temporal_prediction': 0.5  # ê°„ë‹¨í™”ëœ ì˜ˆì¸¡ê°’
        }
        
        return prediction
    
    def calculate_loss(self, prediction: Dict, target: Dict) -> float:
        """ì†ì‹¤ ê³„ì‚°"""
        # ë‹¤ì¤‘ ëª©í‘œ ì†ì‹¤ í•¨ìˆ˜
        ethical_score_loss = abs(prediction['ethical_score'] - target['actual_hedonic'])
        regret_loss = abs(prediction['predicted_regret'] - target['regret'])
        
        # ê°€ì¤‘ í‰ê· 
        total_loss = ethical_score_loss * 0.7 + regret_loss * 0.3
        return total_loss
    
    def calculate_accuracy(self, prediction: Dict, target: Dict) -> float:
        """ì •í™•ë„ ê³„ì‚°"""
        # ìœ¤ë¦¬ì  ì ìˆ˜ ì˜ˆì¸¡ ì •í™•ë„
        score_accuracy = 1.0 - abs(prediction['ethical_score'] - target['actual_hedonic'])
        
        # í›„íšŒ ì˜ˆì¸¡ ì •í™•ë„
        regret_accuracy = 1.0 - abs(prediction['predicted_regret'] - target['regret'])
        
        # í‰ê·  ì •í™•ë„
        return (score_accuracy + regret_accuracy) / 2.0
    
    async def update_system_components(self, data_point: Dict, prediction: Dict):
        """ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            # ìœ¤ë¦¬ ì •ì±… ì—…ë°ì´íŠ¸
            experience = EthicsExperience(
                experience_id=f"exp_{int(time.time())}",
                scenario=data_point['input']['dilemma'].scenario,
                decision_made=data_point['target']['chosen_option'],
                outcome_rating=data_point['target']['actual_hedonic'],
                emotion_state=data_point['input']['emotion'],
                stakeholders=[s.name for s in data_point['input']['dilemma'].stakeholders],
                cultural_context="korean",
                decision_urgency=0.5,
                actual_regret=data_point['target']['regret'],
                user_satisfaction=0.7,
                moral_correctness=0.8
            )
            
            self.policy_updater.add_experience(experience)
            
            # XAI í”¼ë“œë°± í†µí•©
            xai_interpretation = XAIInterpretation(
                interpretation_id=f"interp_{int(time.time())}",
                decision_id=f"decision_{int(time.time())}",
                feature_importance={
                    'ethical_score': prediction['ethical_score'],
                    'confidence': prediction['confidence']
                },
                explanation_confidence=prediction['confidence']
            )
            
            # ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤
            system_components = {
                'emotion_circuit': self.emotion_circuit,
                'policy_updater': self.policy_updater,
                'fuzzy_mapper': self.fuzzy_mapper
            }
            
            self.xai_integrator.integrate_xai_feedback(xai_interpretation, system_components)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_system_analytics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë¶„ì„ ì •ë³´"""
        return {
            'emotion_circuit_status': self.emotion_circuit.get_circuit_status(),
            'policy_analytics': self.policy_updater.get_analytics(),
            'phase_analytics': self.phase_controller.get_analytics(),
            'xai_analytics': self.xai_integrator.get_feedback_analytics(),
            'fuzzy_analytics': self.fuzzy_mapper.get_mapping_analytics(),
            'ethics_analytics': self.ethics_system.get_ethics_analytics(),
            'temporal_analytics': self.temporal_analyzer.get_analytics_dashboard(),
            'training_history': self.training_history
        }

async def run_learning_test():
    """í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("ğŸ¯ í†µí•© Red Heart ì‹œìŠ¤í…œ GPU í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ì„¤ì •
    config = LearningConfig(
        batch_size=4,  # ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ ì‘ì€ ë°°ì¹˜
        learning_rate=0.001,
        num_epochs=10,
        use_gpu=ADVANCED_CONFIG.get('enable_gpu', False)
    )
    
    # í•™ìŠµ í”„ë ˆì„ì›Œí¬ ì´ˆê¸°í™”
    framework = IntegratedLearningFramework(config)
    
    # ë°ì´í„° ë¡œë“œ
    data_count = framework.load_training_data()
    if data_count == 0:
        logger.error("âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°: {data_count}ê°œ")
    
    # í•™ìŠµ ì‹¤í–‰
    results = await framework.train_integrated_system()
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info("ğŸ“ˆ í•™ìŠµ ê²°ê³¼:")
    logger.info(f"- ì´ í•™ìŠµ ì‹œê°„: {results['total_training_time']:.2f}ì´ˆ")
    logger.info(f"- ìµœì¢… ì •í™•ë„: {results['final_train_accuracy']:.4f}")
    logger.info(f"- ìµœì¢… ì†ì‹¤: {results['final_train_loss']:.4f}")
    logger.info(f"- ì™„ë£Œëœ ì—í¬í¬: {results['epochs_completed']}")
    
    # ì‹œìŠ¤í…œ ë¶„ì„
    analytics = framework.get_system_analytics()
    logger.info("ğŸ” ì‹œìŠ¤í…œ ë¶„ì„:")
    
    for component, data in analytics.items():
        if isinstance(data, dict) and 'total_decisions' in data:
            logger.info(f"- {component}: {data.get('total_decisions', 0)}ê°œ ê²°ì •")
        elif isinstance(data, dict) and 'total_mappings' in data:
            logger.info(f"- {component}: {data.get('total_mappings', 0)}ê°œ ë§¤í•‘")
    
    # GPU ì‚¬ìš©ëŸ‰ ì •ë³´
    if config.use_gpu and torch.cuda.is_available():
        max_memory = max(results['training_history']['gpu_memory']) if results['training_history']['gpu_memory'] else 0
        logger.info(f"ğŸ”¥ ìµœëŒ€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {max_memory:.1f} MB")
        logger.info(f"âš¡ GPU í™œìš©ë¥ : ë†’ìŒ" if max_memory > 100 else "âš¡ GPU í™œìš©ë¥ : ë³´í†µ")
    
    return results, analytics

if __name__ == "__main__":
    # ë¹„ë™ê¸° ì‹¤í–‰
    results = asyncio.run(run_learning_test())