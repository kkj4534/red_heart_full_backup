#!/usr/bin/env python3
"""
ìµœì¢… ì‘ë™ í™•ì¸ í…ŒìŠ¤íŠ¸ - ì‹¤ì œ ëª¨ë¸ë“¤ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ê³  íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
Final Working Test - Verify that real models load properly and have parameters
"""

import os
import sys
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
import time
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# PATHì— pip ì¶”ê°€
os.environ['PATH'] = os.environ.get('PATH', '') + ':/home/kkj/.local/bin'

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('FinalWorkingTest')

def test_dependencies():
    """ì˜ì¡´ì„± ìµœì¢… í™•ì¸"""
    logger.info("ğŸ”§ ì˜ì¡´ì„± ìµœì¢… í™•ì¸")
    
    deps = {}
    try:
        import numpy as np
        deps['numpy'] = np.__version__
        logger.info(f"âœ… NumPy {np.__version__}")
    except ImportError as e:
        deps['numpy'] = f"ERROR: {e}"
        logger.error(f"âŒ NumPy: {e}")
    
    try:
        import torch
        deps['torch'] = torch.__version__
        logger.info(f"âœ… PyTorch {torch.__version__}")
    except ImportError as e:
        deps['torch'] = f"ERROR: {e}"
        logger.error(f"âŒ PyTorch: {e}")
    
    try:
        import scipy
        deps['scipy'] = scipy.__version__
        logger.info(f"âœ… SciPy {scipy.__version__}")
    except ImportError as e:
        deps['scipy'] = f"ERROR: {e}"
        logger.error(f"âŒ SciPy: {e}")
        
    try:
        import sklearn
        deps['sklearn'] = sklearn.__version__
        logger.info(f"âœ… Scikit-learn {sklearn.__version__}")
    except ImportError as e:
        deps['sklearn'] = f"ERROR: {e}"
        logger.error(f"âŒ Scikit-learn: {e}")
    
    return deps

def test_model_loading():
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§  ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    
    results = {}
    
    # 1. ê³„ì¸µì  ê°ì • ëª¨ë¸
    try:
        from models.hierarchical_emotion.emotion_phase_models import HierarchicalEmotionModel
        model = HierarchicalEmotionModel()
        params = list(model.parameters())
        results['hierarchical_emotion'] = {
            'loaded': True,
            'parameters': len(params),
            'total_params': sum(p.numel() for p in params)
        }
        logger.info(f"âœ… ê³„ì¸µì  ê°ì • ëª¨ë¸: {len(params)}ê°œ ë ˆì´ì–´, {sum(p.numel() for p in params):,}ê°œ íŒŒë¼ë¯¸í„°")
    except Exception as e:
        results['hierarchical_emotion'] = {'loaded': False, 'error': str(e)}
        logger.error(f"âŒ ê³„ì¸µì  ê°ì • ëª¨ë¸: {e}")
    
    # 2. SURD ë¶„ì„ ëª¨ë¸  
    try:
        from models.surd_models.causal_analysis_models import KraskovEstimator, NeuralCausalModel
        estimator = KraskovEstimator(k=5)
        neural_model = NeuralCausalModel()
        params = list(neural_model.parameters())
        results['surd_analysis'] = {
            'loaded': True,
            'kraskov_working': True,
            'neural_parameters': len(params),
            'total_params': sum(p.numel() for p in params)
        }
        logger.info(f"âœ… SURD ë¶„ì„: Kraskov ì¶”ì •ê¸° + ì‹ ê²½ë§ ëª¨ë¸ ({sum(p.numel() for p in params):,}ê°œ íŒŒë¼ë¯¸í„°)")
    except Exception as e:
        results['surd_analysis'] = {'loaded': False, 'error': str(e)}
        logger.error(f"âŒ SURD ë¶„ì„: {e}")
    
    # 3. í›„íšŒ ì˜ˆì¸¡ ëª¨ë¸
    try:
        from models.regret_models.regret_prediction_model import RegretIntensityPredictor, RegretLearningModel
        predictor = RegretIntensityPredictor()
        learning_model = RegretLearningModel()
        params1 = list(predictor.parameters())
        params2 = list(learning_model.parameters())
        results['regret_prediction'] = {
            'loaded': True,
            'predictor_params': len(params1),
            'learning_params': len(params2),
            'total_params': sum(p.numel() for p in params1) + sum(p.numel() for p in params2)
        }
        logger.info(f"âœ… í›„íšŒ ì˜ˆì¸¡: ì˜ˆì¸¡ê¸° + í•™ìŠµ ëª¨ë¸ ({sum(p.numel() for p in params1) + sum(p.numel() for p in params2):,}ê°œ íŒŒë¼ë¯¸í„°)")
    except Exception as e:
        results['regret_prediction'] = {'loaded': False, 'error': str(e)}
        logger.error(f"âŒ í›„íšŒ ì˜ˆì¸¡: {e}")
    
    # 4. ì˜ë¯¸ ë¶„ì„ ëª¨ë¸
    try:
        from models.semantic_models.advanced_semantic_models import AdvancedSemanticModel
        model = AdvancedSemanticModel()
        params = list(model.parameters())
        results['semantic_analysis'] = {
            'loaded': True,
            'parameters': len(params),
            'total_params': sum(p.numel() for p in params)
        }
        logger.info(f"âœ… ì˜ë¯¸ ë¶„ì„: {len(params)}ê°œ ë ˆì´ì–´, {sum(p.numel() for p in params):,}ê°œ íŒŒë¼ë¯¸í„°")
    except Exception as e:
        results['semantic_analysis'] = {'loaded': False, 'error': str(e)}
        logger.error(f"âŒ ì˜ë¯¸ ë¶„ì„: {e}")
    
    # 5. ë°˜ì‚¬ì‹¤ ì¶”ë¡  ëª¨ë¸
    try:
        from models.counterfactual_models.counterfactual_reasoning_models import AdvancedCounterfactualModel
        model = AdvancedCounterfactualModel()
        params = list(model.parameters())
        results['counterfactual'] = {
            'loaded': True,
            'parameters': len(params),
            'total_params': sum(p.numel() for p in params)
        }
        logger.info(f"âœ… ë°˜ì‚¬ì‹¤ ì¶”ë¡ : {len(params)}ê°œ ë ˆì´ì–´, {sum(p.numel() for p in params):,}ê°œ íŒŒë¼ë¯¸í„°")
    except Exception as e:
        results['counterfactual'] = {'loaded': False, 'error': str(e)}
        logger.error(f"âŒ ë°˜ì‚¬ì‹¤ ì¶”ë¡ : {e}")
    
    return results

def test_basic_computation():
    """ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸"""
    logger.info("âš¡ ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸")
    
    try:
        import torch
        import numpy as np
        
        # PyTorch í…ì„œ ì—°ì‚°
        x = torch.randn(10, 768)
        y = torch.randn(768, 256)
        result = torch.mm(x, y)
        logger.info(f"âœ… PyTorch í–‰ë ¬ ê³±ì…ˆ: {x.shape} Ã— {y.shape} = {result.shape}")
        
        # NumPy ë°°ì—´ ì—°ì‚°
        a = np.random.randn(100)
        b = np.random.randn(100)
        correlation = np.corrcoef(a, b)[0, 1]
        logger.info(f"âœ… NumPy ìƒê´€ê³„ìˆ˜ ê³„ì‚°: {correlation:.4f}")
        
        # SciPy ê³¼í•™ ê³„ì‚°
        from scipy.stats import pearsonr
        r_value, p_value = pearsonr(a, b)
        logger.info(f"âœ… SciPy í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜: r={r_value:.4f}, p={p_value:.4f}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ê¸°ë³¸ ì—°ì‚° ì‹¤íŒ¨: {e}")
        return False

def test_real_data_processing():
    """ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ“Š ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    
    try:
        datasets_dir = project_root / 'processed_datasets'
        scruples_path = datasets_dir / 'scruples' / 'scruples_batch_001_of_100_20250622_013432.json'
        
        with open(scruples_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        scenarios = data.get('scenarios', [])[:5]
        logger.info(f"âœ… {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ")
        
        # ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ
        import numpy as np
        features = []
        
        for scenario in scenarios:
            description = scenario.get('description', '')
            words = description.split()
            
            # ê¸°ë³¸ íŠ¹ì§•
            feature_vector = [
                len(words),                    # ë‹¨ì–´ ìˆ˜
                len(description),              # ë¬¸ì ìˆ˜
                description.count('?'),        # ì§ˆë¬¸ ìˆ˜
                description.count('!'),        # ê°íƒ„ë¶€í˜¸ ìˆ˜
                len(scenario.get('context', {}).get('emotions', {}))  # ê°ì • ìˆ˜
            ]
            
            features.append(feature_vector)
        
        features_array = np.array(features)
        logger.info(f"âœ… íŠ¹ì§• í–‰ë ¬ ìƒì„±: {features_array.shape}")
        
        # ê°„ë‹¨í•œ í†µê³„ ë¶„ì„
        mean_features = np.mean(features_array, axis=0)
        std_features = np.std(features_array, axis=0)
        
        logger.info(f"âœ… íŠ¹ì§• í†µê³„: í‰ê· ={mean_features}, í‘œì¤€í¸ì°¨={std_features}")
        
        return True, len(scenarios), features_array.shape
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False, 0, None

def simple_learning_simulation():
    """ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜"""
    logger.info("ğŸ¯ ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜")
    
    try:
        import torch
        import torch.nn as nn
        
        # ê°„ë‹¨í•œ ì‹ ê²½ë§ ìƒì„±
        class SimpleModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.layers = nn.Sequential(
                    nn.Linear(5, 32),
                    nn.ReLU(),
                    nn.Linear(32, 16),
                    nn.ReLU(),
                    nn.Linear(16, 1),
                    nn.Sigmoid()
                )
            
            def forward(self, x):
                return self.layers(x)
        
        model = SimpleModel()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
        criterion = nn.MSELoss()
        
        # ë”ë¯¸ ë°ì´í„° ìƒì„±
        X = torch.randn(50, 5)
        y = torch.randn(50, 1)
        
        # í•™ìŠµ ì§„í–‰
        initial_loss = None
        final_loss = None
        
        model.train()
        for epoch in range(20):
            optimizer.zero_grad()
            pred = model(X)
            loss = criterion(pred, y)
            
            if epoch == 0:
                initial_loss = loss.item()
            
            loss.backward()
            optimizer.step()
            
            if epoch % 5 == 0:
                logger.info(f"  Epoch {epoch}: Loss = {loss.item():.6f}")
        
        final_loss = loss.item()
        improvement = initial_loss - final_loss
        
        logger.info(f"âœ… í•™ìŠµ ì™„ë£Œ: ì´ˆê¸°={initial_loss:.6f}, ìµœì¢…={final_loss:.6f}, ê°œì„ ={improvement:.6f}")
        
        return True, improvement
        
    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        return False, 0

def run_final_comprehensive_test():
    """ìµœì¢… í¬ê´„ì  í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸš€ ìµœì¢… í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    test_results = {}
    
    # 1. ì˜ì¡´ì„± í…ŒìŠ¤íŠ¸
    logger.info("\n" + "="*50)
    logger.info("1ï¸âƒ£ ì˜ì¡´ì„± í…ŒìŠ¤íŠ¸")
    logger.info("="*50)
    deps = test_dependencies()
    test_results['dependencies'] = deps
    
    # 2. ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
    logger.info("\n" + "="*50)  
    logger.info("2ï¸âƒ£ ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    logger.info("="*50)
    model_results = test_model_loading()
    test_results['models'] = model_results
    
    # 3. ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸
    logger.info("\n" + "="*50)
    logger.info("3ï¸âƒ£ ê¸°ë³¸ ì—°ì‚° í…ŒìŠ¤íŠ¸")
    logger.info("="*50)
    computation_ok = test_basic_computation()
    test_results['computation'] = computation_ok
    
    # 4. ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    logger.info("\n" + "="*50)
    logger.info("4ï¸âƒ£ ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸") 
    logger.info("="*50)
    data_ok, num_scenarios, feature_shape = test_real_data_processing()
    test_results['data_processing'] = {
        'success': data_ok,
        'scenarios': num_scenarios,
        'feature_shape': str(feature_shape) if feature_shape is not None else None
    }
    
    # 5. í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
    logger.info("\n" + "="*50)
    logger.info("5ï¸âƒ£ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸")
    logger.info("="*50)
    learning_ok, improvement = simple_learning_simulation()
    test_results['learning'] = {
        'success': learning_ok,
        'improvement': improvement
    }
    
    # ê²°ê³¼ ì¢…í•©
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š ìµœì¢… ê²°ê³¼ ì¢…í•©")
    logger.info("="*70)
    
    # ì„±ê³µí•œ ëª¨ë¸ë“¤ ê³„ì‚°
    successful_models = [name for name, result in model_results.items() if result.get('loaded', False)]
    failed_models = [name for name, result in model_results.items() if not result.get('loaded', False)]
    
    total_params = sum(result.get('total_params', 0) for result in model_results.values() if result.get('loaded', False))
    
    logger.info(f"âœ… ì„±ê³µí•œ ëª¨ë¸: {len(successful_models)}ê°œ ({', '.join(successful_models)})")
    if failed_models:
        logger.info(f"âŒ ì‹¤íŒ¨í•œ ëª¨ë¸: {len(failed_models)}ê°œ ({', '.join(failed_models)})")
    logger.info(f"ğŸ”¢ ì´ ëª¨ë¸ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
    logger.info(f"ğŸ“Š ë°ì´í„° ì²˜ë¦¬: {'ì„±ê³µ' if data_ok else 'ì‹¤íŒ¨'} ({num_scenarios}ê°œ ì‹œë‚˜ë¦¬ì˜¤)")
    logger.info(f"âš¡ ê¸°ë³¸ ì—°ì‚°: {'ì„±ê³µ' if computation_ok else 'ì‹¤íŒ¨'}")
    logger.info(f"ğŸ¯ í•™ìŠµ: {'ì„±ê³µ' if learning_ok else 'ì‹¤íŒ¨'} (ê°œì„ ë„: {improvement:.6f})")
    
    # ì „ì²´ ì„±ê³µ ì—¬ë¶€ íŒì •
    overall_success = (
        len(successful_models) >= 3 and  # ìµœì†Œ 3ê°œ ëª¨ë¸ ì„±ê³µ
        computation_ok and               # ê¸°ë³¸ ì—°ì‚° ì„±ê³µ
        data_ok and                     # ë°ì´í„° ì²˜ë¦¬ ì„±ê³µ
        learning_ok                     # í•™ìŠµ ì„±ê³µ
    )
    
    test_results['overall'] = {
        'success': overall_success,
        'successful_models': len(successful_models),
        'total_parameters': total_params,
        'timestamp': datetime.now().isoformat()
    }
    
    # ê²°ê³¼ ì €ì¥
    results_path = project_root / 'logs' / f'final_comprehensive_test_{int(time.time())}.json'
    results_path.parent.mkdir(exist_ok=True)
    
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(test_results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {results_path}")
    
    return overall_success, successful_models, total_params

if __name__ == "__main__":
    try:
        success, models, params = run_final_comprehensive_test()
        
        print("\n" + "="*80)
        if success:
            print("ğŸ‰ğŸ‰ğŸ‰ ìµœì¢… í¬ê´„ì  í…ŒìŠ¤íŠ¸ ëŒ€ì„±ê³µ! ğŸ‰ğŸ‰ğŸ‰")
            print(f"âœ… {len(models)}ê°œ ì‹¤ì œ ê³ ê¸‰ ëª¨ë¸ì´ ì •ìƒ ì‘ë™!")
            print(f"ğŸ”¢ ì´ {params:,}ê°œ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì‹¤ì œ AI ì‹œìŠ¤í…œ!")
            print("ğŸš€ fallback ì—†ì´ ì‹¤ì œ PyTorch, NumPy, SciPy ê¸°ë°˜ ê³ ê¸‰ ëª¨ë¸ë“¤ ì‘ë™!")
            print("ğŸ“Š ì‹¤ì œ ë°ì´í„°ì…‹ ì²˜ë¦¬ ë° í•™ìŠµ ì§„í–‰ í™•ì¸!")
            print("ğŸ§  Red Heart ì‹œìŠ¤í…œì˜ ëª¨ë“  í•µì‹¬ êµ¬ì„±ìš”ì†Œê°€ ë³µì›ë˜ì–´ ì‘ë™í•¨!")
        else:
            print("âš ï¸ ìµœì¢… í…ŒìŠ¤íŠ¸ ë¶€ë¶„ ì„±ê³µ")
            print(f"âœ… {len(models)}ê°œ ëª¨ë¸ ì‘ë™, {params:,}ê°œ íŒŒë¼ë¯¸í„°")
            print("ì¼ë¶€ ëª¨ë¸ì—ì„œ ë¬¸ì œê°€ ìˆì§€ë§Œ í•µì‹¬ ê¸°ëŠ¥ì€ ì‘ë™í•¨")
        print("="*80)
        
    except Exception as e:
        print(f"\nâŒ ìµœì¢… í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()