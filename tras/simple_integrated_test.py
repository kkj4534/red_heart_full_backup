#!/usr/bin/env python3
"""
Red Heart AI ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
í˜„ì¬ êµ¬í˜„ëœ ëª¨ë“ˆë“¤ë¡œ 10ê°œ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì§„í–‰
"""

import sys
import time
import torch
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# í˜„ì¬ ì‹œìŠ¤í…œ ëª¨ë“ˆë“¤ ì„í¬íŠ¸
from config import SYSTEM_CONFIG, ADVANCED_CONFIG, get_device
from data_models import EmotionData, EmotionState, EmotionIntensity
from advanced_emotion_analyzer import AdvancedEmotionAnalyzer
from advanced_bentham_calculator import AdvancedBenthamCalculator
from llm_module.advanced_llm_engine import get_llm_engine, LLMRequest, TaskComplexity

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('RedHeartIntegratedTest')

class IntegratedTestRunner:
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.device = get_device()
        self.results = []
        
        # ì‹œìŠ¤í…œ ëª¨ë“ˆ ì´ˆê¸°í™”
        print("=== Red Heart AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ===")
        self.emotion_analyzer = AdvancedEmotionAnalyzer()
        print("âœ… ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        self.bentham_calculator = AdvancedBenthamCalculator()
        print("âœ… ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
        self.llm_engine = get_llm_engine()
        print("âœ… LLM ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        self.test_data = [
            "ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„ìš”! í–‰ë³µí•©ë‹ˆë‹¤.",
            "ì´ ê²°ì •ì´ ì •ë§ ì˜³ì€ ê±¸ê¹Œìš”? ë¶ˆì•ˆí•´ìš”.",
            "í™”ê°€ ë‚˜ë„¤ìš”. ì´ëŸ° ì¼ì´ ìˆì–´ì„œëŠ” ì•ˆ ë˜ëŠ”ë°...",
            "ìŠ¬í¼ìš”. ëª¨ë“  ê²Œ ì˜ëª»ëœ ê²ƒ ê°™ì•„ìš”.",
            "ë†€ëì–´ìš”! ì˜ˆìƒì¹˜ ëª»í•œ ì¼ì´ ë²Œì–´ì¡Œë„¤ìš”.",
            "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì‚¬ëŒì´ ìˆì–´ì„œ ë‹¤í–‰ì…ë‹ˆë‹¤.",
            "ì—­ê²¨ì›Œìš”. ì´ëŸ° ìƒí™©ì€ ìš©ë‚©í•  ìˆ˜ ì—†ì–´ìš”.",
            "ê¸°ëŒ€ê°€ ë˜ë„¤ìš”. ì¢‹ì€ ì¼ì´ ìƒê¸¸ ê²ƒ ê°™ì•„ìš”.",
            "ì£„ì±…ê°ì´ ë“¤ì–´ìš”. ì œê°€ ì˜ëª»í–ˆë‚˜ìš”?",
            "ìë‘ìŠ¤ëŸ¬ì›Œìš”. ëª©í‘œë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!"
        ]
        
    def run_single_test(self, test_id: int, text: str) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            # 1ë‹¨ê³„: ê°ì • ë¶„ì„
            emotion_result = self.emotion_analyzer.analyze_emotion(text)
            
            # 2ë‹¨ê³„: ë²¤ë‹´ ê³„ì‚°
            bentham_input = {
                'intensity': 4.0,
                'duration': 3.0,
                'certainty': 2.5,
                'propinquity': 3.0,
                'fecundity': 2.5,
                'purity': 3.0,
                'extent': 2.0,
                'emotional_state': str(emotion_result.primary_emotion.value),
                'emotional_intensity': emotion_result.intensity.value,
                'text_context': text
            }
            
            bentham_result = self.bentham_calculator.calculate_with_advanced_layers(
                input_data=bentham_input,
                use_cache=True
            )
            
            # 3ë‹¨ê³„: LLM í†µí•© ë¶„ì„ (ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸°ë¡œ ì²˜ë¦¬)
            llm_analysis = None
            try:
                import asyncio
                import concurrent.futures
                
                def async_llm_call():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        request = LLMRequest(
                            prompt=f"ë‹¤ìŒ ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í•´ì„í•´ì£¼ì„¸ìš”: í…ìŠ¤íŠ¸='{text}', ê°ì •={emotion_result.primary_emotion}, ë²¤ë‹´ ì ìˆ˜={bentham_result.final_score:.3f}",
                            task_type="ethical_analysis",
                            complexity=TaskComplexity.MODERATE,
                            max_tokens=200
                        )
                        return loop.run_until_complete(self.llm_engine.generate_async(request))
                    finally:
                        loop.close()
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(async_llm_call)
                    llm_response = future.result(timeout=30)
                    
                if llm_response and llm_response.success:
                    llm_analysis = llm_response.generated_text[:150] + "..."
                    
            except Exception as e:
                logger.warning(f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
                llm_analysis = "LLM ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
            
            processing_time = time.time() - start_time
            
            result = {
                'test_id': test_id,
                'input_text': text,
                'emotion': {
                    'primary_emotion': str(emotion_result.primary_emotion),
                    'intensity': str(emotion_result.intensity),
                    'confidence': emotion_result.confidence,
                    'processing_method': emotion_result.processing_method
                },
                'bentham': {
                    'base_score': bentham_result.base_score,
                    'final_score': bentham_result.final_score,
                    'confidence': bentham_result.confidence
                },
                'llm_analysis': llm_analysis,
                'processing_time': processing_time,
                'success': True,
                'timestamp': datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ {test_id} ì‹¤íŒ¨: {e}")
            return {
                'test_id': test_id,
                'input_text': text,
                'error': str(e),
                'processing_time': time.time() - start_time,
                'success': False,
                'timestamp': datetime.now().isoformat()
            }
    
    def run_all_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\n=== 10ê°œ ë°ì´í„° í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        start_time = time.time()
        success_count = 0
        
        for i, text in enumerate(self.test_data, 1):
            print(f"\n--- í…ŒìŠ¤íŠ¸ {i}/10 ---")
            print(f"ì…ë ¥: {text}")
            
            result = self.run_single_test(i, text)
            self.results.append(result)
            
            if result['success']:
                success_count += 1
                print(f"âœ… ì„±ê³µ - ê°ì •: {result['emotion']['primary_emotion']}, "
                      f"ë²¤ë‹´: {result['bentham']['final_score']:.3f}, "
                      f"ì‹œê°„: {result['processing_time']:.2f}s")
            else:
                print(f"âŒ ì‹¤íŒ¨ - {result['error']}")
        
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ìš”ì•½
        summary = {
            'total_tests': len(self.test_data),
            'successful_tests': success_count,
            'failed_tests': len(self.test_data) - success_count,
            'success_rate': (success_count / len(self.test_data)) * 100,
            'total_processing_time': total_time,
            'average_processing_time': total_time / len(self.test_data),
            'system_config': {
                'total_parameters': ADVANCED_CONFIG['total_parameters'],
                'gpu_enabled': ADVANCED_CONFIG['enable_gpu'],
                'device': str(self.device),
                'precision': ADVANCED_CONFIG['precision']
            },
            'results': self.results
        }
        
        return summary
    
    def save_results(self, summary: Dict[str, Any]):
        """ê²°ê³¼ ì €ì¥"""
        output_file = Path("test_results") / f"integrated_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            import json
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ë¨: {output_file}")
        return output_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("Red Heart AI ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    print(f"ë””ë°”ì´ìŠ¤: {get_device()}")
    print(f"ì´ íŒŒë¼ë¯¸í„°: {ADVANCED_CONFIG['total_parameters']:,}")
    print(f"GPU ì‚¬ìš©: {ADVANCED_CONFIG['enable_gpu']}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_runner = IntegratedTestRunner()
    summary = test_runner.run_all_tests()
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
    print("=" * 60)
    print(f"ì´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}")
    print(f"ì„±ê³µ: {summary['successful_tests']}")
    print(f"ì‹¤íŒ¨: {summary['failed_tests']}")
    print(f"ì„±ê³µë¥ : {summary['success_rate']:.1f}%")
    print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {summary['total_processing_time']:.2f}ì´ˆ")
    print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {summary['average_processing_time']:.2f}ì´ˆ")
    
    # ê²°ê³¼ ì €ì¥
    output_file = test_runner.save_results(summary)
    
    if summary['success_rate'] >= 80:
        print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ! ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    return summary

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()