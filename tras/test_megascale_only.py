#!/usr/bin/env python3
"""
ë©”ê°€ ìŠ¤ì¼€ì¼ ëª¨ë¸ë§Œ ë‹¨ë… í…ŒìŠ¤íŠ¸
"""

import torch
import sys
from pathlib import Path

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_megascale_model():
    print("ğŸ§  ë©”ê°€ ìŠ¤ì¼€ì¼ ëª¨ë¸ ë‹¨ë… í…ŒìŠ¤íŠ¸")
    
    try:
        from models.mega_scale_models.scalable_xai_model import create_mega_scale_model, optimize_model_for_inference
        
        # ì‘ì€ í¬ê¸°ë¡œ ìš°ì„  í…ŒìŠ¤íŠ¸
        print("ëª¨ë¸ ìƒì„± ì¤‘...")
        model = create_mega_scale_model(target_params=50_000_000)  # 5ì²œë§Œìœ¼ë¡œ ì¶•ì†Œ
        model = optimize_model_for_inference(model)
        
        actual_params = model.get_parameter_count()
        print(f"âœ… ëª¨ë¸ ìƒì„± ì„±ê³µ: {actual_params:,}ê°œ íŒŒë¼ë¯¸í„°")
        
        # í…ŒìŠ¤íŠ¸ ì…ë ¥
        batch_size = 2
        seq_len = 32  # ë” ì‘ì€ ì‹œí€€ìŠ¤
        input_dim = 1024
        
        test_input = torch.randn(batch_size, seq_len, input_dim)
        print(f"ğŸ“Š ì…ë ¥ ì°¨ì›: {test_input.shape}")
        
        # ì¶”ë¡  í…ŒìŠ¤íŠ¸
        with torch.no_grad():
            outputs = model(test_input)
        
        print(f"âœ… ì¶”ë¡  ì„±ê³µ")
        print(f"ğŸ“Š ì¶œë ¥ í‚¤: {list(outputs.keys())}")
        if 'emotion_predictions' in outputs:
            print(f"ğŸ“Š ê°ì • ì˜ˆì¸¡ ì°¨ì›: {outputs['emotion_predictions'].shape}")
        
        return True, outputs
        
    except Exception as e:
        print(f"âŒ ë©”ê°€ ìŠ¤ì¼€ì¼ ëª¨ë¸ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False, None

if __name__ == "__main__":
    success, output = test_megascale_model()
    if success:
        print("ğŸ‰ ë©”ê°€ ìŠ¤ì¼€ì¼ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    else:
        print("ğŸ’¥ ë©”ê°€ ìŠ¤ì¼€ì¼ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")