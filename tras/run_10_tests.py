#!/usr/bin/env python3
"""
10íšŒ ì—°ì† í†µí•© í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°
Continuous 10x Integrated Learning Test Runner
"""

import asyncio
import json
import time
from datetime import datetime
from pathlib import Path
import logging

# ê¸°ì¡´ í†µí•© í•™ìŠµ í…ŒìŠ¤íŠ¸ ì„í¬íŠ¸
from integrated_learning_test import run_learning_test

def setup_test_logging():
    """í…ŒìŠ¤íŠ¸ ì „ìš© ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger('Continuous10Tests')
    return logger

async def run_continuous_tests(num_tests=10):
    """10íšŒ ì—°ì† í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger = setup_test_logging()
    
    # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    all_results = []
    
    logger.info(f"ğŸš€ {num_tests}íšŒ ì—°ì† í†µí•© í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("="*80)
    
    total_start_time = time.time()
    
    for test_run in range(1, num_tests + 1):
        logger.info(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {test_run}/{num_tests} ì‹œì‘...")
        
        run_start_time = time.time()
        
        try:
            # ê°œë³„ í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            results = await run_learning_test()
            
            if results:
                run_time = time.time() - run_start_time
                
                # ê²°ê³¼ ìš”ì•½
                test_summary = {
                    'test_run': test_run,
                    'timestamp': datetime.now().isoformat(),
                    'run_time': run_time,
                    'status': 'success',
                    'results': results[0] if isinstance(results, tuple) else results,
                    'analytics': results[1] if isinstance(results, tuple) and len(results) > 1 else None
                }
                
                all_results.append(test_summary)
                
                logger.info(f"âœ… í…ŒìŠ¤íŠ¸ {test_run} ì™„ë£Œ - ì†Œìš”ì‹œê°„: {run_time:.2f}ì´ˆ")
                
                # ê°„ë‹¨í•œ ì„±ëŠ¥ ìš”ì•½
                if isinstance(results, tuple) and len(results) > 0:
                    result_data = results[0]
                    if isinstance(result_data, dict):
                        final_acc = result_data.get('final_train_accuracy', 0)
                        final_loss = result_data.get('final_train_loss', 0)
                        epochs = result_data.get('epochs_completed', 0)
                        logger.info(f"   - ìµœì¢… ì •í™•ë„: {final_acc:.4f}")
                        logger.info(f"   - ìµœì¢… ì†ì‹¤: {final_loss:.4f}")
                        logger.info(f"   - ì™„ë£Œ ì—í¬í¬: {epochs}")
            else:
                logger.error(f"âŒ í…ŒìŠ¤íŠ¸ {test_run} ì‹¤íŒ¨ - ê²°ê³¼ ì—†ìŒ")
                test_summary = {
                    'test_run': test_run,
                    'timestamp': datetime.now().isoformat(),
                    'run_time': time.time() - run_start_time,
                    'status': 'failed',
                    'error': 'No results returned'
                }
                all_results.append(test_summary)
                
        except Exception as e:
            run_time = time.time() - run_start_time
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ {test_run} ì˜¤ë¥˜: {str(e)}")
            
            test_summary = {
                'test_run': test_run,
                'timestamp': datetime.now().isoformat(),
                'run_time': run_time,
                'status': 'error',
                'error': str(e)
            }
            all_results.append(test_summary)
        
        # í…ŒìŠ¤íŠ¸ ê°„ ì ê¹ ëŒ€ê¸° (GPU ë©”ëª¨ë¦¬ ì •ë¦¬)
        if test_run < num_tests:
            logger.info("   ğŸ”„ ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì¤‘...")
            await asyncio.sleep(2)
    
    total_time = time.time() - total_start_time
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info("="*80)
    
    successful_tests = [r for r in all_results if r['status'] == 'success']
    failed_tests = [r for r in all_results if r['status'] != 'success']
    
    logger.info(f"âœ… ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len(successful_tests)}/{num_tests}")
    logger.info(f"âŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {len(failed_tests)}/{num_tests}")
    logger.info(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
    logger.info(f"ğŸ“ˆ í‰ê·  í…ŒìŠ¤íŠ¸ ì‹œê°„: {total_time/num_tests:.2f}ì´ˆ")
    
    if successful_tests:
        avg_run_time = sum(r['run_time'] for r in successful_tests) / len(successful_tests)
        logger.info(f"âš¡ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ í‰ê·  ì‹œê°„: {avg_run_time:.2f}ì´ˆ")
        
        # ì„±ëŠ¥ í†µê³„ (ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ë§Œ)
        successful_results = [r['results'] for r in successful_tests if r['results']]
        if successful_results:
            accuracies = [r.get('final_train_accuracy', 0) for r in successful_results]
            losses = [r.get('final_train_loss', 0) for r in successful_results]
            
            if accuracies:
                avg_accuracy = sum(accuracies) / len(accuracies)
                min_accuracy = min(accuracies)
                max_accuracy = max(accuracies)
                logger.info(f"ğŸ¯ í‰ê·  ì •í™•ë„: {avg_accuracy:.4f} (ë²”ìœ„: {min_accuracy:.4f} - {max_accuracy:.4f})")
            
            if losses:
                avg_loss = sum(losses) / len(losses)
                min_loss = min(losses)
                max_loss = max(losses)
                logger.info(f"ğŸ“‰ í‰ê·  ì†ì‹¤: {avg_loss:.4f} (ë²”ìœ„: {min_loss:.4f} - {max_loss:.4f})")
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    results_file = Path(f"logs/continuous_10_tests_{int(time.time())}.json")
    results_file.parent.mkdir(exist_ok=True)
    
    final_report = {
        'total_tests': num_tests,
        'successful_tests': len(successful_tests),
        'failed_tests': len(failed_tests),
        'total_time': total_time,
        'average_test_time': total_time / num_tests,
        'timestamp': datetime.now().isoformat(),
        'individual_results': all_results
    }
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(final_report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {results_file}")
    
    # ì„±ê³µë¥  ì²´í¬
    success_rate = len(successful_tests) / num_tests * 100
    
    if success_rate >= 80:
        logger.info(f"ğŸ† ì‹œìŠ¤í…œ ì•ˆì •ì„± ìš°ìˆ˜: {success_rate:.1f}% ì„±ê³µë¥ ")
    elif success_rate >= 60:
        logger.info(f"âœ… ì‹œìŠ¤í…œ ì•ˆì •ì„± ì–‘í˜¸: {success_rate:.1f}% ì„±ê³µë¥ ")
    else:
        logger.warning(f"âš ï¸ ì‹œìŠ¤í…œ ì•ˆì •ì„± ê°œì„  í•„ìš”: {success_rate:.1f}% ì„±ê³µë¥ ")
    
    return final_report

if __name__ == "__main__":
    # 10íšŒ ì—°ì† í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(run_continuous_tests(10))