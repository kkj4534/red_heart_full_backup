#!/usr/bin/env python3
"""
ì—…ê·¸ë ˆì´ë“œëœ 10íšŒ ì—°ì† í†µí•© í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°
Upgraded 10x Continuous Integrated Learning Test Runner

Features:
- ë™ì  GPU ë©”ëª¨ë¦¬ ê´€ë¦¬
- ê²¬ê³ í•œ ë¡œê¹… ì‹œìŠ¤í…œ
- ê°•ì œ ê²°ê³¼ íŒŒì¼ ìƒì„± ë³´ì¥
- ì •í™•í•œ GPU ë©”ëª¨ë¦¬ ì¶”ì 
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import asyncio
import json
import time
import traceback
from datetime import datetime
from pathlib import Path
import logging

# ì—…ê·¸ë ˆì´ë“œëœ ì‹œìŠ¤í…œ ì„í¬íŠ¸
from dynamic_gpu_manager import get_gpu_manager, optimize_gpu_for_learning, emergency_gpu_cleanup, allocate_gpu_memory
from robust_logging_system import get_robust_logger, test_session, add_performance_sample, generate_test_report

# ê¸°ì¡´ í†µí•© í•™ìŠµ í…ŒìŠ¤íŠ¸ ì„í¬íŠ¸
from integrated_learning_test import run_learning_test, LearningConfig, IntegratedLearningFramework

def setup_upgraded_logging():
    """ì—…ê·¸ë ˆì´ë“œëœ ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger('UpgradedContinuous10Tests')
    return logger

async def run_single_optimized_test(test_number: int, gpu_manager, robust_logger) -> dict:
    """ìµœì í™”ëœ ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    test_name = f"integrated_learning_test_{test_number:02d}"
    
    with test_session(test_name, {"test_number": test_number}) as test_id:
        robust_logger.log("INFO", "TestRunner", f"í…ŒìŠ¤íŠ¸ {test_number} ì‹œì‘", {"test_id": test_id})
        
        start_time = time.time()
        
        try:
            # GPU ë©”ëª¨ë¦¬ ìµœì í™”
            with allocate_gpu_memory('main_learning_pipeline', dynamic_boost=True):
                # ì„±ëŠ¥ ìƒ˜í”Œ ì¶”ê°€
                add_performance_sample({
                    "phase": "start",
                    "test_number": test_number,
                    "gpu_status": gpu_manager.get_memory_status()
                })
                
                # ì‹¤ì œ í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                results = await run_learning_test()
                
                # ì¤‘ê°„ ì„±ëŠ¥ ìƒ˜í”Œ
                add_performance_sample({
                    "phase": "learning_complete",
                    "test_number": test_number,
                    "gpu_status": gpu_manager.get_memory_status(),
                    "results_available": results is not None
                })
                
                if results:
                    run_time = time.time() - start_time
                    
                    # ê²°ê³¼ ì²˜ë¦¬
                    if isinstance(results, tuple):
                        result_data = results[0]
                        analytics_data = results[1] if len(results) > 1 else None
                    else:
                        result_data = results
                        analytics_data = None
                    
                    # ìµœì¢… ì„±ëŠ¥ ìƒ˜í”Œ
                    add_performance_sample({
                        "phase": "complete",
                        "test_number": test_number,
                        "run_time": run_time,
                        "gpu_status": gpu_manager.get_memory_status(),
                        "result_data": result_data if isinstance(result_data, dict) else None
                    })
                    
                    # ì„±ê³µ ê²°ê³¼ ë°˜í™˜
                    success_result = {
                        'test_number': test_number,
                        'test_id': test_id,
                        'status': 'success',
                        'run_time': run_time,
                        'timestamp': datetime.now().isoformat(),
                        'results': result_data,
                        'analytics': analytics_data,
                        'gpu_memory_usage': gpu_manager.get_memory_status()
                    }
                    
                    robust_logger.log("INFO", "TestRunner", 
                                     f"í…ŒìŠ¤íŠ¸ {test_number} ì„±ê³µ ì™„ë£Œ - {run_time:.2f}ì´ˆ",
                                     {"test_id": test_id, "run_time": run_time})
                    
                    return success_result
                    
                else:
                    # ê²°ê³¼ ì—†ìŒ
                    run_time = time.time() - start_time
                    
                    failure_result = {
                        'test_number': test_number,
                        'test_id': test_id,
                        'status': 'failed',
                        'run_time': run_time,
                        'timestamp': datetime.now().isoformat(),
                        'error': 'No results returned from learning test',
                        'gpu_memory_usage': gpu_manager.get_memory_status()
                    }
                    
                    robust_logger.log("ERROR", "TestRunner",
                                     f"í…ŒìŠ¤íŠ¸ {test_number} ì‹¤íŒ¨ - ê²°ê³¼ ì—†ìŒ",
                                     {"test_id": test_id, "run_time": run_time})
                    
                    return failure_result
                    
        except Exception as e:
            # ì˜ˆì™¸ ì²˜ë¦¬
            run_time = time.time() - start_time
            error_info = {
                "error": str(e),
                "error_type": type(e).__name__,
                "traceback": traceback.format_exc()
            }
            
            error_result = {
                'test_number': test_number,
                'test_id': test_id,
                'status': 'error',
                'run_time': run_time,
                'timestamp': datetime.now().isoformat(),
                'error_info': error_info,
                'gpu_memory_usage': gpu_manager.get_memory_status()
            }
            
            robust_logger.log("ERROR", "TestRunner",
                             f"í…ŒìŠ¤íŠ¸ {test_number} ì˜¤ë¥˜: {str(e)}",
                             {"test_id": test_id, "error_info": error_info})
            
            return error_result

async def run_upgraded_continuous_tests(num_tests: int = 10):
    """ì—…ê·¸ë ˆì´ë“œëœ 10íšŒ ì—°ì† í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    logger = setup_upgraded_logging()
    gpu_manager = get_gpu_manager()
    robust_logger = get_robust_logger()
    
    logger.info(f"ğŸš€ ì—…ê·¸ë ˆì´ë“œëœ {num_tests}íšŒ ì—°ì† í†µí•© í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 80)
    
    # ì „ì²´ í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì‹œì‘
    with test_session(f"continuous_{num_tests}_tests", {"total_tests": num_tests}) as session_id:
        
        robust_logger.log("INFO", "ContinuousTestRunner", 
                         f"{num_tests}íšŒ ì—°ì† í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì‹œì‘",
                         {"session_id": session_id, "total_tests": num_tests})
        
        total_start_time = time.time()
        
        # ì´ˆê¸° GPU ìµœì í™”
        optimization_success = optimize_gpu_for_learning()
        robust_logger.log("INFO", "GPU_Optimization", 
                         f"ì´ˆê¸° GPU ìµœì í™”: {'ì„±ê³µ' if optimization_success else 'ì œí•œë¨'}")
        
        # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
        all_results = []
        
        for test_run in range(1, num_tests + 1):
            logger.info(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {test_run}/{num_tests} ì‹¤í–‰ ì¤‘...")
            
            try:
                # ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                test_result = await run_single_optimized_test(test_run, gpu_manager, robust_logger)
                all_results.append(test_result)
                
                # ì§„í–‰ ìƒí™© ë¡œê¹…
                if test_result['status'] == 'success':
                    logger.info(f"âœ… í…ŒìŠ¤íŠ¸ {test_run} ì„±ê³µ - {test_result['run_time']:.2f}ì´ˆ")
                    if 'results' in test_result and isinstance(test_result['results'], dict):
                        result_data = test_result['results']
                        final_acc = result_data.get('final_train_accuracy', 0)
                        final_loss = result_data.get('final_train_loss', 0)
                        logger.info(f"   ğŸ“Š ì •í™•ë„: {final_acc:.4f}, ì†ì‹¤: {final_loss:.4f}")
                else:
                    logger.error(f"âŒ í…ŒìŠ¤íŠ¸ {test_run} ì‹¤íŒ¨: {test_result.get('error', 'Unknown error')}")
                
                # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
                gpu_status = gpu_manager.get_memory_status()
                logger.info(f"   ğŸ”§ GPU ë©”ëª¨ë¦¬: {gpu_status['allocated_gb']:.1f}/{gpu_status['total_gb']:.1f}GB")
                
            except Exception as e:
                logger.error(f"âŒ í…ŒìŠ¤íŠ¸ {test_run} ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
                
                # ì‘ê¸‰ ì˜¤ë¥˜ ê²°ê³¼ ìƒì„±
                emergency_result = {
                    'test_number': test_run,
                    'test_id': f"emergency_{test_run}",
                    'status': 'fatal_error',
                    'run_time': 0,
                    'timestamp': datetime.now().isoformat(),
                    'error': str(e),
                    'gpu_memory_usage': gpu_manager.get_memory_status()
                }
                all_results.append(emergency_result)
                
                # ì‘ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬
                emergency_gpu_cleanup()
            
            # í…ŒìŠ¤íŠ¸ ê°„ ëŒ€ê¸° ë° ë©”ëª¨ë¦¬ ì •ë¦¬
            if test_run < num_tests:
                logger.info("   ğŸ”„ ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì¤‘...")
                await asyncio.sleep(3)  # ì¢€ ë” ì—¬ìœ ìˆëŠ” ëŒ€ê¸°
                
                # ì¤‘ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬
                gpu_manager.emergency_cleanup()
        
        total_time = time.time() - total_start_time
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š ì—…ê·¸ë ˆì´ë“œëœ ì—°ì† í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
        logger.info("=" * 80)
        
        successful_tests = [r for r in all_results if r['status'] == 'success']
        failed_tests = [r for r in all_results if r['status'] in ['failed', 'error', 'fatal_error']]
        
        success_rate = len(successful_tests) / num_tests * 100
        
        logger.info(f"âœ… ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len(successful_tests)}/{num_tests} ({success_rate:.1f}%)")
        logger.info(f"âŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {len(failed_tests)}/{num_tests}")
        logger.info(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“ˆ í‰ê·  í…ŒìŠ¤íŠ¸ ì‹œê°„: {total_time/num_tests:.2f}ì´ˆ")
        
        if successful_tests:
            avg_run_time = sum(r['run_time'] for r in successful_tests) / len(successful_tests)
            logger.info(f"âš¡ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ í‰ê·  ì‹œê°„: {avg_run_time:.2f}ì´ˆ")
        
        # ê²¬ê³ í•œ ë¡œê¹… ì‹œìŠ¤í…œì„ í†µí•œ ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        final_report = generate_test_report(num_tests)
        
        # ê°•ì œ ê²°ê³¼ íŒŒì¼ ìƒì„± ë³´ì¥
        timestamp = int(time.time())
        
        # ìƒì„¸ ê²°ê³¼ íŒŒì¼
        results_file = Path(f"logs/upgraded_continuous_{num_tests}_tests_{timestamp}.json")
        results_file.parent.mkdir(exist_ok=True)
        
        comprehensive_report = {
            'session_info': {
                'session_id': session_id,
                'test_type': 'upgraded_continuous',
                'total_tests': num_tests,
                'timestamp': datetime.now().isoformat(),
                'total_time': total_time,
                'success_rate': success_rate
            },
            'gpu_optimization': {
                'initial_optimization': optimization_success,
                'final_memory_status': gpu_manager.get_memory_status()
            },
            'individual_results': all_results,
            'robust_logging_report': final_report,
            'performance_summary': {
                'successful_tests': len(successful_tests),
                'failed_tests': len(failed_tests),
                'avg_test_time': total_time / num_tests,
                'total_duration': total_time
            }
        }
        
        # ê°•ì œ íŒŒì¼ ì €ì¥ (ë‹¤ì¤‘ ì•ˆì „ì¥ì¹˜)
        try:
            # ì£¼ ê²°ê³¼ íŒŒì¼
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, indent=2, ensure_ascii=False)
                f.flush()
                import os
                os.fsync(f.fileno())  # ê°•ì œ ë””ìŠ¤í¬ ë™ê¸°í™”
            
            # ë°±ì—… ê²°ê³¼ íŒŒì¼
            backup_file = Path(f"logs/backup_continuous_{num_tests}_tests_{timestamp}.json")
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, indent=2, ensure_ascii=False)
                f.flush()
                os.fsync(f.fileno())
            
            logger.info(f"ğŸ’¾ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {results_file}")
            logger.info(f"ğŸ’¾ ë°±ì—… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {backup_file}")
            
        except Exception as e:
            logger.error(f"âš ï¸ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            # ì‘ê¸‰ ì €ì¥ ì‹œë„
            emergency_file = Path(f"emergency_results_{timestamp}.json")
            try:
                with open(emergency_file, 'w', encoding='utf-8') as f:
                    json.dump(all_results, f, indent=2, ensure_ascii=False)
                logger.info(f"ğŸš¨ ì‘ê¸‰ ê²°ê³¼ íŒŒì¼ ì €ì¥: {emergency_file}")
            except Exception as e2:
                logger.error(f"ğŸš¨ ì‘ê¸‰ ì €ì¥ë„ ì‹¤íŒ¨: {e2}")
        
        # ìµœì¢… í‰ê°€
        if success_rate >= 90:
            logger.info(f"ğŸ† ì‹œìŠ¤í…œ ì„±ëŠ¥ ìš°ìˆ˜: {success_rate:.1f}% ì„±ê³µë¥ ")
        elif success_rate >= 70:
            logger.info(f"âœ… ì‹œìŠ¤í…œ ì„±ëŠ¥ ì–‘í˜¸: {success_rate:.1f}% ì„±ê³µë¥ ")
        else:
            logger.warning(f"âš ï¸ ì‹œìŠ¤í…œ ì„±ëŠ¥ ê°œì„  í•„ìš”: {success_rate:.1f}% ì„±ê³µë¥ ")
        
        robust_logger.log("INFO", "ContinuousTestRunner", 
                         f"ì—°ì† í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì„±ê³µë¥ : {success_rate:.1f}%",
                         {"total_tests": num_tests, "successful_tests": len(successful_tests)})
        
        return comprehensive_report

if __name__ == "__main__":
    # ì—…ê·¸ë ˆì´ë“œëœ 10íšŒ ì—°ì† í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸš€ ì—…ê·¸ë ˆì´ë“œëœ Red Heart AI ì—°ì† í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ğŸ“‹ íŠ¹ì§•: ë™ì  GPU ê´€ë¦¬ + ê²¬ê³ í•œ ë¡œê¹… + ê°•ì œ ê²°ê³¼ íŒŒì¼ ìƒì„±")
    
    try:
        asyncio.run(run_upgraded_continuous_tests(10))
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")
    except Exception as e:
        print(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ìµœì¢… ì •ë¦¬
        try:
            emergency_gpu_cleanup()
            get_robust_logger().shutdown()
            print("âœ… ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")
        except:
            pass