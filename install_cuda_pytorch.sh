#!/bin/bash
# CUDA ì§€ì› PyTorch ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸

echo "ğŸ”¥ CUDA ì§€ì› PyTorch ì„¤ì¹˜ ì‹œì‘..."

# í˜„ì¬ PyTorch CPU ë²„ì „ ì œê±°
echo "ğŸ—‘ï¸ ê¸°ì¡´ CPU PyTorch ì œê±°..."
pip uninstall -y torch torchvision torchaudio

# CUDA 11.8 ì§€ì› PyTorch ì„¤ì¹˜ (WSLì—ì„œ ì•ˆì •ì )
echo "ğŸš€ CUDA ì§€ì› PyTorch ì„¤ì¹˜..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA íˆ´í‚· ì„¤ì¹˜ (í•„ìš”ì‹œ)
echo "ğŸ› ï¸ CUDA ê°œë°œ ë„êµ¬ ì„¤ì¹˜..."
sudo apt update
sudo apt install -y nvidia-cuda-toolkit

# ì„¤ì¹˜ í™•ì¸
echo "âœ… ì„¤ì¹˜ í™•ì¸..."
python3 -c "
import torch
print('PyTorch version:', torch.__version__)
print('CUDA available:', torch.cuda.is_available())
if torch.cuda.is_available():
    print('CUDA version:', torch.version.cuda)
    print('CUDA devices:', torch.cuda.device_count())
    print('Device name:', torch.cuda.get_device_name(0))
    print('Device memory:', torch.cuda.get_device_properties(0).total_memory / 1024**3, 'GB')
else:
    print('âš ï¸ CUDA ì‚¬ìš© ë¶ˆê°€ - WSL GPU íŒ¨ìŠ¤ìŠ¤ë£¨ í™•ì¸ í•„ìš”')
"

echo "ğŸ‰ CUDA PyTorch ì„¤ì¹˜ ì™„ë£Œ!"
echo "ğŸ“ WSLì—ì„œ GPU ì‚¬ìš©ì„ ìœ„í•´ì„œëŠ” Windowsì—ì„œ NVIDIA ë“œë¼ì´ë²„ì™€ WSL CUDA ì§€ì›ì´ í•„ìš”í•©ë‹ˆë‹¤."