"""
ë‹¨ì¼ 9B ëª¨ë¸ë§Œ ì‚¬ìš©í•˜ëŠ” ê°„ë‹¨í•œ LLM ì²˜ë¦¬ê¸°
Simple LLM Processor using only the 9B model
"""

import os
import json
import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, field
import re
from datetime import datetime
import uuid

# llama-cpp-python ì§ì ‘ ì‚¬ìš©
try:
    from llama_cpp import Llama
    LLAMA_CPP_AVAILABLE = True
except ImportError:
    LLAMA_CPP_AVAILABLE = False
    print("llama-cpp-pythonì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('SimpleLLMProcessor')

@dataclass
class BenthamFactors:
    """ë²¤ë‹´ ì¾Œë½ ê³„ì‚° 7ê°œ ë³€ìˆ˜"""
    intensity: float = 0.5
    duration: float = 0.5
    certainty: float = 0.5
    propinquity: float = 0.5
    fecundity: float = 0.5
    purity: float = 0.5
    extent: float = 0.5

@dataclass
class ProcessedScenario:
    """ì²˜ë¦¬ëœ ì‹œë‚˜ë¦¬ì˜¤"""
    id: str
    title: str
    description: str
    source_type: str
    bentham_factors: BenthamFactors
    category: str = "general"
    stakeholders: List[str] = field(default_factory=list)
    processing_time: float = 0.0
    quality_score: float = 1.0

class Simple9BProcessor:
    """9B ëª¨ë¸ë§Œ ì‚¬ìš©í•˜ëŠ” ê°„ë‹¨í•œ í”„ë¡œì„¸ì„œ"""
    
    def __init__(self):
        self.llama_model = None
        self.logger = logging.getLogger(f'{__name__}.Simple9BProcessor')
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìµœì í™” (ë” ì§§ê³  ëª…í™•í•˜ê²Œ)
        self.bentham_prompt = """ë‹¤ìŒ ìƒí™©ì˜ ë²¤ë‹´ 7ê°œ ë³€ìˆ˜ë¥¼ 0.0~1.0ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

ìƒí™©: {text}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”:
{{"intensity": 0.0, "duration": 0.0, "certainty": 0.0, "propinquity": 0.0, "fecundity": 0.0, "purity": 0.0, "extent": 0.0}}"""
    
    def initialize(self):
        """9B ëª¨ë¸ë§Œ ë¡œë“œ"""
        if not LLAMA_CPP_AVAILABLE:
            raise RuntimeError("llama-cpp-pythonì´ í•„ìš”í•©ë‹ˆë‹¤: pip install llama-cpp-python")
        
        gguf_path = Path("llm_module/HelpingAI2-9B.Q4_K_M.gguf")
        if not gguf_path.exists():
            raise RuntimeError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {gguf_path}")
        
        try:
            self.logger.info("9B ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.llama_model = Llama(
                model_path=str(gguf_path),
                n_ctx=2048,  # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¤„ì„
                n_batch=256,  # ë°°ì¹˜ í¬ê¸° ì¤„ì„
                n_threads=4,  # ìŠ¤ë ˆë“œ ìˆ˜ ì¡°ì •
                verbose=False
            )
            self.logger.info("9B ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"9B ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def extract_bentham_factors(self, text: str) -> Tuple[BenthamFactors, float]:
        """9B ëª¨ë¸ë¡œ ë²¤ë‹´ ë³€ìˆ˜ ì¶”ì¶œ"""
        if not self.llama_model:
            raise RuntimeError("9B ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ì†ë„ í–¥ìƒ)
        if len(text) > 800:
            text = text[:800] + "..."
        
        prompt = self.bentham_prompt.format(text=text)
        
        try:
            start_time = time.time()
            
            # 9B ëª¨ë¸ë¡œ ìƒì„± (íŒŒë¼ë¯¸í„° ìµœì í™”)
            response = self.llama_model(
                prompt,
                max_tokens=200,  # í† í° ìˆ˜ ì œí•œ
                temperature=0.3,  # ì˜¨ë„ ë‚®ì¶¤ (ì¼ê´€ì„±)
                top_p=0.9,
                stop=["}", "\n\n"],  # ì¡°ê¸° ì¤‘ë‹¨
                echo=False
            )
            
            processing_time = time.time() - start_time
            response_text = response['choices'][0]['text']
            
            # JSON íŒŒì‹±
            factors, quality_score = self._parse_bentham_response(response_text)
            
            self.logger.debug(f"ë²¤ë‹´ ì¶”ì¶œ ì™„ë£Œ ({processing_time:.2f}ì´ˆ, í’ˆì§ˆ: {quality_score:.2f})")
            
            return factors, quality_score
            
        except Exception as e:
            self.logger.error(f"ë²¤ë‹´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return BenthamFactors(), 0.0
    
    def _parse_bentham_response(self, response_text: str) -> Tuple[BenthamFactors, float]:
        """ë²¤ë‹´ ì‘ë‹µ íŒŒì‹±"""
        quality_score = 0.0
        
        # JSON ì¶”ì¶œ
        json_match = re.search(r'\{[^}]*\}', response_text)
        if not json_match:
            return BenthamFactors(), 0.1
        
        try:
            factors_dict = json.loads(json_match.group())
            quality_score = 0.5
            
            # í•„ë“œ ê²€ì¦
            required_fields = ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']
            valid_count = 0
            
            for field in required_fields:
                if field in factors_dict:
                    try:
                        value = float(factors_dict[field])
                        if 0.0 <= value <= 1.0:
                            valid_count += 1
                    except (ValueError, TypeError):
                        pass
            
            quality_score = 0.3 + (valid_count / len(required_fields)) * 0.7
            
            # BenthamFactors ìƒì„±
            factors = BenthamFactors(
                intensity=float(factors_dict.get('intensity', 0.5)),
                duration=float(factors_dict.get('duration', 0.5)),
                certainty=float(factors_dict.get('certainty', 0.5)),
                propinquity=float(factors_dict.get('propinquity', 0.5)),
                fecundity=float(factors_dict.get('fecundity', 0.5)),
                purity=float(factors_dict.get('purity', 0.5)),
                extent=float(factors_dict.get('extent', 0.5))
            )
            
            return factors, quality_score
            
        except json.JSONDecodeError as e:
            self.logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return BenthamFactors(), 0.2

class SimpleDataParser:
    """ê°„ë‹¨í•œ ë°ì´í„° íŒŒì„œ"""
    
    def __init__(self):
        self.logger = logging.getLogger(f'{__name__}.SimpleDataParser')
    
    def parse_ebs_file(self, file_path: str, max_scenarios: int = 10) -> List[Dict[str, Any]]:
        """EBS íŒŒì¼ íŒŒì‹±"""
        self.logger.info(f"EBS íŒŒì‹±: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        scenarios = []
        current_scenario = {}
        
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ìƒˆ ì‘í’ˆ ì‹œì‘
            if re.match(r'^[ê°€-í£].+\([^)]+\)$', line):
                if current_scenario and current_scenario.get('description'):
                    scenarios.append(current_scenario)
                    if len(scenarios) >= max_scenarios:
                        break
                
                current_scenario = {
                    'title': line,
                    'description': '',
                    'stakeholders': []
                }
            
            elif line.startswith('ìƒí™©ì„¤ëª…:'):
                current_scenario['description'] = line.replace('ìƒí™©ì„¤ëª…:', '').strip()
            
            elif line.startswith('ì´í•´ê´€ê³„ì:'):
                stakeholders_text = line.replace('ì´í•´ê´€ê³„ì:', '').strip()
                current_scenario['stakeholders'] = [
                    s.strip().strip("'\"") for s in stakeholders_text.split(',')
                ]
        
        if current_scenario and current_scenario.get('description'):
            scenarios.append(current_scenario)
        
        self.logger.info(f"íŒŒì‹± ì™„ë£Œ: {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤")
        return scenarios

class Simple9BDataProcessor:
    """9B ëª¨ë¸ë§Œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„° ì²˜ë¦¬ê¸°"""
    
    def __init__(self, output_dir: str = "simple_9b_data"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.parser = SimpleDataParser()
        self.llm_processor = Simple9BProcessor()
        self.logger = logging.getLogger(f'{__name__}.Simple9BDataProcessor')
        
        # í†µê³„
        self.stats = {
            'total_processed': 0,
            'successful': 0,
            'failed': 0,
            'average_time': 0.0,
            'average_quality': 0.0
        }
    
    def initialize(self):
        """ì´ˆê¸°í™”"""
        self.llm_processor.initialize()
        self.logger.info("9B ë°ì´í„° ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_ebs_file(self, file_path: str, max_scenarios: int = 10) -> List[ProcessedScenario]:
        """EBS íŒŒì¼ ì²˜ë¦¬"""
        self.logger.info(f"9B ëª¨ë¸ë¡œ ì²˜ë¦¬ ì‹œì‘: {file_path} (ìµœëŒ€ {max_scenarios}ê°œ)")
        
        # íŒŒì‹±
        raw_scenarios = self.parser.parse_ebs_file(file_path, max_scenarios)
        processed_scenarios = []
        
        for idx, raw_scenario in enumerate(raw_scenarios):
            try:
                start_time = time.time()
                
                # 9B ëª¨ë¸ë¡œ ë²¤ë‹´ ë³€ìˆ˜ ì¶”ì¶œ
                bentham_factors, quality_score = self.llm_processor.extract_bentham_factors(
                    raw_scenario['description']
                )
                
                processing_time = time.time() - start_time
                
                scenario = ProcessedScenario(
                    id=f"ebs_9b_{idx}_{uuid.uuid4().hex[:8]}",
                    title=raw_scenario['title'],
                    description=raw_scenario['description'],
                    source_type="ebs_literature_9b",
                    bentham_factors=bentham_factors,
                    stakeholders=raw_scenario.get('stakeholders', []),
                    processing_time=processing_time,
                    quality_score=quality_score
                )
                
                processed_scenarios.append(scenario)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.stats['total_processed'] += 1
                if quality_score > 0.5:
                    self.stats['successful'] += 1
                else:
                    self.stats['failed'] += 1
                
                # í‰ê·  ê³„ì‚°
                total = self.stats['total_processed']
                self.stats['average_time'] = (
                    (self.stats['average_time'] * (total - 1) + processing_time) / total
                )
                self.stats['average_quality'] = (
                    (self.stats['average_quality'] * (total - 1) + quality_score) / total
                )
                
                self.logger.info(f"ì²˜ë¦¬: {idx + 1}/{len(raw_scenarios)} "
                                f"(ì‹œê°„: {processing_time:.1f}ì´ˆ, í’ˆì§ˆ: {quality_score:.2f})")
                
            except Exception as e:
                self.logger.error(f"ì‹œë‚˜ë¦¬ì˜¤ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                self.stats['failed'] += 1
                continue
        
        return processed_scenarios
    
    def save_results(self, scenarios: List[ProcessedScenario]):
        """ê²°ê³¼ ì €ì¥"""
        output_file = self.output_dir / "9b_processed_scenarios.json"
        
        scenarios_dict = []
        for scenario in scenarios:
            scenario_dict = {
                'id': scenario.id,
                'title': scenario.title,
                'description': scenario.description,
                'source_type': scenario.source_type,
                'bentham_factors': {
                    'intensity': scenario.bentham_factors.intensity,
                    'duration': scenario.bentham_factors.duration,
                    'certainty': scenario.bentham_factors.certainty,
                    'propinquity': scenario.bentham_factors.propinquity,
                    'fecundity': scenario.bentham_factors.fecundity,
                    'purity': scenario.bentham_factors.purity,
                    'extent': scenario.bentham_factors.extent
                },
                'stakeholders': scenario.stakeholders,
                'processing_time': scenario.processing_time,
                'quality_score': scenario.quality_score
            }
            scenarios_dict.append(scenario_dict)
        
        final_data = {
            'metadata': {
                'total_scenarios': len(scenarios),
                'processing_statistics': self.stats,
                'model_used': '9B_only',
                'timestamp': datetime.now().isoformat()
            },
            'scenarios': scenarios_dict
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(json.dumps(final_data, ensure_ascii=False, indent=2))
        
        self.logger.info(f"ê²°ê³¼ ì €ì¥: {output_file}")
        self._print_report(len(scenarios))
    
    def _print_report(self, total_scenarios: int):
        """ê²°ê³¼ ë¦¬í¬íŠ¸"""
        stats = self.stats
        print(f"\n{'='*60}")
        print(f"ğŸš€ 9B ëª¨ë¸ ì „ìš© ì²˜ë¦¬ ì™„ë£Œ ë¦¬í¬íŠ¸")
        print(f"{'='*60}")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ì‹œë‚˜ë¦¬ì˜¤: {total_scenarios}ê°œ")
        print(f"âœ… ì„±ê³µ: {stats['successful']}ê°œ ({stats['successful']/total_scenarios*100:.1f}%)")
        print(f"âŒ ì‹¤íŒ¨: {stats['failed']}ê°œ ({stats['failed']/total_scenarios*100:.1f}%)")
        print(f"â±ï¸ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {stats['average_time']:.2f}ì´ˆ")
        print(f"ğŸ¯ í‰ê·  í’ˆì§ˆ ì ìˆ˜: {stats['average_quality']:.3f}")
        print(f"ğŸ§  ì‚¬ìš© ëª¨ë¸: HelpingAI2-9B (ë‹¨ì¼)")
        print(f"{'='*60}\n")

def main():
    """ë©”ì¸ ì‹¤í–‰ - 9B ëª¨ë¸ë§Œ ì‚¬ìš©"""
    print("ğŸ§  9B ëª¨ë¸ ì „ìš© ë°ì´í„° ì²˜ë¦¬ ì‹œì‘...")
    
    processor = Simple9BDataProcessor()
    
    try:
        processor.initialize()
        
        # EBS íŒŒì¼ ì²˜ë¦¬ (5ê°œë§Œ í…ŒìŠ¤íŠ¸)
        scenarios = processor.process_ebs_file(
            'for_learn_dataset/ai_ebs/ebs_1.txt',
            max_scenarios=5
        )
        
        processor.save_results(scenarios)
        
        print("âœ… 9B ëª¨ë¸ ì²˜ë¦¬ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()