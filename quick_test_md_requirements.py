#!/usr/bin/env python3
"""
MD ë¬¸ì„œ ìš”êµ¬ì‚¬í•­ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
Red Heart AI í†µí•© ìƒíƒœ í™•ì¸
"""

import sys
sys.path.append('/mnt/c/large_project/linux_red_heart')

print("ğŸ” Red Heart AI MD ë¬¸ì„œ ìš”êµ¬ì‚¬í•­ êµ¬í˜„ ê²€ì¦")
print("="*70)

# ìƒ‰ìƒ ì½”ë“œ
GREEN = '\033[92m'
RED = '\033[91m'
YELLOW = '\033[93m'
BLUE = '\033[94m'
END = '\033[0m'

def check_requirement(name, check_func):
    """ìš”êµ¬ì‚¬í•­ ì²´í¬"""
    try:
        result = check_func()
        if result:
            print(f"{GREEN}âœ…{END} {name}")
            return True
        else:
            print(f"{RED}âŒ{END} {name}")
            return False
    except Exception as e:
        print(f"{RED}âŒ{END} {name}: {e}")
        return False

# ì²´í¬ë¦¬ìŠ¤íŠ¸
checks_passed = 0
checks_total = 0

print("\nğŸ“‹ MD ë¬¸ì„œ í•µì‹¬ ìš”êµ¬ì‚¬í•­ ì²´í¬ë¦¬ìŠ¤íŠ¸")
print("-"*70)

# 1. ë©”ëª¨ë¦¬ ëª¨ë“œ ì²´í¬
print(f"\n{BLUE}1. ë©”ëª¨ë¦¬ ëª¨ë“œ (MD ë¬¸ì„œ ì‚¬ì–‘){END}")
def check_memory_modes():
    from main_unified import MemoryMode
    required = ['LIGHT', 'MEDIUM', 'HEAVY', 'MCP']
    for mode in required:
        if not hasattr(MemoryMode, mode):
            return False
        print(f"   - {mode}: {getattr(MemoryMode, mode).value}")
    return True
checks_total += 1
if check_requirement("ë©”ëª¨ë¦¬ ëª¨ë“œ 4ê°œ êµ¬í˜„", check_memory_modes):
    checks_passed += 1

# 2. 3ë·° ì‹œë‚˜ë¦¬ì˜¤ ì‹œìŠ¤í…œ
print(f"\n{BLUE}2. 3ë·° ì‹œë‚˜ë¦¬ì˜¤ ì‹œìŠ¤í…œ{END}")
def check_three_view():
    from three_view_scenario_system import ThreeViewScenarioSystem, ScenarioType
    from main_unified import UnifiedInferenceSystem
    
    # í´ë˜ìŠ¤ ì¡´ì¬ í™•ì¸
    print(f"   - ThreeViewScenarioSystem: êµ¬í˜„ë¨")
    print(f"   - ScenarioType: {[t.value for t in ScenarioType]}")
    
    # main_unified.py í†µí•© í™•ì¸
    if hasattr(UnifiedInferenceSystem, '_load_three_view_scenario_system'):
        print(f"   - main_unified.py í†µí•©: âœ…")
        return True
    else:
        print(f"   - main_unified.py í†µí•©: âŒ")
        return False
checks_total += 1
if check_requirement("3ë·° ì‹œë‚˜ë¦¬ì˜¤ ì‹œìŠ¤í…œ", check_three_view):
    checks_passed += 1

# 3. ë‹¤ì›ì  ìœ¤ë¦¬ ì²´ê³„ (Bì•ˆ: 5ê°œ)
print(f"\n{BLUE}3. ë‹¤ì›ì  ìœ¤ë¦¬ ì²´ê³„ (MD ë¬¸ì„œ Bì•ˆ: 5ê°œ){END}")
def check_ethics():
    from deep_multi_dimensional_ethics_system import (
        UtilitarianEngine, DeontologicalEngine, VirtueEthicsEngine,
        CareEthicsEngine, JusticeTheoryEngine
    )
    engines = [
        'UtilitarianEngine', 'DeontologicalEngine', 
        'VirtueEthicsEngine', 'CareEthicsEngine', 'JusticeTheoryEngine'
    ]
    for engine in engines:
        print(f"   - {engine}: âœ…")
    return True
checks_total += 1
if check_requirement("5ê°œ ìœ¤ë¦¬ ì—”ì§„", check_ethics):
    checks_passed += 1

# 4. ë¹„ì„ í˜• ì›Œí¬í”Œë¡œìš°
print(f"\n{BLUE}4. ë¹„ì„ í˜• ì›Œí¬í”Œë¡œìš°{END}")
def check_workflow():
    from main_unified import UnifiedInferenceSystem
    import inspect
    
    if hasattr(UnifiedInferenceSystem, 'analyze_ethical_dilemma'):
        sig = inspect.signature(UnifiedInferenceSystem.analyze_ethical_dilemma)
        params = list(sig.parameters.keys())
        print(f"   - analyze_ethical_dilemma: êµ¬í˜„ë¨")
        print(f"   - íŒŒë¼ë¯¸í„°: {params}")
        
        if 'llm_scenarios' in params:
            print(f"   - llm_scenarios íŒŒë¼ë¯¸í„°: âœ…")
            return True
        else:
            print(f"   - llm_scenarios íŒŒë¼ë¯¸í„°: âŒ")
            return False
    return False
checks_total += 1
if check_requirement("ë¹„ì„ í˜• ì›Œí¬í”Œë¡œìš°", check_workflow):
    checks_passed += 1

# 5. ë©”ëª¨ë¦¬ ìŠ¤ì™‘ ë§¤ë‹ˆì €
print(f"\n{BLUE}5. ë©”ëª¨ë¦¬ ìŠ¤ì™‘ ë§¤ë‹ˆì €{END}")
def check_swap():
    from memory_swap_manager import SystemSwapManager, SystemType
    print(f"   - SystemSwapManager: êµ¬í˜„ë¨")
    print(f"   - SystemType: {[t.value for t in SystemType]}")
    return True
checks_total += 1
if check_requirement("ë©”ëª¨ë¦¬ ìŠ¤ì™‘ ë§¤ë‹ˆì €", check_swap):
    checks_passed += 1

# 6. LLM í†µí•©
print(f"\n{BLUE}6. LLM í†µí•©{END}")
def check_llm():
    from llm_module.advanced_llm_engine import AdvancedLLMEngine
    from main_unified import UnifiedInferenceSystem
    
    print(f"   - AdvancedLLMEngine: êµ¬í˜„ë¨")
    
    if hasattr(AdvancedLLMEngine, 'check_plausibility'):
        print(f"   - check_plausibility: âœ…")
    else:
        print(f"   - check_plausibility: âŒ")
        
    if hasattr(UnifiedInferenceSystem, '_load_llm_integration'):
        print(f"   - _load_llm_integration: âœ…")
        return True
    else:
        print(f"   - _load_llm_integration: âŒ")
        return False
checks_total += 1
if check_requirement("LLM í†µí•©", check_llm):
    checks_passed += 1

# 7. í›„íšŒ ì‹œìŠ¤í…œ ëŒ€ì•ˆ ìƒì„±
print(f"\n{BLUE}7. í›„íšŒ ì‹œìŠ¤í…œ ëŒ€ì•ˆ ìƒì„±{END}")
def check_regret():
    from advanced_regret_learning_system import AdvancedRegretLearningSystem
    if hasattr(AdvancedRegretLearningSystem, 'suggest_alternatives'):
        print(f"   - suggest_alternatives: âœ…")
        return True
    else:
        print(f"   - suggest_alternatives: âŒ")
        return False
checks_total += 1
if check_requirement("suggest_alternatives ë©”ì„œë“œ", check_regret):
    checks_passed += 1

# 8. ê²½í—˜ DB ì €ì¥
print(f"\n{BLUE}8. ê²½í—˜ DB ì €ì¥{END}")
def check_experience_db():
    from advanced_experience_database import AdvancedExperienceDatabase
    
    if hasattr(AdvancedExperienceDatabase, 'store_experience'):
        print(f"   - store_experience ë©”ì„œë“œ: âœ…")
        
        # main_unified.pyì—ì„œ ì‹¤ì œ ì‚¬ìš© í™•ì¸
        with open('main_unified.py', 'r') as f:
            content = f.read()
            if 'experience_database.store' in content or 'store_experience' in content:
                print(f"   - main_unified.pyì—ì„œ í˜¸ì¶œ: âœ…")
                return True
            else:
                print(f"   - main_unified.pyì—ì„œ í˜¸ì¶œ: âŒ")
                return False
    return False
checks_total += 1
if check_requirement("ê²½í—˜ DB ì €ì¥", check_experience_db):
    checks_passed += 1

# 9. MCP ì„œë²„
print(f"\n{BLUE}9. MCP ì„œë²„{END}")
def check_mcp():
    from mcp_server import RedHeartMCPServer
    print(f"   - RedHeartMCPServer: êµ¬í˜„ë¨")
    
    if hasattr(RedHeartMCPServer, 'handle_request'):
        print(f"   - handle_request: âœ…")
        return True
    else:
        print(f"   - handle_request: âŒ")
        return False
checks_total += 1
if check_requirement("MCP ì„œë²„", check_mcp):
    checks_passed += 1

# 10. ì‹œê°„ì  ì „íŒŒ ë¶„ì„
print(f"\n{BLUE}10. ì‹œê°„ì  ì „íŒŒ ë¶„ì„{END}")
def check_temporal():
    from temporal_event_propagation_analyzer import TemporalEventPropagationAnalyzer
    print(f"   - TemporalEventPropagationAnalyzer: êµ¬í˜„ë¨")
    return True
checks_total += 1
if check_requirement("ì‹œê°„ì  ì „íŒŒ ë¶„ì„", check_temporal):
    checks_passed += 1

# 11. MEDIUM ëª¨ë“œ 600M êµ¬í˜„
print(f"\n{BLUE}11. MEDIUM ëª¨ë“œ 600M ì¬ì„¤ê³„{END}")
def check_medium_mode():
    with open('main_unified.py', 'r') as f:
        content = f.read()
        if 'MEDIUM ëª¨ë“œ (600M) - MD ë¬¸ì„œ ì¬ì„¤ê³„ ì‚¬ì–‘' in content:
            print(f"   - MEDIUM ëª¨ë“œ 600M ì¬ì„¤ê³„: âœ…")
            return True
        else:
            print(f"   - MEDIUM ëª¨ë“œ 600M ì¬ì„¤ê³„: âŒ")
            return False
checks_total += 1
if check_requirement("MEDIUM ëª¨ë“œ 600M", check_medium_mode):
    checks_passed += 1

# 12. ì •í•©ì„± íŒë‹¨ (LLM + ì‹œìŠ¤í…œ)
print(f"\n{BLUE}12. ì •í•©ì„± íŒë‹¨{END}")
def check_plausibility():
    with open('main_unified.py', 'r') as f:
        content = f.read()
        if '_calculate_plausibility' in content:
            print(f"   - _calculate_plausibility: âœ…")
            if 'llm_engine.check_plausibility' in content:
                print(f"   - LLM ì •í•©ì„± ê²€ì¦ ì—°ë™: âœ…")
                return True
            else:
                print(f"   - LLM ì •í•©ì„± ê²€ì¦ ì—°ë™: âŒ")
                return False
        return False
checks_total += 1
if check_requirement("ì •í•©ì„± íŒë‹¨", check_plausibility):
    checks_passed += 1

# ê²°ê³¼ ìš”ì•½
print("\n" + "="*70)
print(f"{BLUE}ğŸ“Š MD ë¬¸ì„œ ìš”êµ¬ì‚¬í•­ êµ¬í˜„ ì™„ì„±ë„{END}")
print("="*70)

completion_rate = (checks_passed / checks_total) * 100
color = GREEN if completion_rate >= 90 else YELLOW if completion_rate >= 70 else RED

print(f"âœ… êµ¬í˜„ ì™„ë£Œ: {checks_passed}/{checks_total}")
print(f"ğŸ“ˆ ì™„ì„±ë„: {color}{completion_rate:.1f}%{END}")

if checks_passed < checks_total:
    print(f"\n{YELLOW}âš ï¸ ë¯¸êµ¬í˜„ í•­ëª©ì´ {checks_total - checks_passed}ê°œ ìˆìŠµë‹ˆë‹¤.{END}")
else:
    print(f"\n{GREEN}ğŸ‰ ëª¨ë“  MD ë¬¸ì„œ ìš”êµ¬ì‚¬í•­ì´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!{END}")

# ì¶”ê°€ ì •ë³´
print("\n" + "="*70)
print(f"{BLUE}ğŸ“ ì¶”ê°€ í™•ì¸ì‚¬í•­{END}")
print("-"*70)

# GPU ë©”ëª¨ë¦¬ í™•ì¸
try:
    import torch
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"GPU: {gpu_name} ({gpu_memory:.1f}GB)")
    else:
        print("GPU: ì‚¬ìš© ë¶ˆê°€ (CPU ëª¨ë“œ)")
except:
    print("GPU: í™•ì¸ ì‹¤íŒ¨")

# ì²´í¬í¬ì¸íŠ¸ í™•ì¸
import os
checkpoint_dir = "training/checkpoints_final"
if os.path.exists(checkpoint_dir):
    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')]
    if checkpoints:
        latest = sorted(checkpoints)[-1]
        print(f"ìµœì‹  ì²´í¬í¬ì¸íŠ¸: {latest}")
    else:
        print("ì²´í¬í¬ì¸íŠ¸: ì—†ìŒ")
else:
    print("ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬: ì—†ìŒ")

print("\nâœ… MD ë¬¸ì„œ ìš”êµ¬ì‚¬í•­ ê²€ì¦ ì™„ë£Œ!")