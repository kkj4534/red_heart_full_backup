"""
Advanced Analyzer nn.Module ë˜í¼
nn.Moduleì„ ìƒì†í•˜ì§€ ì•ŠëŠ” Advanced Analyzerë“¤ì„ ë˜í•‘í•˜ì—¬ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦
"""

import torch
import torch.nn as nn
from typing import Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)


class AdvancedEmotionAnalyzerWrapper(nn.Module):
    """Advanced Emotion Analyzerë¥¼ nn.Moduleë¡œ ë˜í•‘ (48M íŒŒë¼ë¯¸í„°)"""
    
    def __init__(self):
        super().__init__()
        
        # ì›ë³¸ Analyzer import ë° ì´ˆê¸°í™”
        from advanced_emotion_analyzer import AdvancedEmotionAnalyzer
        self.analyzer = AdvancedEmotionAnalyzer()
        
        # ë‚´ë¶€ nn.Moduleë“¤ì„ ì§ì ‘ ì†ì„±ìœ¼ë¡œ ë“±ë¡ (í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ)
        self._register_internal_modules()
        
        logger.info("âœ… Advanced Emotion Analyzer Wrapper ì´ˆê¸°í™” (48M íŒŒë¼ë¯¸í„°)")
    
    def _register_internal_modules(self):
        """ë‚´ë¶€ nn.Moduleë“¤ì„ selfì˜ ì†ì„±ìœ¼ë¡œ ë“±ë¡"""
        
        # ìƒì²´ì‹ í˜¸ ì²˜ë¦¬ ë„¤íŠ¸ì›Œí¬ (10M)
        if hasattr(self.analyzer, 'biometric_processor'):
            self.biometric_processor = self.analyzer.biometric_processor
            logger.info("  - biometric_processor ë“±ë¡ (10M)")
        
        # ë©€í‹°ëª¨ë‹¬ ìœµí•© ë ˆì´ì–´ (10M)
        if hasattr(self.analyzer, 'multimodal_fusion'):
            self.multimodal_fusion = self.analyzer.multimodal_fusion
            logger.info("  - multimodal_fusion ë“±ë¡ (10M)")
        
        # ì‹œê³„ì—´ ê°ì • ì¶”ì  (10M)
        if hasattr(self.analyzer, 'temporal_emotion'):
            self.temporal_emotion = self.analyzer.temporal_emotion
            logger.info("  - temporal_emotion ë“±ë¡ (10M)")
        
        # ë¬¸í™”ì  ë‰˜ì•™ìŠ¤ ê°ì§€ (13M)
        if hasattr(self.analyzer, 'cultural_nuance'):
            self.cultural_nuance = self.analyzer.cultural_nuance
            logger.info("  - cultural_nuance ë“±ë¡ (13M)")
        
        # ê³ ê¸‰ MoE í™•ì¥ (5M)
        if hasattr(self.analyzer, 'advanced_moe'):
            self.advanced_moe = self.analyzer.advanced_moe
            logger.info("  - advanced_moe ë“±ë¡ (5M)")
        
        # emotion_moe ì²´í¬
        if hasattr(self.analyzer, 'emotion_moe'):
            self.emotion_moe = self.analyzer.emotion_moe
            logger.info("  - emotion_moe ë“±ë¡")
    
    def forward(self, x: torch.Tensor, **kwargs) -> Dict[str, torch.Tensor]:
        """Forward pass - ì œê³µëœ ì„ë² ë”© ì§ì ‘ ì²˜ë¦¬"""
        logger.info("ğŸ”„ AdvancedEmotionAnalyzerWrapper forward ì‹¤í–‰ ì‹œì‘")
        logger.info(f"   ì…ë ¥ ì„ë² ë”© ì°¨ì›: {x.shape}")
        
        try:
            # ì œê³µëœ 896ì°¨ì› ì„ë² ë”©ì„ ì§ì ‘ ì²˜ë¦¬
            # analyze_emotionì„ í˜¸ì¶œí•˜ë©´ ìƒˆë¡œìš´ 768ì°¨ì› ì„ë² ë”©ì„ ìƒì„±í•˜ë¯€ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            return self._process_embeddings(x, **kwargs)
        except Exception as e:
            logger.error(f"âŒ AdvancedEmotionAnalyzerWrapper ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise RuntimeError(f"ê°ì • ë¶„ì„ ì‹¤íŒ¨ - NO FALLBACK: {e}")
    
    def _process_embeddings(self, embeddings: torch.Tensor, **kwargs) -> Dict[str, torch.Tensor]:
        """ì„ë² ë”© ì§ì ‘ ì²˜ë¦¬ - NO FALLBACK"""
        logger.info("   ğŸ”„ ì„ë² ë”© ì§ì ‘ ì²˜ë¦¬ ì‹œì‘")
        logger.info(f"      ì…ë ¥ ì°¨ì›: {embeddings.shape}")
        output = {}
        
        # ì…ë ¥ ì°¨ì›ì— ë”°ë¼ ì²˜ë¦¬ ë¶„ê¸°
        if embeddings.shape[-1] == 896:
            # 896ì°¨ì› â†’ 768ì°¨ì› í”„ë¡œì ì…˜ (ë‚´ë¶€ ëª¨ë“ˆë“¤ì´ 768ì°¨ì› ê¸°ëŒ€)
            if not hasattr(self, 'embedding_projection_896'):
                self.embedding_projection_896 = nn.Sequential(
                    nn.Linear(896, 768),
                    nn.LayerNorm(768),
                    nn.GELU(),
                    nn.Dropout(0.1)
                ).to(embeddings.device)
                logger.info("      896â†’768 í”„ë¡œì ì…˜ ë ˆì´ì–´ ìƒì„±")
            
            self.embedding_projection_896 = self.embedding_projection_896.to(embeddings.device)
            embeddings_768 = self.embedding_projection_896(embeddings)
            logger.info(f"      896ì°¨ì› ì…ë ¥, í”„ë¡œì ì…˜ í›„ ì°¨ì›: {embeddings_768.shape}")
        elif embeddings.shape[-1] == 768:
            # ì´ë¯¸ 768ì°¨ì›ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            embeddings_768 = embeddings
            logger.info(f"      768ì°¨ì› ì…ë ¥, í”„ë¡œì ì…˜ ì—†ì´ ì§ì ‘ ì‚¬ìš©")
        else:
            # ì˜ˆìƒì¹˜ ëª»í•œ ì°¨ì›
            raise RuntimeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ ì°¨ì›: {embeddings.shape[-1]} (896 ë˜ëŠ” 768 í•„ìš”)")
        
        # ê° ë‚´ë¶€ ëª¨ë“ˆì— í”„ë¡œì ì…˜ëœ ì„ë² ë”© ì „ë‹¬
        if hasattr(self, 'temporal_emotion') and 'lstm_tracker' in self.temporal_emotion:
            try:
                # LSTM ê¸°ë°˜ ì²˜ë¦¬
                logger.info("      - temporal_emotion LSTM ì²˜ë¦¬ ì¤‘...")
                # LSTMì˜ ë””ë°”ì´ìŠ¤ë¥¼ í™•ì¸í•˜ê³  ì…ë ¥ì„ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                lstm_device = next(self.temporal_emotion['lstm_tracker'].parameters()).device
                embeddings_on_device = embeddings_768.to(lstm_device)
                temporal_out = self.temporal_emotion['lstm_tracker'](embeddings_on_device.unsqueeze(1))
                # ê²°ê³¼ë¥¼ ì›ë˜ ì…ë ¥ ë””ë°”ì´ìŠ¤ë¡œ ë‹¤ì‹œ ì´ë™
                output['temporal_emotion'] = temporal_out[0].squeeze(1).to(embeddings.device)
                logger.info("      âœ… temporal_emotion ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"      âŒ temporal_emotion ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"temporal_emotion ì²˜ë¦¬ ì‹¤íŒ¨ - NO FALLBACK: {e}")
        
        # multimodal fusion ì²˜ë¦¬
        if hasattr(self, 'multimodal_fusion') and 'text_encoder' in self.multimodal_fusion:
            try:
                logger.info("      - multimodal_fusion ì²˜ë¦¬ ì¤‘...")
                # text_encoderì˜ ë””ë°”ì´ìŠ¤ë¥¼ í™•ì¸í•˜ê³  ì…ë ¥ì„ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                encoder_device = next(self.multimodal_fusion['text_encoder'].parameters()).device
                embeddings_on_device = embeddings_768.to(encoder_device)
                encoded = self.multimodal_fusion['text_encoder'](embeddings_on_device.unsqueeze(1))
                # ê²°ê³¼ë¥¼ ì›ë˜ ì…ë ¥ ë””ë°”ì´ìŠ¤ë¡œ ë‹¤ì‹œ ì´ë™
                output['multimodal'] = encoded.mean(dim=1).to(embeddings.device)  # í‰ê·  í’€ë§
                logger.info("      âœ… multimodal_fusion ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"      âŒ multimodal_fusion ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"multimodal_fusion ì²˜ë¦¬ ì‹¤íŒ¨ - NO FALLBACK: {e}")
        
        # advanced_moe ì²˜ë¦¬ (ê°ì • ìƒì„±)
        if hasattr(self, 'advanced_moe') and 'router' in self.advanced_moe:
            try:
                logger.info("      - advanced_moe ì²˜ë¦¬ ì¤‘...")
                # routerì˜ ë””ë°”ì´ìŠ¤ë¥¼ í™•ì¸í•˜ê³  ì…ë ¥ì„ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                router_device = next(self.advanced_moe['router'].parameters()).device
                embeddings_on_device = embeddings_768.to(router_device)
                router_weights = self.advanced_moe['router'](embeddings_on_device)
                expert_outputs = []
                for i, expert in enumerate(self.advanced_moe['micro_experts']):
                    expert_out = expert(embeddings_on_device)
                    expert_outputs.append(expert_out * router_weights[:, i:i+1])
                # ê²°ê³¼ë¥¼ ì›ë˜ ì…ë ¥ ë””ë°”ì´ìŠ¤ë¡œ ë‹¤ì‹œ ì´ë™
                output['emotions'] = torch.stack(expert_outputs).sum(dim=0)[:, :7].to(embeddings.device)  # 7ì°¨ì› ê°ì •
                logger.info("      âœ… advanced_moe ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"      âŒ advanced_moe ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                # advanced_moe ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ë°©ë²• ì‹œë„
        
        # ê°ì • ë²¡í„°ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if 'emotions' not in output:
            # 896ì°¨ì›ì„ 7ì°¨ì› ê°ì •ìœ¼ë¡œ ì§ì ‘ í”„ë¡œì ì…˜
            if not hasattr(self, 'emotion_projection'):
                self.emotion_projection = nn.Sequential(
                    nn.Linear(896, 128),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(128, 7),
                    nn.Softmax(dim=-1)
                )
                logger.info("      896â†’7 ê°ì • í”„ë¡œì ì…˜ ë ˆì´ì–´ ìƒì„±")
            
            # í”„ë¡œì ì…˜ ë ˆì´ì–´ë¥¼ ì…ë ¥ê³¼ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.emotion_projection = self.emotion_projection.to(embeddings.device)
            output['emotions'] = self.emotion_projection(embeddings)
            logger.info("      âœ… ê°ì • ë²¡í„° í”„ë¡œì ì…˜ ìƒì„±")
        
        # valence, arousal ì¶”ê°€ (ê°ì • ë²¡í„°ì—ì„œ ê³„ì‚°)
        if 'emotions' in output:
            # positive emotions (joy, surprise) vs negative emotions (sadness, anger, fear, disgust)
            valence = output['emotions'][:, 0] + output['emotions'][:, 4] - \
                     (output['emotions'][:, 1] + output['emotions'][:, 2] + output['emotions'][:, 3] + output['emotions'][:, 5])
            output['valence'] = valence.unsqueeze(-1)
            
            # arousal: í™œì„±í™” ì •ë„ (neutralì´ ì•„ë‹Œ ì •ë„)
            arousal = 1.0 - output['emotions'][:, 6] if output['emotions'].shape[1] > 6 else torch.ones_like(valence)
            output['arousal'] = arousal.unsqueeze(-1)
        
        logger.info(f"   âœ… ì„ë² ë”© ì²˜ë¦¬ ì™„ë£Œ: {list(output.keys())}")
        return output
    
    def _convert_emotion_data_to_tensor(self, emotion_data, device) -> Dict[str, torch.Tensor]:
        """EmotionDataë¥¼ í…ì„œë¡œ ë³€í™˜"""
        output = {}
        
        # ì£¼ìš” ê°ì • ë²¡í„°
        emotions = torch.zeros(1, 7).to(device)
        if hasattr(emotion_data, 'primary_emotion'):
            emotion_map = {'joy': 0, 'sadness': 1, 'anger': 2, 'fear': 3, 'surprise': 4, 'disgust': 5, 'neutral': 6}
            primary = str(emotion_data.primary_emotion).lower()
            if primary in emotion_map:
                emotions[0, emotion_map[primary]] = emotion_data.intensity if hasattr(emotion_data, 'intensity') else 1.0
        
        output['emotions'] = emotions
        
        # valence, arousal ì¶”ê°€
        if hasattr(emotion_data, 'valence'):
            output['valence'] = torch.tensor([[emotion_data.valence]], device=device)
        if hasattr(emotion_data, 'arousal'):
            output['arousal'] = torch.tensor([[emotion_data.arousal]], device=device)
        
        return output
    
    def _direct_forward(self, x: torch.Tensor, **kwargs) -> Dict[str, torch.Tensor]:
        """ë‚´ë¶€ ëª¨ë“ˆ ì§ì ‘ forward - NO FALLBACK"""
        logger.info("   ğŸ”„ ë‚´ë¶€ ëª¨ë“ˆ ì§ì ‘ forward ì‹œì‘")
        output = {}
        
        # ë©€í‹°ëª¨ë‹¬ ìœµí•© ì²˜ë¦¬
        if hasattr(self, 'multimodal_fusion') and 'text_encoder' in self.multimodal_fusion:
            try:
                logger.info("      - multimodal_fusion text_encoder ì²˜ë¦¬ ì¤‘...")
                encoded = self.multimodal_fusion['text_encoder'](x.unsqueeze(1))
                output['multimodal'] = encoded.mean(dim=1)  # í‰ê·  í’€ë§
                logger.info("      âœ… multimodal_fusion ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"      âŒ multimodal_fusion ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"multimodal_fusion ì²˜ë¦¬ ì‹¤íŒ¨ - NO FALLBACK: {e}")
        
        # advanced_moe ì²˜ë¦¬
        if hasattr(self, 'advanced_moe') and 'router' in self.advanced_moe:
            try:
                logger.info("      - advanced_moe ì²˜ë¦¬ ì¤‘...")
                router_weights = self.advanced_moe['router'](x)
                expert_outputs = []
                for i, expert in enumerate(self.advanced_moe['micro_experts']):
                    expert_out = expert(x)
                    expert_outputs.append(expert_out * router_weights[:, i:i+1])
                output['emotions'] = torch.stack(expert_outputs).sum(dim=0)
                logger.info("      âœ… advanced_moe ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"      âŒ advanced_moe ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"advanced_moe ì²˜ë¦¬ ì‹¤íŒ¨ - NO FALLBACK: {e}")
        
        # ì¶œë ¥ì´ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not output:
            raise RuntimeError("ë‚´ë¶€ ëª¨ë“ˆ forward ì‹¤íŒ¨: ì–´ë–¤ ëª¨ë“ˆë„ ì²˜ë¦¬í•˜ì§€ ëª»í•¨ - NO FALLBACK")
        
        logger.info(f"   âœ… ë‚´ë¶€ ëª¨ë“ˆ ì²˜ë¦¬ ì™„ë£Œ: {list(output.keys())}")
        return output


class AdvancedRegretAnalyzerWrapper(nn.Module):
    """Advanced Regret Analyzerë¥¼ nn.Moduleë¡œ ë˜í•‘ (50M íŒŒë¼ë¯¸í„°)"""
    
    def __init__(self):
        super().__init__()
        
        from advanced_regret_analyzer import AdvancedRegretAnalyzer
        self.analyzer = AdvancedRegretAnalyzer()
        
        self._register_internal_modules()
        
        logger.info("âœ… Advanced Regret Analyzer Wrapper ì´ˆê¸°í™” (50M íŒŒë¼ë¯¸í„°)")
    
    def _register_internal_modules(self):
        """ë‚´ë¶€ nn.Moduleë“¤ì„ ë“±ë¡"""
        
        # GPU í›„íšŒ ë„¤íŠ¸ì›Œí¬ (3M)
        if hasattr(self.analyzer, 'regret_network'):
            self.regret_network = self.analyzer.regret_network
            logger.info("  - regret_network ë“±ë¡ (3M)")
        
        # ë°˜ì‚¬ì‹¤ ì‹œë®¬ë ˆì´ì…˜ (15M)
        if hasattr(self.analyzer, 'counterfactual_sim'):
            self.counterfactual_sim = self.analyzer.counterfactual_sim
            logger.info("  - counterfactual_sim ë“±ë¡ (15M)")
        
        # ì‹œê°„ì¶• í›„íšŒ ì „íŒŒ (12M)
        if hasattr(self.analyzer, 'temporal_propagation'):
            self.temporal_propagation = self.analyzer.temporal_propagation
            logger.info("  - temporal_propagation ë“±ë¡ (12M)")
        
        # ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ (10M)
        if hasattr(self.analyzer, 'decision_tree'):
            self.decision_tree = self.analyzer.decision_tree
            logger.info("  - decision_tree ë“±ë¡ (10M)")
        
        # ë² ì´ì§€ì•ˆ ì¶”ë¡  (10M)
        if hasattr(self.analyzer, 'bayesian_inference'):
            self.bayesian_inference = self.analyzer.bayesian_inference
            logger.info("  - bayesian_inference ë“±ë¡ (10M)")
    
    def forward(self, x: torch.Tensor, **kwargs) -> Dict[str, torch.Tensor]:
        """Forward pass - NO FALLBACK"""
        logger.info("ğŸ”„ AdvancedRegretAnalyzerWrapper forward ì‹¤í–‰ ì‹œì‘")
        logger.info(f"   ì…ë ¥ ì°¨ì›: {x.shape}")
        output = {}
        
        # í›„íšŒ ë„¤íŠ¸ì›Œí¬ ì²˜ë¦¬
        if hasattr(self, 'regret_network'):
            try:
                logger.info("   - regret_network ì²˜ë¦¬ ì¤‘...")
                
                # ì°¨ì› ì²´í¬ ë° í”„ë¡œì ì…˜ ì–´ëŒ‘í„° ì²˜ë¦¬
                # ì²´í¬í¬ì¸íŠ¸ê°€ 768ì°¨ì›ì¸ ê²½ìš°ë¥¼ ìœ„í•œ í”„ë¡œì ì…˜
                expected_dim = next(self.regret_network.regret_predictor[0].parameters()).shape[1]
                logger.info(f"   regret_network ê¸°ëŒ€ ì°¨ì›: {expected_dim}, ì…ë ¥ ì°¨ì›: {x.shape[-1]}")
                
                if x.shape[-1] == 896 and expected_dim == 768:
                    # 896 -> 768 í”„ë¡œì ì…˜ í•„ìš”
                    if not hasattr(self, 'input_projection_896_to_768'):
                        logger.info("   896â†’768 í”„ë¡œì ì…˜ ì–´ëŒ‘í„° ìƒì„± ì¤‘...")
                        self.input_projection_896_to_768 = nn.Sequential(
                            nn.Linear(896, 768),
                            nn.LayerNorm(768),
                            nn.GELU()
                        ).to(x.device)
                    
                    self.input_projection_896_to_768 = self.input_projection_896_to_768.to(x.device)
                    x_projected = self.input_projection_896_to_768(x)
                    logger.info(f"   í”„ë¡œì ì…˜ í›„ ì°¨ì›: {x_projected.shape}")
                    regret_out = self.regret_network(x_projected)
                elif x.shape[-1] == 768 and expected_dim == 896:
                    # 768 -> 896 í”„ë¡œì ì…˜ í•„ìš” (Advanced Analysis ë‹¨ê³„ì—ì„œ ë°œìƒ)
                    if not hasattr(self, 'input_projection_768_to_896'):
                        logger.info("   768â†’896 í”„ë¡œì ì…˜ ì–´ëŒ‘í„° ìƒì„± ì¤‘...")
                        self.input_projection_768_to_896 = nn.Sequential(
                            nn.Linear(768, 896),
                            nn.LayerNorm(896),
                            nn.GELU()
                        ).to(x.device)
                    
                    self.input_projection_768_to_896 = self.input_projection_768_to_896.to(x.device)
                    x_projected = self.input_projection_768_to_896(x)
                    logger.info(f"   í”„ë¡œì ì…˜ í›„ ì°¨ì›: {x_projected.shape}")
                    regret_out = self.regret_network(x_projected)
                else:
                    # ì°¨ì›ì´ ì¼ì¹˜í•˜ê±°ë‚˜ ì´ë¯¸ ë§ëŠ” ê²½ìš°
                    regret_out = self.regret_network(x)
                
                # GPURegretNetworkëŠ” tupleì„ ë°˜í™˜: (regret_score, emotion_vector, uncertainty)
                if isinstance(regret_out, tuple):
                    regret_score, emotion_vector, uncertainty = regret_out
                    output['regret_score'] = regret_score
                    output['regret_emotion_vector'] = emotion_vector
                    output['regret_uncertainty'] = uncertainty
                elif isinstance(regret_out, dict):
                    output['regret_score'] = regret_out.get('regret_score', regret_out)
                else:
                    output['regret_score'] = regret_out
                logger.info("   âœ… regret_network ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"   âŒ regret_network ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"Regret network ì²˜ë¦¬ ì‹¤íŒ¨ - NO FALLBACK: {e}")
        
        # ë°˜ì‚¬ì‹¤ ì‹œë®¬ë ˆì´ì…˜
        if hasattr(self, 'counterfactual_sim') and 'world_model' in self.counterfactual_sim:
            try:
                cf_out = self.counterfactual_sim['world_model'](x)
                output['counterfactual'] = cf_out
            except:
                pass
        
        # ì¶œë ¥ ê²€ì¦ - NO FALLBACK
        if 'regret_score' not in output:
            logger.error("âŒ Regret score ê³„ì‚° ì‹¤íŒ¨")
            raise RuntimeError("Regret ë¶„ì„ ì‹¤íŒ¨: regret_score ìƒì„± ëª»í•¨ - NO FALLBACK")
        
        logger.info(f"   âœ… AdvancedRegretAnalyzer ì²˜ë¦¬ ì™„ë£Œ: {list(output.keys())}")
        return output


class AdvancedSURDAnalyzerWrapper(nn.Module):
    """Advanced SURD Analyzerë¥¼ nn.Moduleë¡œ ë˜í•‘ (25M íŒŒë¼ë¯¸í„°)"""
    
    def __init__(self):
        super().__init__()
        
        from advanced_surd_analyzer import AdvancedSURDAnalyzer
        self.analyzer = AdvancedSURDAnalyzer()
        
        # ë””ë°”ì´ìŠ¤ ê²°ì •
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        
        # 896ì°¨ì› â†’ 768ì°¨ì› íˆ¬ì˜ ë ˆì´ì–´ ì¶”ê°€ (deep_causalì„ ìœ„í•´)
        self.input_projection = nn.Sequential(
            nn.Linear(896, 768),
            nn.LayerNorm(768),
            nn.ReLU(),
            nn.Dropout(0.1)
        ).to(device)
        
        self._register_internal_modules()
        
        logger.info(f"âœ… Advanced SURD Analyzer Wrapper ì´ˆê¸°í™” (25M íŒŒë¼ë¯¸í„°, device: {device})")
    
    def _register_internal_modules(self):
        """ë‚´ë¶€ nn.Moduleë“¤ì„ ë“±ë¡"""
        
        # ì‹¬ì¸µ ì¸ê³¼ ì¶”ë¡  (10M)
        if hasattr(self.analyzer, 'deep_causal'):
            self.deep_causal = self.analyzer.deep_causal
            logger.info("  - deep_causal ë“±ë¡ (10M)")
        
        # ì •ë³´ì´ë¡  ë¶„í•´ (8M)
        if hasattr(self.analyzer, 'info_decomposition'):
            self.info_decomposition = self.analyzer.info_decomposition
            logger.info("  - info_decomposition ë“±ë¡ (8M)")
        
        # Neural Causal Model (5M)
        if hasattr(self.analyzer, 'neural_causal_model'):
            self.neural_causal_model = self.analyzer.neural_causal_model
            logger.info("  - neural_causal_model ë“±ë¡ (5M)")
        
        # Network Optimizer (2M)
        if hasattr(self.analyzer, 'network_optimizer'):
            self.network_optimizer = self.analyzer.network_optimizer
            logger.info("  - network_optimizer ë“±ë¡ (2M)")
    
    def forward(self, x: torch.Tensor, **kwargs) -> Dict[str, torch.Tensor]:
        """Forward pass - NO FALLBACK"""
        logger.info("ğŸ”„ AdvancedSURDAnalyzerWrapper forward ì‹¤í–‰ ì‹œì‘")
        output = {}
        
        # ë””ë°”ì´ìŠ¤ ì¼ì¹˜ ì²˜ë¦¬
        logger.info(f"   ì…ë ¥ ì°¨ì›: {x.shape}")
        
        # input_projectionì˜ ë””ë°”ì´ìŠ¤ í™•ì¸
        projection_device = next(self.input_projection.parameters()).device
        logger.info(f"   projection device: {projection_device}, input device: {x.device}")
        
        # ì…ë ¥ í…ì„œë¥¼ projection layerì™€ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        if x.device != projection_device:
            logger.info(f"   ë””ë°”ì´ìŠ¤ ë¶ˆì¼ì¹˜ ê°ì§€ - ì…ë ¥ì„ {projection_device}ë¡œ ì´ë™")
            x = x.to(projection_device)
        
        # 768ì°¨ì› ì…ë ¥ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì²´í¬
        if x.shape[-1] == 768:
            # 768ì°¨ì›ì€ ì´ë¯¸ deep_causalì— ë§ìœ¼ë¯€ë¡œ íˆ¬ì˜ ì—†ì´ ì‚¬ìš©
            logger.info("   768ì°¨ì› ì…ë ¥ ê°ì§€ - ì§ì ‘ ì‚¬ìš©")
            x_projected = x
        else:
            # 896 -> 768 íˆ¬ì˜
            x_projected = self.input_projection(x)
        logger.info(f"   íˆ¬ì˜ í›„ ì°¨ì›: {x_projected.shape}")
        
        # ì‹¬ì¸µ ì¸ê³¼ ì¶”ë¡ 
        if hasattr(self, 'deep_causal') and 'causal_encoder' in self.deep_causal:
            try:
                logger.info("   - deep_causal ì²˜ë¦¬ ì¤‘...")
                causal_out = self.deep_causal['causal_encoder'](x_projected)
                # S, U, R, D ë¶„í•´
                output['surd_metrics'] = causal_out[:, :4]  # ì²« 4ì°¨ì›
                logger.info("   âœ… deep_causal ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"   âŒ deep_causal ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"Deep causal ì²˜ë¦¬ ì‹¤íŒ¨ - NO FALLBACK: {e}")
        
        # ì •ë³´ì´ë¡  ë¶„í•´
        if hasattr(self, 'info_decomposition') and 'mutual_info' in self.info_decomposition:
            try:
                # info_decompositionë„ 768ì°¨ì› ê¸°ë°˜ì´ë¯€ë¡œ íˆ¬ì˜ëœ ì…ë ¥ ì‚¬ìš©
                info_out = self.info_decomposition['mutual_info'](torch.cat([x_projected, x_projected], dim=-1))
                if 'surd_metrics' not in output:
                    output['surd_metrics'] = info_out[:, :4]
            except:
                pass
        
        # ì¶œë ¥ ê²€ì¦ - NO FALLBACK
        if 'surd_metrics' not in output:
            logger.error("âŒ SURD metrics ê³„ì‚° ì‹¤íŒ¨")
            raise RuntimeError("SURD ë¶„ì„ ì‹¤íŒ¨: surd_metrics ìƒì„± ëª»í•¨ - NO FALLBACK")
        
        logger.info(f"   âœ… AdvancedSURDAnalyzer ì²˜ë¦¬ ì™„ë£Œ: {list(output.keys())}")
        return output


class AdvancedBenthamCalculatorWrapper(nn.Module):
    """Advanced Bentham Calculatorë¥¼ nn.Moduleë¡œ ë˜í•‘ (2.5M íŒŒë¼ë¯¸í„°)"""
    
    def __init__(self):
        super().__init__()
        
        from advanced_bentham_calculator import AdvancedBenthamCalculator
        self.analyzer = AdvancedBenthamCalculator()
        
        # ë””ë°”ì´ìŠ¤ ê²°ì • (bentham_default_networkì™€ ë™ì¼í•˜ê²Œ)
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        
        # 896ì°¨ì› â†’ 7ì°¨ì› íˆ¬ì˜ ë ˆì´ì–´ ì¶”ê°€ (Benthamì˜ 7ê°€ì§€ ë³€ìˆ˜ë¥¼ ìœ„í•´)
        self.input_projection = nn.Sequential(
            nn.Linear(896, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 7)
        ).to(device)  # ë””ë°”ì´ìŠ¤ ì§€ì •
        
        # 768ì°¨ì› ì…ë ¥ì„ ìœ„í•œ ë³„ë„ íˆ¬ì˜ ë ˆì´ì–´ ì¶”ê°€
        self.input_projection_768 = nn.Sequential(
            nn.Linear(768, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 7)
        ).to(device)  # ë””ë°”ì´ìŠ¤ ì§€ì •
        
        self._register_internal_modules()
        
        logger.info(f"âœ… Advanced Bentham Calculator Wrapper ì´ˆê¸°í™” (2.5M íŒŒë¼ë¯¸í„°, device: {device})")
    
    def _register_internal_modules(self):
        """ë‚´ë¶€ nn.Moduleë“¤ì„ ë“±ë¡"""
        
        # ë™ì ìœ¼ë¡œ ëª¨ë“  nn.Module ì°¾ê¸°
        module_count = 0
        for attr_name in dir(self.analyzer):
            if not attr_name.startswith('_'):
                # í”„ë¡œí¼í‹°ë‚˜ ë©”ì†Œë“œê°€ ì•„ë‹Œ ì§ì ‘ ì†ì„±ë§Œ ì ‘ê·¼
                # getattr ëŒ€ì‹  __dict__ ì§ì ‘ í™•ì¸ìœ¼ë¡œ í”„ë¡œí¼í‹° í˜¸ì¶œ ë°©ì§€
                if hasattr(self.analyzer, '__dict__') and attr_name in self.analyzer.__dict__:
                    attr = self.analyzer.__dict__[attr_name]
                    if attr is not None and isinstance(attr, nn.Module):
                        setattr(self, f"bentham_{attr_name}", attr)
                        module_count += 1
                        logger.info(f"  - {attr_name} ë“±ë¡")
        
        if module_count == 0:
            # ê¸°ë³¸ ì‹ ê²½ë§ ìƒì„± (2.5M)
            self.bentham_network = nn.Sequential(
                nn.Linear(768, 512),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(512, 256),
                nn.ReLU(),
                nn.Linear(256, 10)  # 10ê°œ ë²¤ë‹´ ì°¨ì›
            )
            logger.info("  - ê¸°ë³¸ bentham_network ìƒì„± (2.5M)")
    
    def forward(self, x: torch.Tensor, **kwargs) -> Dict[str, torch.Tensor]:
        """Forward pass - NO FALLBACK"""
        logger.info("ğŸ”„ AdvancedBenthamCalculatorWrapper forward ì‹¤í–‰ ì‹œì‘")
        output = {}
        
        # ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš© - bentham_network ë˜ëŠ” bentham_default_network ì°¾ê¸°
        network_found = False
        
        # ìš°ì„  bentham_network í™•ì¸
        if hasattr(self, 'bentham_network'):
            try:
                logger.info("   - bentham_network ì²˜ë¦¬ ì¤‘...")
                bentham_scores = self.bentham_network(x)
                output['bentham_scores'] = bentham_scores
                network_found = True
                logger.info("   âœ… bentham_network ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"   âŒ bentham_network ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"Bentham network ì²˜ë¦¬ ì‹¤íŒ¨ - NO FALLBACK: {e}")
        
        # bentham_default_network í™•ì¸ (7ì°¨ì› ì…ë ¥ í•„ìš”)
        elif hasattr(self, 'bentham_default_network'):
            try:
                logger.info("   - bentham_default_network ì²˜ë¦¬ ì¤‘...")
                logger.info(f"     ì…ë ¥ ì°¨ì›: {x.shape}")
                
                # ì›ë˜ device ì €ì¥
                original_device = x.device
                
                # device ì¼ê´€ì„± ë³´ì¥ - bentham_default_networkì™€ ê°™ì€ deviceë¡œ ì´ë™
                network_device = next(self.bentham_default_network.parameters()).device
                logger.info(f"     network device: {network_device}, input device: {original_device}")
                
                # ì…ë ¥ ì°¨ì›ì— ë”°ë¼ ì ì ˆí•œ projection layer ì„ íƒ
                input_dim = x.shape[-1]
                if input_dim == 768:
                    # 768ì°¨ì› ì…ë ¥ìš© projection ì‚¬ìš©
                    if hasattr(self, 'input_projection_768'):
                        self.input_projection_768 = self.input_projection_768.to(network_device)
                        projection_layer = self.input_projection_768
                    else:
                        logger.error(f"768ì°¨ì› projection layerê°€ ì—†ìŒ")
                        raise RuntimeError("768ì°¨ì› ì…ë ¥ì„ ìœ„í•œ projection layer ì—†ìŒ")
                elif input_dim == 896:
                    # 896ì°¨ì› ì…ë ¥ìš© projection ì‚¬ìš©
                    if hasattr(self, 'input_projection'):
                        self.input_projection = self.input_projection.to(network_device)
                        projection_layer = self.input_projection
                    else:
                        logger.error(f"896ì°¨ì› projection layerê°€ ì—†ìŒ")
                        raise RuntimeError("896ì°¨ì› ì…ë ¥ì„ ìœ„í•œ projection layer ì—†ìŒ")
                else:
                    logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ ì°¨ì›: {input_dim}")
                    raise RuntimeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ ì°¨ì›: {input_dim} (768 ë˜ëŠ” 896ë§Œ ì§€ì›)")
                
                # ì…ë ¥ í…ì„œë„ ê°™ì€ deviceë¡œ ì´ë™
                if x.device != network_device:
                    x = x.to(network_device)
                
                # ì…ë ¥ ì°¨ì›ì— ë§ëŠ” projection ì‚¬ìš©í•˜ì—¬ 7ì°¨ì›ìœ¼ë¡œ íˆ¬ì˜
                x_projected = projection_layer(x)
                logger.info(f"     íˆ¬ì˜ í›„ ì°¨ì›: {x_projected.shape}, device: {x_projected.device}")
                
                bentham_scores = self.bentham_default_network(x_projected)
                
                # ê²°ê³¼ë¥¼ ì›ë˜ deviceë¡œ ë˜ëŒë¦¼
                if bentham_scores.device != original_device:
                    bentham_scores = bentham_scores.to(original_device)
                
                output['bentham_scores'] = bentham_scores[:, :10] if bentham_scores.shape[1] > 10 else bentham_scores
                network_found = True
                logger.info("   âœ… bentham_default_network ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"   âŒ bentham_default_network ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"Bentham default network ì²˜ë¦¬ ì‹¤íŒ¨ - NO FALLBACK: {e}")
        
        # ê·¸ ì™¸ bentham_ ì ‘ë‘ì‚¬ ëª¨ë“ˆë“¤ ì‹œë„
        if not network_found:
            for attr_name in dir(self):
                if attr_name.startswith('bentham_') and hasattr(self, attr_name):
                    module = getattr(self, attr_name)
                    if isinstance(module, nn.Module):
                        try:
                            logger.info(f"   - {attr_name} ì²˜ë¦¬ ì‹œë„...")
                            result = module(x)
                            output['bentham_scores'] = result[:, :10] if result.shape[1] > 10 else result
                            network_found = True
                            logger.info(f"   âœ… {attr_name} ì²˜ë¦¬ ì™„ë£Œ")
                            break
                        except Exception as e:
                            logger.debug(f"   - {attr_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            continue
        
        # ì¶œë ¥ ê²€ì¦ - NO FALLBACK
        if 'bentham_scores' not in output:
            logger.error("âŒ Bentham scores ê³„ì‚° ì‹¤íŒ¨")
            raise RuntimeError("Bentham ê³„ì‚° ì‹¤íŒ¨: bentham_scores ìƒì„± ëª»í•¨ - NO FALLBACK")
        
        logger.info(f"   âœ… AdvancedBenthamCalculator ì²˜ë¦¬ ì™„ë£Œ: {list(output.keys())}")
        return output


def create_advanced_analyzer_wrappers() -> Dict[str, nn.Module]:
    """ëª¨ë“  Advanced Analyzer Wrapper ìƒì„±"""
    wrappers = {}
    required_wrappers = ['advanced_emotion', 'advanced_regret', 'advanced_surd', 'advanced_bentham']
    
    # Emotion Wrapper ìƒì„± (í•„ìˆ˜)
    try:
        wrappers['advanced_emotion'] = AdvancedEmotionAnalyzerWrapper()
    except Exception as e:
        logger.error(f"Advanced Emotion Wrapper ìƒì„± ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"í•„ìˆ˜ Wrapper ìƒì„± ì‹¤íŒ¨ - advanced_emotion: {e}")
    
    # Regret Wrapper ìƒì„± (í•„ìˆ˜)
    try:
        wrappers['advanced_regret'] = AdvancedRegretAnalyzerWrapper()
    except Exception as e:
        logger.error(f"Advanced Regret Wrapper ìƒì„± ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"í•„ìˆ˜ Wrapper ìƒì„± ì‹¤íŒ¨ - advanced_regret: {e}")
    
    # SURD Wrapper ìƒì„± (í•„ìˆ˜)
    try:
        wrappers['advanced_surd'] = AdvancedSURDAnalyzerWrapper()
    except Exception as e:
        logger.error(f"Advanced SURD Wrapper ìƒì„± ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"í•„ìˆ˜ Wrapper ìƒì„± ì‹¤íŒ¨ - advanced_surd: {e}")
    
    # Bentham Wrapper ìƒì„± (í•„ìˆ˜)
    try:
        wrappers['advanced_bentham'] = AdvancedBenthamCalculatorWrapper()
    except Exception as e:
        logger.error(f"Advanced Bentham Wrapper ìƒì„± ì‹¤íŒ¨: {e}")
        raise RuntimeError(f"í•„ìˆ˜ Wrapper ìƒì„± ì‹¤íŒ¨ - advanced_bentham: {e}")
    
    # ëª¨ë“  í•„ìˆ˜ wrapper í™•ì¸
    for wrapper_name in required_wrappers:
        if wrapper_name not in wrappers:
            raise RuntimeError(f"í•„ìˆ˜ Wrapper ëˆ„ë½: {wrapper_name}")
    
    total_params = sum(
        sum(p.numel() for p in w.parameters()) 
        for w in wrappers.values()
    )
    
    logger.info(f"âœ… Advanced Analyzer Wrappers ìƒì„± ì™„ë£Œ")
    logger.info(f"  - ì´ Wrapper ìˆ˜: {len(wrappers)}")
    logger.info(f"  - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
    
    return wrappers