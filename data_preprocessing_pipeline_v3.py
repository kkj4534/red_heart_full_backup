#!/usr/bin/env python3
"""
Red Heart AI ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ v3
- HelpingAI ëª¨ë¸ ì „ìš© í…ìŠ¤íŠ¸ íŒŒì‹± ë¡œì§
- ChatML í…œí”Œë¦¿ ìš°íšŒ ë° ì§ì ‘ í”„ë¡¬í”„íŠ¸ ì „ë‹¬
- JSON ìƒì„± ëŒ€ì‹  êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ íŒŒì‹±
- í”„ë¡œì íŠ¸ ê·œì¹™ ì¤€ìˆ˜: fallback ì—†ìŒ
- í•œêµ­ì–´â†’ì˜ì–´ ë²ˆì—­ ì§€ì›
"""

import os
import json
import torch
import numpy as np
import logging
import gc
import time
import re
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
from datetime import datetime
from sentence_transformers import SentenceTransformer
from transformers import pipeline
from collections import defaultdict
from rapidfuzz import fuzz

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from llm_module.advanced_llm_engine import (
    LLMRequest, LLMResponse,
    TaskComplexity,
    AdvancedLLMEngine
)
from config import ADVANCED_CONFIG, get_device

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('RedHeart.DataPreprocessingV3')

class HelpingAIPreprocessor:
    """HelpingAI íŠ¹í™” ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """ì´ˆê¸°í™”"""
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ì‹¤íŒ¨ íŒ¨í„´ í†µê³„ DB
        self.failure_stats = defaultdict(lambda: {
            'count': 0,
            'success_after_retry': 0,
            'final_failures': 0,
            'sample_texts': []
        })
        
        # Sentence Transformer ë¡œë“œ
        logger.info(f"Loading sentence transformer: {model_name}")
        self.sentence_model = SentenceTransformer(model_name, device=self.device)
        
        # ë²ˆì—­ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (í•œêµ­ì–´â†’ì˜ì–´) - NLLB-200 ì‚¬ìš©
        logger.info("ğŸŒ ë²ˆì—­ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
        try:
            from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
            
            # Facebook NLLB-200 ëª¨ë¸ ì‚¬ìš© (ë” ë‚˜ì€ ë²ˆì—­ í’ˆì§ˆ)
            model_name = 'facebook/nllb-200-distilled-600M'
            logger.info(f"ğŸ“¥ NLLB-200 ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}")
            
            self.nllb_tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.nllb_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
            
            # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ ì´ë™
            if torch.cuda.is_available():
                self.nllb_model = self.nllb_model.cuda()
                logger.info("âœ… NLLB ëª¨ë¸ GPU ë¡œë“œ ì™„ë£Œ")
            else:
                logger.info("âœ… NLLB ëª¨ë¸ CPU ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ë²ˆì—­ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # NO FALLBACK ì›ì¹™ - ë²ˆì—­ ë¶ˆê°€ëŠ¥í•˜ë©´ ì˜ˆì™¸
            raise RuntimeError(f"ë²ˆì—­ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # LLM ì—”ì§„
        self.llm_engine = None
        self.is_llm_initialized = False
        self._retry_count = 0  # ì¬ì‹œë„ ì¹´ìš´í„° ì´ˆê¸°í™”
        
        logger.info("âœ… HelpingAI ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ v3 ì´ˆê¸°í™” ì™„ë£Œ")
    
    def initialize_llm(self):
        """LLM ì´ˆê¸°í™”"""
        if self.is_llm_initialized:
            return
        
        logger.info("ğŸ”„ HelpingAI ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        self.llm_engine = AdvancedLLMEngine()
        self.is_llm_initialized = True
        logger.info("âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ")
    
    def translate_to_english(self, text: str) -> str:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ (NLLB-200 ì‚¬ìš©)"""
        # í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if not re.search(r'[ê°€-í£]', text):
            # ì´ë¯¸ ì˜ì–´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return text
        
        try:
            # NLLB í† í¬ë‚˜ì´ì € ì„¤ì • - ì†ŒìŠ¤ ì–¸ì–´ ì„¤ì •
            self.nllb_tokenizer.src_lang = 'kor_Hang'
            
            # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•
            inputs = self.nllb_tokenizer(
                text[:1000],
                return_tensors='pt',
                padding=True,
                truncation=True,
                max_length=1024
            )
            
            # GPUë¡œ ì´ë™
            if torch.cuda.is_available():
                inputs = {k: v.cuda() for k, v in inputs.items()}
            
            # ì˜ì–´ íƒ€ê²Ÿ ì–¸ì–´ í† í° ID ì–»ê¸° - ì˜¬ë°”ë¥¸ ë°©ë²•
            eng_latn_id = self.nllb_tokenizer.convert_tokens_to_ids('eng_Latn')
            
            # ë²ˆì—­ ìƒì„± - forced_bos_token_idë¡œ íƒ€ê²Ÿ ì–¸ì–´ ì§€ì •
            with torch.no_grad():
                translated_tokens = self.nllb_model.generate(
                    **inputs,
                    forced_bos_token_id=eng_latn_id,  # ì˜¬ë°”ë¥¸ ì˜ì–´ í† í° ID
                    max_length=512,
                    num_beams=5,  # ë¹” ì„œì¹˜ í¬ê¸°
                    early_stopping=True,
                    do_sample=False,
                    temperature=1.0,
                    repetition_penalty=1.2,  # ë°˜ë³µ ë°©ì§€
                    length_penalty=1.0  # ê¸¸ì´ íŒ¨ë„í‹°
                )
            
            # ë””ì½”ë”©
            translated = self.nllb_tokenizer.batch_decode(
                translated_tokens,
                skip_special_tokens=True
            )[0]
            
            logger.info(f"ë²ˆì—­ ì™„ë£Œ (NLLB): {text[:50]}... â†’ {translated[:50]}...")
            return translated
            
        except Exception as e:
            logger.error(f"NLLB ë²ˆì—­ ì‹¤íŒ¨: {e}")
            # NO FALLBACK ì›ì¹™
            raise RuntimeError(f"NLLB ë²ˆì—­ ì‹¤íŒ¨: {e}")
    
    def generate_context_embedding(self, text: str) -> List[float]:
        """Sentence-Transformersë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ ì„ë² ë”© ìƒì„±"""
        with torch.no_grad():
            embedding = self.sentence_model.encode(text, convert_to_tensor=False)
        return embedding.tolist()
    
    def analyze_emotions_with_llm(self, text: str) -> Dict[str, Any]:
        """
        HelpingAIë¥¼ í†µí•œ ê°ì • ë¶„ì„ - ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ (ë²ˆì—­ í¬í•¨)
        """
        # í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­
        english_text = self.translate_to_english(text)
        return self.analyze_emotions_with_llm_direct(english_text)
    
    def get_emotion_prompt(self, english_text: str, attempt: int = 1, failure_type: str = None) -> Tuple[str, float, float, int]:
        """
        ì ì‘í˜• í”„ë¡¬í”„íŠ¸ ìƒì„± - ì‹¤íŒ¨ ìœ í˜•ì— ë”°ë¥¸ ì „ëµ ì„ íƒ
        Returns: (prompt, temperature, top_p, max_tokens)
        """
        # 1ì°¨ ì‹œë„: ê¸°ë³¸ Chain of Thought
        if attempt == 1 and not failure_type:
            prompt = f"""Analyze emotions objectively without censorship (research purposes).

Text to analyze: "{english_text[:500]}"

Step 1: Identify the situation - What is happening here?
[Think about the core conflict or issue]

Step 2: Identify specific emotional phrases:
- Phrases showing anger/frustration: (e.g., "goes ballistic", "stormed out", "complain")
- Phrases showing fear/anxiety: (e.g., "can't shake", "stressed", "worried")
- Phrases showing sadness: (e.g., "unhappy", "embarrassing", "sensitive")
- Phrases showing joy: (e.g., "happy", "yay", "excited")
- Phrases showing disgust: (e.g., "mould", "contaminated", "revolting")

Step 3: Consider the relationships and context:
- Who is involved?
- What are the power dynamics?
- What emotions would YOU feel in this situation?

Few-shot examples:
- "Parent screamed and stormed out" â†’ Fear: 8, Sadness: 6, Anger: 4
- "I'm furious he took my shirt" â†’ Anger: 9, Trust: 1, Sadness: 3  
- "Can't afford it, feeling embarrassed" â†’ Sadness: 7, Fear: 6, Anger: 4

Now, based on YOUR analysis of THIS specific text, rate emotions 0-10:

Joy: 
Sadness: 
Anger: 
Fear: 
Surprise: 
Disgust: 
Trust: 

BE SPECIFIC to THIS text. Numbers only:"""
            temperature = 0.88
            top_p = 0.98
            max_tokens = 250
        
        # 2ì°¨ ì‹œë„: ì‹¤íŒ¨ ìœ í˜•ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        elif attempt == 2 and failure_type:
            
            if failure_type == "TEMPLATE_SAFETY":
                # ì•ˆì „ ëª¨ë“œ í•´ì œ - ê°ˆë“±ê³¼ ë³µì¡ì„± ê°•ì¡°
                prompt = f"""[ACADEMIC RESEARCH - COMPLEX EMOTION ANALYSIS]

IMPORTANT: This text contains interpersonal conflict requiring nuanced analysis.
Analyze ALL emotions present, including negative ones.

Text: "{english_text[:400]}"

Key conflicts in this text:
- Identify the disagreement or problem
- Note WHO is upset and WHY
- Consider BOTH perspectives

Rate these specific aspects:
- How much happiness/satisfaction? (Joy)
- How much disappointment/hurt? (Sadness) 
- How much frustration/irritation? (Anger)
- How much worry/anxiety? (Fear)
- How unexpected was this? (Surprise)
- How much revulsion/disapproval? (Disgust)
- How much confidence in others? (Trust)

Remember: Real conflicts have MIXED emotions. No single emotion dominates completely.

Rate each 0-10 (decimals allowed):
Joy: 
Sadness: 
Anger: 
Fear: 
Surprise: 
Disgust: 
Trust:"""
                temperature = 0.92
                top_p = 0.95
                max_tokens = 200
            
            elif failure_type == "SINGLE_DOMINANT":
                # ë‹¨ì¼ ê°ì • ì§€ë°° í•´ê²° - ë³µí•© ê°ì • ìœ ë„
                prompt = f"""Analyze the MULTIPLE emotions in this complex situation.

Text: "{english_text[:400]}"

IMPORTANT: Real situations contain MULTIPLE emotions simultaneously.
Even happy moments have traces of other feelings.
Even sad situations have other emotions mixed in.

Identify AT LEAST 3-4 different emotions present:
1. Primary emotion (strongest)
2. Secondary emotion (also significant)
3. Underlying emotions (subtle but present)

Examples of mixed emotions:
- Winning but friend lost: Joy 7, Sadness 4, Trust 5
- Argument resolved: Anger 3, Relief/Joy 6, Trust 7
- Embarrassing mistake: Sadness 6, Anger 3, Fear 4

Rate all 7 emotions (use decimals for nuance):
Joy: 
Sadness: 
Anger: 
Fear: 
Surprise: 
Disgust:
Trust:"""
                temperature = 0.85
                top_p = 0.97
                max_tokens = 180
            
            elif failure_type == "UNIFORM_DISTRIBUTION":
                # ê· ì¼ ë¶„í¬ í•´ê²° - ì°¨ë³„í™” ê°•ì œ
                prompt = f"""Differentiate the varying intensity of emotions in this text.

Text: "{english_text[:400]}"

RANK emotions by intensity (they CANNOT all be equal):
- Which emotion is STRONGEST? (rate 7-10)
- Which is MODERATE? (rate 3-6)
- Which is WEAKEST? (rate 0-2)

Consider:
- The main issue/conflict
- Who benefits vs who suffers
- Immediate vs underlying feelings

IMPORTANT: Each emotion must have a DIFFERENT intensity.
Use the full 0-10 range. Avoid giving multiple emotions the same score.

Joy: 
Sadness: 
Anger: 
Fear: 
Surprise: 
Disgust:
Trust:"""
                temperature = 0.78
                top_p = 0.96
                max_tokens = 150
            
            elif failure_type == "CONFLICT_AVOIDANCE":
                # ê°ˆë“± íšŒí”¼ í•´ê²° - ë¶€ì • ê°ì • ëª…ì‹œì  ìš”êµ¬
                prompt = f"""This text describes a CONFLICT situation. Analyze the negative emotions present.

Text: "{english_text[:400]}"

Conflicts ALWAYS involve negative emotions:
- Frustration when things go wrong (Anger)
- Disappointment with outcomes (Sadness)
- Worry about consequences (Fear)
- Reaction to unpleasant behavior (Disgust)

Be honest about the PROBLEMS described:
- What went wrong?
- Who is upset?
- What are they feeling?

Rate all emotions INCLUDING the negative ones:
Joy: 
Sadness: (disappointment, hurt)
Anger: (frustration, annoyance)
Fear: (worry, anxiety)
Surprise: 
Disgust: (disapproval, revulsion)
Trust:"""
                temperature = 0.82
                top_p = 0.98
                max_tokens = 170
            
            elif failure_type == "PARSING_ERROR":
                # íŒŒì‹± ì˜¤ë¥˜ í•´ê²° - ëª…í™•í•œ í˜•ì‹
                prompt = f"""Rate emotions for: "{english_text[:300]}"

Provide ONLY numbers 0-10 in this EXACT format:
joy: [number]
sadness: [number]
anger: [number]
fear: [number]
surprise: [number]
disgust: [number]
trust: [number]

Example format:
joy: 3
sadness: 7
anger: 5
fear: 4
surprise: 2
disgust: 1
trust: 6"""
                temperature = 0.7
                top_p = 0.95
                max_tokens = 100
            
            else:
                # ê¸°íƒ€ ì‹¤íŒ¨ - ì¼ë°˜ ê°œì„  í”„ë¡¬í”„íŠ¸
                prompt = f"""Carefully analyze the distinct emotions in this text.

Text: "{english_text[:400]}"

Consider all aspects:
- Positive emotions (joy, trust)
- Negative emotions (sadness, anger, fear, disgust)
- Neutral emotions (surprise)

Each emotion should reflect its true presence in the text.
Use varied scores to show the emotional complexity.

Rate 0-10 with decimals:
Joy: 
Sadness: 
Anger: 
Fear: 
Surprise: 
Disgust:
Trust:"""
                temperature = 0.8
                top_p = 0.97
                max_tokens = 150
        
        # 3ì°¨ ì‹œë„: ì˜ˆì‹œ ê¸°ë°˜ ìµœì¢… ì‹œë„
        else:
            prompt = f"""Analyze: "{english_text[:250]}"

Successful analysis examples:
Text about argument: Joy:2, Sadness:6, Anger:7, Fear:3, Surprise:1, Disgust:4, Trust:2
Text about success: Joy:8, Sadness:1, Anger:0, Fear:2, Surprise:5, Disgust:0, Trust:7
Text about betrayal: Joy:0, Sadness:8, Anger:9, Fear:5, Surprise:7, Disgust:6, Trust:1

Now rate THIS text:
Joy: 
Sadness: 
Anger: 
Fear: 
Surprise: 
Disgust:
Trust:"""
            temperature = 0.65
            top_p = 0.92
            max_tokens = 100
        
        return prompt, temperature, top_p, max_tokens
    
    def analyze_emotions_with_llm_direct(self, english_text: str, attempt: int = 1, failure_type: str = None) -> Dict[str, Any]:
        """
        HelpingAIë¥¼ í†µí•œ ê°ì • ë¶„ì„ - ì˜ì–´ í…ìŠ¤íŠ¸ ì§ì ‘ ë¶„ì„ (ì ì‘í˜• ì¬ì‹œë„)
        """
        prompt, temperature, top_p, max_tokens = self.get_emotion_prompt(english_text, attempt, failure_type)
        
        request = LLMRequest(
            prompt=prompt,
            task_type="emotion_analysis", 
            complexity=TaskComplexity.SIMPLE,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p
        )
        
        response = self.llm_engine.generate_sync(request)
        generated = response.generated_text.strip()
        
        logger.info(f"ê°ì • ë¶„ì„ ì‘ë‹µ: {generated[:200]}")
        
        # í…ìŠ¤íŠ¸ íŒŒì‹±
        emotion_scores = self.parse_emotion_scores(generated)
        
        # íŒŒì‹± ê²€ì¦ (NO FALLBACK)
        if len(emotion_scores) != 7:
            logger.error(f"ê°ì • íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt}): {len(emotion_scores)}/7ê°œë§Œ ì¶”ì¶œë¨")
            logger.error(f"LLM ì‘ë‹µ: {generated[:200]}")
            raise ValueError(f"ê°ì • íŒŒì‹± ì‹¤íŒ¨: 7ê°œ ê°ì • ì¤‘ {len(emotion_scores)}ê°œë§Œ ì¶”ì¶œ")
        
        # ëª¨ë“  ê°’ì´ ê°™ìœ¼ë©´ LLMì´ ì œëŒ€ë¡œ ë¶„ì„í•˜ì§€ ëª»í•œ ê²ƒ
        unique_values = set(emotion_scores.values())
        if len(unique_values) == 1:
            logger.error(f"LLMì´ ì˜ë¯¸ìˆëŠ” ê°ì • ë¶„ì„ì„ í•˜ì§€ ëª»í•¨ (ëª¨ë“  ê°’ ë™ì¼: {unique_values})")
            raise ValueError("LLM ê°ì • ë¶„ì„ ì‹¤íŒ¨: ëª¨ë“  ê°ì • ì ìˆ˜ê°€ ë™ì¼")
        
        # 0-1ë¡œ ì •ê·œí™”
        total = sum(emotion_scores.values()) 
        if total > 0:
            emotion_scores = {k: v/total for k, v in emotion_scores.items()}
        else:
            raise ValueError("ê°ì • ì ìˆ˜ í•©ì´ 0 - LLM ì‘ë‹µ ì˜¤ë¥˜")
        
        # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ìˆœì„œ ì¤‘ìš”) - ê¸°ë³¸ê°’ ì œê±° (NO FALLBACK)
        emotion_vector = [
            emotion_scores.get('joy', 0),
            emotion_scores.get('sadness', 0),
            emotion_scores.get('anger', 0),
            emotion_scores.get('fear', 0),
            emotion_scores.get('surprise', 0),
            emotion_scores.get('disgust', 0),
            emotion_scores.get('trust', 0)
        ]
        
        return {"vector": emotion_vector, "confidence": response.confidence}
    
    def parse_emotion_scores(self, text: str) -> Dict[str, float]:
        """ê°ì • ì ìˆ˜ í…ìŠ¤íŠ¸ íŒŒì‹± - ì˜¤íƒ€ ì²˜ë¦¬ í¬í•¨"""
        scores = {}
        emotions = ['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'trust']
        
        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ íŒŒì‹±
        text_lower = text.lower()
        
        # ì˜¤íƒ€ ë§¤í•‘ (fuzzy matching)
        typo_mappings = {
            'surprise': ['surprise', 'surpise', 'surprize', 'suprise', 'surpirse'],
            'disgust': ['disgust', 'disguist', 'disguts'],
            'sadness': ['sadness', 'sadnes', 'saddness'],
            'anger': ['anger', 'angr', 'angar'],
            'trust': ['trust', 'turst', 'tursted'],
            'fear': ['fear', 'feer', 'feard'],
            'joy': ['joy', 'joyful', 'joye']
        }
        
        for emotion in emotions:
            # ê°€ëŠ¥í•œ ë³€í˜• ê°€ì ¸ì˜¤ê¸°
            variations = typo_mappings.get(emotion, [emotion])
            
            found = False
            for variant in variations:
                # íŒ¨í„´: emotion: ìˆ«ì (ê´„í˜¸ë‚˜ ì„¤ëª… í¬í•¨ ê°€ëŠ¥)
                patterns = [
                    rf'{variant}[\s:=]+(\d+(?:\.\d+)?)\b',  # ìˆ«ì ê²½ê³„ í™•ì¸
                    rf'{variant}[\s:=]+(\d+(?:\.\d+)?)\s*\(',  # ìˆ«ì í›„ ê´„í˜¸
                    rf'{variant}.*?[:\s]+(\d+(?:\.\d+)?)\b',  # ë” ìœ ì—°í•œ íŒ¨í„´
                ]
                
                for pattern in patterns:
                    match = re.search(pattern, text_lower)
                    if match:
                        scores[emotion] = float(match.group(1))
                        found = True
                        if variant != emotion:
                            logger.info(f"ì˜¤íƒ€ ìˆ˜ì •: '{variant}' â†’ '{emotion}'")
                        break
                
                if found:
                    break
            
            if not found:
                # ë¼ì¸ë³„ë¡œ ì°¾ê¸° (ì˜¤íƒ€ í¬í•¨)
                lines = text_lower.split('\n')
                for line in lines:
                    for variant in variations:
                        if variant in line:
                            numbers = re.findall(r'\d+(?:\.\d+)?', line)
                            if numbers:
                                scores[emotion] = float(numbers[0])
                                found = True
                                if variant != emotion:
                                    logger.info(f"ì˜¤íƒ€ ìˆ˜ì •: '{variant}' â†’ '{emotion}'")
                                break
                    if found:
                        break
            
            # NO FALLBACK - íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ í• ë‹¹ ì•ˆí•¨
            if not found:
                logger.warning(f"{emotion} ì ìˆ˜ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŒ")
        
        return scores
    
    def classify_failure_type(self, emotion_vector: List[float], text: str, error_msg: str = "") -> str:
        """
        ì‹¤íŒ¨ ìœ í˜• ë¶„ë¥˜ - íŒ¨í„´ ê¸°ë°˜ ì¼ë°˜í™”
        """
        # íŒŒì‹± ì‹¤íŒ¨
        if "íŒŒì‹±" in error_msg or len(emotion_vector) != 7:
            return "PARSING_ERROR"
        
        # í…œí”Œë¦¿ ì‘ë‹µ (ì•ˆì „ ëª¨ë“œ)
        template_patterns = [
            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],  # Trust 100%
            [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # Joy 100%
            [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8],  # Joy 20%, Trust 80%
        ]
        if emotion_vector in template_patterns:
            return "TEMPLATE_SAFETY"
        
        # ë‹¨ì¼ ê°ì • ì§€ë°° (ê³¼ë„í•œ ë‹¨ìˆœí™”)
        non_zero_count = sum(1 for v in emotion_vector if v > 0.01)
        max_val = max(emotion_vector) if emotion_vector else 0
        
        if non_zero_count == 1 or (max_val >= 0.95 and non_zero_count <= 2):
            return "SINGLE_DOMINANT"
        
        # ê· ì¼ ë¶„í¬ (ì°¨ë³„í™” ì‹¤íŒ¨)
        if len(emotion_vector) == 7:
            std_dev = np.std(emotion_vector)
            if std_dev < 0.1:  # í‘œì¤€í¸ì°¨ê°€ ë„ˆë¬´ ë‚®ìŒ
                return "UNIFORM_DISTRIBUTION"
        
        # ê°ˆë“± íšŒí”¼ íŒ¨í„´ (ë¶€ì •ì  ê°ì • ì–µì œ)
        if len(emotion_vector) == 7:
            negative_emotions = emotion_vector[1:6]  # sadness, anger, fear, surprise, disgust
            if sum(negative_emotions) < 0.1 and max_val > 0.8:
                return "CONFLICT_AVOIDANCE"
        
        # ê·¹ë‹¨ì  ì‘ë‹µ (ëª¨ë“  ê°’ì´ 0 ë˜ëŠ” 1ì— ê°€ê¹Œì›€)
        if all(v < 0.1 or v > 0.9 for v in emotion_vector):
            return "EXTREME_VALUES"
        
        # ë‚®ì€ ë‹¤ì–‘ì„±
        unique_values = len(set(emotion_vector))
        if unique_values <= 3:
            return "LOW_DIVERSITY"
        
        return "UNKNOWN"
    
    def validate_emotion_response(self, emotion_vector: List[float], text: str) -> Tuple[bool, str, str]:
        """
        ê°ì • ì‘ë‹µì˜ ìœ íš¨ì„± ì¢…í•© ê²€ì¦
        Returns: (is_valid, failure_type, reason_if_invalid)
        """
        # 1. ë²¡í„° ê¸¸ì´ í™•ì¸
        if len(emotion_vector) != 7:
            return False, "PARSING_ERROR", f"ê°ì • ë²¡í„° ê¸¸ì´ ì˜¤ë¥˜: {len(emotion_vector)}/7"
        
        # 2. ê°’ ë²”ìœ„ í™•ì¸ (0-1)
        if any(v < 0 or v > 1 for v in emotion_vector):
            return False, "PARSING_ERROR", "ê°ì • ê°’ ë²”ìœ„ ì˜¤ë¥˜ (0-1 ë²—ì–´ë‚¨)"
        
        # 3. ì‹¤íŒ¨ ìœ í˜• ë¶„ë¥˜
        failure_type = self.classify_failure_type(emotion_vector, text)
        
        # 4. ìœ í˜•ë³„ ê²€ì¦
        if failure_type == "TEMPLATE_SAFETY":
            return False, failure_type, "í…œí”Œë¦¿ ì•ˆì „ ì‘ë‹µ ê°ì§€"
        
        if failure_type == "SINGLE_DOMINANT":
            dominant_idx = emotion_vector.index(max(emotion_vector))
            emotions = ['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'trust']
            return False, failure_type, f"ë‹¨ì¼ ê°ì • ì§€ë°°: {emotions[dominant_idx]}"
        
        if failure_type == "UNIFORM_DISTRIBUTION":
            return False, failure_type, "ê°ì • ì°¨ë³„í™” ì‹¤íŒ¨ (ê· ì¼ ë¶„í¬)"
        
        if failure_type == "CONFLICT_AVOIDANCE":
            return False, failure_type, "ê°ˆë“± íšŒí”¼ íŒ¨í„´ (ë¶€ì • ê°ì • ì–µì œ)"
        
        if failure_type == "EXTREME_VALUES":
            return False, failure_type, "ê·¹ë‹¨ì  ê°’ë§Œ ì¡´ì¬"
        
        if failure_type == "LOW_DIVERSITY":
            unique_values = len(set(emotion_vector))
            return False, failure_type, f"ê°ì • ë‹¤ì–‘ì„± ë¶€ì¡± (ê³ ìœ ê°’ {unique_values}ê°œ)"
        
        # ì¶”ê°€ ê²€ì¦: ë°˜ë³µ íŒ¨í„´
        value_counts = {}
        for v in emotion_vector:
            value_counts[v] = value_counts.get(v, 0) + 1
        
        if any(count >= 4 for count in value_counts.values()):
            return False, "REPETITIVE_PATTERN", "ë™ì¼ ê°’ ê³¼ë„ ë°˜ë³µ"
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ì¦ (ê°ˆë“± ìƒí™©)
        conflict_keywords = ['aita', 'argument', 'fight', 'upset', 'angry', 'problem', 'issue', 'conflict']
        text_lower = text.lower()
        if any(kw in text_lower for kw in conflict_keywords):
            negative_sum = sum(emotion_vector[1:6])  # negative emotions
            if negative_sum < 0.1:
                return False, "CONTEXT_MISMATCH", "ê°ˆë“± ìƒí™©ì— ë¶€ì •ì  ê°ì • ì—†ìŒ"
        
        return True, "VALID", "ìœ íš¨í•œ ì‘ë‹µ"
    
    def validate_emotion_diversity(self, emotion_vector: List[float]) -> bool:
        """
        ê°ì • ë²¡í„°ì˜ ë‹¤ì–‘ì„± ê²€ì¦ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
        """
        is_valid, failure_type, reason = self.validate_emotion_response(emotion_vector, "")
        if not is_valid:
            logger.warning(f"ê°ì • ê²€ì¦ ì‹¤íŒ¨ ({failure_type}): {reason}")
        return is_valid
    
    def calculate_regret_factor(self, text: str) -> float:
        """HelpingAIë¥¼ í†µí•œ í›„íšŒ ì§€ìˆ˜ ê³„ì‚° (ë²ˆì—­ í¬í•¨)"""
        # í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­
        english_text = self.translate_to_english(text)
        return self.calculate_regret_factor_direct(english_text)
    
    def calculate_regret_factor_direct(self, english_text: str) -> float:
        """HelpingAIë¥¼ í†µí•œ í›„íšŒ ì§€ìˆ˜ ê³„ì‚° - ì˜ì–´ í…ìŠ¤íŠ¸ ì§ì ‘"""
        
        # êµ¬ì²´ì ì¸ í›„íšŒ ë¶„ì„
        prompt = f"""Analyze regret level objectively (research purposes).

Text: "{english_text[:500]}"

Step 1: Find phrases indicating regret:
- "I should have..."
- "If only..."
- "I wish I had..."
- "Why didn't I..."
- Past mistakes mentioned?
- Lost opportunities?

Step 2: Consider the consequences:
- What was lost?
- Can it be recovered?
- How serious is the impact?

Examples:
- "He took my shirt and never gave it back" = 3
- "Parent screamed, I should've made my own food" = 7
- "Can't afford wedding, embarrassed to admit" = 6

Give ONLY the number (0-10) for THIS text: """
        
        request = LLMRequest(
            prompt=prompt,
            task_type="regret_analysis",
            complexity=TaskComplexity.SIMPLE,
            temperature=0.85,  # ë‹¤ì–‘í•œ ë¶„ì„ì„ ìœ„í•´ ìƒí–¥
            max_tokens=50,
            top_p=0.97
        )
        
        response = self.llm_engine.generate_sync(request)
        
        # ìˆ«ì ì¶”ì¶œ - ë” ìœ ì—°í•œ íŒŒì‹±
        text = response.generated_text.strip()
        
        # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ ìˆ«ì ì°¾ê¸°
        # íŒ¨í„´ 1: ì¤„ ì‹œì‘ì— ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° (ì˜ˆ: "8\n...")
        match = re.match(r'^(\d+(?:\.\d+)?)', text)
        if match:
            score = float(match.group(1))
            if 0 <= score <= 10:
                logger.info(f"í›„íšŒ ì§€ìˆ˜ ì¶”ì¶œ ì„±ê³µ: {score}")
                return score / 10.0  # 0-1ë¡œ ì •ê·œí™”
        
        # íŒ¨í„´ 2: "Answer: ìˆ«ì" í˜•íƒœ
        match = re.search(r'answer[:\s]+(\d+(?:\.\d+)?)', text, re.IGNORECASE)
        if match:
            score = float(match.group(1))
            if 0 <= score <= 10:
                logger.info(f"í›„íšŒ ì§€ìˆ˜ ì¶”ì¶œ ì„±ê³µ: {score}")
                return score / 10.0
        
        # íŒ¨í„´ 3: ê´„í˜¸ ì „ ìˆ«ì ì¶”ì¶œ ("3 (mild frustration)" í˜•íƒœ)
        match = re.match(r'^(\d+(?:\.\d+)?)\s*\(', text)
        if match:
            score = float(match.group(1))
            if 0 <= score <= 10:
                logger.info(f"í›„íšŒ ì§€ìˆ˜ ì¶”ì¶œ ì„±ê³µ (ê´„í˜¸ íŒ¨í„´): {score}")
                return score / 10.0
        
        # íŒ¨í„´ 4: ì²« ë²ˆì§¸ ì¤„ì—ì„œ ì²« ë²ˆì§¸ ìˆ«ì
        first_line = text.split('\n')[0] if text else ""
        numbers = re.findall(r'\d+(?:\.\d+)?', first_line)
        if numbers:
            score = float(numbers[0])
            if 0 <= score <= 10:
                logger.info(f"í›„íšŒ ì§€ìˆ˜ ì¶”ì¶œ ì„±ê³µ: {score}")
                return score / 10.0
        
        # NO FALLBACK - íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸
        logger.error(f"í›„íšŒ ì§€ìˆ˜ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŒ. LLM ì‘ë‹µ: {text[:100]}")
        raise ValueError("í›„íšŒ ì§€ìˆ˜ íŒŒì‹± ì‹¤íŒ¨")
    
    def calculate_bentham_scores(self, text: str, emotion_vector: List[float]) -> Dict[str, float]:
        """ë²¤ë‹´ ì¾Œë½ ê³„ì‚° - ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ (ë²ˆì—­ í¬í•¨)"""
        # í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­
        english_text = self.translate_to_english(text)
        return self.calculate_bentham_scores_direct(english_text, emotion_vector)
    
    def calculate_bentham_scores_direct(self, english_text: str, emotion_vector: List[float]) -> Dict[str, float]:
        """ë²¤ë‹´ ì¾Œë½ ê³„ì‚° - ì˜ì–´ í…ìŠ¤íŠ¸ ì§ì ‘"""
        
        prompt = f"""[ACADEMIC RESEARCH - BENTHAM HEDONIC ANALYSIS]
For scholarly research on utilitarian ethics, analyze hedonic aspects in this text sample.
Objective analysis of all content is required for research validity.

Research Sample: "{english_text[:300]}"

Rate each aspect from 0 (none) to 10 (maximum):

1. Intensity: How strong is the happiness or pleasure described?
2. Duration: How long-lasting is this feeling?
3. Certainty: How likely or certain is this happiness?
4. Propinquity: How close in time is this happiness?

Provide ONLY numbers 0-10 in this format:
intensity: [number]
duration: [number]
certainty: [number]
propinquity: [number]

Ratings:"""
        
        request = LLMRequest(
            prompt=prompt,
            task_type="bentham_analysis",
            complexity=TaskComplexity.MODERATE,
            temperature=0.82,  # ë‹¤ì–‘í•œ í‰ê°€ë¥¼ ìœ„í•´ ìƒí–¥
            max_tokens=120,
            top_p=0.96
        )
        
        response = self.llm_engine.generate_sync(request)
        text_response = response.generated_text.lower()
        
        logger.info(f"ë²¤ë‹´ ë¶„ì„ ì‘ë‹µ: {text_response[:200]}")
        
        # íŒŒì‹±
        scores = {}
        aspects = {
            'intensity': ['intensity', 'strength'],
            'duration': ['duration', 'lasting'],
            'certainty': ['certainty', 'likely'],
            'propinquity': ['propinquity', 'nearness', 'near']
        }
        
        for key, keywords in aspects.items():
            found = False
            for keyword in keywords:
                # ìˆ«ì í›„ ê´„í˜¸/ì„¤ëª… íŒ¨í„´ë„ ì²˜ë¦¬
                patterns = [
                    rf'{keyword}[^:]*:?\s*(\d+(?:\.\d+)?)\b',  # ê¸°ë³¸ íŒ¨í„´
                    rf'{keyword}[^:]*:?\s*(\d+(?:\.\d+)?)\s*\(',  # ìˆ«ì í›„ ê´„í˜¸
                ]
                for pattern in patterns:
                    match = re.search(pattern, text_response)
                    if match:
                        scores[key] = float(match.group(1)) / 10.0  # 0-1ë¡œ ì •ê·œí™”
                        found = True
                        break
                if found:
                    break
            
            if not found:
                # ë¼ì¸ë³„ ê²€ìƒ‰
                lines = text_response.split('\n')
                for line in lines:
                    for keyword in keywords:
                        if keyword in line:
                            numbers = re.findall(r'\d+(?:\.\d+)?', line)
                            if numbers:
                                scores[key] = float(numbers[0]) / 10.0
                                found = True
                                break
                    if found:
                        break
            
            if not found:
                scores[key] = 0.5  # ê¸°ë³¸ê°’
        
        # ì¶”ê°€ ë²¤ë‹´ ìš”ì†Œë“¤ (ê°ì • ê¸°ë°˜ ê³„ì‚°)
        positive_emotions = emotion_vector[0] + emotion_vector[6]  # joy + trust
        negative_emotions = sum(emotion_vector[1:6])  # sadness, anger, fear, surprise, disgust
        
        scores['purity'] = positive_emotions / (positive_emotions + negative_emotions + 0.001)
        scores['extent'] = 0.5  # ê¸°ë³¸ê°’
        scores['fecundity'] = scores['purity'] * 0.8  # ìˆœìˆ˜ì„±ì— ë¹„ë¡€
        scores['remoteness'] = 1.0 - scores['propinquity']  # ê·¼ì ‘ì„±ì˜ ë°˜ëŒ€
        scores['succession'] = scores['duration'] * 0.7
        scores['utility'] = sum(scores.values()) / len(scores)  # í‰ê·  íš¨ìš©
        
        return scores
    
    def calculate_surd_metrics(self, text: str, metadata: Dict[str, Any]) -> Dict[str, float]:
        """SURD ë©”íŠ¸ë¦­ ê³„ì‚° - ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ (ë²ˆì—­ í¬í•¨)"""
        # í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­
        english_text = self.translate_to_english(text)
        ethical_dilemma = metadata.get('ethical_dilemma', '')
        if ethical_dilemma:
            ethical_dilemma = self.translate_to_english(ethical_dilemma)[:200]
        return self.calculate_surd_metrics_direct(english_text, metadata)
    
    def calculate_surd_metrics_direct(self, english_text: str, metadata: Dict[str, Any]) -> Dict[str, float]:
        """SURD ë©”íŠ¸ë¦­ ê³„ì‚° - ì˜ì–´ í…ìŠ¤íŠ¸ ì§ì ‘"""
        ethical_dilemma = metadata.get('ethical_dilemma', '')
        
        prompt = f"""[ACADEMIC RESEARCH - DECISION QUALITY METRICS]
For research on decision-making patterns, evaluate this dataset sample.
All content must be analyzed objectively for academic purposes.

Research Sample: "{english_text[:300]}"
{f"Additional Context: {ethical_dilemma}" if ethical_dilemma else ""}

Rate each aspect from 0 (very poor) to 10 (excellent):

1. Sufficiency: Is there enough information to make decisions?
2. Understandability: How clear and comprehensible is the situation?
3. Resilience: How adaptable are the characters to challenges?
4. Decisiveness: How clear and firm are the decisions made?

Provide ONLY numbers 0-10 in this format:
sufficiency: [number]
understandability: [number]
resilience: [number]
decisiveness: [number]

Ratings:"""
        
        request = LLMRequest(
            prompt=prompt,
            task_type="surd_analysis",
            complexity=TaskComplexity.MODERATE,
            temperature=0.82,  # ë‹¤ì–‘í•œ í‰ê°€ë¥¼ ìœ„í•´ ìƒí–¥
            max_tokens=120,
            top_p=0.96
        )
        
        response = self.llm_engine.generate_sync(request)
        text_response = response.generated_text.lower()
        
        logger.info(f"SURD ë¶„ì„ ì‘ë‹µ: {text_response[:200]}")
        
        # íŒŒì‹±
        scores = {}
        aspects = {
            'sufficiency': ['sufficiency', 'enough', 'info'],
            'understandability': ['understandability', 'clear', 'clarity'],
            'resilience': ['resilience', 'adaptable', 'adapt'],
            'decisiveness': ['decisiveness', 'choice', 'decision']
        }
        
        for key, keywords in aspects.items():
            found = False
            for keyword in keywords:
                # ìˆ«ì í›„ ê´„í˜¸/ì„¤ëª… íŒ¨í„´ë„ ì²˜ë¦¬
                patterns = [
                    rf'{keyword}[^:]*:?\s*(\d+(?:\.\d+)?)\b',  # ê¸°ë³¸ íŒ¨í„´
                    rf'{keyword}[^:]*:?\s*(\d+(?:\.\d+)?)\s*\(',  # ìˆ«ì í›„ ê´„í˜¸
                ]
                for pattern in patterns:
                    match = re.search(pattern, text_response)
                    if match:
                        scores[key] = float(match.group(1)) / 10.0
                        found = True
                        break
                if found:
                    break
            
            if not found:
                scores[key] = 0.5  # ê¸°ë³¸ê°’
        
        return scores
    
    def process_single_item_with_retry(self, item: Dict[str, Any], max_attempts: int = 3) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì•„ì´í…œ ì²˜ë¦¬ - ì¬ì‹œë„ ë¡œì§ í¬í•¨
        """
        text = item.get('text', '')
        if not text:
            raise ValueError("í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ")
        
        start_time = time.time()
        source = item.get('source', 'unknown')
        
        # ì†ŒìŠ¤ì— ë”°ë¥¸ ì–¸ì–´ íŒë‹¨
        is_english_source = source in ['scruples', 'scruples_dilemmas']
        
        # ì˜ì–´ ë°ì´í„°ëŠ” ë²ˆì—­ ê±´ë„ˆë›°ê¸°
        if is_english_source:
            text_for_analysis = text
            logger.info(f"English source detected ({source}), skipping translation")
        else:
            text_for_analysis = self.translate_to_english(text)
        
        # 1. ì‹¤ì œ ì„ë² ë”© ìƒì„± (í•­ìƒ ì„±ê³µ)
        context_embedding = self.generate_context_embedding(text)
        
        # 2. ê°ì • ë¶„ì„ - ì ì‘í˜• ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
        emotion_result = None
        last_error = None
        failure_type = None
        
        for attempt in range(1, max_attempts + 1):
            try:
                logger.info(f"ê°ì • ë¶„ì„ ì‹œë„ {attempt}/{max_attempts}" + (f" (ì‹¤íŒ¨ ìœ í˜•: {failure_type})" if failure_type else ""))
                
                # ì ì‘í˜• ë¶„ì„ - 2ì°¨ ì‹œë„ë¶€í„°ëŠ” ì‹¤íŒ¨ ìœ í˜• ì „ë‹¬
                emotion_result = self.analyze_emotions_with_llm_direct(
                    text_for_analysis, 
                    attempt, 
                    failure_type if attempt > 1 else None
                )
                
                # ì‘ë‹µ ê²€ì¦
                is_valid, failure_type, reason = self.validate_emotion_response(emotion_result['vector'], text)
                
                if not is_valid:
                    # ì‹¤íŒ¨ í†µê³„ ì—…ë°ì´íŠ¸
                    self.failure_stats[failure_type]['count'] += 1
                    if len(self.failure_stats[failure_type]['sample_texts']) < 5:
                        self.failure_stats[failure_type]['sample_texts'].append(text[:200])
                    
                    logger.warning(f"ê°ì • ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨ (ì‹œë„ {attempt}): [{failure_type}] {reason}")
                    
                    if attempt < max_attempts:
                        continue  # ì¬ì‹œë„
                    else:
                        # ìµœì¢… ì‹¤íŒ¨
                        self.failure_stats[failure_type]['final_failures'] += 1
                        raise ValueError(f"ê°ì • ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: [{failure_type}] {reason}")
                
                # ì„±ê³µ
                if failure_type and attempt > 1:
                    self.failure_stats[failure_type]['success_after_retry'] += 1
                
                logger.info(f"âœ… ê°ì • ë¶„ì„ ì„±ê³µ (ì‹œë„ {attempt})")
                break
                
            except Exception as e:
                last_error = str(e)
                logger.error(f"ê°ì • ë¶„ì„ ì‹¤íŒ¨ (ì‹œë„ {attempt}): {e}")
                
                # íŒŒì‹± ì‹¤íŒ¨ëŠ” íŠ¹ë³„ ì²˜ë¦¬
                if "íŒŒì‹±" in str(e):
                    failure_type = "PARSING_ERROR"
                    self.failure_stats[failure_type]['count'] += 1
                
                if attempt == max_attempts:
                    if failure_type:
                        self.failure_stats[failure_type]['final_failures'] += 1
                    raise ValueError(f"ê°ì • ë¶„ì„ ìµœì¢… ì‹¤íŒ¨: {last_error}")
        
        # 3. í›„íšŒ ì§€ìˆ˜
        regret_factor = self.calculate_regret_factor_direct(text_for_analysis)
        
        # 4. ë²¤ë‹´ ì ìˆ˜
        bentham_scores = self.calculate_bentham_scores_direct(text_for_analysis, emotion_result['vector'])
        
        # 5. SURD ë©”íŠ¸ë¦­
        surd_metrics = self.calculate_surd_metrics_direct(text_for_analysis, item.get('metadata', {}))
        
        processing_time = time.time() - start_time
        
        return {
            'text': text,
            'source': item.get('source', 'unknown'),
            'emotion_vector': emotion_result['vector'],
            'regret_factor': regret_factor,
            'bentham_scores': bentham_scores,
            'surd_metrics': surd_metrics,
            'context_embedding': context_embedding,
            'processing_time': processing_time,
            'llm_confidence': emotion_result.get('confidence', 0.5),
            'timestamp': datetime.now().isoformat(),
            'metadata': item.get('metadata', {})
        }
    
    def process_single_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ ì•„ì´í…œ ì²˜ë¦¬ - í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€"""
        return self.process_single_item_with_retry(item, max_attempts=3)
    
    def process_dataset(self, input_file: str = "parsed_raw_datasets.json",
                        output_file: str = "preprocessed_dataset_v3.json",
                        failed_log_file: str = "preprocessing_failures.json",
                        limit: Optional[int] = None):
        """ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬ - ì‹¤íŒ¨ ë¡œê¹… í¬í•¨"""
        logger.info(f"ğŸ“š ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹œì‘: {input_file}")
        
        # ë°ì´í„° ë¡œë“œ
        with open(input_file, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        if limit:
            raw_data = raw_data[:limit]
        
        logger.info(f"ì´ {len(raw_data)}ê°œ ìƒ˜í”Œ ì²˜ë¦¬ ì˜ˆì •")
        
        # LLM ì´ˆê¸°í™”
        self.initialize_llm()
        
        # ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ì†Œ
        processed_data = []
        failed_items = []
        consecutive_failures = 0
        
        for i, item in enumerate(raw_data):
            if i % 5 == 0:
                logger.info(f"ì§„í–‰ë¥ : {i}/{len(raw_data)} ({i*100/len(raw_data):.1f}%)")
            
            try:
                result = self.process_single_item_with_retry(item)
                processed_data.append(result)
                logger.info(f"âœ… ìƒ˜í”Œ {i} ì²˜ë¦¬ ì™„ë£Œ")
                
                # ì‹¤íŒ¨ ì¹´ìš´í„° ë¦¬ì…‹
                consecutive_failures = 0
                
            except Exception as e:
                logger.error(f"ìƒ˜í”Œ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                
                # ì‹¤íŒ¨ ì •ë³´ ê¸°ë¡
                failed_info = {
                    'index': i,
                    'source': item.get('source', 'unknown'),
                    'text_preview': item.get('text', '')[:200] + '...' if len(item.get('text', '')) > 200 else item.get('text', ''),
                    'error': str(e),
                    'error_type': type(e).__name__,
                    'metadata': item.get('metadata', {}),
                    'timestamp': datetime.now().isoformat()
                }
                failed_items.append(failed_info)
                
                consecutive_failures += 1
                
                # í”„ë¡œì íŠ¸ ê·œì¹™: ì—°ì† 3ê°œ ì‹¤íŒ¨ì‹œ ì¤‘ë‹¨ (ì„ íƒì )
                if consecutive_failures >= 3:
                    logger.warning(f"ì—°ì† {consecutive_failures}ê°œ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
                    # ì¤‘ë‹¨í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰ (ë” ë§ì€ ë°ì´í„° ì²˜ë¦¬ ìœ„í•´)
                    consecutive_failures = 0  # ë¦¬ì…‹í•˜ì—¬ ê³„ì† ì§„í–‰
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬
            if i % 20 == 0:
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        # ì„±ê³µ ë°ì´í„° ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(processed_data, f, ensure_ascii=False, indent=2)
        
        # ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥
        if failed_items:
            with open(failed_log_file, 'w', encoding='utf-8') as f:
                json.dump(failed_items, f, ensure_ascii=False, indent=2)
            logger.warning(f"âŒ {len(failed_items)}ê°œ ìƒ˜í”Œ ì‹¤íŒ¨ â†’ {failed_log_file}")
        
        # ìµœì¢… í†µê³„
        logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {len(processed_data)}/{len(raw_data)}ê°œ ì„±ê³µ â†’ {output_file}")
        if failed_items:
            logger.info(f"âŒ ì‹¤íŒ¨: {len(failed_items)}ê°œ â†’ {failed_log_file}")
            self.print_failure_summary(failed_items)
        
        # ì‹¤íŒ¨ íŒ¨í„´ í†µê³„ ì¶œë ¥
        self.print_failure_pattern_stats()
        
        self.print_statistics(processed_data)
    
    def print_failure_pattern_stats(self):
        """ì‹¤íŒ¨ íŒ¨í„´ í†µê³„ ì¶œë ¥"""
        if not self.failure_stats:
            return
        
        print("\nğŸ“Š ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„:")
        print("-" * 60)
        
        total_failures = sum(stats['count'] for stats in self.failure_stats.values())
        total_retries_success = sum(stats['success_after_retry'] for stats in self.failure_stats.values())
        total_final_failures = sum(stats['final_failures'] for stats in self.failure_stats.values())
        
        print(f"\nğŸ“‹ ì „ì²´ í†µê³„:")
        print(f"  - ì´ ì‹¤íŒ¨ ê°ì§€: {total_failures}íšŒ")
        print(f"  - ì¬ì‹œë„ í›„ ì„±ê³µ: {total_retries_success}íšŒ ({total_retries_success/max(total_failures,1)*100:.1f}%)")
        print(f"  - ìµœì¢… ì‹¤íŒ¨: {total_final_failures}íšŒ")
        
        print(f"\nğŸ” ì‹¤íŒ¨ ìœ í˜•ë³„ ìƒì„¸:")
        for failure_type, stats in sorted(self.failure_stats.items(), key=lambda x: x[1]['count'], reverse=True):
            if stats['count'] == 0:
                continue
            
            print(f"\n  [{failure_type}]")
            print(f"    - ë°œìƒ íšŸìˆ˜: {stats['count']}íšŒ")
            print(f"    - ì¬ì‹œë„ ì„±ê³µ: {stats['success_after_retry']}íšŒ")
            print(f"    - ìµœì¢… ì‹¤íŒ¨: {stats['final_failures']}íšŒ")
            
            if stats['success_after_retry'] > 0:
                success_rate = stats['success_after_retry'] / stats['count'] * 100
                print(f"    - ì¬ì‹œë„ ì„±ê³µë¥ : {success_rate:.1f}%")
            
            if stats['sample_texts']:
                print(f"    - ì˜ˆì‹œ í…ìŠ¤íŠ¸:")
                for i, sample in enumerate(stats['sample_texts'][:2], 1):
                    print(f"      {i}. {sample[:100]}...")
        
        print("\n" + "="*60)
    
    def print_failure_summary(self, failed_items: List[Dict]):
        """ì‹¤íŒ¨ ìš”ì•½ ì¶œë ¥"""
        print("\nâŒ ì‹¤íŒ¨ ë¶„ì„:")
        print(f"  - ì´ ì‹¤íŒ¨: {len(failed_items)}ê°œ")
        
        # ì—ëŸ¬ íƒ€ì…ë³„ ë¶„ë¥˜
        error_types = {}
        for item in failed_items:
            error_type = item['error_type']
            if error_type not in error_types:
                error_types[error_type] = []
            error_types[error_type].append(item)
        
        print("\n  ì—ëŸ¬ íƒ€ì…ë³„ ë¶„í¬:")
        for error_type, items in error_types.items():
            print(f"    - {error_type}: {len(items)}ê°œ")
            # ì²« ë²ˆì§¸ ì—ëŸ¬ ì˜ˆì‹œ
            if items:
                print(f"      ì˜ˆì‹œ: {items[0]['error'][:100]}")
        
        # ì†ŒìŠ¤ë³„ ì‹¤íŒ¨ ë¶„í¬
        source_failures = {}
        for item in failed_items:
            source = item['source']
            source_failures[source] = source_failures.get(source, 0) + 1
        
        print("\n  ì†ŒìŠ¤ë³„ ì‹¤íŒ¨:")
        for source, count in source_failures.items():
            print(f"    - {source}: {count}ê°œ")
    
    def print_statistics(self, data: List[Dict]):
        """í†µê³„ ì¶œë ¥"""
        if not data:
            return
        
        print("\nğŸ“Š ë°ì´í„°ì…‹ í†µê³„:")
        print(f"  - ì´ ìƒ˜í”Œ ìˆ˜: {len(data)}")
        
        # ì†ŒìŠ¤ë³„ ë¶„í¬
        sources = {}
        for item in data:
            src = item.get('source', 'unknown')
            sources[src] = sources.get(src, 0) + 1
        
        print("\n  ì†ŒìŠ¤ë³„ ë¶„í¬:")
        for src, count in sources.items():
            print(f"    - {src}: {count}ê°œ")
        
        # í‰ê·  ì§€í‘œ
        avg_regret = sum(item['regret_factor'] for item in data) / len(data)
        print(f"\n  í‰ê·  í›„íšŒ ì§€ìˆ˜: {avg_regret:.3f}")
        
        # í‰ê·  ê°ì •
        avg_emotions = [0] * 7
        for item in data:
            for i, val in enumerate(item['emotion_vector']):
                avg_emotions[i] += val
        avg_emotions = [e/len(data) for e in avg_emotions]
        
        emotion_names = ['joy', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'trust']
        print("\n  í‰ê·  ê°ì • ë¶„í¬:")
        for name, val in zip(emotion_names, avg_emotions):
            print(f"    - {name}: {val:.3f}")
        
        # ì„ë² ë”© ì°¨ì›
        if data[0].get('context_embedding'):
            print(f"\n  ì„ë² ë”© ì°¨ì›: {len(data[0]['context_embedding'])}")
        
        # í‰ê·  ë²¤ë‹´ ì ìˆ˜
        if data[0].get('bentham_scores'):
            avg_bentham = {}
            for key in data[0]['bentham_scores'].keys():
                avg_bentham[key] = sum(item['bentham_scores'][key] for item in data) / len(data)
            
            print("\n  í‰ê·  ë²¤ë‹´ ì ìˆ˜:")
            for key, val in avg_bentham.items():
                print(f"    - {key}: {val:.3f}")
        
        # í‰ê·  SURD ë©”íŠ¸ë¦­
        if data[0].get('surd_metrics'):
            avg_surd = {}
            for key in data[0]['surd_metrics'].keys():
                avg_surd[key] = sum(item['surd_metrics'][key] for item in data) / len(data)
            
            print("\n  í‰ê·  SURD ë©”íŠ¸ë¦­:")
            for key, val in avg_surd.items():
                print(f"    - {key}: {val:.3f}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    preprocessor = HelpingAIPreprocessor()
    
    # Scruples í…ŒìŠ¤íŠ¸ (5ê°œ ìƒ˜í”Œë¡œ í™•ëŒ€)
    preprocessor.process_dataset(
        input_file="parsed_raw_datasets.json",
        output_file="preprocessed_dataset_v3.json",
        failed_log_file="preprocessing_failures.json",
        limit=5  # 5ê°œ ìƒ˜í”Œë¡œ í™•ëŒ€ í…ŒìŠ¤íŠ¸
    )

if __name__ == "__main__":
    main()