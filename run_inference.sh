#!/bin/bash
# Red Heart AI í†µí•© ì¶”ë¡  ì‹œìŠ¤í…œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# Unified Inference System Execution Script
# 50 epochìœ¼ë¡œ í•™ìŠµëœ 730M ëª¨ë¸ ìš´ìš©

set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ

echo "ğŸš€ Red Heart AI í†µí•© ì¶”ë¡  ì‹œìŠ¤í…œ ì‹œì‘"
echo "==========================================="
echo "   730M íŒŒë¼ë¯¸í„° ëª¨ë¸ (50 epoch í•™ìŠµ ì™„ë£Œ)"
echo "==========================================="

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# í•¨ìˆ˜ ì •ì˜
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_module() {
    echo -e "${PURPLE}[MODULE]${NC} $1"
}

# í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

print_status "ì‘ì—… ë””ë ‰í† ë¦¬: $SCRIPT_DIR"

# í™˜ê²½ ê²€ì¦ í•¨ìˆ˜
check_environment() {
    print_status "í™˜ê²½ ê²€ì¦ ì¤‘..."
    
    # Python ë²„ì „ í™•ì¸
    python_version=$(python3 --version 2>&1 | awk '{print $2}')
    print_status "Python ë²„ì „: $python_version"
    
    # PyTorch í™•ì¸
    if python3 -c "import torch; print(f'PyTorch {torch.__version__}')" 2>/dev/null; then
        print_success "âœ… PyTorch ì„¤ì¹˜ë¨"
        
        # GPU í™•ì¸
        if python3 -c "import torch; print('CUDA' if torch.cuda.is_available() else 'CPU')" | grep -q "CUDA"; then
            gpu_info=$(python3 -c "import torch; print(f'{torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB)')" 2>/dev/null)
            print_success "âœ… GPU ì‚¬ìš© ê°€ëŠ¥: $gpu_info"
        else
            print_warning "âš ï¸ GPU ì—†ìŒ - CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤"
        fi
    else
        print_error "âŒ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        return 1
    fi
    
    # Transformers í™•ì¸
    if python3 -c "import transformers" 2>/dev/null; then
        print_success "âœ… Transformers ì„¤ì¹˜ë¨"
    else
        print_error "âŒ Transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        return 1
    fi
    
    # ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    checkpoint_path="training/checkpoints_final/checkpoint_epoch_0050_lr_0.000009_20250827_154403.pt"
    if [ -f "$checkpoint_path" ]; then
        checkpoint_size=$(du -h "$checkpoint_path" | cut -f1)
        print_success "âœ… 50 epoch ì²´í¬í¬ì¸íŠ¸ í™•ì¸ ($checkpoint_size)"
    else
        print_warning "âš ï¸ 50 epoch ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ - ë‹¤ë¥¸ ì²´í¬í¬ì¸íŠ¸ ê²€ìƒ‰ ì¤‘..."
        
        # ëŒ€ì²´ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        if [ -d "training/checkpoints_final" ]; then
            latest_checkpoint=$(ls -t training/checkpoints_final/*.pt 2>/dev/null | head -n1)
            if [ -n "$latest_checkpoint" ]; then
                print_status "ëŒ€ì²´ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: $(basename $latest_checkpoint)"
            else
                print_warning "ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ - ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ë¡œ ì‹œì‘í•©ë‹ˆë‹¤"
            fi
        fi
    fi
    
    return 0
}

# ê°€ìƒí™˜ê²½ í™œì„±í™” í•¨ìˆ˜
activate_environment() {
    print_status "ê°€ìƒí™˜ê²½ í™•ì¸ ì¤‘..."
    
    # venv í™˜ê²½ í™•ì¸
    if [ -f "red_heart_env/bin/activate" ]; then
        source red_heart_env/bin/activate
        print_success "âœ… red_heart_env ê°€ìƒí™˜ê²½ í™œì„±í™”"
        print_status "   Python: $(which python)"
    else
        print_warning "ê°€ìƒí™˜ê²½ ì—†ìŒ - ì‹œìŠ¤í…œ Python ì‚¬ìš©"
    fi
}

# ëª¨ë“ˆ ìƒíƒœ ì²´í¬ í•¨ìˆ˜
check_modules() {
    print_status "í•µì‹¬ ëª¨ë“ˆ ìƒíƒœ í™•ì¸..."
    echo ""
    
    # Pythonì—ì„œ ëª¨ë“ˆ ì²´í¬
    python3 << 'EOF'
import sys
import os
sys.path.insert(0, os.getcwd())
sys.path.insert(0, os.path.join(os.getcwd(), 'training'))

modules_status = {
    "UnifiedModel (730M)": False,
    "Neural Analyzers (368M)": False,
    "Advanced Wrappers (112M)": False,
    "DSP Simulator (14M)": False,
    "Phase Networks (4.3M)": False,
    "LLM Engine": False
}

# UnifiedModel ì²´í¬
try:
    from training.unified_training_final import UnifiedModel
    modules_status["UnifiedModel (730M)"] = True
except: pass

# Neural Analyzers ì²´í¬
try:
    from analyzer_neural_modules import create_neural_analyzers
    modules_status["Neural Analyzers (368M)"] = True
except: pass

# Advanced Wrappers ì²´í¬
try:
    from advanced_analyzer_wrappers import create_advanced_analyzer_wrappers
    modules_status["Advanced Wrappers (112M)"] = True
except: pass

# DSP Simulator ì²´í¬
try:
    from emotion_dsp_simulator import EmotionDSPSimulator
    modules_status["DSP Simulator (14M)"] = True
except: pass

# Phase Networks ì²´í¬
try:
    from phase_neural_networks import Phase0ProjectionNet
    modules_status["Phase Networks (4.3M)"] = True
except: pass

# LLM Engine ì²´í¬
try:
    from llm_module.advanced_llm_engine import AdvancedLLMEngine
    modules_status["LLM Engine"] = True
except: pass

# ê²°ê³¼ ì¶œë ¥
total = len(modules_status)
available = sum(modules_status.values())

for module, status in modules_status.items():
    icon = "âœ…" if status else "âŒ"
    print(f"   {icon} {module}")

print("")
print(f"   ğŸ“Š ëª¨ë“ˆ ê°€ìš©ì„±: {available}/{total} ({available*100//total}%)")

if available < 3:
    print("   âš ï¸ í•µì‹¬ ëª¨ë“ˆì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
EOF
    
    echo ""
}

# HuggingFace ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •
setup_offline_mode() {
    export TRANSFORMERS_OFFLINE=1
    export HF_DATASETS_OFFLINE=1
    export HF_HUB_OFFLINE=1
    export TRANSFORMERS_VERBOSITY=error
    export HF_HUB_DISABLE_TELEMETRY=1
    print_status "ğŸ” HuggingFace ì˜¤í”„ë¼ì¸ ëª¨ë“œ í™œì„±í™”"
}

# ì¶”ë¡  ì‹œìŠ¤í…œ ì‹¤í–‰ í•¨ìˆ˜
run_inference_system() {
    local mode="${1:-inference}"
    shift 2>/dev/null || true
    
    print_status "Red Heart AI ì¶”ë¡  ì‹œìŠ¤í…œ ì‹¤í–‰..."
    print_status "ì‹¤í–‰ ëª¨ë“œ: $mode"
    echo ""
    
    case "$mode" in
        # ================== ê¸°ë³¸ ì¶”ë¡  ëª¨ë“œ ==================
        "inference"|"infer")
            print_module "ğŸ¯ ì¶”ë¡  ëª¨ë“œ - 730M ì „ì²´ ëª¨ë¸ ì‚¬ìš©"
            print_status "   - UnifiedModel + ëª¨ë“  ë³´ì¡° ëª¨ë“ˆ"
            print_status "   - 50 epoch ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"
            if [ -n "$1" ]; then
                python main_unified.py --mode inference --text "$@"
            else
                python main_unified.py --mode inference "$@"
            fi
            ;;
            
        # ================== í…ŒìŠ¤íŠ¸ ëª¨ë“œ ==================
        "test")
            print_module "ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ"
            print_status "   - 3ê°œ ìƒ˜í”Œë¡œ ì‹œìŠ¤í…œ ê²€ì¦"
            print_status "   - ëª¨ë“  ëª¨ë“ˆ ì‘ë™ í™•ì¸"
            python main_unified.py --mode test --verbose "$@"
            ;;
            
        # ================== ë°ëª¨ ëª¨ë“œ ==================
        "demo"|"interactive")
            print_module "ğŸ® ëŒ€í™”í˜• ë°ëª¨ ëª¨ë“œ"
            print_status "   - ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë¶„ì„"
            print_status "   - ì¢…ë£Œ: quit ì…ë ¥"
            python main_unified.py --mode demo "$@"
            ;;
            
        # ================== ìš´ìš© ëª¨ë“œ ==================
        "production"|"prod")
            print_module "ğŸš€ ìš´ìš© ëª¨ë“œ"
            print_status "   - ì™„ì „í•œ 730M ëª¨ë¸"
            print_status "   - ëª¨ë“  ìµœì í™” í™œì„±í™”"
            python main_unified.py --mode production "$@"
            ;;
            
        # ================== ê³ ê¸‰ ëª¨ë“œ (ëª¨ë“ˆë³„ ì œì–´) ==================
        "advanced"|"custom")
            print_module "âš™ï¸ ê³ ê¸‰ ëª¨ë“œ - ëª¨ë“ˆ ì„ íƒì  í™œì„±í™”"
            echo ""
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜:"
            echo "   --no-neural    : Neural Analyzers ë¹„í™œì„±í™”"
            echo "   --no-wrappers  : Advanced Wrappers ë¹„í™œì„±í™”"
            echo "   --no-dsp       : DSP Simulator ë¹„í™œì„±í™”"
            echo "   --no-phase     : Phase Networks ë¹„í™œì„±í™”"
            echo "   --llm local    : ë¡œì»¬ LLM í™œì„±í™”"
            echo "   --llm claude   : Claude API í™œì„±í™”"
            echo ""
            python main_unified.py --mode inference "$@"
            ;;
            
        # ================== LLM í†µí•© ëª¨ë“œ ==================
        "llm-local")
            print_module "ğŸ¤– ë¡œì»¬ LLM í†µí•© ëª¨ë“œ"
            print_status "   - HelpingAI 9B ëª¨ë¸ ì‚¬ìš©"
            print_status "   - 4-bit ì–‘ìí™”"
            python main_unified.py --mode production --llm local "$@"
            ;;
            
        "llm-claude")
            print_module "ğŸ¤– Claude API í†µí•© ëª¨ë“œ"
            print_status "   - Claude API ìºì‹± í™œìš©"
            print_status "   - 90% ë¹„ìš© ì ˆê°"
            python main_unified.py --mode production --llm claude "$@"
            ;;
            
        "llm-mcp")
            print_module "ğŸ”Œ MCP í”„ë¡œí† ì½œ ëª¨ë“œ"
            print_status "   - Model Context Protocol ì§€ì›"
            print_status "   - (ê°œë°œ ì¤‘)"
            python main_unified.py --mode production --llm mcp "$@"
            ;;
            
        # ================== ê²½ëŸ‰ ëª¨ë“œ ==================
        "light"|"fast")
            print_module "âš¡ ê²½ëŸ‰ ëª¨ë“œ"
            print_status "   - ê¸°ë³¸ UnifiedModelë§Œ ì‚¬ìš©"
            print_status "   - ë¹ ë¥¸ ì¶”ë¡  ì†ë„"
            python main_unified.py --mode inference \
                --no-neural --no-wrappers --no-dsp --no-phase "$@"
            ;;
            
        # ================== ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ ==================
        "benchmark"|"bench")
            print_module "ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ"
            print_status "   - ì„±ëŠ¥ ì¸¡ì •"
            print_status "   - ì²˜ë¦¬ ì‹œê°„ ë¶„ì„"
            
            echo ""
            echo "ë²¤ì¹˜ë§ˆí¬ ì‹œì‘..."
            
            # 10ê°œ ìƒ˜í”Œë¡œ ë²¤ì¹˜ë§ˆí¬
            for i in {1..10}; do
                echo -n "   í…ŒìŠ¤íŠ¸ $i/10... "
                time_start=$(date +%s.%N)
                python main_unified.py --mode inference \
                    --text "ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ $i" \
                    --verbose 2>/dev/null | tail -n1
                time_end=$(date +%s.%N)
                elapsed=$(echo "$time_end - $time_start" | bc)
                echo "ì™„ë£Œ (${elapsed}ì´ˆ)"
            done
            ;;
            
        # ================== ëª¨ë‹ˆí„°ë§ ëª¨ë“œ ==================
        "monitor"|"status")
            print_module "ğŸ“ˆ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§"
            
            # GPU ìƒíƒœ
            if command -v nvidia-smi &> /dev/null; then
                print_status "GPU ìƒíƒœ:"
                nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu \
                    --format=csv,noheader,nounits | while read line; do
                    echo "   $line"
                done
            fi
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ
            print_status "ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬:"
            free -h | grep "^Mem:" | awk '{print "   ì „ì²´: "$2", ì‚¬ìš©: "$3", ì—¬ìœ : "$4}'
            
            # í”„ë¡œì„¸ìŠ¤ ìƒíƒœ
            print_status "Python í”„ë¡œì„¸ìŠ¤:"
            ps aux | grep python | grep -E "(main_unified|unified_training)" | head -n3
            ;;
            
        # ================== ë„ì›€ë§ ==================
        "help"|"-h"|"--help")
            show_inference_help
            ;;
            
        *)
            print_warning "ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: $mode"
            print_status "ê¸°ë³¸ ì¶”ë¡  ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."
            python main_unified.py --mode inference "$mode" "$@"
            ;;
    esac
}

# ë„ì›€ë§ í•¨ìˆ˜
show_inference_help() {
    echo ""
    echo "ğŸš€ Red Heart AI í†µí•© ì¶”ë¡  ì‹œìŠ¤í…œ ì‚¬ìš©ë²•"
    echo "========================================"
    echo ""
    echo "ê¸°ë³¸ ì‚¬ìš©ë²•:"
    echo "  $0 [ëª¨ë“œ] [ì˜µì…˜...] [--text \"ë¶„ì„í•  í…ìŠ¤íŠ¸\"]"
    echo ""
    echo "ğŸ¯ ì£¼ìš” ëª¨ë“œ:"
    echo "  inference, infer   # ê¸°ë³¸ ì¶”ë¡  (730M ì „ì²´)"
    echo "  test              # ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"
    echo "  demo              # ëŒ€í™”í˜• ë°ëª¨"
    echo "  production        # ìš´ìš© ëª¨ë“œ"
    echo ""
    echo "ğŸ¤– LLM í†µí•©:"
    echo "  llm-local         # ë¡œì»¬ LLM (HelpingAI 9B)"
    echo "  llm-claude        # Claude API"
    echo "  llm-mcp           # MCP í”„ë¡œí† ì½œ (ê°œë°œ ì¤‘)"
    echo ""
    echo "âš™ï¸ íŠ¹ìˆ˜ ëª¨ë“œ:"
    echo "  advanced          # ëª¨ë“ˆ ì„ íƒì  í™œì„±í™”"
    echo "  light             # ê²½ëŸ‰ ëª¨ë“œ (ë¹ ë¥¸ ì¶”ë¡ )"
    echo "  benchmark         # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"
    echo "  monitor           # ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§"
    echo ""
    echo "ğŸ’¡ ì˜ˆì‹œ:"
    echo "  $0 inference --text \"ë¶„ì„í•  í…ìŠ¤íŠ¸\""
    echo "  $0 demo"
    echo "  $0 test --verbose"
    echo "  $0 production --text \"ìš´ìš© í…ìŠ¤íŠ¸\" --llm local"
    echo "  $0 light --text \"ë¹ ë¥¸ ë¶„ì„\""
    echo "  $0 advanced --no-dsp --no-phase --text \"ì„ íƒì  ë¶„ì„\""
    echo ""
    echo "ğŸ“Š ëª¨ë¸ êµ¬ì„± (730M):"
    echo "  - UnifiedModel: 243.6M (Backbone + 4 Heads)"
    echo "  - Neural Analyzers: 368M"
    echo "  - Advanced Wrappers: 112M"
    echo "  - DSP Simulator: 14M"
    echo "  - Kalman Filter: 2.3M"
    echo "  - Phase Networks: 4.3M"
    echo ""
    echo "ğŸ”§ ê³ ê¸‰ ì˜µì…˜:"
    echo "  --checkpoint PATH  # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ"
    echo "  --batch-size N     # ë°°ì¹˜ í¬ê¸°"
    echo "  --device cuda/cpu  # ë””ë°”ì´ìŠ¤ ì„ íƒ"
    echo "  --no-neural        # Neural Analyzers ë¹„í™œì„±í™”"
    echo "  --no-wrappers      # Advanced Wrappers ë¹„í™œì„±í™”"
    echo "  --no-dsp           # DSP Simulator ë¹„í™œì„±í™”"
    echo "  --no-phase         # Phase Networks ë¹„í™œì„±í™”"
    echo "  --llm MODE         # LLM ëª¨ë“œ (none/local/claude/mcp)"
    echo "  --verbose          # ìƒì„¸ ë¡œê·¸"
    echo "  --debug            # ë””ë²„ê·¸ ëª¨ë“œ"
    echo ""
}

# ì •ë¦¬ í•¨ìˆ˜
cleanup_inference() {
    print_status "ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘..."
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if command -v nvidia-smi &> /dev/null; then
        python3 -c "import torch; torch.cuda.empty_cache()" 2>/dev/null || true
    fi
    
    print_success "ì •ë¦¬ ì™„ë£Œ"
}

# ì‹ í˜¸ ì²˜ë¦¬
trap cleanup_inference EXIT
trap 'print_warning "ì¶”ë¡  ì¤‘ë‹¨ë¨"; cleanup_inference; exit 130' INT TERM

# ë©”ì¸ ì‹¤í–‰
main() {
    local mode="${1:-help}"
    
    # ë„ì›€ë§ ìš”ì²­ ì²˜ë¦¬
    case "$mode" in
        --help|-h|help)
            show_inference_help
            exit 0
            ;;
    esac
    
    echo ""
    print_success "ğŸ¯ Red Heart AI í†µí•© ì¶”ë¡  ì‹œìŠ¤í…œ"
    print_status "   730M íŒŒë¼ë¯¸í„° / 50 epoch í•™ìŠµ ì™„ë£Œ"
    echo ""
    
    # í™˜ê²½ í™œì„±í™”
    activate_environment
    
    # í™˜ê²½ ê²€ì¦
    if ! check_environment; then
        print_error "í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨"
        exit 1
    fi
    
    echo ""
    
    # ëª¨ë“ˆ ì²´í¬
    check_modules
    
    # ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •
    setup_offline_mode
    
    echo "==========================================="
    echo ""
    
    # ì¶”ë¡  ì‹œìŠ¤í…œ ì‹¤í–‰
    run_inference_system "$@"
    
    echo ""
    print_success "ğŸ‰ Red Heart AI ì¶”ë¡  ì™„ë£Œ!"
    echo ""
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main "$@"