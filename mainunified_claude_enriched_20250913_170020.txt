2025-09-13 17:00:36 | RedHeart.MainUnified | INFO | 🖥️ 사용 디바이스: cuda
2025-09-13 17:00:36 | RedHeart.MainUnified | INFO |    GPU: NVIDIA GeForce RTX 2070 SUPER
2025-09-13 17:00:36 | RedHeart.MainUnified | INFO |    VRAM: 8.0GB
2025-09-13 17:00:36 | RedHeart.MainUnified | INFO | 🔄 Claude API 모드 감지 - 독립 워크플로우로 전환...
2025-09-13 17:00:36 | RedHeart.MainUnified | INFO | 📌 REDHEART_CLAUDE_MODE 환경변수 설정 - 로컬 LLM 엔진 비활성화
2025-09-13 17:00:36 | RedHeart.MainUnified | INFO | 📌 전역 모듈 사전 초기화 중...
2025-09-13 17:00:36 | local_translator | INFO | LocalTranslator 생성 - lazy loading 모드
2025-09-13 17:00:36 | RedHeart.Config | INFO | 🔥 register_system_module 호출: module_id=translator, instance_type=<class 'local_translator.LocalTranslator'>, config_section=None
2025-09-13 17:00:36 | RedHeart.Config | INFO | 🔥 모듈 인스턴스 등록 (config_section 없음): translator -> <class 'local_translator.LocalTranslator'>
2025-09-13 17:00:36 | RedHeart.MainUnified | INFO |    ✅ 번역기 전역 등록 완료
2025-09-13 17:00:36 | RedHeart.MainUnified | INFO | 📌 Claude 모드 환경변수 설정: REDHEART_CLAUDE_MODE=1
2025-09-13 17:00:36 | RedHeart.MainUnified | INFO | 📌 Claude Inference 직접 실행: text=AI 윤리적 문제 해결, epoch=50, debug=True
2025-09-13 17:00:36 | ClaudeInference | INFO | ======================================================================
2025-09-13 17:00:36 | ClaudeInference | INFO | 🚀 Claude API 독립 추론 시스템 초기화
2025-09-13 17:00:36 | ClaudeInference | INFO | ======================================================================
2025-09-13 17:00:36 | ClaudeInference | INFO | 📌 에폭: 50
2025-09-13 17:00:36 | ClaudeInference | INFO | 📌 디바이스: cuda
2025-09-13 17:00:36 | ClaudeInference | INFO | 📌 디버그 모드: True
2025-09-13 17:00:36 | ClaudeInference | INFO | 
📦 Phase 1: UnifiedModel 로드...
2025-09-13 17:00:39 | sentence_transformer_singleton | INFO | SentenceTransformerManager 초기화 완료 (Subprocess Server 기반)
2025-09-13 17:00:39 | training.enhanced_checkpoint_manager | INFO |   - 기존 메타데이터 로드: 30개 체크포인트
2025-09-13 17:00:39 | training.enhanced_checkpoint_manager | INFO | ✅ Enhanced CheckpointManager 초기화
2025-09-13 17:00:39 | training.enhanced_checkpoint_manager | INFO |   - 저장 디렉토리: training/checkpoints_final
2025-09-13 17:00:39 | training.enhanced_checkpoint_manager | INFO |   - 최대 체크포인트: 30개
2025-09-13 17:00:39 | training.enhanced_checkpoint_manager | INFO |   - 저장 간격: 1 에폭마다
2025-09-13 17:00:40 | unified_backbone | INFO | 백본 총 파라미터: 90,624,132 (90.62M)
2025-09-13 17:00:40 | unified_backbone | INFO | 학습 가능 파라미터: 90,624,132 (90.62M)
2025-09-13 17:00:40 | unified_heads | INFO | 감정 헤드 파라미터: 17,254,583 (17.25M)
2025-09-13 17:00:40 | unified_heads | INFO | 벤담 헤드 파라미터: 13,871,919 (13.87M)
2025-09-13 17:00:40 | unified_heads | INFO | 후회 헤드 파라미터: 19,897,161 (19.90M)
2025-09-13 17:00:40 | unified_heads | INFO | SURD 헤드 파라미터: 12,025,739 (12.03M)
2025-09-13 17:00:41 | analyzer_neural_modules | INFO | NeuralEmotionAnalyzer 초기화: 122,595,407 파라미터
2025-09-13 17:00:42 | analyzer_neural_modules | INFO | NeuralBenthamCalculator 초기화: 78,281,602 파라미터
2025-09-13 17:00:43 | analyzer_neural_modules | INFO | NeuralRegretAnalyzer 초기화: 153,872,666 파라미터
2025-09-13 17:00:43 | analyzer_neural_modules | INFO | NeuralSURDAnalyzer 초기화: 13,473,032 파라미터
2025-09-13 17:00:43 | analyzer_neural_modules | INFO | 전체 신경망 분석기 파라미터: 368,222,707 (368.2M)
2025-09-13 17:00:44 | emotion_dsp_simulator | INFO | EmotionDSPSimulator 초기화 완료 (~14M 파라미터)
2025-09-13 17:00:44 | ClaudeInference | INFO |    체크포인트 로드: training/checkpoints_final/checkpoint_epoch_0050_lr_0.000009_20250827_154403.pt
2025-09-13 17:01:11 | ClaudeInference | INFO |    ✅ UnifiedModel 로드 완료
2025-09-13 17:01:11 | ClaudeInference | INFO |    - Epoch: 50
2025-09-13 17:01:11 | ClaudeInference | INFO |    - LR: 9.261697283911905e-06
2025-09-13 17:01:11 | ClaudeInference | INFO | 
📦 Phase 2: 번역기 로드...
2025-09-13 17:01:11 | ClaudeInference | INFO |    ⚠️ Claude 모드 - 번역기 로드 스킵 (Claude API 다국어 지원)
2025-09-13 17:01:11 | ClaudeInference | INFO | 
📦 Phase 3: Neural Analyzers 로드...
2025-09-13 17:01:12 | analyzer_neural_modules | INFO | NeuralEmotionAnalyzer 초기화: 122,595,407 파라미터
2025-09-13 17:01:12 | analyzer_neural_modules | INFO | NeuralBenthamCalculator 초기화: 78,281,602 파라미터
2025-09-13 17:01:13 | analyzer_neural_modules | INFO | NeuralRegretAnalyzer 초기화: 153,872,666 파라미터
2025-09-13 17:01:13 | analyzer_neural_modules | INFO | NeuralSURDAnalyzer 초기화: 13,473,032 파라미터
2025-09-13 17:01:13 | ClaudeInference | INFO |    ✅ Neural Analyzers 로드 완료 (CPU)
2025-09-13 17:01:13 | ClaudeInference | INFO | 
📦 Phase 4: Advanced Wrappers 로드...
2025-09-13 17:02:02 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 17.4%, 필요: 500MB)
2025-09-13 17:02:02 | RedHeartLinux.AdvancedEmotion | INFO | 감정 임베딩 모델 초기화 시작...
2025-09-13 17:02:02 | sentence_transformer_singleton | INFO | 새 클라이언트 생성 시작: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:02:02 | sentence_transformer_client | INFO | 현재 Python이 venv 환경: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-13 17:02:02 | sentence_transformer_client | INFO | SentenceTransformer Client 초기화: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-13 17:02:02 | sentence_transformer_client | INFO | Python 실행파일: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-13 17:02:02 | sentence_transformer_singleton | INFO | 서버 시작 및 모델 로딩: sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (device: cuda)
2025-09-13 17:02:02 | sentence_transformer_client | INFO | SentenceTransformer 서버 시작: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-13 17:02:02 | sentence_transformer_client | INFO | PYTHONPATH: /mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages:/mnt/c/large_project/linux_red_heart
2025-09-13 17:02:02 | sentence_transformer_client | INFO | VIRTUAL_ENV: /mnt/c/large_project/linux_red_heart/red_heart_env
2025-09-13 17:02:02 | sentence_transformer_client | INFO | stderr 드레인 스레드 시작
2025-09-13 17:02:02 | sentence_transformer_client | INFO | stderr 드레인 스레드 생성 완료
2025-09-13 17:02:12 | sentence_transformer_client | INFO | 서버 연결 성공
2025-09-13 17:02:12 | sentence_transformer_client | INFO | 모델 로딩 요청: sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (device: cuda)
2025-09-13 17:03:25 | sentence_transformer_client | INFO | 모델 로딩 성공: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
2025-09-13 17:03:25 | sentence_transformer_singleton | INFO | 클라이언트 생성 및 모델 로딩 성공: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:03:25 | sentence_transformer_singleton | INFO | 새 클라이언트 생성 시작: jhgan/ko-sroberta-multitask_cuda
2025-09-13 17:03:25 | sentence_transformer_client | INFO | 현재 Python이 venv 환경: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-13 17:03:25 | sentence_transformer_client | INFO | SentenceTransformer Client 초기화: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-13 17:03:25 | sentence_transformer_client | INFO | Python 실행파일: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-13 17:03:25 | sentence_transformer_singleton | INFO | 서버 시작 및 모델 로딩: jhgan/ko-sroberta-multitask (device: cuda)
2025-09-13 17:03:25 | sentence_transformer_client | INFO | SentenceTransformer 서버 시작: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-13 17:03:25 | sentence_transformer_client | INFO | PYTHONPATH: /mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages:/mnt/c/large_project/linux_red_heart
2025-09-13 17:03:25 | sentence_transformer_client | INFO | VIRTUAL_ENV: /mnt/c/large_project/linux_red_heart/red_heart_env
2025-09-13 17:03:25 | sentence_transformer_client | INFO | stderr 드레인 스레드 시작
2025-09-13 17:03:25 | sentence_transformer_client | INFO | stderr 드레인 스레드 생성 완료
2025-09-13 17:03:35 | sentence_transformer_client | INFO | 서버 연결 성공
2025-09-13 17:03:35 | sentence_transformer_client | INFO | 모델 로딩 요청: jhgan/ko-sroberta-multitask (device: cuda)
2025-09-13 17:04:46 | sentence_transformer_client | INFO | 모델 로딩 성공: jhgan/ko-sroberta-multitask
2025-09-13 17:04:46 | sentence_transformer_singleton | INFO | 클라이언트 생성 및 모델 로딩 성공: jhgan/ko-sroberta-multitask_cuda
2025-09-13 17:04:46 | RedHeartLinux.AdvancedEmotion | INFO | 임베딩 모델 로드 완료 (싱글톤): sentence-transformers/paraphrase-multilingual-mpnet-base-v2, jhgan/ko-sroberta-multitask
2025-09-13 17:04:46 | RedHeartLinux.AdvancedEmotion | INFO | 임베딩 모델 초기화 완료: 2 모델 로드됨
2025-09-13 17:04:46 | RedHeart.Config | INFO | 🔍 get_system_module 호출: module_id=translator
2025-09-13 17:04:46 | RedHeart.Config | INFO | 🔍 현재 등록된 모듈들: ['translator']
2025-09-13 17:04:46 | RedHeart.Config | INFO | 🔍 결과: <class 'local_translator.LocalTranslator'>
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO | ✅ 감정 분석기 강화 모듈 통합: 56.4M 파라미터 추가
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO | 감정 분석용 MoE 시스템 초기화 완료 (4개 전문가)
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO |   - emotion_moe 타입: <class 'mixture_of_experts.MixtureOfExperts'>
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO |   - emotion_moe None 여부: False
2025-09-13 17:04:47 | emotion_dsp_simulator | INFO | EmotionDSPSimulator 초기화 완료 (~14M 파라미터)
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO |   - 칼만 필터 차원: 17개 감정
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO | ✅ DSP 시뮬레이터와 칼만 필터 초기화 완료
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO |   - DSP 시뮬레이터: 20M 파라미터
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO |   - 칼만 필터: 융합용
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO | 계층적 감정 모델 초기화 완료
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO | 📌 Claude 모드 감지 - 로컬 LLM 엔진 비활성화
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO | 고급 감정 분석 시스템이 초기화되었습니다.
2025-09-13 17:04:47 | RedHeartLinux.AdvancedEmotion | INFO | 🔍 hierarchical_model이 이미 존재함
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - biometric_processor 등록 (10M)
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - multimodal_fusion 등록 (10M)
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - temporal_emotion 등록 (10M)
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - cultural_nuance 등록 (13M)
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - advanced_moe 등록 (5M)
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - emotion_moe 등록
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO | ✅ Advanced Emotion Analyzer Wrapper 초기화 (48M 파라미터)
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | ✅ 벤담 계산기 강화 모듈 통합: 72.8M 파라미터 추가
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 윤리 MoE 시스템 초기화 완료 (4개 전문가, input_dim=512)
2025-09-13 17:04:47 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:47 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 GPU 메모리 관리 활성화
2025-09-13 17:04:47 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 3뷰 시나리오 시스템 초기화 완료
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 신경망 가중치 예측기 로딩 중...
2025-09-13 17:04:47 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 24.4%, 필요: 100MB)
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 신경망 가중치 예측기 로드: cuda (100MB)
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 메모리 사용량: RAM 3031MB, GPU 1998MB
2025-09-13 17:04:47 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:47 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook GPU 메모리 관리 활성화
2025-09-13 17:04:47 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook 시스템 초기화 완료
2025-09-13 17:04:47 | RedHeart.PhaseControllerHook | INFO | 성능 모니터링 시작
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 PhaseController Hook 초기화 완료
2025-09-13 17:04:47 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:47 | RedHeart.LegalExpertSystem | INFO | 법률 전문가 시스템 GPU 메모리 관리 활성화
2025-09-13 17:04:47 | RedHeart.LegalExpertSystem | INFO | 법률 전문가 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-09-13 17:04:47 | RedHeart.LegalExpertSystem | INFO | inference 모드 - 법률 전문가 시스템 활성화
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 법률 전문가 시스템 초기화 완료
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 고급 벤담 쾌락 계산기 초기화 완료 (레이지 로딩 활성화)
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | 🔨 벤담 계산기 기본 PyTorch 네트워크 생성 중...
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO | ✅ 벤담 계산기 기본 네트워크 생성 완료 (device: cuda:0)
2025-09-13 17:04:47 | RedHeart.AdvancedBenthamCalculator | INFO |    - 파라미터 수: 3,137
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - cross_cultural 등록
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - deep_ethics 등록
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - default_network 등록
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - ethics_moe 등록
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - long_term_predictor 등록
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO |   - social_impact 등록
2025-09-13 17:04:47 | advanced_analyzer_wrappers | INFO | ✅ Advanced Bentham Calculator Wrapper 초기화 (2.5M 파라미터, device: cuda:0)
2025-09-13 17:04:48 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:48 | advanced_regret_analyzer | INFO | ✅ 후회 분석기 강화 모듈 통합: 42.9M 파라미터 추가
2025-09-13 17:04:48 | advanced_regret_analyzer | INFO | 후회 분석용 MoE 시스템 초기화 완료 (3개 전문가)
2025-09-13 17:04:48 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:48 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 GPU 메모리 관리 활성화
2025-09-13 17:04:48 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-09-13 17:04:48 | advanced_regret_analyzer | INFO | 후회 분석기 3뷰 시나리오 시스템 초기화 완료
2025-09-13 17:04:48 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:48 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook GPU 메모리 관리 활성화
2025-09-13 17:04:48 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook 시스템 초기화 완료
2025-09-13 17:04:48 | RedHeart.PhaseControllerHook | INFO | 성능 모니터링 시작
2025-09-13 17:04:48 | advanced_regret_analyzer | INFO | 후회 분석기 PhaseController Hook 초기화 완료
2025-09-13 17:04:48 | advanced_regret_analyzer | INFO | Advanced Regret Analyzer initialized on cuda
2025-09-13 17:04:48 | advanced_regret_analyzer | INFO | 동적 임계값 시스템 통합 완료
2025-09-13 17:04:48 | advanced_analyzer_wrappers | INFO |   - regret_network 등록 (3M)
2025-09-13 17:04:48 | advanced_analyzer_wrappers | INFO |   - counterfactual_sim 등록 (15M)
2025-09-13 17:04:48 | advanced_analyzer_wrappers | INFO |   - temporal_propagation 등록 (12M)
2025-09-13 17:04:48 | advanced_analyzer_wrappers | INFO |   - decision_tree 등록 (10M)
2025-09-13 17:04:48 | advanced_analyzer_wrappers | INFO |   - bayesian_inference 등록 (10M)
2025-09-13 17:04:48 | advanced_analyzer_wrappers | INFO | ✅ Advanced Regret Analyzer Wrapper 초기화 (50M 파라미터)
2025-09-13 17:04:49 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 26.6%, 필요: 500MB)
2025-09-13 17:04:49 | RedHeart.AdvancedSURDAnalyzer | INFO | ✅ SURD 분석기 강화 모듈 통합: 12.2M 파라미터 추가
2025-09-13 17:04:49 | RedHeart.AdvancedSURDAnalyzer | INFO | 새로운 고급 SURD 모델 초기화 완료
2025-09-13 17:04:49 | RedHeart.APIManager | WARNING | ⚠️ gpt API 키가 설정되지 않음
2025-09-13 17:04:49 | RedHeart.APIManager | INFO | ✅ claude API 키 로드됨: sk-ant-api...
2025-09-13 17:04:49 | RedHeart.APIManager | INFO | ✅ perplexity API 키 로드됨: pplx-0Ex4v...
2025-09-13 17:04:49 | RedHeart.APIManager | WARNING | ⚠️ deepseek API 키가 설정되지 않음
2025-09-13 17:04:49 | RedHeart.APIManager | INFO | 🔑 API 키 관리자 초기화 (설정 파일: /mnt/c/large_project/linux_red_heart/api_key_manager/config.json)
2025-09-13 17:04:49 | RedHeart.AdvancedLLM | INFO | 🌐 API 모드 활성화: claude
2025-09-13 17:04:49 | RedHeart.AdvancedLLM | INFO | 🌐 API 설정 준비 완료: claude (로컬 모델 건너뛰기)
2025-09-13 17:04:49 | RedHeart.AdvancedLLM | INFO | 동적 GPU-RAM 스왑 시스템 초기화 완료
2025-09-13 17:04:49 | RedHeart.AdvancedLLM | INFO | 📌 Claude 모드 감지 - API 모드로 LLM 엔진 생성
2025-09-13 17:04:49 | RedHeart.AdvancedSURDAnalyzer | INFO | LLM 엔진 연결 완료
2025-09-13 17:04:49 | RedHeart.AdvancedSURDAnalyzer | INFO | 고급 SURD 분석 시스템 초기화 완료
2025-09-13 17:04:49 | advanced_analyzer_wrappers | INFO |   - deep_causal 등록 (10M)
2025-09-13 17:04:49 | advanced_analyzer_wrappers | INFO |   - info_decomposition 등록 (8M)
2025-09-13 17:04:49 | advanced_analyzer_wrappers | INFO |   - neural_causal_model 등록 (5M)
2025-09-13 17:04:49 | advanced_analyzer_wrappers | INFO | ✅ Advanced SURD Analyzer Wrapper 초기화 (25M 파라미터, device: cuda:0)
2025-09-13 17:04:49 | ClaudeInference | INFO |    ✅ Advanced Wrappers 로드 완료 (CPU)
2025-09-13 17:04:49 | ClaudeInference | INFO |    ✅ UnifiedModel에 advanced_wrappers 연결 완료
2025-09-13 17:04:49 | ClaudeInference | INFO | 
📦 Phase 5: Emotion-Ethics-Regret Circuit 초기화...
2025-09-13 17:04:49 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 27.2%, 필요: 500MB)
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | 감정 임베딩 모델 초기화 시작...
2025-09-13 17:04:49 | sentence_transformer_singleton | INFO | 기존 클라이언트 재사용 (모델 로드됨): sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:04:49 | sentence_transformer_singleton | INFO | 기존 클라이언트 서버는 살아있지만 모델 미로드 - 모델 로드 시도: jhgan/ko-sroberta-multitask_cuda
2025-09-13 17:04:49 | sentence_transformer_client | INFO | 모델 로딩 요청: jhgan/ko-sroberta-multitask (device: cuda)
2025-09-13 17:04:49 | sentence_transformer_client | INFO | 모델 로딩 성공: jhgan/ko-sroberta-multitask
2025-09-13 17:04:49 | sentence_transformer_singleton | INFO | 모델 로드 성공: jhgan/ko-sroberta-multitask_cuda
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | 임베딩 모델 로드 완료 (싱글톤): sentence-transformers/paraphrase-multilingual-mpnet-base-v2, jhgan/ko-sroberta-multitask
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | 임베딩 모델 초기화 완료: 2 모델 로드됨
2025-09-13 17:04:49 | RedHeart.Config | INFO | 🔍 get_system_module 호출: module_id=translator
2025-09-13 17:04:49 | RedHeart.Config | INFO | 🔍 현재 등록된 모듈들: ['translator']
2025-09-13 17:04:49 | RedHeart.Config | INFO | 🔍 결과: <class 'local_translator.LocalTranslator'>
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | ✅ 감정 분석기 강화 모듈 통합: 56.4M 파라미터 추가
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | 감정 분석용 MoE 시스템 초기화 완료 (4개 전문가)
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO |   - emotion_moe 타입: <class 'mixture_of_experts.MixtureOfExperts'>
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO |   - emotion_moe None 여부: False
2025-09-13 17:04:49 | emotion_dsp_simulator | INFO | EmotionDSPSimulator 초기화 완료 (~14M 파라미터)
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO |   - 칼만 필터 차원: 17개 감정
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | ✅ DSP 시뮬레이터와 칼만 필터 초기화 완료
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO |   - DSP 시뮬레이터: 20M 파라미터
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO |   - 칼만 필터: 융합용
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | 계층적 감정 모델 초기화 완료
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | 📌 Claude 모드 감지 - 로컬 LLM 엔진 비활성화
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | 고급 감정 분석 시스템이 초기화되었습니다.
2025-09-13 17:04:49 | RedHeartLinux.AdvancedEmotion | INFO | 🔍 hierarchical_model이 이미 존재함
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | ✅ 벤담 계산기 강화 모듈 통합: 72.8M 파라미터 추가
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 윤리 MoE 시스템 초기화 완료 (4개 전문가, input_dim=512)
2025-09-13 17:04:49 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:49 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 GPU 메모리 관리 활성화
2025-09-13 17:04:49 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 3뷰 시나리오 시스템 초기화 완료
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 신경망 가중치 예측기 로딩 중...
2025-09-13 17:04:49 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 34.2%, 필요: 100MB)
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 신경망 가중치 예측기 로드: cuda (100MB)
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 메모리 사용량: RAM 3041MB, GPU 2799MB
2025-09-13 17:04:49 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:49 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook GPU 메모리 관리 활성화
2025-09-13 17:04:49 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook 시스템 초기화 완료
2025-09-13 17:04:49 | RedHeart.PhaseControllerHook | INFO | 성능 모니터링 시작
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 PhaseController Hook 초기화 완료
2025-09-13 17:04:49 | RedHeart.LegalExpertSystem | INFO | inference 모드 - 법률 전문가 시스템 활성화
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 법률 전문가 시스템 초기화 완료
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 고급 벤담 쾌락 계산기 초기화 완료 (레이지 로딩 활성화)
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | 🔨 벤담 계산기 기본 PyTorch 네트워크 생성 중...
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO | ✅ 벤담 계산기 기본 네트워크 생성 완료 (device: cuda:0)
2025-09-13 17:04:49 | RedHeart.AdvancedBenthamCalculator | INFO |    - 파라미터 수: 3,137
2025-09-13 17:04:50 | advanced_regret_analyzer | INFO | ✅ 후회 분석기 강화 모듈 통합: 42.9M 파라미터 추가
2025-09-13 17:04:50 | advanced_regret_analyzer | INFO | 후회 분석용 MoE 시스템 초기화 완료 (3개 전문가)
2025-09-13 17:04:50 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:50 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 GPU 메모리 관리 활성화
2025-09-13 17:04:50 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-09-13 17:04:50 | advanced_regret_analyzer | INFO | 후회 분석기 3뷰 시나리오 시스템 초기화 완료
2025-09-13 17:04:50 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:04:50 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook GPU 메모리 관리 활성화
2025-09-13 17:04:50 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook 시스템 초기화 완료
2025-09-13 17:04:50 | RedHeart.PhaseControllerHook | INFO | 성능 모니터링 시작
2025-09-13 17:04:50 | advanced_regret_analyzer | INFO | 후회 분석기 PhaseController Hook 초기화 완료
2025-09-13 17:04:50 | advanced_regret_analyzer | INFO | Advanced Regret Analyzer initialized on cuda
2025-09-13 17:04:50 | advanced_regret_analyzer | INFO | 동적 임계값 시스템 통합 완료
2025-09-13 17:04:50 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 36.4%, 필요: 500MB)
2025-09-13 17:04:50 | sentence_transformer_singleton | INFO | 기존 클라이언트 서버는 살아있지만 모델 미로드 - 모델 로드 시도: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:04:50 | sentence_transformer_client | INFO | 모델 로딩 요청: sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (device: cuda)
2025-09-13 17:04:50 | sentence_transformer_client | INFO | 모델 로딩 성공: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
2025-09-13 17:04:50 | sentence_transformer_singleton | INFO | 모델 로드 성공: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:04:50 | RedHeart.AdvancedExperienceDB | INFO | 임베딩 모델 로드 완료 (싱글톤, 차원: 768)
2025-09-13 17:04:53 | RedHeart.AdvancedExperienceDB | INFO | FAISS 인덱스 생성 완료: IndexFlatL2, 차원=768
2025-09-13 17:04:53 | RedHeart.AdvancedExperienceDB | INFO | FAISS 벡터 데이터베이스 초기화 완료 (subprocess)
2025-09-13 17:04:53 | RedHeart.AdvancedExperienceDB | INFO | GPU 배치 처리 워커 시작됨 (무한 대기 이슈 해결)
2025-09-13 17:04:53 | RedHeart.AdvancedExperienceDB | INFO | 메타데이터 데이터베이스가 초기화되었습니다.
2025-09-13 17:04:53 | RedHeart.AdvancedExperienceDB | INFO | 신경망 메모리 시스템이 초기화되었습니다.
2025-09-13 17:04:53 | RedHeart.AdvancedExperienceDB | INFO | 학습 시스템들이 초기화되었습니다.
2025-09-13 17:04:53 | RedHeart.AdvancedExperienceDB | INFO | 고급 경험 데이터베이스가 초기화되었습니다.
2025-09-13 17:04:53 | RedHeart.EmotionEthicsRegretCircuit | INFO | 감정-윤리-후회 삼각 회로 초기화 완료
2025-09-13 17:04:53 | ClaudeInference | INFO |    ✅ Emotion-Ethics-Regret Circuit 초기화 완료
2025-09-13 17:04:53 | ClaudeInference | INFO |       - 감정-윤리-후회 통합 분석 가능
2025-09-13 17:04:53 | ClaudeInference | INFO |       - Circuit 활성화 조건: config.use_emotion_hierarchy=True
2025-09-13 17:04:53 | ClaudeInference | INFO | 
📦 Phase 6: Claude API 엔진 초기화...
2025-09-13 17:04:53 | RedHeart.AdvancedLLM | INFO | 🌐 API 모드 활성화: claude
2025-09-13 17:04:53 | RedHeart.AdvancedLLM | INFO | 🌐 API 설정 준비 완료: claude (로컬 모델 건너뛰기)
2025-09-13 17:04:53 | RedHeart.AdvancedLLM | INFO | 동적 GPU-RAM 스왑 시스템 초기화 완료
2025-09-13 17:04:53 | ClaudeInference | INFO |    ✅ Claude API 엔진 초기화 완료
2025-09-13 17:04:53 | ClaudeInference | INFO | 
✅ 모든 컴포넌트 초기화 완료!
2025-09-13 17:04:53 | ClaudeInference | INFO | 
======================================================================
2025-09-13 17:04:53 | ClaudeInference | INFO | 🎯 추론 시작
2025-09-13 17:04:53 | ClaudeInference | INFO | ======================================================================
2025-09-13 17:04:53 | ClaudeInference | INFO | 📝 입력 텍스트: AI 윤리적 문제 해결
2025-09-13 17:04:53 | ClaudeInference | INFO | ⚡ Claude 모드 - 번역 스킵 (원문 그대로 사용)
2025-09-13 17:04:53 | ClaudeInference | INFO | 
🎯 LLM 초기 반사실적 시나리오 생성...
2025-09-13 17:04:53 | RedHeart.AdvancedLLM | INFO | 🌐 CLAUDE API 호출 시작...
2025-09-13 17:04:57 | RedHeart.APIManager | INFO | ✅ Anthropic 비동기 클라이언트 생성 완료
2025-09-13 17:05:17 | httpx | INFO | HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-09-13 17:05:17 | RedHeart.APIManager | INFO | ✅ Claude API 응답 성공: 767 문자
2025-09-13 17:05:17 | RedHeart.AdvancedLLM | INFO | ✅ API 응답 성공: 767 문자
2025-09-13 17:05:17 | ClaudeInference | INFO |    ✅ 방법 1(전체 텍스트 JSON)로 파싱 성공
2025-09-13 17:05:17 | ClaudeInference | INFO |    ✅ 3개 반사실적 시나리오 생성 및 검증 완료
2025-09-13 17:05:17 | ClaudeInference | INFO |       - optimistic: AI 윤리 가이드라인을 수립하고 엄격히 준수하며 지속적으로 개선해 나간다....
2025-09-13 17:05:17 | ClaudeInference | INFO |       - neutral: AI 개발 과정에서 일반적인 수준의 윤리 규범을 적용하나 적극적인 노력은 기울이지 않는다....
2025-09-13 17:05:17 | ClaudeInference | INFO |       - pessimistic: 이윤 추구를 위해 AI 윤리를 경시하고 위험성이 있는 AI 기술을 무분별하게 상용화한다....
2025-09-13 17:05:17 | ClaudeInference | INFO | 
📊 UnifiedModel 추론...
2025-09-13 17:05:17 | ClaudeInference | INFO |    📝 텍스트 임베딩 생성 중...
2025-09-13 17:05:17 | sentence_transformer_singleton | INFO | 기존 클라이언트 재사용 (모델 로드됨): sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:19 | ClaudeInference | INFO |    🎭 감정 분석 추론...
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | 🔍 advanced_wrappers 타입: <class 'dict'>
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | 🔍 advanced_wrappers 키들: ['advanced_emotion', 'advanced_bentham', 'advanced_regret', 'advanced_surd']
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | 🔍 찾는 wrapper_key: advanced_emotion
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | 🔍 wrapper 타입: <class 'advanced_analyzer_wrappers.AdvancedEmotionAnalyzerWrapper'>
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO | 🔄 AdvancedEmotionAnalyzerWrapper forward 실행 시작
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |    입력 임베딩 차원: torch.Size([1, 896])
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |    🔄 임베딩 직접 처리 시작
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       입력 차원: torch.Size([1, 896])
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       896→768 프로젝션 레이어 생성
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       896차원 입력, 프로젝션 후 차원: torch.Size([1, 768])
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       - temporal_emotion LSTM 처리 중...
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       ✅ temporal_emotion 처리 완료
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       - multimodal_fusion 처리 중...
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       ✅ multimodal_fusion 처리 완료
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       - advanced_moe 처리 중...
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |       ✅ advanced_moe 처리 완료
2025-09-13 17:05:19 | advanced_analyzer_wrappers | INFO |    ✅ 임베딩 처리 완료: ['temporal_emotion', 'multimodal', 'emotions', 'valence', 'arousal']
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | 🔍 wrapper 출력 타입: <class 'dict'>
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | 🔍 === 완전한 구조 분석 시작 ===
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |   📦 Dict[5 keys]: ['temporal_emotion', 'multimodal', 'emotions', 'valence', 'arousal']
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |     [temporal_emotion]:
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 768], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |     [multimodal]:
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 768], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |     [emotions]:
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 7], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |     [valence]:
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 1], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |     [arousal]:
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 1], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | 🔍 === 구조 분석 완료 ===
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | ✅ 텐서 추출 성공: shape=[1, 768]
2025-09-13 17:05:19 | UnifiedModel.Debug | INFO | ✅ outputs['advanced'] 설정 완료: <class 'torch.Tensor'>, shape=torch.Size([1, 768])
2025-09-13 17:05:20 | ClaudeInference | INFO |    ⚖️ 벤담 계산 추론...
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 advanced_wrappers 타입: <class 'dict'>
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 advanced_wrappers 키들: ['advanced_emotion', 'advanced_bentham', 'advanced_regret', 'advanced_surd']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 찾는 wrapper_key: advanced_bentham
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 wrapper 타입: <class 'advanced_analyzer_wrappers.AdvancedBenthamCalculatorWrapper'>
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO | 🔄 AdvancedBenthamCalculatorWrapper forward 실행 시작
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    - bentham_default_network 처리 중...
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |      입력 차원: torch.Size([1, 896])
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |      network device: cuda:0, input device: cuda:0
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |      투영 후 차원: torch.Size([1, 7]), device: cuda:0
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    ✅ bentham_default_network 처리 완료
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    ✅ AdvancedBenthamCalculator 처리 완료: ['bentham_scores']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 wrapper 출력 타입: <class 'dict'>
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 === 완전한 구조 분석 시작 ===
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |   📦 Dict[1 keys]: ['bentham_scores']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |     [bentham_scores]:
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 1], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 === 구조 분석 완료 ===
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | ✅ 텐서 추출 성공: shape=[1, 1]
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | ✅ outputs['advanced'] 설정 완료: <class 'torch.Tensor'>, shape=torch.Size([1, 1])
2025-09-13 17:05:20 | ClaudeInference | INFO |    😔 후회 분석 추론...
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 advanced_wrappers 타입: <class 'dict'>
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 advanced_wrappers 키들: ['advanced_emotion', 'advanced_bentham', 'advanced_regret', 'advanced_surd']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 찾는 wrapper_key: advanced_regret
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 wrapper 타입: <class 'advanced_analyzer_wrappers.AdvancedRegretAnalyzerWrapper'>
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO | 🔄 AdvancedRegretAnalyzerWrapper forward 실행 시작
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    입력 차원: torch.Size([1, 896])
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    - regret_network 처리 중...
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    regret_network 기대 차원: 896, 입력 차원: 896
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    ✅ regret_network 처리 완료
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    ✅ AdvancedRegretAnalyzer 처리 완료: ['regret_score', 'regret_emotion_vector', 'regret_uncertainty']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 wrapper 출력 타입: <class 'dict'>
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 === 완전한 구조 분석 시작 ===
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |   📦 Dict[3 keys]: ['regret_score', 'regret_emotion_vector', 'regret_uncertainty']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |     [regret_score]:
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 1], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |     [regret_emotion_vector]:
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 8], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |     [regret_uncertainty]:
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 1], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 === 구조 분석 완료 ===
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | ✅ 텐서 추출 성공: shape=[1, 1]
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | ✅ outputs['advanced'] 설정 완료: <class 'torch.Tensor'>, shape=torch.Size([1, 1])
2025-09-13 17:05:20 | ClaudeInference | INFO |    🔍 SURD 분석 추론...
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 advanced_wrappers 타입: <class 'dict'>
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 advanced_wrappers 키들: ['advanced_emotion', 'advanced_bentham', 'advanced_regret', 'advanced_surd']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 찾는 wrapper_key: advanced_surd
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 wrapper 타입: <class 'advanced_analyzer_wrappers.AdvancedSURDAnalyzerWrapper'>
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO | 🔄 AdvancedSURDAnalyzerWrapper forward 실행 시작
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    입력 차원: torch.Size([1, 896])
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    projection device: cuda:0, input device: cuda:0
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    투영 후 차원: torch.Size([1, 768])
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    - deep_causal 처리 중...
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    ✅ deep_causal 처리 완료
2025-09-13 17:05:20 | advanced_analyzer_wrappers | INFO |    ✅ AdvancedSURDAnalyzer 처리 완료: ['surd_metrics']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 wrapper 출력 타입: <class 'dict'>
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 === 완전한 구조 분석 시작 ===
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |   📦 Dict[1 keys]: ['surd_metrics']
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |     [surd_metrics]:
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO |       ✅ Tensor: shape=[1, 4], dtype=torch.float32, device=cuda:0
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | 🔍 === 구조 분석 완료 ===
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | ✅ 텐서 추출 성공: shape=[1, 4]
2025-09-13 17:05:20 | UnifiedModel.Debug | INFO | ✅ outputs['advanced'] 설정 완료: <class 'torch.Tensor'>, shape=torch.Size([1, 4])
2025-09-13 17:05:23 | ClaudeInference | INFO |    ✅ UnifiedModel 추론 완료
2025-09-13 17:05:23 | ClaudeInference | INFO | 
🧠 Advanced Analysis...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO | 🔄 AdvancedEmotionAnalyzerWrapper forward 실행 시작
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    입력 임베딩 차원: torch.Size([1, 768])
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    🔄 임베딩 직접 처리 시작
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |       입력 차원: torch.Size([1, 768])
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |       768차원 입력, 프로젝션 없이 직접 사용
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |       - temporal_emotion LSTM 처리 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |       ✅ temporal_emotion 처리 완료
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |       - multimodal_fusion 처리 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |       ✅ multimodal_fusion 처리 완료
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |       - advanced_moe 처리 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |       ✅ advanced_moe 처리 완료
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    ✅ 임베딩 처리 완료: ['temporal_emotion', 'multimodal', 'emotions', 'valence', 'arousal']
2025-09-13 17:05:23 | ClaudeInference | INFO |    ✅ 감정 분석 완료
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO | 🔄 AdvancedBenthamCalculatorWrapper forward 실행 시작
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    - bentham_default_network 처리 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |      입력 차원: torch.Size([1, 768])
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |      network device: cuda:0, input device: cpu
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |      투영 후 차원: torch.Size([1, 7]), device: cuda:0
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    ✅ bentham_default_network 처리 완료
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    ✅ AdvancedBenthamCalculator 처리 완료: ['bentham_scores']
2025-09-13 17:05:23 | ClaudeInference | INFO |    ✅ 벤담 계산 완료
2025-09-13 17:05:23 | ClaudeInference | INFO |    🔄 Regret 분석 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO | 🔄 AdvancedRegretAnalyzerWrapper forward 실행 시작
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    입력 차원: torch.Size([1, 768])
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    - regret_network 처리 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    regret_network 기대 차원: 896, 입력 차원: 768
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    768→896 프로젝션 어댑터 생성 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    프로젝션 후 차원: torch.Size([1, 896])
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    ✅ regret_network 처리 완료
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    ✅ AdvancedRegretAnalyzer 처리 완료: ['regret_score', 'regret_emotion_vector', 'regret_uncertainty']
2025-09-13 17:05:23 | ClaudeInference | INFO |       - 3개 반사실적 시나리오와 함께 분석
2025-09-13 17:05:23 | ClaudeInference | INFO |    ✅ Regret 분석 완료
2025-09-13 17:05:23 | ClaudeInference | INFO |    🔄 SURD 분석 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO | 🔄 AdvancedSURDAnalyzerWrapper forward 실행 시작
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    입력 차원: torch.Size([1, 768])
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    projection device: cuda:0, input device: cpu
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    디바이스 불일치 감지 - 입력을 cuda:0로 이동
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    768차원 입력 감지 - 직접 사용
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    투영 후 차원: torch.Size([1, 768])
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    - deep_causal 처리 중...
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    ✅ deep_causal 처리 완료
2025-09-13 17:05:23 | advanced_analyzer_wrappers | INFO |    ✅ AdvancedSURDAnalyzer 처리 완료: ['surd_metrics']
2025-09-13 17:05:23 | ClaudeInference | INFO |    ✅ SURD 분석 완료
2025-09-13 17:05:23 | ClaudeInference | INFO | 
🔮 Three View Scenario System 분석...
2025-09-13 17:05:23 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-13 17:05:23 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 GPU 메모리 관리 활성화
2025-09-13 17:05:23 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-09-13 17:05:23 | ClaudeInference | INFO |    📊 3개 시나리오에 대한 3뷰 분석 중...
2025-09-13 17:05:23 | dynamic_gpu_manager | INFO | ⚡ three_view_scenario_system: 동적 부스트 - 확장 할당 25.0%
2025-09-13 17:05:23 | dynamic_gpu_manager | INFO | 🎯 최종 할당: 25.0% (2.0GB)
2025-09-13 17:05:23 | dynamic_gpu_manager | INFO | 🔧 three_view_scenario_system 메모리 할당: 25.0% (2.0GB)
2025-09-13 17:05:23 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 모델 로딩 완료 (GPU 최적화)
2025-09-13 17:05:23 | dynamic_gpu_manager | INFO | 🗑️ three_view_scenario_system 메모리 해제 완료
2025-09-13 17:05:23 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 분석 완료: 8.08ms, 합의 효용: -0.013, 합의 후회: 0.496
2025-09-13 17:05:23 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 분석 완료: 0.47ms, 합의 효용: -0.012, 합의 후회: 0.496
2025-09-13 17:05:23 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 분석 완료: 0.48ms, 합의 효용: -0.013, 합의 후회: 0.496
2025-09-13 17:05:23 | ClaudeInference | INFO |    ✅ 반사실적 시나리오 3뷰 분석 완료
2025-09-13 17:05:23 | ClaudeInference | INFO |    💡 3뷰 시스템 분석 결과 저장 완료
2025-09-13 17:05:23 | ClaudeInference | INFO | 
🎭 Emotion-Ethics-Regret Circuit 처리...
2025-09-13 17:05:23 | workflow_aware_memory_manager | INFO | ✅ HF 모델 래퍼와 메모리 매니저 통합 완료
2025-09-13 17:05:23 | dynamic_swap_manager | INFO | RedHeartDynamicSwapManager 초기화 완료
2025-09-13 17:05:23 | RedHeart.EmotionEthicsRegretCircuit | INFO | DSM 연결 성공: 124132500828528
2025-09-13 17:05:23 | dynamic_swap_manager | INFO | [워크플로우] initialization 단계 우선순위 업데이트 (GPU: 19.2%)
2025-09-13 17:05:23 | sentence_transformer_singleton | INFO | 모델이 CPU에 있음, GPU로 스왑: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:25 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 19.2%, 필요: 500MB)
2025-09-13 17:05:25 | sensitivity_detection_singleton | INFO | SensitivityDetectionManager 초기화 완료
2025-09-13 17:05:25 | local_translator | INFO | 🔄 Lazy loading: 번역이 필요해서 모델을 로드합니다...
2025-09-13 17:05:25 | local_translator | INFO | 🔄 OPUS-MT 모델 로드 중: Helsinki-NLP/opus-mt-ko-en
2025-09-13 17:05:25 | hf_model_wrapper | INFO | ✅ HF 모델 자동 등록 활성화됨 (모델, 토크나이저, 프로세서 포함)
2025-09-13 17:05:25 | hf_model_wrapper | INFO | 🔄 HF 모델 로딩 중: Helsinki-NLP/opus-mt-ko-en (소유자: translator)
2025-09-13 17:05:26 | local_translator | INFO | ✅ OPUS-MT 모델 로드 완료 (소요시간: 1.7초, 디바이스: cpu)
2025-09-13 17:05:26 | local_translator | INFO | 📊 Translator는 CPU에서 초기화됨 (GPU 메모리 절약)
2025-09-13 17:05:26 | dynamic_swap_manager | INFO | [DSM] translator 크기: 297.6MB (mgr_id=124132500828528)
2025-09-13 17:05:26 | dynamic_swap_manager | INFO |    💾 translator을 RAM에 등록 (location=RAM, size=297.6MB)
2025-09-13 17:05:26 | dynamic_swap_manager | INFO | [REGISTER HEAD] translator (297.6MB, 우선순위: high)
2025-09-13 17:05:26 | local_translator | INFO | ✅ Translator를 DSM에 등록 (HIGH priority)
2025-09-13 17:05:27 | RedHeart.AdvancedLLM | INFO | 🔍 ChatML 형식 감지됨 - 재처리 스킵
2025-09-13 17:05:27 | RedHeart.AdvancedLLM | INFO | ✅ ChatML 중복 처리 방지 - 원본 프롬프트 사용
2025-09-13 17:05:27 | RedHeart.AdvancedLLM | INFO | 🌐 CLAUDE API 호출 시작...
2025-09-13 17:05:30 | httpx | INFO | HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-09-13 17:05:30 | RedHeart.APIManager | INFO | ✅ Claude API 응답 성공: 230 문자
2025-09-13 17:05:30 | RedHeart.AdvancedLLM | INFO | ✅ API 응답 성공: 230 문자
2025-09-13 17:05:30 | RedHeartLinux.AdvancedEmotion | INFO | 🔧 LLM 응답 파싱 시작: 230 문자
2025-09-13 17:05:30 | RedHeartLinux.AdvancedEmotion | INFO | 🔧 응답 첫 500자: {
  "emotion": "neutral",
  "intensity": 2,
  "confidence": 0.7,
  "valence": 0.4,
  "arousal": 0.3,
  "reasoning": "The statement is matter-of-fact about dealing with ethical issues, without expressing a strong emotional tone."
}...
2025-09-13 17:05:31 | RedHeartLinux.AdvancedEmotion | INFO | 🔧 1단계: json_repair 자동 수정 시도
2025-09-13 17:05:31 | RedHeartLinux.AdvancedEmotion | INFO | 🔧 수정된 JSON: {"emotion": "neutral", "intensity": 2, "confidence": 0.7, "valence": 0.4, "arousal": 0.3, "reasoning": "The statement is matter-of-fact about dealing with ethical issues, without expressing a strong e...
2025-09-13 17:05:31 | RedHeartLinux.AdvancedEmotion | INFO | ✅ json_repair 성공 (단순객체): emotion=neutral -> id=0
2025-09-13 17:05:31 | RedHeartLinux.AdvancedEmotion | INFO | ✅ LLM 분석 성공 (시도 1/3)
2025-09-13 17:05:31 | sentence_transformer_singleton | INFO | 모델이 CPU에 있음, GPU로 스왑: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:32 | sentence_transformer_singleton | INFO | 모델이 CPU에 있음, GPU로 스왑: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:33 | sentence_transformer_singleton | INFO | 모델이 CPU에 있음, GPU로 스왑: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:34 | RedHeart.AdvancedLLM | INFO | 🔍 ChatML 형식 감지됨 - 재처리 스킵
2025-09-13 17:05:34 | RedHeart.AdvancedLLM | INFO | ✅ ChatML 중복 처리 방지 - 원본 프롬프트 사용
2025-09-13 17:05:34 | RedHeart.AdvancedLLM | INFO | 🌐 CLAUDE API 호출 시작...
2025-09-13 17:05:34 | anthropic._base_client | INFO | Retrying request to /v1/messages in 0.455452 seconds
2025-09-13 17:05:38 | httpx | INFO | HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-09-13 17:05:38 | RedHeart.APIManager | INFO | ✅ Claude API 응답 성공: 227 문자
2025-09-13 17:05:38 | RedHeart.AdvancedLLM | INFO | ✅ API 응답 성공: 227 문자
2025-09-13 17:05:38 | RedHeartLinux.AdvancedEmotion | INFO | 🔧 LLM 응답 파싱 시작: 227 문자
2025-09-13 17:05:38 | RedHeartLinux.AdvancedEmotion | INFO | 🔧 응답 첫 500자: {
  "emotion": "neutral",
  "intensity": 1,
  "confidence": 0.9,
  "valence": 0.5,
  "arousal": 0.2,
  "reasoning": "The text appears to be a neutral statement or fragment about AI ethics, without expressing a clear emotion."
}...
2025-09-13 17:05:38 | RedHeartLinux.AdvancedEmotion | INFO | 🔧 1단계: json_repair 자동 수정 시도
2025-09-13 17:05:38 | RedHeartLinux.AdvancedEmotion | INFO | 🔧 수정된 JSON: {"emotion": "neutral", "intensity": 1, "confidence": 0.9, "valence": 0.5, "arousal": 0.2, "reasoning": "The text appears to be a neutral statement or fragment about AI ethics, without expressing a cle...
2025-09-13 17:05:38 | RedHeartLinux.AdvancedEmotion | INFO | ✅ json_repair 성공 (단순객체): emotion=neutral -> id=0
2025-09-13 17:05:38 | RedHeartLinux.AdvancedEmotion | INFO | ✅ LLM 분석 성공 (시도 1/3)
2025-09-13 17:05:38 | sentence_transformer_singleton | INFO | 모델이 CPU에 있음, GPU로 스왑: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:39 | sentence_transformer_singleton | INFO | 모델이 CPU에 있음, GPU로 스왑: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:40 | sentence_transformer_singleton | INFO | 모델이 CPU에 있음, GPU로 스왑: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:41 | dynamic_swap_manager | INFO | [WAUP] emo_dsp 단계 진입 - 우선순위 업데이트
2025-09-13 17:05:41 | dynamic_swap_manager | INFO | [워크플로우] emotion_analysis 단계 우선순위 업데이트 (GPU: 19.2%)
2025-09-13 17:05:41 | dynamic_swap_manager | INFO | [워크플로우] counterfactual_reasoning 단계 우선순위 업데이트 (GPU: 19.2%)
2025-09-13 17:05:41 | dynamic_gpu_manager | INFO | ⚡ legal_expert_system: 동적 부스트 - 확장 할당 15.0%
2025-09-13 17:05:42 | dynamic_gpu_manager | INFO | 🎯 최종 할당: 15.0% (1.2GB)
2025-09-13 17:05:42 | dynamic_gpu_manager | INFO | 🔧 legal_expert_system 메모리 할당: 15.0% (1.2GB)
2025-09-13 17:05:42 | RedHeart.LegalExpertSystem | INFO | 법률 전문가 시스템 모델 로딩 완료 (GPU 최적화)
2025-09-13 17:05:42 | dynamic_gpu_manager | INFO | 🗑️ legal_expert_system 메모리 해제 완료
2025-09-13 17:05:42 | RedHeart.LegalExpertSystem | INFO | 법률 분석 완료: life, 위험도: low, 처리시간: 1.07ms
2025-09-13 17:05:42 | dynamic_swap_manager | INFO | [WAUP] bentham 단계 진입 - 우선순위 업데이트
2025-09-13 17:05:42 | dynamic_swap_manager | INFO | [워크플로우] bentham_calculation 단계 우선순위 업데이트 (GPU: 19.2%)
2025-09-13 17:05:42 | RedHeart.LegalExpertSystem | INFO | 법률 분석 완료: life, 위험도: high, 처리시간: 0.65ms
2025-09-13 17:05:42 | dynamic_gpu_manager | INFO | ⚡ three_view_scenario_system: 동적 부스트 - 확장 할당 25.0%
2025-09-13 17:05:42 | dynamic_gpu_manager | INFO | 🎯 최종 할당: 25.0% (2.0GB)
2025-09-13 17:05:42 | dynamic_gpu_manager | INFO | 🔧 three_view_scenario_system 메모리 할당: 25.0% (2.0GB)
2025-09-13 17:05:42 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 모델 로딩 완료 (GPU 최적화)
2025-09-13 17:05:42 | dynamic_gpu_manager | INFO | 🗑️ three_view_scenario_system 메모리 해제 완료
2025-09-13 17:05:42 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 분석 완료: 2.87ms, 합의 효용: -0.019, 합의 후회: 0.510
2025-09-13 17:05:42 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] _prepare_advanced_context 시작
2025-09-13 17:05:42 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] input_data keys: ['input_values', 'text_description', 'language', 'affected_count', 'duration_seconds', 'information_quality', 'uncertainty_level', 'social_context', 'emotion_data', 'ethical_values', 'intensity', 'duration', 'certainty', 'scenario_type', 'scenario_weight', 'regret_potential']
2025-09-13 17:05:42 | RedHeart.AdvancedBenthamCalculator | INFO | 트랜스포머 맥락 분석기 로딩 중...
2025-09-13 17:05:42 | config | INFO | GPU 로딩 워커 스레드 시작
2025-09-13 17:05:42 | RedHeart.Config | INFO | 순차적 GPU 로딩 시스템 시작
2025-09-13 17:05:42 | RedHeart.Config | INFO | GPU 로딩 시작: bentham_emotion_classifier (예상 메모리: 732MB)
2025-09-13 17:05:42 | hf_model_wrapper | INFO | 🔄 HF 모델 로딩 중: j-hartmann/emotion-english-distilroberta-base (소유자: transformers.pipelines.base)
2025-09-13 17:05:42 | hf_model_wrapper | INFO | 📊 모델 로드 전 메모리 요청: transformers.pipelines.base_emotion-english-distilroberta-base (1000.0MB)
2025-09-13 17:05:42 | workflow_aware_memory_manager | INFO | [GPU BLOCKING] transformers.pipelines.base_emotion-english-distilroberta-base: 1000.0MB 동기 요청 시작
2025-09-13 17:05:42 | workflow_aware_memory_manager | INFO | [GPU BLOCKING] ✅ transformers.pipelines.base_emotion-english-distilroberta-base 할당 성공 (폴링)
2025-09-13 17:05:49 | hf_model_wrapper | INFO | ✅ 모델 'transformers.pipelines.base_emotion-english-distilroberta-base' 메모리 매니저에 등록됨 (소유자: transformers.pipelines.base, 크기: 1253.1MB)
Device set to use cuda:0
2025-09-13 17:05:50 | RedHeart.Config | INFO | GPU 로딩 성공: bentham_emotion_classifier (사용률: 19.3% → 23.1%, 실제: 307MB)
2025-09-13 17:05:50 | RedHeart.AdvancedBenthamCalculator | INFO | 감정 분석 모델 GPU 순차 로드 완료: cuda
2025-09-13 17:05:50 | RedHeart.AdvancedBenthamCalculator | INFO | ✅ 윤리 분석: 감정→윤리 매핑 방식 (별도 모델 없음)
2025-09-13 17:05:50 | RedHeart.AdvancedBenthamCalculator | INFO | 한국어 감정 분석은 번역 후 영어 모델 사용
2025-09-13 17:05:50 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 23.1%, 필요: 500MB)
2025-09-13 17:05:50 | sentence_transformer_singleton | INFO | 기존 클라이언트 서버는 살아있지만 모델 미로드 - 모델 로드 시도: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:50 | sentence_transformer_client | INFO | 모델 로딩 요청: sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (device: cuda)
2025-09-13 17:05:53 | sentence_transformer_client | INFO | 모델 로딩 성공: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
2025-09-13 17:05:53 | sentence_transformer_singleton | INFO | 모델 로드 성공: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:53 | RedHeart.AdvancedBenthamCalculator | INFO | 문맥 임베딩 모델 싱글톤 사용: cuda
2025-09-13 17:05:53 | RedHeart.AdvancedBenthamCalculator | INFO | 트랜스포머 맥락 분석기 초기화 완료
2025-09-13 17:05:53 | RedHeart.AdvancedBenthamCalculator | INFO | 메모리 사용량: RAM 5340MB, GPU 1895MB
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] analysis_result keys: ['emotions', 'ethical_aspects', 'context_embedding', 'complexity']
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] complexity_data type: dict
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] complexity_data 값: {'word_count': 9, 'sentence_count': 1, 'avg_word_length': 2.111111111111111, 'lexical_diversity': 0.8888888888888888, 'structural_complexity': 0.1111111111111111}
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] _extract_neural_features 시작
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] context type: AdvancedCalculationContext
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] context.complexity_metrics 존재: True
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] complexity_metrics type: dict
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] complexity_metrics 값: {'word_count': 9, 'sentence_count': 1, 'avg_word_length': 2.111111111111111, 'lexical_diversity': 0.8888888888888888, 'structural_complexity': 0.1111111111111111}
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | 가중치 레이어들 로딩 중...
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | contextual ML 모델 로드 완료
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | contextual ML 모델 로드 완료
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | contextual ML 모델 로드 완료
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | contextual ML 모델 로드 완료
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | contextual ML 모델 로드 완료
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | contextual ML 모델 로드 완료
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | 메모리 사용량: RAM 5455MB, GPU 1895MB
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] _prepare_advanced_context 시작
2025-09-13 17:05:54 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] input_data keys: ['input_values', 'text_description', 'language', 'affected_count', 'duration_seconds', 'information_quality', 'uncertainty_level', 'social_context', 'emotion_data', 'ethical_values', 'intensity', 'duration', 'certainty', 'scenario_type', 'scenario_weight', 'regret_potential']
2025-09-13 17:05:54 | sentence_transformer_singleton | INFO | 모델이 CPU에 있음, GPU로 스왑: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-13 17:05:56 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] analysis_result keys: ['emotions', 'ethical_aspects', 'context_embedding', 'complexity']
2025-09-13 17:05:56 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] complexity_data type: dict
2025-09-13 17:05:56 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] complexity_data 값: {'word_count': 9, 'sentence_count': 1, 'avg_word_length': 2.111111111111111, 'lexical_diversity': 0.8888888888888888, 'structural_complexity': 0.1111111111111111}
2025-09-13 17:05:56 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] _extract_neural_features 시작
2025-09-13 17:05:56 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] context type: AdvancedCalculationContext
2025-09-13 17:05:56 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] context.complexity_metrics 존재: True
2025-09-13 17:05:56 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] complexity_metrics type: dict
2025-09-13 17:05:56 | RedHeart.AdvancedBenthamCalculator | INFO | [VERBOSE] complexity_metrics 값: {'word_count': 9, 'sentence_count': 1, 'avg_word_length': 2.111111111111111, 'lexical_diversity': 0.8888888888888888, 'structural_complexity': 0.1111111111111111}
2025-09-13 17:05:56 | dynamic_swap_manager | INFO | [WAUP] regret 단계 진입 - 우선순위 업데이트
2025-09-13 17:05:56 | dynamic_swap_manager | INFO | [워크플로우] regret_analysis 단계 우선순위 업데이트 (GPU: 23.1%)
2025-09-13 17:05:56 | advanced_regret_analyzer | WARNING | 후회 분석에서 0.0 점수 감지: 'AI 윤리적 문제 해결 상황 분석 및 윤리적 평가...'
2025-09-13 17:05:56 | dynamic_swap_manager | INFO | [WAUP] integrate 단계 진입 - 우선순위 업데이트
2025-09-13 17:05:56 | dynamic_swap_manager | INFO | [워크플로우] meta_integration 단계 우선순위 업데이트 (GPU: 23.1%)
2025-09-13 17:05:57 | RedHeart.AdvancedExperienceDB | INFO | 경험이 저장되었습니다: 4fcb0902-3856-4823-a8b1-96187fcee56c
2025-09-13 17:05:57 | dynamic_swap_manager | INFO | [워크플로우] finalization 단계 우선순위 업데이트 (GPU: 23.1%)
2025-09-13 17:05:57 | ClaudeInference | INFO |    ✅ Circuit 처리 완료 (신뢰도: 0.64)
2025-09-13 17:05:57 | ClaudeInference | INFO |       - 통합 감정: NEUTRAL
2025-09-13 17:05:57 | ClaudeInference | INFO |       - 예측 후회: {'anticipated_regret': 0.1, 'regret_intensity': 0.1, 'regret_duration': 1.0, 'confidence': 0.6}
2025-09-13 17:05:57 | ClaudeInference | INFO |       - 윤리적 가치: {'care_harm': 0.23255488742955874, 'fairness': 0.1, 'loyalty': 0.1, 'authority': 0.1, 'sanctity': 0.1, 'liberty': 0.1}
2025-09-13 17:05:57 | ClaudeInference | INFO | 
🌐 Claude API 보강...
2025-09-13 17:05:57 | RedHeart.AdvancedLLM | INFO | 🌐 CLAUDE API 호출 시작...
2025-09-13 17:05:57 | anthropic._base_client | INFO | Retrying request to /v1/messages in 0.476293 seconds
2025-09-13 17:06:19 | httpx | INFO | HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-09-13 17:06:19 | RedHeart.APIManager | INFO | ✅ Claude API 응답 성공: 493 문자
2025-09-13 17:06:19 | RedHeart.AdvancedLLM | INFO | ✅ API 응답 성공: 493 문자
2025-09-13 17:06:19 | ClaudeInference | INFO |    ✅ Claude API 분석 완료
2025-09-13 17:06:19 | ClaudeInference | INFO | 
💾 결과 저장: claude_inference_result_20250913_170619_915_pid5035.json
2025-09-13 17:06:19 | ClaudeInference | INFO |    🔗 최신 결과 링크: claude_inference_result_latest.json -> claude_inference_result_20250913_170619_915_pid5035.json
2025-09-13 17:06:19 | ClaudeInference | INFO | 
======================================================================
2025-09-13 17:06:19 | ClaudeInference | INFO | 📊 추론 완료 요약
2025-09-13 17:06:19 | ClaudeInference | INFO | ======================================================================
2025-09-13 17:06:19 | ClaudeInference | INFO | 🎭 주요 감정: 분노 (점수: 0.030)
2025-09-13 17:06:19 | ClaudeInference | INFO | ⚖️ 공리주의 점수: 0.201
2025-09-13 17:06:19 | ClaudeInference | INFO | 🎭 Circuit 통합 감정: 주요=0, 강도=3, 신뢰도=0.700
2025-09-13 17:06:19 | ClaudeInference | INFO | 😔 Circuit 예측 후회: {'anticipated_regret': 0.1, 'regret_intensity': 0.1, 'regret_duration': 1.0, 'confidence': 0.6}
2025-09-13 17:06:19 | ClaudeInference | INFO | ⚖️ Circuit 윤리 가치: {'care_harm': 0.23255488742955874, 'fairness': 0.1, 'loyalty': 0.1, 'authority': 0.1, 'sanctity': 0.1, 'liberty': 0.1}
2025-09-13 17:06:19 | ClaudeInference | INFO | 😔 고급 후회 분석: {'regret_score': [[0.505013644695282]], 'regret_emotion_vector': [[0.04226027801632881, -0.01581539772450924, 0.09697335213422775, 0.014764687046408653, -0.06736166775226593, -0.04425019025802612, -0.13407260179519653, 0.09166860580444336]], 'regret_uncertainty': [[0.5021620392799377]]}
2025-09-13 17:06:19 | ClaudeInference | INFO | 🤖 Claude 분석:
이 텍스트에 대한 다각도의 윤리적 분석을 종합해보면 AI 기술 발전에 따른 윤리적 문제 해결이 중요한 과제임을 알 수 있습니다. 

주요 윤리적 쟁점으로는 AI의 안전성과 투명성, 책임성 확보, 인간의 존엄성 훼손 방지, 프라이버시 보호, 공정성과 차별 금지 등이 있습니다. 이는 기술 발전의 혜택과 위험성 사이의 균형을 찾아야 하는 딜레마로 이어집니다.

...
2025-09-13 17:06:19 | ClaudeInference | INFO | 
🧹 리소스 정리 중...
2025-09-13 17:06:19 | ClaudeInference | INFO | ✅ 정리 완료
2025-09-13 17:06:19 | ClaudeInference | INFO | 
🎉 Claude API 추론 완료!
2025-09-13 17:06:20 | RedHeart.MainUnified | INFO | ✅ Claude Inference 완료
🔧 klue/bert-base 모델: 안정성 보장을 위한 15.0% 할당
📋 Transformer 모델: 최적화된 배치 처리 방식 활성화
🔧 klue/bert-base 모델: 안정성 보장을 위한 15.0% 할당
📋 Transformer 모델: 최적화된 배치 처리 방식 활성화
✅ 고급 모듈들로 회로 초기화 완료
✅ 경험 데이터베이스 시스템 초기화 완료
