#!/usr/bin/env python3
"""
í—¤ë“œ ì¶œë ¥ í˜•íƒœ í…ŒìŠ¤íŠ¸
"""

import torch
import sys
sys.path.append('/mnt/c/large_project/linux_red_heart')

def test_head_output():
    print("ğŸ” í—¤ë“œ ì¶œë ¥ í˜•íƒœ í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    # ë°±ë³¸ê³¼ í—¤ë“œ í…ŒìŠ¤íŠ¸
    from unified_backbone import RedHeartUnifiedBackbone
    from unified_heads import EmotionHead
    
    # ë°±ë³¸ ì„¤ì •
    backbone_config = {
        'input_dim': 768,
        'd_model': 896,
        'num_layers': 8,
        'num_heads': 14,
        'feedforward_dim': 3584,
        'dropout': 0.1,
        'task_dim': 896
    }
    
    backbone = RedHeartUnifiedBackbone(backbone_config)
    backbone.eval()
    
    # ê°ì • í—¤ë“œ ì„¤ì • - EmotionHeadëŠ” input_dimë§Œ ë°›ìŒ
    emotion_head = EmotionHead(input_dim=896)
    emotion_head.eval()
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    print("1. ë°±ë³¸ í…ŒìŠ¤íŠ¸ (1x512x768):")
    test_input = torch.randn(1, 512, 768)
    
    with torch.no_grad():
        backbone_output = backbone(test_input, task='emotion')
        print(f"   ë°±ë³¸ ì¶œë ¥ í‚¤: {backbone_output.keys()}")
        
        if 'emotion' in backbone_output:
            emotion_features = backbone_output['emotion']
            print(f"   emotion features shape: {emotion_features.shape}")
            
            # í—¤ë“œì— ì „ë‹¬
            print("\n2. í—¤ë“œ í…ŒìŠ¤íŠ¸:")
            head_output = emotion_head(emotion_features)
            
            if isinstance(head_output, dict):
                print(f"   í—¤ë“œ ì¶œë ¥ íƒ€ì…: dict")
                for key, value in head_output.items():
                    if isinstance(value, torch.Tensor):
                        print(f"   - {key}: {value.shape}")
                    else:
                        print(f"   - {key}: {type(value)}")
            elif isinstance(head_output, torch.Tensor):
                print(f"   í—¤ë“œ ì¶œë ¥ shape: {head_output.shape}")
            else:
                print(f"   í—¤ë“œ ì¶œë ¥ íƒ€ì…: {type(head_output)}")
                
            # DSP Simulator í…ŒìŠ¤íŠ¸
            print("\n3. DSP Simulator í…ŒìŠ¤íŠ¸:")
            from emotion_dsp_simulator import EmotionDSPSimulator
            
            dsp_config = {
                'num_emotions': 7,
                'filter_order': 2,
                'sample_rate': 100,
                'resonance': 0.7
            }
            
            dsp = EmotionDSPSimulator(dsp_config)
            dsp.eval()
            
            # ì‹¤ì œ head_outputì„ DSPì— ì „ë‹¬
            if isinstance(head_output, dict):
                # dictì—ì„œ ì²« ë²ˆì§¸ í…ì„œ ì¶”ì¶œ
                actual_head_output = head_output.get('emotions', 
                                     head_output.get('emotion_logits', 
                                     list(head_output.values())[0] if head_output else None))
            else:
                actual_head_output = head_output
            
            print(f"   DSP ì…ë ¥ shape: {actual_head_output.shape if isinstance(actual_head_output, torch.Tensor) else type(actual_head_output)}")
            
            try:
                dsp_output = dsp.forward(actual_head_output)
                print(f"   âœ… DSP ì„±ê³µ: ì¶œë ¥ shape = {dsp_output.shape if isinstance(dsp_output, torch.Tensor) else type(dsp_output)}")
            except Exception as e:
                print(f"   âŒ DSP ì‹¤íŒ¨: {e}")
    
    print("\n" + "="*50)

if __name__ == "__main__":
    test_head_output()