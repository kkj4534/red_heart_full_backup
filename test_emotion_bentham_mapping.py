#!/usr/bin/env python3
"""
ê°ì •â†’ë²¤ë‹´ ì •ë°€ ë§¤í•‘ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
íœ´ë¦¬ìŠ¤í‹± vs ì˜ë¯¸ë¡ ì  ë§¤í•‘ ë¹„êµ
"""

import numpy as np
import torch
from semantic_emotion_bentham_mapper import (
    SemanticEmotionBenthamMapper,
    NeuralEmotionBenthamAdapter,
    EMOTION_DIMENSIONS,
    BENTHAM_DIMENSIONS
)
import matplotlib.pyplot as plt
import seaborn as sns


def heuristic_mapping(emotion_scores):
    """ê¸°ì¡´ íœ´ë¦¬ìŠ¤í‹± ë§¤í•‘ (ë‹¨ìˆœ ì¸ë±ìŠ¤)"""
    bentham = {}
    bentham_names = list(BENTHAM_DIMENSIONS.keys())
    
    for i, name in enumerate(bentham_names):
        if i < len(emotion_scores):
            bentham[name] = emotion_scores[i]
        else:
            bentham[name] = 0.5
    
    return bentham


def test_mapping_quality():
    """ë§¤í•‘ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("ê°ì •â†’ë²¤ë‹´ ë§¤í•‘ í’ˆì§ˆ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
    test_scenarios = [
        {
            'name': 'ê¸ì •ì  í¥ë¶„ ìƒíƒœ',
            'emotion': {
                'valence': 0.8,      # ë§¤ìš° ê¸ì •ì 
                'arousal': 0.9,      # ë†’ì€ ê°ì„±
                'dominance': 0.7,    # í†µì œê°
                'certainty': 0.8,    # í™•ì‹¤
                'surprise': 0.2,     # ì˜ˆìƒë¨
                'anticipation': 0.9  # ë†’ì€ ê¸°ëŒ€
            },
            'expected': {
                'intensity': 'high',       # ë†’ì€ ê°ì„± â†’ ë†’ì€ ê°•ë„
                'duration': 'medium-high', # í†µì œê° â†’ ì§€ì†ì„±
                'fecundity': 'high',      # ê¸ì •+ê¸°ëŒ€ â†’ ìƒì‚°ì„±
                'extent': 'high'          # ê°•í•œ ê°ì • â†’ ë„“ì€ ì˜í–¥
            }
        },
        {
            'name': 'ë¶ˆì•ˆê³¼ ë¬´ë ¥ê°',
            'emotion': {
                'valence': -0.7,     # ë¶€ì •ì 
                'arousal': 0.8,      # ë†’ì€ ê°ì„± (ë¶ˆì•ˆ)
                'dominance': -0.6,   # ë¬´ë ¥ê°
                'certainty': 0.2,    # ë¶ˆí™•ì‹¤
                'surprise': 0.7,     # ì˜ˆìƒ ëª»í•¨
                'anticipation': 0.1  # ê¸°ëŒ€ ì—†ìŒ
            },
            'expected': {
                'intensity': 'high',        # ë¶ˆì•ˆí•œ ê°ì„±
                'duration': 'low',          # ë¬´ë ¥ê° â†’ ì§§ì€ ì§€ì†
                'self_damage': 'high',      # ë¶€ì •+ë¬´ë ¥ â†’ ìê¸°ì†ìƒ
                'external_cost': 'high'     # ë¶€ì •ì  ì˜í–¥
            }
        },
        {
            'name': 'í‰ì˜¨í•œ í™•ì‹ ',
            'emotion': {
                'valence': 0.5,      # ì•½ê°„ ê¸ì •ì 
                'arousal': -0.2,     # ë‚®ì€ ê°ì„± (í‰ì˜¨)
                'dominance': 0.6,    # ì ì ˆí•œ í†µì œ
                'certainty': 0.9,    # ë§¤ìš° í™•ì‹¤
                'surprise': 0.0,     # ì™„ì „ ì˜ˆìƒ
                'anticipation': 0.4  # ë³´í†µ ê¸°ëŒ€
            },
            'expected': {
                'intensity': 'low',         # ë‚®ì€ ê°ì„±
                'duration': 'high',         # í™•ì‹¤+í†µì œ â†’ ì§€ì†
                'certainty': 'very-high',   # ë§¤ìš° í™•ì‹¤
                'purity': 'high'            # ëª…í™•í•œ ìƒíƒœ
            }
        }
    ]
    
    # ë§¤í¼ ì´ˆê¸°í™”
    semantic_mapper = SemanticEmotionBenthamMapper()
    
    # ê° ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
    for scenario in test_scenarios:
        print(f"\nğŸ”¬ ì‹œë‚˜ë¦¬ì˜¤: {scenario['name']}")
        print("-" * 50)
        
        # ê°ì • ë²¡í„° ìƒì„± (ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ)
        emotion_list = [scenario['emotion'][dim] for dim in EMOTION_DIMENSIONS.keys()]
        
        # íœ´ë¦¬ìŠ¤í‹± ë§¤í•‘
        heuristic_result = heuristic_mapping(emotion_list)
        
        # ì˜ë¯¸ë¡ ì  ë§¤í•‘
        semantic_result = semantic_mapper.map_emotion_to_bentham(scenario['emotion'])
        
        # ê²°ê³¼ ë¹„êµ
        print("\nğŸ“Š ë§¤í•‘ ê²°ê³¼ ë¹„êµ:")
        print(f"{'ë²¤ë‹´ ì°¨ì›':<20} {'íœ´ë¦¬ìŠ¤í‹±':<12} {'ì˜ë¯¸ë¡ ì ':<12} {'ì˜ˆìƒ':<15}")
        print("-" * 60)
        
        for bentham_dim in BENTHAM_DIMENSIONS.keys():
            heur_val = heuristic_result.get(bentham_dim, 0)
            sem_val = semantic_result.get(bentham_dim, 0)
            
            # ì˜ˆìƒê°’ê³¼ ë¹„êµ
            expected = scenario['expected'].get(bentham_dim, '')
            if expected:
                if 'high' in expected and sem_val > 0.7:
                    match = 'âœ…'
                elif 'low' in expected and sem_val < 0.3:
                    match = 'âœ…'
                elif 'medium' in expected and 0.3 <= sem_val <= 0.7:
                    match = 'âœ…'
                else:
                    match = 'âŒ'
                expected += f" {match}"
            
            print(f"{bentham_dim:<20} {heur_val:<12.3f} {sem_val:<12.3f} {expected:<15}")
        
        # ì˜ë¯¸ë¡ ì  ì¼ê´€ì„± ì ìˆ˜
        print(f"\nğŸ’¡ ì˜ë¯¸ë¡ ì  ì¼ê´€ì„± ë¶„ì„:")
        
        # í•µì‹¬ ì—°ê²° í™•ì¸
        checks = []
        
        # ê°ì„±ë„ â†’ ê°•ë„
        if scenario['emotion']['arousal'] > 0.5 and semantic_result['intensity'] > 0.6:
            checks.append("âœ… ê°ì„±ë„ â†’ ê°•ë„")
        elif scenario['emotion']['arousal'] < 0 and semantic_result['intensity'] < 0.4:
            checks.append("âœ… ë‚®ì€ ê°ì„± â†’ ë‚®ì€ ê°•ë„")
        
        # í†µì œê° â†’ ì§€ì†ì„±
        if scenario['emotion']['dominance'] > 0.5 and semantic_result['duration'] > 0.6:
            checks.append("âœ… í†µì œê° â†’ ì§€ì†ì„±")
        elif scenario['emotion']['dominance'] < 0 and semantic_result['duration'] < 0.4:
            checks.append("âœ… ë¬´ë ¥ê° â†’ ì§§ì€ ì§€ì†")
        
        # ë¶€ì • ê°ì • â†’ ìê¸°ì†ìƒ
        if scenario['emotion']['valence'] < -0.5 and semantic_result['self_damage'] > 0.6:
            checks.append("âœ… ë¶€ì • ê°ì • â†’ ìê¸°ì†ìƒ")
        
        # ê¸ì •+ê¸°ëŒ€ â†’ ìƒì‚°ì„±
        if scenario['emotion']['valence'] > 0.5 and scenario['emotion']['anticipation'] > 0.5:
            if semantic_result['fecundity'] > 0.6:
                checks.append("âœ… ê¸ì •+ê¸°ëŒ€ â†’ ìƒì‚°ì„±")
        
        for check in checks:
            print(f"   {check}")


def visualize_mapping_comparison():
    """ë§¤í•‘ ë¹„êµ ì‹œê°í™”"""
    print("\n" + "=" * 70)
    print("ë§¤í•‘ í–‰ë ¬ ì‹œê°í™”")
    print("=" * 70)
    
    # ì˜ë¯¸ë¡ ì  ë§¤í•‘ í–‰ë ¬ ìƒì„±
    mapper = SemanticEmotionBenthamMapper()
    mapping_matrix = np.zeros((10, 6))
    
    for b_idx, b_name in enumerate(BENTHAM_DIMENSIONS.keys()):
        if b_name in mapper.mapping_rules:
            for e_name, weight in mapper.mapping_rules[b_name]:
                e_idx = EMOTION_DIMENSIONS[e_name]
                mapping_matrix[b_idx, e_idx] = weight
    
    # íˆíŠ¸ë§µ ìƒì„±
    plt.figure(figsize=(10, 8))
    
    # ì˜ë¯¸ë¡ ì  ë§¤í•‘ íˆíŠ¸ë§µ
    plt.subplot(1, 2, 1)
    sns.heatmap(mapping_matrix, 
                xticklabels=list(EMOTION_DIMENSIONS.keys()),
                yticklabels=list(BENTHAM_DIMENSIONS.keys()),
                cmap='RdBu_r', center=0, vmin=-1, vmax=1,
                annot=True, fmt='.2f', cbar_kws={'label': 'ê°€ì¤‘ì¹˜'})
    plt.title('ì˜ë¯¸ë¡ ì  ë§¤í•‘ í–‰ë ¬')
    plt.xlabel('ê°ì • ì°¨ì›')
    plt.ylabel('ë²¤ë‹´ ì°¨ì›')
    
    # íœ´ë¦¬ìŠ¤í‹± ë§¤í•‘ (ëŒ€ê°ì„ )
    plt.subplot(1, 2, 2)
    heuristic_matrix = np.zeros((10, 6))
    for i in range(min(6, 10)):
        heuristic_matrix[i, i] = 1.0
    
    sns.heatmap(heuristic_matrix,
                xticklabels=list(EMOTION_DIMENSIONS.keys()),
                yticklabels=list(BENTHAM_DIMENSIONS.keys()),
                cmap='RdBu_r', center=0, vmin=-1, vmax=1,
                annot=True, fmt='.1f', cbar_kws={'label': 'ê°€ì¤‘ì¹˜'})
    plt.title('íœ´ë¦¬ìŠ¤í‹± ë§¤í•‘ (ë‹¨ìˆœ ì¸ë±ìŠ¤)')
    plt.xlabel('ê°ì • ì°¨ì›')
    plt.ylabel('ë²¤ë‹´ ì°¨ì›')
    
    plt.tight_layout()
    plt.savefig('emotion_bentham_mapping_comparison.png', dpi=150)
    print("ğŸ“Š ì‹œê°í™” ì €ì¥: emotion_bentham_mapping_comparison.png")
    plt.show()


def test_neural_adapter():
    """ì‹ ê²½ë§ ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("ì‹ ê²½ë§ ì–´ëŒ‘í„° í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜")
    print("=" * 70)
    
    # ì–´ëŒ‘í„° ì´ˆê¸°í™”
    adapter = NeuralEmotionBenthamAdapter()
    optimizer = torch.optim.Adam(adapter.parameters(), lr=0.001)
    
    # ì˜ë¯¸ë¡ ì  ë§¤í¼ë¡œ í•™ìŠµ ë°ì´í„° ìƒì„±
    semantic_mapper = SemanticEmotionBenthamMapper()
    
    # ê°„ë‹¨í•œ í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
    print("\nğŸ§  ì‹ ê²½ë§ ì–´ëŒ‘í„° í•™ìŠµ ì¤‘...")
    
    losses = []
    for epoch in range(100):
        # ëœë¤ ê°ì • ìƒì„±
        random_emotion = np.random.randn(6)
        random_emotion = np.tanh(random_emotion)  # -1 ~ 1 ë²”ìœ„
        
        # íƒ€ê²Ÿ: ì˜ë¯¸ë¡ ì  ë§¤í•‘ ê²°ê³¼
        emotion_dict = {dim: random_emotion[idx] for idx, dim in enumerate(EMOTION_DIMENSIONS.keys())}
        target_bentham = semantic_mapper.map_emotion_to_bentham(emotion_dict)
        target_tensor = torch.tensor([target_bentham[dim] for dim in BENTHAM_DIMENSIONS.keys()], dtype=torch.float32)
        
        # ìˆœì „íŒŒ
        emotion_tensor = torch.tensor(random_emotion, dtype=torch.float32).unsqueeze(0)
        output = adapter(emotion_tensor)
        
        # ì†ì‹¤ ê³„ì‚°
        loss = torch.nn.functional.mse_loss(output[0], target_tensor)
        
        # ì—­ì „íŒŒ
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        losses.append(loss.item())
        
        if (epoch + 1) % 20 == 0:
            print(f"   Epoch {epoch+1:3d}: Loss = {loss.item():.6f}")
    
    print("\nâœ… í•™ìŠµ ì™„ë£Œ!")
    
    # í•™ìŠµ ê²°ê³¼ í…ŒìŠ¤íŠ¸
    print("\nğŸ“ˆ í•™ìŠµëœ ì–´ëŒ‘í„° vs ì˜ë¯¸ë¡ ì  ë§¤í¼ ë¹„êµ:")
    
    test_emotion = np.array([0.7, 0.5, 0.6, 0.8, 0.2, 0.7])  # í…ŒìŠ¤íŠ¸ ê°ì •
    
    # ì˜ë¯¸ë¡ ì  ê²°ê³¼
    emotion_dict = {dim: test_emotion[idx] for idx, dim in enumerate(EMOTION_DIMENSIONS.keys())}
    semantic_result = semantic_mapper.map_emotion_to_bentham(emotion_dict)
    
    # ì‹ ê²½ë§ ê²°ê³¼
    with torch.no_grad():
        emotion_tensor = torch.tensor(test_emotion, dtype=torch.float32).unsqueeze(0)
        neural_result = adapter(emotion_tensor)[0].numpy()
    
    print(f"{'ë²¤ë‹´ ì°¨ì›':<20} {'ì˜ë¯¸ë¡ ì ':<12} {'ì‹ ê²½ë§':<12} {'ì°¨ì´':<10}")
    print("-" * 55)
    
    for idx, dim in enumerate(BENTHAM_DIMENSIONS.keys()):
        sem_val = semantic_result[dim]
        neural_val = neural_result[idx]
        diff = abs(sem_val - neural_val)
        
        print(f"{dim:<20} {sem_val:<12.3f} {neural_val:<12.3f} {diff:<10.3f}")
    
    # í•™ìŠµ ê³¡ì„  ê·¸ë¦¬ê¸°
    plt.figure(figsize=(8, 4))
    plt.plot(losses)
    plt.title('ì‹ ê²½ë§ ì–´ëŒ‘í„° í•™ìŠµ ê³¡ì„ ')
    plt.xlabel('Epoch')
    plt.ylabel('MSE Loss')
    plt.grid(True, alpha=0.3)
    plt.savefig('neural_adapter_training.png', dpi=150)
    print("\nğŸ“Š í•™ìŠµ ê³¡ì„  ì €ì¥: neural_adapter_training.png")
    plt.show()


if __name__ == '__main__':
    # 1. ë§¤í•‘ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
    test_mapping_quality()
    
    # 2. ì‹œê°í™” (matplotlib ìˆì„ ê²½ìš°)
    try:
        visualize_mapping_comparison()
    except ImportError:
        print("\nâš ï¸ matplotlib/seaborn ì—†ìŒ - ì‹œê°í™” ê±´ë„ˆëœ€")
    
    # 3. ì‹ ê²½ë§ ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸
    test_neural_adapter()
    
    print("\n" + "=" * 70)
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)
    print("\nğŸ’¡ ê²°ë¡ :")
    print("   - ì˜ë¯¸ë¡ ì  ë§¤í•‘ì´ íœ´ë¦¬ìŠ¤í‹±ë³´ë‹¤ í›¨ì”¬ ì •ë°€í•¨")
    print("   - ê°ì •ê³¼ ë²¤ë‹´ ì°¨ì› ê°„ ì˜ë¯¸ë¡ ì  ì—°ê²° í™•ì¸")
    print("   - ì‹ ê²½ë§ ì–´ëŒ‘í„°ë¡œ ì¶”ê°€ ê°œì„  ê°€ëŠ¥")
    print("   - ê³„ì¸µë³„ ì²˜ë¦¬ (ê³µë™ì²´/íƒ€ì/ìì•„) ì§€ì›")