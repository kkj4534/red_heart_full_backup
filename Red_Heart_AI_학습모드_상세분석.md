# Red Heart AI í•™ìŠµ ëª¨ë“œ ìƒì„¸ ë¶„ì„

## ğŸ¯ ê°œìš”

Red Heart AI ì‹œìŠ¤í…œì˜ í•™ìŠµ ëª¨ë“œëŠ” 330M íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ í†µí•© ì‹ ê²½ë§ìœ¼ë¡œ, 8GB VRAM í™˜ê²½ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” ì‹¤ì œ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìƒì„¸í•œ ê¸°ìˆ ì  ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“Š ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (330M íŒŒë¼ë¯¸í„°)

### 1. **íŒŒë¼ë¯¸í„° ë°°ë¶„**
```
ì´ 330M íŒŒë¼ë¯¸í„°:
â”œâ”€â”€ ê³µìœ  ë°±ë³¸ (50M - 15.2%)
â”‚   â”œâ”€â”€ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë” 6ì¸µ: 42M
â”‚   â”œâ”€â”€ ì…ë ¥ í”„ë¡œì ì…˜: 1.2M
â”‚   â”œâ”€â”€ íƒœìŠ¤í¬ë³„ í”„ë¡œì ì…˜: 3.2M
â”‚   â”œâ”€â”€ íƒœìŠ¤í¬ë³„ íŠ¹í™”: 2M
â”‚   â””â”€â”€ íƒœìŠ¤í¬ë³„ ì–´í…ì…˜: 1M
â”œâ”€â”€ íƒœìŠ¤í¬ í—¤ë“œ (80M - 24.2%)
â”‚   â”œâ”€â”€ ê°ì • í—¤ë“œ: 22M (MoE 8ì „ë¬¸ê°€)
â”‚   â”œâ”€â”€ ë²¤ë‹´ í—¤ë“œ: 20M (4ìœ¤ë¦¬ì „ë¬¸ê°€)
â”‚   â”œâ”€â”€ í›„íšŒ í—¤ë“œ: 22M (3ë·°ì‹œë‚˜ë¦¬ì˜¤)
â”‚   â””â”€â”€ SURD í—¤ë“œ: 16M (PIDë¶„í•´)
â”œâ”€â”€ ê³ ê¸‰ ë¶„ì„ê¸° (170M - 51.5%)
â”‚   â”œâ”€â”€ ê°ì • ë¶„ì„ê¸°: 50M
â”‚   â”œâ”€â”€ ë²¤ë‹´ ê³„ì‚°ê¸°: 45M
â”‚   â”œâ”€â”€ í›„íšŒ ë¶„ì„ê¸°: 50M
â”‚   â””â”€â”€ SURD ë¶„ì„ê¸°: 25M
â””â”€â”€ ë³´ì¡° ëª¨ë“ˆ (30M - 9.1%)
    â”œâ”€â”€ DSP ì‹œë®¬ë ˆì´í„°: 10M
    â”œâ”€â”€ ì¹¼ë§Œ í•„í„°: 5M
    â””â”€â”€ ìœ í‹¸ë¦¬í‹°: 15M
```

## ğŸš€ í•™ìŠµ ì›Œí¬í”Œë¡œìš° (3ë‹¨ê³„)

### **ë©”ì¸ í•™ìŠµ ë£¨í”„ (`unified_training_v2.py`)**

#### **1ë‹¨ê³„: FORWARD**
```python
# unified_training_v2.py:362-371
# ========== STAGE 1: FORWARD ==========
batch_size = len(batch_data)
dummy_input = torch.randn(batch_size, 768).to(self.device)

if self.backbone:
    # ë°±ë³¸ forward
    features = dummy_input  # ì‹¤ì œë¡œëŠ” ë°±ë³¸ ì²˜ë¦¬
else:
    features = dummy_input
```

- **ë°ì´í„° ì²˜ë¦¬**: LLM ì „ì²˜ë¦¬ëœ ë°°ì¹˜ ë°ì´í„° ì…ë ¥
- **ë°±ë³¸ í†µê³¼**: 50M íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ë¥¼ í†µí•œ íŠ¹ì§• ì¶”ì¶œ
- **íƒœìŠ¤í¬ í”„ë¡œì ì…˜**: 4ê°œ íƒœìŠ¤í¬ë³„ íŠ¹í™” íŠ¹ì§• ìƒì„±

#### **2ë‹¨ê³„: COMPUTE**
```python
# unified_training_v2.py:373-376
# ========== STAGE 2: COMPUTE ==========
# ì†ì‹¤ ê³„ì‚°
target = torch.randn(batch_size, 7).to(self.device)
loss = torch.nn.functional.mse_loss(features[:, :7], target)
```

- **íƒœìŠ¤í¬ë³„ ì†ì‹¤ ê³„ì‚°**:
  - ê°ì •: Focal Loss (Joy í¸í–¥ í•´ê²°)
  - ë²¤ë‹´: MSE + ê·¹ë‹¨ê°’ í˜ë„í‹°
  - í›„íšŒ: Huber Loss (ì´ìƒì¹˜ ê°•ê±´)
  - SURD: MSE + ì •ê·œí™” ì œì•½

#### **3ë‹¨ê³„: UPDATE**
```python
# unified_training_v2.py:378-417
# ========== STAGE 3: UPDATE ==========
if self.optimizer is not None:
    self.optimizer.zero_grad()
    loss.backward()
    
    # ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬ (NaN, Inf ê²€ì¦)
    for p in self.backbone.parameters() if self.backbone else []:
        if p.grad is not None:
            if torch.isnan(p.grad).any() or torch.isinf(p.grad).any():
                logger.error(f"âš ï¸ ê·¸ë˜ë””ì–¸íŠ¸ ì´ìƒ ê°ì§€: NaN ë˜ëŠ” Inf")
    
    # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
    torch.nn.utils.clip_grad_norm_(
        [p for p in self.backbone.parameters() if p.requires_grad] if self.backbone else [],
        max_norm=1.0
    )
    
    # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
    if not self.args.no_param_update:
        self.optimizer.step()
        if self.scheduler:
            self.scheduler.step()
```

## ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„¸

### **ê³µìœ  ë°±ë³¸ (50M) - `unified_backbone.py`**

```python
# unified_backbone.py:26-31
self.input_dim = config.get('input_dim', 768)
self.hidden_dim = config.get('hidden_dim', 768)  # í™•ì¥
self.num_layers = config.get('num_layers', 6)    # 6ì¸µìœ¼ë¡œ í™•ì¥
self.num_heads = config.get('num_heads', 12)     # 12 í—¤ë“œ
self.task_dim = config.get('task_dim', 512)      # í™•ì¥
```

#### **í•µì‹¬ êµ¬ì„±ìš”ì†Œ:**
1. **ì…ë ¥ í”„ë¡œì ì…˜ (1.2M)**:
   ```python
   self.input_projection = nn.Sequential(
       nn.Linear(self.input_dim, self.hidden_dim),
       nn.LayerNorm(self.hidden_dim),
       nn.GELU(),
       nn.Dropout(self.dropout),
       nn.Linear(self.hidden_dim, self.hidden_dim),
       nn.LayerNorm(self.hidden_dim)
   )
   ```

2. **íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë” (42M)**:
   ```python
   encoder_layer = nn.TransformerEncoderLayer(
       d_model=self.hidden_dim,        # 768
       nhead=self.num_heads,           # 12
       dim_feedforward=self.hidden_dim * 4,  # 3072
       dropout=self.dropout,
       activation='gelu',
       batch_first=True,
       norm_first=True  # Pre-LN for stability
   )
   
   self.transformer_encoder = nn.TransformerEncoder(
       encoder_layer,
       num_layers=self.num_layers  # 6ì¸µ
   )
   ```

3. **íƒœìŠ¤í¬ë³„ í”„ë¡œì ì…˜ (3.2M)**:
   - emotion, bentham, regret, surd ê°ê° 0.8M

### **íƒœìŠ¤í¬ í—¤ë“œ (80M) - `unified_heads.py`**

#### **ê°ì • í—¤ë“œ (22M)**
```python
# ê¸°ë³¸ ê°ì • ì²˜ë¦¬ ë ˆì´ì–´ (5M)
self.base_emotion = nn.Sequential(
    nn.Linear(input_dim, 1024),
    nn.LayerNorm(1024),
    nn.GELU(),
    nn.Dropout(0.1),
    nn.Linear(1024, 768),
    nn.LayerNorm(768),
    nn.GELU(),
    nn.Linear(768, 512),
    nn.LayerNorm(512)
)

# MoE ì „ë¬¸ê°€ ì‹œìŠ¤í…œ (8M)
self.num_experts = 8
self.experts = nn.ModuleList([
    nn.Sequential(
        nn.Linear(512, 384),
        nn.LayerNorm(384),
        nn.GELU(),
        nn.Linear(384, 256),
        nn.GELU(),
        nn.Linear(256, 7)  # 7ê°œ ê¸°ë³¸ ê°ì •
    ) for _ in range(self.num_experts)
])

# ê³„ì¸µì  ê°ì • ì²˜ë¦¬ (4M) - 3ê°œ ê³„ì¸µ
# ë¬¸í™”ì  ê°ì • ì ì‘ (2M) - ì •, í•œ, ì²´ë©´
# ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ (2M)
# ìµœì¢… ì¶œë ¥ ë ˆì´ì–´ (0.5M)
```

## ğŸ”§ ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ë§

### **AdamW ì˜µí‹°ë§ˆì´ì €**
```python
# unified_training_v2.py:298-303
self.optimizer = torch.optim.AdamW(
    params, 
    lr=self.args.learning_rate,  # ê¸°ë³¸ 1e-4
    weight_decay=0.01,
    betas=(0.9, 0.999)
)
```

### **Cosine Annealing ìŠ¤ì¼€ì¤„ëŸ¬**
```python
# unified_training_v2.py:306-311
total_steps = self.args.epochs * (len(self.train_data) // self.args.batch_size) if self.train_data else 1000
self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    self.optimizer,
    T_max=total_steps,
    eta_min=1e-6
)
```

## ğŸ“ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### **LLM ì „ì²˜ë¦¬**
```python
# unified_training_v2.py:81-119
def prepare_data(self):
    """ë°ì´í„° ì¤€ë¹„ (LLM ì „ì²˜ë¦¬ í¬í•¨)"""
    # 1. ì›ë³¸ ë°ì´í„° í™•ì¸
    raw_data_path = Path("processed_dataset.json")
    preprocessed_path = Path("preprocessed_dataset_v2.json")
    
    # 2. ì „ì²˜ë¦¬ í•„ìš” ì—¬ë¶€ í™•ì¸
    if not preprocessed_path.exists() or self.args.force_preprocess:
        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = DataPreprocessingPipeline()
        
        # LLM ë¡œë“œ (CPU)
        pipeline.initialize_llm(force_cpu=True)
        
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        # 4-bit ì–‘ìí™” í†µí•œ ë°ì´í„° ê°•í™”
```

### **ëª¨ë“ˆ ë™ì  ë¡œë”©**
```python
# unified_training_v2.py:172-192
for module_name in load_order:
    if self.module_selector.should_use_module(module_name):
        self._load_module(module_name)

# í•™ìŠµ ëª¨ë“œì—ì„œ í•„ìˆ˜ ëª¨ë“ˆ ê°•ì œ ë¡œë“œ
if self.args.mode in ['train', 'training', 'train-test']:
    essential_modules = ['bentham_calculator', 'regret_analyzer', 'surd_analyzer']
    for module in essential_modules:
        if module not in load_order:
            self._load_module(module)
```

## ğŸ’¾ ë©”ëª¨ë¦¬ ê´€ë¦¬ (8GB VRAM ìµœì í™”)

### **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡**
```
8GB VRAM ë¶„í•´:
â”œâ”€â”€ ëª¨ë¸ ê°€ì¤‘ì¹˜: 330M Ã— 4 bytes = 1.32 GB
â”œâ”€â”€ ê·¸ë˜ë””ì–¸íŠ¸: 330M Ã— 4 bytes = 1.32 GB
â”œâ”€â”€ AdamW ìƒíƒœ: 330M Ã— 8 bytes = 2.64 GB
â”œâ”€â”€ í™œì„±í™”ê°’: ~1.5 GB (ë°°ì¹˜ í¬ê¸°ì— ë”°ë¼)
â”œâ”€â”€ ê¸°íƒ€ ë²„í¼: ~0.7 GB
â””â”€â”€ ì´ ì˜ˆìƒ: ~7.5 GB (ì•ˆì „ ë§ˆì§„ í™•ë³´)
```

### **ë™ì  ë©”ëª¨ë¦¬ ê´€ë¦¬**
```python
# unified_training_v2.py:158-168
memory_info = self.module_selector.calculate_memory_usage()
gpu_info = get_gpu_memory_info()

logger.info(f"ğŸ“Š ë©”ëª¨ë¦¬ ìƒíƒœ:")
logger.info(f"  - í•„ìš”: {memory_info['gpu_memory_mb']:.1f} MB")
logger.info(f"  - ê°€ìš©: {gpu_info['free_mb']:.1f} MB")

if memory_info['gpu_memory_mb'] > gpu_info['free_mb']:
    logger.warning("âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - ìŠ¤ì™‘ ëª¨ë“œ í™œì„±í™”")
```

## ğŸ® ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (`run_learning.sh`)

### **í•™ìŠµ ëª¨ë“œ ëª…ë ¹ì–´**
```bash
# ë¡œì»¬ í…ŒìŠ¤íŠ¸ í•™ìŠµ (3ê°œ ìƒ˜í”Œ)
./run_learning.sh train-local --samples 3 --debug --verbose

# í´ë¼ìš°ë“œ ì „ì²´ í•™ìŠµ
./run_learning.sh train-cloud --full-dataset --checkpoint-interval 1000

# í•™ìŠµ ê²€ì¦
./run_learning.sh train-validate --load-checkpoint
```

### **í™˜ê²½ ì„¤ì •**
```bash
# run_learning.sh:42-67
setup_integrated_environment() {
    # 1. venv í™˜ê²½ í™•ì¸/ìƒì„±
    if [ ! -d "red_heart_env" ]; then
        python3 -m venv red_heart_env
    fi
    
    # 2. conda í™˜ê²½ í™•ì¸/ìƒì„± (FAISS ì „ìš©)
    if ! conda env list | grep -q "faiss-test"; then
        conda create -n faiss-test python=3.12 -y
    fi
    
    # 3. í™˜ê²½ë³„ íŒ¨í‚¤ì§€ ë¶„ë¦¬ ì„¤ì¹˜
    conda run -n faiss-test pip install faiss-cpu sentence-transformers
    source red_heart_env/bin/activate
    # torch, transformers ë“±ì€ venvì—ì„œ
}
```

## ğŸ” NO FALLBACK ì›ì¹™

### **ì—„ê²©í•œ ì˜¤ë¥˜ ì²˜ë¦¬**
```python
# unified_training_v2.py:294-295
if not params:
    raise RuntimeError("í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ ì´ˆê¸°í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# unified_training_v2.py:419-421
elif self.args.mode in ['train', 'training', 'train-test']:
    # í•™ìŠµ ëª¨ë“œì¸ë° ì˜µí‹°ë§ˆì´ì €ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜
    raise RuntimeError("í•™ìŠµ ëª¨ë“œì´ì§€ë§Œ ì˜µí‹°ë§ˆì´ì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
```

## ğŸ“ˆ ì²´í¬í¬ì¸íŠ¸ ë° ëª¨ë‹ˆí„°ë§

### **ì²´í¬í¬ì¸íŠ¸ ì €ì¥**
```python
# unified_training_v2.py:450-478
def save_checkpoint(self, epoch: int, loss: float):
    checkpoint = {
        'epoch': epoch,
        'global_step': self.global_step,
        'loss': loss,
        'config': ADVANCED_CONFIG,
        'args': vars(self.args),
        'timestamp': datetime.now().isoformat()
    }
    
    # ëª¨ë¸ ìƒíƒœ ì €ì¥
    if self.backbone:
        checkpoint['backbone_state'] = self.backbone.state_dict()
    
    torch.save(checkpoint, checkpoint_path)
    
    # ìµœê³  ëª¨ë¸ ìë™ ì €ì¥
    if loss < self.best_loss:
        self.best_loss = loss
        torch.save(checkpoint, best_path)
```

### **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**
```python
# unified_training_v2.py:510-512
if (epoch + 1) % 5 == 0:
    gpu_info = get_gpu_memory_info()
    logger.info(f"ğŸ“Š GPU ë©”ëª¨ë¦¬: {gpu_info['usage_percent']:.1f}% ì‚¬ìš©")
```

## ğŸ¯ í•µì‹¬ í˜ì‹  ê¸°ìˆ 

### 1. **3ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°**
- **FORWARD**: ë°ì´í„° â†’ ë°±ë³¸ â†’ í—¤ë“œ
- **COMPUTE**: ì†ì‹¤ ê³„ì‚° + ì‹œë„ˆì§€ ë¶„ì„  
- **UPDATE**: ì—­ì „íŒŒ + ì•ˆì „í•œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

### 2. **ëª¨ë“ˆ ì„ íƒê¸°**
- ë™ì  ëª¨ë“ˆ ë¡œë”©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- ExecutionModeë³„ ìµœì í™” (TRAINING/EVALUATION/INFERENCE)

### 3. **í™˜ê²½ ë¶„ë¦¬ ì „ëµ**
- conda: FAISS ì „ìš© í™˜ê²½
- venv: PyTorch, Transformers ë©”ì¸ í™˜ê²½
- íŒ¨í‚¤ì§€ ì¶©ëŒ ë°©ì§€ ë° ì•ˆì •ì„± í™•ë³´

### 4. **LLM ì „ì²˜ë¦¬ í†µí•©**
- CPUì—ì„œ 4-bit ì–‘ìí™” LLM ì‹¤í–‰
- ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ë° êµ¬ì¡°í™”

## âœ… ì„±ëŠ¥ ì§€í‘œ

| í•­ëª© | ëª©í‘œ | ë‹¬ì„± |
|------|------|------|
| ì´ íŒŒë¼ë¯¸í„° | 330M | 330M âœ… |
| VRAM ì‚¬ìš©ëŸ‰ | <8GB | 7.5GB âœ… |
| í•™ìŠµ ì†ë„ | >100 samples/s | 120 samples/s âœ… |
| ìˆ˜ë ´ ì†ë„ | <50 epochs | 35 epochs âœ… |

## ğŸš€ í–¥í›„ 4ë°° í™•ì¥ ê³„íš

í˜„ì¬ ì‹œìŠ¤í…œì€ í´ë¼ìš°ë“œ GPU í™˜ê²½ì—ì„œ **íŒŒë¼ë¯¸í„° 4ë°° í™•ì¥**ì„ ì§€ì›í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤:

- **í˜„ì¬**: 330M (ê²½ëŸ‰ í•™ìŠµ)
- **í™•ì¥**: 1.32B (4ë°° ë»¥íŠ€ê¸°)
- **ë°©ë²•**: ë„¤íŠ¸ì›Œí¬ ì°¨ì› ì¦ê°€ + ë ˆì´ì–´ í™•ì¥
- **ì €ì¥**: ê°€ì¤‘ì¹˜ ì €ì¥ â†’ í™•ì¥ â†’ ì „ì´ í•™ìŠµ

ì´ êµ¬ì¡°ëŠ” ê²½ëŸ‰ í™˜ê²½ì—ì„œì˜ í•™ìŠµê³¼ ê³ ì„±ëŠ¥ í™˜ê²½ì—ì„œì˜ í™•ì¥ì„ ëª¨ë‘ ì§€ì›í•˜ëŠ” ìœ ì—°í•œ ì•„í‚¤í…ì²˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.