#!/usr/bin/env python3
"""
Robust Logging System for Red Heart AI
ê²¬ê³ í•œ ë¡œê¹… ì‹œìŠ¤í…œ - ì•ˆì •ì ì¸ ê²°ê³¼ íŒŒì¼ ìƒì„± ë° GPU ë©”ëª¨ë¦¬ ì¶”ì 

Features:
- ê°•ì œ ê²°ê³¼ íŒŒì¼ ìƒì„± ë³´ì¥
- ì •í™•í•œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
- ì‹¤ì‹œê°„ ë¡œê·¸ ë²„í¼ë§ ë° ë°±ì—…
- ì‹œìŠ¤í…œ ì•ˆì •ì„± ëª¨ë‹ˆí„°ë§
- ì˜¤ë¥˜ ë³µêµ¬ ë° ë¡¤ë°± ì‹œìŠ¤í…œ
"""

import json
import time
import logging
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import queue
import asyncio
import torch
import os
from contextlib import contextmanager

# psutil ëŒ€ì²´ - ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì¶”ì ìš©
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("âš ï¸ psutil ë¯¸ì„¤ì¹˜ - ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì¶”ì  ì œí•œ")

@dataclass
class LogEntry:
    """ë¡œê·¸ ì—”íŠ¸ë¦¬ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: str
    level: str
    source: str
    message: str
    gpu_memory_mb: float
    system_memory_mb: float
    metadata: Dict[str, Any]

@dataclass
class TestResult:
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    test_id: str
    test_name: str
    start_time: str
    end_time: str
    duration_seconds: float
    status: str  # success, failed, error
    gpu_peak_memory_mb: float
    gpu_avg_memory_mb: float
    system_metrics: Dict[str, Any]
    performance_data: Dict[str, Any]
    error_info: Optional[Dict[str, Any]] = None

class RobustLogger:
    """ê²¬ê³ í•œ ë¡œê¹… ì‹œìŠ¤í…œ"""
    
    def __init__(self, base_log_dir: str = "logs"):
        self.base_log_dir = Path(base_log_dir)
        self.base_log_dir.mkdir(exist_ok=True)
        
        # ì„¸ì…˜ë³„ ë¡œê·¸ ë””ë ‰í† ë¦¬
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_dir = self.base_log_dir / f"session_{self.session_id}"
        self.session_dir.mkdir(exist_ok=True)
        
        # ë¡œê·¸ í ë° ìŠ¤ë ˆë“œ
        self.log_queue = queue.Queue()
        self.running = True
        self.log_thread = threading.Thread(target=self._log_worker, daemon=True)
        self.log_thread.start()
        
        # ë©”ëª¨ë¦¬ ì¶”ì 
        self.gpu_memory_tracker = []
        self.system_memory_tracker = []
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        self.test_results: List[TestResult] = []
        self.current_test: Optional[Dict[str, Any]] = None
        
        # ë°±ì—… ë° ì•ˆì •ì„±
        self.backup_enabled = True
        self.force_write_interval = 30  # 30ì´ˆë§ˆë‹¤ ê°•ì œ ì €ì¥
        self.last_force_write = time.time()
        
        # ë¡œê±° ì„¤ì •
        self.logger = self._setup_logger()
        
        print(f"ğŸ”§ ê²¬ê³ í•œ ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” - ì„¸ì…˜: {self.session_id}")
        print(f"ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: {self.session_dir}")
    
    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger(f"RobustLogger_{self.session_id}")
        logger.setLevel(logging.INFO)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        log_file = self.session_dir / "system.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        
        return logger
    
    def _log_worker(self):
        """ë¡œê·¸ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                # íì—ì„œ ë¡œê·¸ ì—”íŠ¸ë¦¬ ì²˜ë¦¬
                try:
                    entry = self.log_queue.get(timeout=1.0)
                    self._write_log_entry(entry)
                    self.log_queue.task_done()
                except queue.Empty:
                    pass
                
                # ì£¼ê¸°ì  ê°•ì œ ì €ì¥
                current_time = time.time()
                if current_time - self.last_force_write > self.force_write_interval:
                    self._force_write_all()
                    self.last_force_write = current_time
                    
            except Exception as e:
                print(f"âš ï¸ ë¡œê·¸ ì›Œì»¤ ì˜¤ë¥˜: {e}")
    
    def _write_log_entry(self, entry: LogEntry):
        """ë¡œê·¸ ì—”íŠ¸ë¦¬ ê¸°ë¡"""
        try:
            # ì‹œìŠ¤í…œ ë¡œê·¸ì— ê¸°ë¡
            self.logger.info(f"{entry.source}: {entry.message}")
            
            # JSON ë¡œê·¸ íŒŒì¼ì— ì¶”ê°€
            json_log_file = self.session_dir / "detailed_logs.jsonl"
            with open(json_log_file, 'a', encoding='utf-8') as f:
                json.dump(asdict(entry), f, ensure_ascii=False)
                f.write('\n')
                f.flush()  # ê°•ì œ í”ŒëŸ¬ì‹œ
                
        except Exception as e:
            print(f"âš ï¸ ë¡œê·¸ ê¸°ë¡ ì˜¤ë¥˜: {e}")
    
    def _get_current_memory_usage(self) -> Dict[str, float]:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
        gpu_memory = 0.0
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated() / (1024 * 1024)  # MB
        
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì¶”ì  - psutil ì‚¬ìš© ê°€ëŠ¥ì‹œì—ë§Œ
        system_memory = 0.0
        if PSUTIL_AVAILABLE:
            try:
                system_memory = psutil.Process().memory_info().rss / (1024 * 1024)  # MB
            except:
                system_memory = 0.0
        
        return {
            "gpu_memory_mb": gpu_memory,
            "system_memory_mb": system_memory
        }
    
    def log(self, level: str, source: str, message: str, metadata: Dict[str, Any] = None):
        """ë¡œê·¸ ë©”ì‹œì§€ ê¸°ë¡"""
        if metadata is None:
            metadata = {}
        
        memory_usage = self._get_current_memory_usage()
        
        entry = LogEntry(
            timestamp=datetime.now().isoformat(),
            level=level,
            source=source,
            message=message,
            gpu_memory_mb=memory_usage["gpu_memory_mb"],
            system_memory_mb=memory_usage["system_memory_mb"],
            metadata=metadata
        )
        
        # ë©”ëª¨ë¦¬ ì¶”ì  ì—…ë°ì´íŠ¸
        self.gpu_memory_tracker.append(memory_usage["gpu_memory_mb"])
        self.system_memory_tracker.append(memory_usage["system_memory_mb"])
        
        # íì— ì¶”ê°€
        try:
            self.log_queue.put(entry, timeout=5.0)
        except queue.Full:
            print("âš ï¸ ë¡œê·¸ í ê°€ë“ì°¸ - ì§ì ‘ ê¸°ë¡")
            self._write_log_entry(entry)
    
    @contextmanager
    def test_session(self, test_name: str, test_metadata: Dict[str, Any] = None):
        """í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        if test_metadata is None:
            test_metadata = {}
        
        test_id = f"{test_name}_{int(time.time())}"
        start_time = datetime.now()
        start_memory = self._get_current_memory_usage()
        
        self.current_test = {
            "test_id": test_id,
            "test_name": test_name,
            "start_time": start_time.isoformat(),
            "start_memory": start_memory,
            "metadata": test_metadata,
            "gpu_memory_samples": [],
            "performance_samples": []
        }
        
        self.log("INFO", "TestSession", f"í…ŒìŠ¤íŠ¸ ì‹œì‘: {test_name}", {"test_id": test_id})
        
        try:
            yield test_id
            
            # ì„±ê³µ ì™„ë£Œ
            self._finalize_test_session("success")
            
        except Exception as e:
            # ì˜¤ë¥˜ ì™„ë£Œ
            self._finalize_test_session("error", {"error": str(e), "error_type": type(e).__name__})
            raise
    
    def _finalize_test_session(self, status: str, error_info: Dict[str, Any] = None):
        """í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì™„ë£Œ ì²˜ë¦¬"""
        if not self.current_test:
            return
        
        end_time = datetime.now()
        end_memory = self._get_current_memory_usage()
        
        # ì§€ì† ì‹œê°„ ê³„ì‚°
        start_dt = datetime.fromisoformat(self.current_test["start_time"])
        duration = (end_time - start_dt).total_seconds()
        
        # GPU ë©”ëª¨ë¦¬ í†µê³„
        gpu_samples = self.current_test["gpu_memory_samples"]
        if gpu_samples:
            gpu_peak = max(gpu_samples)
            gpu_avg = sum(gpu_samples) / len(gpu_samples)
        else:
            gpu_peak = end_memory["gpu_memory_mb"]
            gpu_avg = end_memory["gpu_memory_mb"]
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìƒì„±
        test_result = TestResult(
            test_id=self.current_test["test_id"],
            test_name=self.current_test["test_name"],
            start_time=self.current_test["start_time"],
            end_time=end_time.isoformat(),
            duration_seconds=duration,
            status=status,
            gpu_peak_memory_mb=gpu_peak,
            gpu_avg_memory_mb=gpu_avg,
            system_metrics={
                "start_memory": self.current_test["start_memory"],
                "end_memory": end_memory,
                "peak_system_memory": max(self.system_memory_tracker[-100:]) if self.system_memory_tracker else 0
            },
            performance_data=self.current_test.get("performance_data", {}),
            error_info=error_info
        )
        
        self.test_results.append(test_result)
        
        # ë¡œê·¸ ê¸°ë¡
        self.log("INFO", "TestSession", 
                f"í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {self.current_test['test_name']} - {status} ({duration:.2f}ì´ˆ)",
                {"test_id": self.current_test["test_id"], "status": status})
        
        # ì¦‰ì‹œ ì €ì¥
        self._save_test_result(test_result)
        
        self.current_test = None
    
    def add_performance_sample(self, sample_data: Dict[str, Any]):
        """ì„±ëŠ¥ ìƒ˜í”Œ ë°ì´í„° ì¶”ê°€"""
        if self.current_test:
            memory_usage = self._get_current_memory_usage()
            self.current_test["gpu_memory_samples"].append(memory_usage["gpu_memory_mb"])
            self.current_test["performance_samples"].append({
                "timestamp": datetime.now().isoformat(),
                "memory": memory_usage,
                "data": sample_data
            })
    
    def _save_test_result(self, test_result: TestResult):
        """ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        try:
            # ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒŒì¼
            result_file = self.session_dir / f"test_result_{test_result.test_id}.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(asdict(test_result), f, ensure_ascii=False, indent=2)
                f.flush()
                os.fsync(f.fileno())  # ê°•ì œ ë””ìŠ¤í¬ ë™ê¸°í™”
            
            # ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—…ë°ì´íŠ¸
            self._save_all_results()
            
        except Exception as e:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _save_all_results(self):
        """ì „ì²´ ê²°ê³¼ ì €ì¥"""
        try:
            # ëª¨ë“  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
            summary = {
                "session_id": self.session_id,
                "total_tests": len(self.test_results),
                "successful_tests": len([r for r in self.test_results if r.status == "success"]),
                "failed_tests": len([r for r in self.test_results if r.status in ["failed", "error"]]),
                "total_duration": sum(r.duration_seconds for r in self.test_results),
                "avg_gpu_memory": sum(r.gpu_avg_memory_mb for r in self.test_results) / len(self.test_results) if self.test_results else 0,
                "peak_gpu_memory": max(r.gpu_peak_memory_mb for r in self.test_results) if self.test_results else 0,
                "timestamp": datetime.now().isoformat(),
                "individual_results": [asdict(r) for r in self.test_results]
            }
            
            # ìš”ì•½ íŒŒì¼ ì €ì¥
            summary_file = self.session_dir / "session_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
                f.flush()
                os.fsync(f.fileno())
            
            # ë°±ì—… íŒŒì¼ë„ ìƒì„±
            if self.backup_enabled:
                backup_file = self.base_log_dir / f"backup_session_{self.session_id}.json"
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump(summary, f, ensure_ascii=False, indent=2)
                    f.flush()
                    os.fsync(f.fileno())
            
        except Exception as e:
            print(f"âš ï¸ ì „ì²´ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _force_write_all(self):
        """ëª¨ë“  ëŒ€ê¸° ì¤‘ì¸ ë¡œê·¸ ê°•ì œ ê¸°ë¡"""
        try:
            # íì˜ ëª¨ë“  ì—”íŠ¸ë¦¬ ì²˜ë¦¬
            while not self.log_queue.empty():
                try:
                    entry = self.log_queue.get_nowait()
                    self._write_log_entry(entry)
                    self.log_queue.task_done()
                except queue.Empty:
                    break
            
            # í˜„ì¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
            if self.test_results:
                self._save_all_results()
                
        except Exception as e:
            print(f"âš ï¸ ê°•ì œ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def generate_continuous_test_report(self, test_count: int = 10) -> Dict[str, Any]:
        """ì—°ì† í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
        continuous_results = self.test_results[-test_count:] if len(self.test_results) >= test_count else self.test_results
        
        if not continuous_results:
            return {"error": "No test results available"}
        
        # í†µê³„ ê³„ì‚°
        successful = [r for r in continuous_results if r.status == "success"]
        failed = [r for r in continuous_results if r.status != "success"]
        
        report = {
            "continuous_test_summary": {
                "total_tests": len(continuous_results),
                "successful_tests": len(successful),
                "failed_tests": len(failed),
                "success_rate": len(successful) / len(continuous_results) * 100,
                "total_time": sum(r.duration_seconds for r in continuous_results),
                "avg_test_time": sum(r.duration_seconds for r in continuous_results) / len(continuous_results)
            },
            "performance_metrics": {
                "avg_gpu_memory_mb": sum(r.gpu_avg_memory_mb for r in continuous_results) / len(continuous_results),
                "peak_gpu_memory_mb": max(r.gpu_peak_memory_mb for r in continuous_results),
                "memory_efficiency": "high" if max(r.gpu_peak_memory_mb for r in continuous_results) < 2000 else "medium"
            },
            "detailed_results": [asdict(r) for r in continuous_results],
            "generated_at": datetime.now().isoformat(),
            "session_id": self.session_id
        }
        
        # ë³´ê³ ì„œ ì €ì¥
        report_file = self.session_dir / f"continuous_test_report_{test_count}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
            f.flush()
            os.fsync(f.fileno())
        
        return report
    
    def shutdown(self):
        """ë¡œê¹… ì‹œìŠ¤í…œ ì¢…ë£Œ"""
        self.log("INFO", "System", "ë¡œê¹… ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹œì‘")
        
        # ëª¨ë“  ëŒ€ê¸° ë¡œê·¸ ì²˜ë¦¬
        self._force_write_all()
        
        # ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ
        self.running = False
        if self.log_thread.is_alive():
            self.log_thread.join(timeout=5.0)
        
        # ìµœì¢… ì €ì¥
        self._save_all_results()
        
        print(f"âœ… ë¡œê¹… ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ - {len(self.test_results)}ê°œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ë¨")

# ì „ì—­ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
_robust_logger = None

def get_robust_logger() -> RobustLogger:
    """ì „ì—­ ê²¬ê³ í•œ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _robust_logger
    if _robust_logger is None:
        _robust_logger = RobustLogger()
    return _robust_logger

# í¸ì˜ í•¨ìˆ˜ë“¤
def log_info(source: str, message: str, metadata: Dict[str, Any] = None):
    """INFO ë ˆë²¨ ë¡œê·¸"""
    get_robust_logger().log("INFO", source, message, metadata)

def log_error(source: str, message: str, metadata: Dict[str, Any] = None):
    """ERROR ë ˆë²¨ ë¡œê·¸"""
    get_robust_logger().log("ERROR", source, message, metadata)

def test_session(test_name: str, metadata: Dict[str, Any] = None):
    """í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    return get_robust_logger().test_session(test_name, metadata)

def add_performance_sample(sample_data: Dict[str, Any]):
    """ì„±ëŠ¥ ìƒ˜í”Œ ì¶”ê°€"""
    get_robust_logger().add_performance_sample(sample_data)

def generate_test_report(test_count: int = 10) -> Dict[str, Any]:
    """í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
    return get_robust_logger().generate_continuous_test_report(test_count)