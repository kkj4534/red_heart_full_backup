"""
ê³ ê¸‰ ë²¤ë‹´ ì¾Œë½ ê³„ì‚°ê¸° - Linux ì „ìš©
Advanced Bentham Pleasure Calculator for Linux

ê¸°ì¡´ 7ê°€ì§€ ë³€ìˆ˜ì— 6ê°œì˜ ì¶”ê°€ ê°€ì¤‘ì¹˜ ë ˆì´ì–´ë¥¼ ì ìš©í•˜ì—¬
AI ëª¨ë¸ê³¼ ê³ ê¸‰ ìˆ˜ì¹˜ ê³„ì‚°ì„ í†µí•œ ì •êµí•œ ì¾Œë½ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

__all__ = ['AdvancedBenthamCalculator']

import os
# CVE-2025-32434ëŠ” ê°€ì§œ CVE - torch_security_patch import ì œê±°
# import torch_security_patch

import logging
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import json
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from transformers import pipeline, AutoTokenizer
from sentence_transformer_singleton import SentenceTransformerManager
import scipy.stats as stats  
from scipy.optimize import minimize_scalar
import threading
import time
import asyncio

from config import ADVANCED_CONFIG, DEVICE, TORCH_DTYPE, BATCH_SIZE, MODELS_DIR, get_smart_device, ModelPriority, get_priority_based_device
from data_models import (
    HedonicValues, EmotionData, EmotionState, BenthamVariable, 
    EmotionIntensity, EthicalSituation, EnhancedHedonicResult,
    WeightLayerResult, AdvancedCalculationContext
)

# ì—ë¦¬íˆ í”„ë¡¬ ì² í•™ í†µí•©ì„ ìœ„í•œ ì¶”ê°€ ì„í¬íŠ¸
from enum import Enum

class FrommOrientation(Enum):
    """ì—ë¦¬íˆ í”„ë¡¬ì˜ ì„±ê²© ì§€í–¥ (To Have or To Be ê¸°ë°˜)"""
    HAVING = "having"  # ì†Œìœ  ì§€í–¥
    BEING = "being"   # ì¡´ì¬ ì§€í–¥
    MIXED = "mixed"   # í˜¼í•© ì§€í–¥
from bentham_v2_calculator import bentham_v2_calculator
from mixture_of_experts import create_ethics_moe, MixtureOfExperts
from three_view_scenario_system import ThreeViewScenarioSystem
from phase_controller_hook import PhaseControllerHook, PhaseType, PerformanceMetric
from legal_expert_system import get_legal_expert_system, LegalDomain, OperationMode

# ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ìš©ì„± í™•ì¸ (ê°œë°œìš© ê°„ì†Œí™”)
ADVANCED_LIBS_AVAILABLE = True

logger = logging.getLogger('RedHeart.AdvancedBenthamCalculator')


class NeuralWeightPredictor(nn.Module):
    """ì‹ ê²½ë§ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì˜ˆì¸¡ ëª¨ë¸ - ë©”ëª¨ë¦¬ ìµœì í™”ëœ ê²½ëŸ‰ ë²„ì „"""
    
    def __init__(self, input_dim: int = 50, hidden_dim: int = 256):  # 50ì°¨ì› íŠ¹ì„±ì— ë§ê²Œ ì¡°ì •
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        
        # ë²¤ë‹´ ê³„ì‚° ì‹ ê²½ë§ - 50ì°¨ì› ì…ë ¥ì— ìµœì í™”
        self.layers = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),  # ë™ì¼í•œ ì°¨ì› ìœ ì§€
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.LayerNorm(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, 64),
            nn.ReLU(),
            nn.Dropout(0.05),
            nn.Linear(64, 6),  # 6ê°œ ê°€ì¤‘ì¹˜ ë ˆì´ì–´
            nn.Sigmoid()
        )
        
        # ê°€ì¤‘ì¹˜ ë²”ìœ„ ì¡°ì •ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ë§
        self.weight_scale = nn.Parameter(torch.tensor([1.5, 1.8, 2.0, 2.5, 2.0, 1.5]))
        self.weight_bias = nn.Parameter(torch.tensor([0.3, 0.2, 0.3, 0.2, 0.4, 0.5]))
        
    def forward(self, x):
        weights = self.layers(x)
        # ê°€ì¤‘ì¹˜ë¥¼ 0.3~2.5 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
        scaled_weights = weights * self.weight_scale + self.weight_bias
        return scaled_weights


class TransformerContextAnalyzer:
    """íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ë§¥ë½ ë¶„ì„ê¸°"""
    
    def __init__(self):
        if not ADVANCED_LIBS_AVAILABLE:
            raise ImportError("ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
        # MEDIUM ëª¨ë“œ CPU ê°•ì œ ì´ˆê¸°í™” ì²´í¬
        import os
        if os.environ.get('FORCE_CPU_INIT', '0') == '1':
            self.device = torch.device('cpu')
            self.logger = logger
            self.logger.info("ğŸ“Œ FORCE_CPU_INIT: CPU ëª¨ë“œ ê°•ì œ ì´ˆê¸°í™”")
        else:
            self.device = DEVICE
            self.logger = logger  # logger ì¶”ê°€
        
        # ê°ì • ë¶„ì„ íŒŒì´í”„ë¼ì¸ (ìˆœì°¨ì  ë¡œë”©)
        def load_emotion_classifier():
            # FORCE_CPU_INIT ëª¨ë“œì—ì„œëŠ” CPU ì‚¬ìš©
            if os.environ.get('FORCE_CPU_INIT', '0') == '1':
                return pipeline(
                    "text-classification",
                    model="j-hartmann/emotion-english-distilroberta-base",
                    device=-1,  # CPUì—ì„œ ì‹¤í–‰
                    return_all_scores=True
                )
            # ì´ í•¨ìˆ˜ëŠ” ìˆœì°¨ì  ë¡œë”ì—ì„œ í˜¸ì¶œë˜ë©°, ì´ë¯¸ GPU í• ë‹¹ì´ ìŠ¹ì¸ëœ ìƒíƒœ
            return pipeline(
                "text-classification",
                model="j-hartmann/emotion-english-distilroberta-base",
                device=0,  # GPUì—ì„œ ì‹¤í–‰
                return_all_scores=True
            )
        
        # FORCE_CPU_INIT ëª¨ë“œì—ì„œëŠ” GPU ë¡œë” ê±´ë„ˆë›°ê¸°
        if os.environ.get('FORCE_CPU_INIT', '0') == '1':
            # ì§ì ‘ CPU ë¡œë“œ (GPU ë¡œë” ìš°íšŒ)
            self.emotion_classifier = pipeline(
                "text-classification",
                model="j-hartmann/emotion-english-distilroberta-base",
                device=-1,  # CPU ê°•ì œ
                return_all_scores=True
            )
            self.logger.info("ğŸ“Œ FORCE_CPU_INIT: ê°ì • ë¶„ì„ ëª¨ë¸ CPU ì§ì ‘ ë¡œë“œ")
        else:
            # ê¸°ì¡´ ìˆœì°¨ì  ë¡œë”© ìš”ì²­
            from config import get_gpu_loader
            gpu_loader = get_gpu_loader()
            emotion_device, emotion_model = gpu_loader.request_gpu_loading(
                model_id="bentham_emotion_classifier",
                priority=ModelPriority.MEDIUM,
                estimated_memory_mb=732,
                loading_function=load_emotion_classifier
            )
            
            # ë””ë°”ì´ìŠ¤ì— ë”°ë¼ ìµœì¢… ëª¨ë¸ ì„¤ì •
            if emotion_device.type == 'cuda' and emotion_model is not None:
                # GPUì—ì„œ ë¡œë“œëœ ëª¨ë¸ ì‚¬ìš©
                self.emotion_classifier = emotion_model
                self.logger.info(f"ê°ì • ë¶„ì„ ëª¨ë¸ GPU ìˆœì°¨ ë¡œë“œ ì™„ë£Œ: {emotion_device}")
            else:
                # CPUë¡œ í´ë°±
                self.emotion_classifier = pipeline(
                    "text-classification",
                    model="j-hartmann/emotion-english-distilroberta-base",
                    device=-1,
                    return_all_scores=True
                )
                self.logger.info(f"ê°ì • ë¶„ì„ ëª¨ë¸ CPU ë¡œë“œ ì™„ë£Œ: {emotion_device}")
        
        # ìœ¤ë¦¬ì  ì¶”ë¡  - í”„ë¡œì íŠ¸ ê·œì¹™: ëŒ€í˜• ëª¨ë¸ ì™„ì „ ì œê±°
        # BART/DistilBERT ëª¨ë‘ ì œê±° â†’ ê°ì • ë¶„ì„ ê²°ê³¼ ì¬í™œìš©
        self.ethical_classifier = None
        self.logger.info("âœ… ìœ¤ë¦¬ ë¶„ì„: ê°ì •â†’ìœ¤ë¦¬ ë§¤í•‘ ë°©ì‹ (ë³„ë„ ëª¨ë¸ ì—†ìŒ)")
        
        # í•œêµ­ì–´ ê°ì • ë¶„ì„ - KcELECTRAëŠ” text-classification ë¯¸ì§€ì›
        # í”„ë¡œì íŠ¸ ê·œì¹™: fallback ê¸ˆì§€, ê·¼ë³¸ì  í•´ê²°
        # í•œêµ­ì–´ í…ìŠ¤íŠ¸ëŠ” ë²ˆì—­ í›„ ì˜ì–´ ê°ì • ë¶„ë¥˜ê¸° ì‚¬ìš©
        self.korean_classifier = None  # í•œêµ­ì–´ ì „ìš© ë¶„ë¥˜ê¸° ë¹„í™œì„±í™”
        self.logger.info("í•œêµ­ì–´ ê°ì • ë¶„ì„ì€ ë²ˆì—­ í›„ ì˜ì–´ ëª¨ë¸ ì‚¬ìš©")
        
        # SentenceTransformer ì‹±ê¸€í†¤ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ë¡œë“œ ë°©ì§€
        st_singleton = SentenceTransformerManager()
        
        # paraphrase-multilingual-mpnet-base-v2 ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìœ¼ë©´ ì¬ì‚¬ìš©)
        # Claude ëª¨ë“œì—ì„œ all-MiniLM-L6-v2ê°€ ì—†ìœ¼ë¯€ë¡œ ë‹¤êµ­ì–´ ëª¨ë¸ ì‚¬ìš©
        self.context_model = st_singleton.get_model("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
        
        # FORCE_CPU_INIT ëª¨ë“œ ì²˜ë¦¬
        if os.environ.get('FORCE_CPU_INIT', '0') == '1':
            self.context_model = self.context_model.to('cpu')
            self.logger.info("ğŸ“Œ FORCE_CPU_INIT: ë¬¸ë§¥ ì„ë² ë”© ëª¨ë¸ CPU ì´ë™")
        else:
            # SentenceTransformerProxyì˜ ê²½ìš° ë””ë°”ì´ìŠ¤ ì •ë³´ë¥¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
            if hasattr(self.context_model, '_device'):
                device = self.context_model._device
            else:
                # fallback: cudaê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ cuda, ì•„ë‹ˆë©´ cpu
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.logger.info(f"ë¬¸ë§¥ ì„ë² ë”© ëª¨ë¸ ì‹±ê¸€í†¤ ì‚¬ìš©: {device}")
        
        # í† í¬ë‚˜ì´ì €ëŠ” ì‹±ê¸€í†¤ ë§¤ë‹ˆì €ì—ì„œ ê°€ì ¸ì˜¤ê¸° (ì¤‘ë³µ ë¡œë“œ ë°©ì§€)
        # ì´ë¯¸ global importê°€ ìˆìœ¼ë¯€ë¡œ ë¡œì»¬ import ì œê±°
        # í† í¬ë‚˜ì´ì €ëŠ” ëª¨ë¸ê³¼ í•¨ê»˜ ê´€ë¦¬ë˜ë¯€ë¡œ ì§ì ‘ ë¡œë“œëŠ” í”¼í•¨
        # context_modelì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê·¸ê²ƒì„ í™œìš©
        self.context_tokenizer = None  # í•„ìš”ì‹œ ëŸ°íƒ€ì„ì— ë¡œë“œ
        
        logger.info("íŠ¸ëœìŠ¤í¬ë¨¸ ë§¥ë½ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
    def analyze_context(self, text: str, language: str = "ko") -> Dict[str, Any]:
        """ì¢…í•©ì  ë§¥ë½ ë¶„ì„"""
        results = {}
        
        try:
            # 1. ê°ì • ë¶„ì„
            # í•œêµ­ì–´ë„ ì˜ì–´ ëª¨ë¸ ì‚¬ìš© (KcELECTRA í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
            emotion_results = self.emotion_classifier(text)
            # HuggingFace íŒŒì´í”„ë¼ì¸ì´ ë°°ì¹˜ ì²˜ë¦¬ë¡œ [[ê²°ê³¼]] ë°˜í™˜í•˜ëŠ” ë¬¸ì œ í•´ê²°
            if isinstance(emotion_results, list) and len(emotion_results) == 1:
                results['emotions'] = emotion_results[0]  # í‰íƒ„í™”
            else:
                results['emotions'] = emotion_results
            
            # 2. ìœ¤ë¦¬ì  ë¶„ë¥˜ - BART ì œê±°, ê°ì • ê¸°ë°˜ ë§¤í•‘
            # í”„ë¡œì íŠ¸ ê·œì¹™: ë¶ˆí•„ìš”í•œ ëŒ€í˜• ëª¨ë¸ ì œê±°
            if self.ethical_classifier is None:
                # ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ìœ¤ë¦¬ ì ìˆ˜ë¡œ ë§¤í•‘
                emotion_scores = emotion_results[0] if isinstance(emotion_results, list) else emotion_results
                ethical_mapping = {
                    'joy': 'ê°œì¸ì  ì´ìµ',
                    'anger': 'ì •ì˜ì™€ ê³µì •ì„±', 
                    'fear': 'ìƒëª…ê³¼ ì•ˆì „',
                    'sadness': 'ì·¨ì•½ê³„ì¸µ ë³´í˜¸',
                    'surprise': 'ììœ¨ì„±ê³¼ ììœ ',
                    'disgust': 'ì‚¬íšŒì  ì±…ì„'
                }
                
                ethical_scores = {}
                for emotion, label in ethical_mapping.items():
                    if isinstance(emotion_scores, dict) and 'score' in emotion_scores:
                        score = emotion_scores.get('score', 0.5)
                    else:
                        score = 0.5  # ê¸°ë³¸ê°’
                    ethical_scores[label] = score
                    
                results['ethical_aspects'] = {'scores': list(ethical_scores.values())}
            else:
                # ê¸°ì¡´ ë¶„ë¥˜ê¸°ê°€ ìˆìœ¼ë©´ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
                ethical_labels = [
                    "ìƒëª…ê³¼ ì•ˆì „", "ì •ì˜ì™€ ê³µì •ì„±", "ììœ¨ì„±ê³¼ ììœ ", 
                    "ì·¨ì•½ê³„ì¸µ ë³´í˜¸", "ì‚¬íšŒì  ì±…ì„", "ê°œì¸ì  ì´ìµ"
                ]
                ethical_results = self.ethical_classifier(text, ethical_labels)
                results['ethical_aspects'] = ethical_results
            
            # 3. ë§¥ë½ ì„ë² ë”©
            with torch.no_grad():
                # SentenceTransformerProxyì˜ encode ë©”ì„œë“œ ì‚¬ìš©
                # context_tokenizerê°€ Noneì´ë¯€ë¡œ context_model.encode ì§ì ‘ ì‚¬ìš©
                embeddings = self.context_model.encode(text, convert_to_tensor=True)
                
                # í…ì„œë¡œ ë³€í™˜ëœ ì„ë² ë”© ì²˜ë¦¬
                if torch.is_tensor(embeddings):
                    results['context_embedding'] = embeddings.cpu().numpy()
                elif isinstance(embeddings, list):
                    # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° numpy arrayë¡œ ë³€í™˜
                    import numpy as np
                    results['context_embedding'] = np.array(embeddings)
                else:
                    results['context_embedding'] = embeddings
                
            # 4. ë³µì¡ë„ ë¶„ì„
            complexity_metrics = self._analyze_complexity(text)
            results['complexity'] = complexity_metrics
            
        except Exception as e:
            logger.error(f"ë§¥ë½ ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise RuntimeError(
                f"íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ë§¥ë½ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}. "
                f"ì ì ˆí•œ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì…ë ¥ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                f"ëŒ€ì²´ ë¶„ì„ ë°©ë²•ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì •í™•í•œ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
            
        return results
        
    def _analyze_complexity(self, text: str) -> Dict[str, float]:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ ë¶„ì„"""
        words = text.split()
        sentences = text.split('.')
        
        return {
            'word_count': len(words),
            'sentence_count': len(sentences),
            'avg_word_length': np.mean([len(word) for word in words]) if words else 0,
            'lexical_diversity': len(set(words)) / len(words) if words else 0,
            'structural_complexity': len(sentences) / len(words) if words else 0
        }
        


class AdvancedWeightLayer:
    """ê³ ê¸‰ ê°€ì¤‘ì¹˜ ë ˆì´ì–´ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, neural_predictor: NeuralWeightPredictor = None):
        self.name = name
        self.neural_predictor = neural_predictor
        self.last_contribution = 0.0
        self.last_reasoning = ""
        self.confidence_score = 0.0
        
        # ML ëª¨ë¸ ì´ˆê¸°í™”
        self.ml_model = RandomForestRegressor(
            n_estimators=100, 
            random_state=42,
            n_jobs=-1 if ADVANCED_CONFIG['use_multiprocessing'] else 1
        )
        self.feature_scaler = StandardScaler()
        self.is_trained = False
        
        # ëª¨ë¸ ë¡œë“œ ì‹œë„ (ì´ˆê¸°í™” ì‹œì ì—)
        self._try_load_trained_model()
        
    def compute_weight(self, context: AdvancedCalculationContext) -> float:
        """ê³ ê¸‰ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        try:
            # 1. íŠ¹ì„± ë²¡í„° ì¶”ì¶œ
            features = self._extract_features(context)
            
            # 2. ì‹ ê²½ë§ ì˜ˆì¸¡ (ê°€ëŠ¥í•œ ê²½ìš°)
            if self.neural_predictor and torch.is_tensor(features):
                with torch.no_grad():
                    neural_weight = self.neural_predictor(features.unsqueeze(0))
                    weight = neural_weight[0, self._get_layer_index()].item()
            else:
                # 3. ML ëª¨ë¸ ì˜ˆì¸¡
                weight = self._ml_predict(features)
                
            # 4. ê·œì¹™ ê¸°ë°˜ ë³´ì •
            weight = self._apply_rule_based_correction(weight, context)
            
            # 5. ì‹ ë¢°ë„ ê³„ì‚°
            self.confidence_score = self._calculate_confidence(context, weight)
            
            return max(0.3, min(2.5, weight))
            
        except Exception as e:
            logger.error(f"{self.name} ê°€ì¤‘ì¹˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 1.0
            
    def _extract_features(self, context: AdvancedCalculationContext) -> np.ndarray:
        """ë§¥ë½ì—ì„œ íŠ¹ì„± ì¶”ì¶œ - ML ëª¨ë¸ìš©ê³¼ ë¶„ì„ìš© ë¶„ë¦¬"""
        
        # input_valuesê°€ listì¸ ê²½ìš° dictë¡œ ë³€í™˜ (GPT ì œì•ˆ - ëª¨ë“  ë©”ì„œë“œì— ê°€ë“œ ì¶”ê°€)
        if hasattr(context, 'input_values') and isinstance(context.input_values, list):
            if len(context.input_values) == 7:
                keys = ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']
                context.input_values = {k: float(v) for k, v in zip(keys, context.input_values)}
                logger.debug("_extract_features: input_valuesë¥¼ listâ†’dictë¡œ ë³€í™˜")
            else:
                raise ValueError(f"input_values must be dict or list(len=7), got list(len={len(context.input_values)})")
        
        # ML ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆê³  5ê°œ íŠ¹ì„±ì„ ê¸°ëŒ€í•˜ë©´ 5ê°œë§Œ ë°˜í™˜
        if self.is_trained and hasattr(self.ml_model, 'n_features_in_') and self.ml_model.n_features_in_ == 5:
            # ML ëª¨ë¸ìš© í•µì‹¬ íŠ¹ì„± (5ê°œ) - ê°€ì¥ ì¤‘ìš”í•œ ë²¤ë‹´ ë³€ìˆ˜ë“¤
            ml_features = []
            for var in ['intensity', 'duration', 'certainty', 'propinquity', 'extent']:
                if var not in context.input_values:
                    raise KeyError(f"í•„ìˆ˜ í‚¤ ëˆ„ë½: {var} (NO FALLBACK)")
                ml_features.append(context.input_values[var])
            return np.array(ml_features, dtype=np.float32)
        
        # ì „ì²´ ë¶„ì„ìš© íŠ¹ì„± (50ê°œ)
        features = []
        
        # ê¸°ë³¸ ë²¤ë‹´ ë³€ìˆ˜ë“¤ (Bentham v2 í™•ì¥)
        for var in ['intensity', 'duration', 'certainty', 'propinquity', 
                   'fecundity', 'purity', 'extent', 'external_cost',
                   'redistribution_effect', 'self_damage']:
            # í•„ìˆ˜ 7ê°œ í‚¤ëŠ” ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•¨
            if var in ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']:
                if var not in context.input_values:
                    raise KeyError(f"í•„ìˆ˜ ë²¤ë‹´ ë³€ìˆ˜ ëˆ„ë½: {var} (NO FALLBACK)")
                features.append(context.input_values[var])
            else:
                # í™•ì¥ ë³€ìˆ˜ëŠ” ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0.0 (ì˜ë¯¸ìƒ 'ì—†ìŒ')
                if var in context.input_values:
                    features.append(context.input_values[var])
                else:
                    features.append(0.0)  # í™•ì¥ ë³€ìˆ˜ëŠ” ì„ íƒì 
            
        # ê°ì • íŠ¹ì„±
        if context.emotion_data:
            from data_models import emotion_intensity_to_float
            valence_val = emotion_intensity_to_float(context.emotion_data.valence)
            arousal_val = emotion_intensity_to_float(context.emotion_data.arousal)
            intensity_val = float(context.emotion_data.intensity.value) / 4.0 if hasattr(context.emotion_data.intensity, 'value') else emotion_intensity_to_float(context.emotion_data.intensity)
            confidence_val = emotion_intensity_to_float(context.emotion_data.confidence)
            
            features.extend([
                valence_val,
                arousal_val,
                intensity_val,
                confidence_val
            ])
        else:
            features.extend([0.0, 0.0, 0.5, 0.5])
            
        # ë§¥ë½ ì„ë² ë”© (ì²˜ìŒ 20ì°¨ì›ë§Œ ì‚¬ìš©)
        if hasattr(context, 'context_embedding') and context.context_embedding is not None:
            # numpy arrayë¡œ í™•ì‹¤íˆ ë³€í™˜
            import numpy as np
            if isinstance(context.context_embedding, list):
                embedding = np.array(context.context_embedding)
            else:
                embedding = context.context_embedding
            
            # flattenê³¼ ìŠ¬ë¼ì´ì‹±
            if hasattr(embedding, 'flatten'):
                embedding = embedding.flatten()[:20]
            else:
                embedding = np.array(embedding).flatten()[:20]
            
            features.extend(embedding.tolist())
        else:
            features.extend([0.0] * 20)
            
        # ì¶”ê°€ ë§¥ë½ ì •ë³´
        features.extend([
            context.affected_count / 100.0,  # ì •ê·œí™”
            min(context.duration_seconds / 3600.0, 1.0),  # ì‹œê°„ ì •ê·œí™”
            context.information_quality,
            context.uncertainty_level
        ])
        
        # ì´ 50ì°¨ì› íŠ¹ì„± ë²¡í„°
        while len(features) < 50:
            features.append(0.0)
            
        return np.array(features[:50], dtype=np.float32)
    
    def _try_load_trained_model(self):
        """í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì‹œë„"""
        try:
            import joblib
            from pathlib import Path
            
            # WSL í˜¸í™˜ì„±ì„ ìœ„í•´ os.path ì‚¬ìš©
            model_dir = os.path.join(MODELS_DIR, "bentham_models")
            layer_name = getattr(self, 'layer_name', 'contextual')  # ê¸°ë³¸ê°’
            
            model_path = os.path.join(model_dir, f"{layer_name}_model.joblib")
            scaler_path = os.path.join(model_dir, f"{layer_name}_scaler.joblib")
            
            if os.path.exists(model_path) and os.path.exists(scaler_path):
                self.ml_model = joblib.load(model_path)
                self.feature_scaler = joblib.load(scaler_path)
                self.is_trained = True
                logger.info(f"{layer_name} ML ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning(f"í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_path}")
                
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
    def _ml_predict(self, features: np.ndarray) -> float:
        """ML ëª¨ë¸ ì˜ˆì¸¡"""
        if not self.is_trained:
            logger.warning(f"{self.name} ML ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ ê°€ì¤‘ì¹˜ ë°˜í™˜")
            return 1.0
            
        try:
            # íŠ¹ì„± í¬ê¸° í™•ì¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì¬ì´ˆê¸°í™”
            if hasattr(self.feature_scaler, 'n_features_in_'):
                expected_features = self.feature_scaler.n_features_in_
                if features.shape[0] != expected_features:
                    logger.warning(f"{self.name} íŠ¹ì„± í¬ê¸° ë¶ˆì¼ì¹˜ ({features.shape[0]} vs {expected_features}). ìŠ¤ì¼€ì¼ëŸ¬ ì¬ì´ˆê¸°í™”")
                    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ìŠ¤ì¼€ì¼ëŸ¬ ì¬í›ˆë ¨ - í”„ë¡œì íŠ¸ ê·œì¹™: ë”ë¯¸ ë°ì´í„° ê¸ˆì§€
                    # í˜„ì¬ íŠ¹ì„±ì„ ë³µì œí•˜ì—¬ ë³€ë™ì„± ìˆëŠ” í›ˆë ¨ ë°ì´í„° ìƒì„±
                    real_data = np.tile(features.reshape(1, -1), (10, 1))
                    # ì‹¤ì œ ë°ì´í„°ì˜ ë³€ë™ì„± ë°˜ì˜ (ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€)
                    real_data += np.random.normal(0, 0.01, real_data.shape)
                    self.feature_scaler.fit(real_data)
            else:
                # ìŠ¤ì¼€ì¼ëŸ¬ê°€ í›ˆë ¨ë˜ì§€ ì•Šì€ ê²½ìš° í˜„ì¬ íŠ¹ì„±ìœ¼ë¡œ ì´ˆê¸°í™”
                logger.info(f"{self.name} ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ {features.shape[0]}ì°¨ì›ìœ¼ë¡œ ì´ˆê¸°í™”")
                # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™” - í”„ë¡œì íŠ¸ ê·œì¹™: ë”ë¯¸ ë°ì´í„° ê¸ˆì§€
                real_data = np.tile(features.reshape(1, -1), (10, 1))
                real_data += np.random.normal(0, 0.01, real_data.shape)
                self.feature_scaler.fit(real_data)
            
            features_scaled = self.feature_scaler.transform(features.reshape(1, -1))
            
            # ML ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” íŠ¹ì„± ìˆ˜ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if hasattr(self.ml_model, 'n_features_in_'):
                expected_features = self.ml_model.n_features_in_
                if features_scaled.shape[1] != expected_features:
                    # íŠ¹ì„± ìˆ˜ ì¡°ì •: ML ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ë§Œí¼ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ íŒ¨ë”©
                    if expected_features == 5 and features_scaled.shape[1] > 5:
                        # 50ê°œ íŠ¹ì„± ì¤‘ ì²˜ìŒ 5ê°œë§Œ ì‚¬ìš©
                        features_scaled = features_scaled[:, :5]
                        logger.debug(f"{self.name}: 50ê°œ íŠ¹ì„± ì¤‘ 5ê°œë§Œ ì‚¬ìš©")
                    elif expected_features == 50 and features_scaled.shape[1] == 5:
                        # 5ê°œ íŠ¹ì„±ì„ 50ê°œë¡œ íŒ¨ë”© (ë‚˜ë¨¸ì§€ëŠ” 0)
                        padded = np.zeros((1, 50))
                        padded[:, :5] = features_scaled
                        features_scaled = padded
                        logger.debug(f"{self.name}: 5ê°œ íŠ¹ì„±ì„ 50ê°œë¡œ íŒ¨ë”©")
                    else:
                        logger.warning(f"{self.name}: ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” íŠ¹ì„± ìˆ˜ ë¶ˆì¼ì¹˜ ({features_scaled.shape[1]} vs {expected_features})")
                        return 1.0
            
            prediction = self.ml_model.predict(features_scaled)[0]
            
            # ì˜ˆì¸¡ê°’ì„ í•©ë¦¬ì ì¸ ë²”ìœ„ë¡œ ì œí•œ
            prediction = max(0.5, min(2.0, prediction))
            
            return prediction
        except Exception as e:
            logger.warning(f"{self.name} ML ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}. ê¸°ë³¸ ê°€ì¤‘ì¹˜ ë°˜í™˜")
            return 1.0
        
    def _apply_rule_based_correction(self, weight: float, 
                                   context: AdvancedCalculationContext) -> float:
        """ê·œì¹™ ê¸°ë°˜ ë³´ì • (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        return weight
        
    def _calculate_confidence(self, context: AdvancedCalculationContext, 
                            weight: float) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_factors = []
        
        # ë°ì´í„° ì™„ì „ì„± (Bentham v2 í™•ì¥: 10ê°œ ë³€ìˆ˜)
        completeness = len([v for v in context.input_values.values() if v != 0.5]) / 10
        confidence_factors.append(completeness)
        
        # ì •ë³´ í’ˆì§ˆ
        confidence_factors.append(context.information_quality)
        
        # ë¶ˆí™•ì‹¤ì„± (ì—­ìˆ˜)
        confidence_factors.append(1.0 - context.uncertainty_level)
        
        # ê°€ì¤‘ì¹˜ ì•ˆì •ì„± (ê·¹ë‹¨ê°’ì´ ì•„ë‹ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„)
        weight_stability = 1.0 - abs(weight - 1.0) / 1.5
        confidence_factors.append(max(0.0, weight_stability))
        
        return float(np.mean(confidence_factors))
        
    def _get_layer_index(self) -> int:
        """ë ˆì´ì–´ ì¸ë±ìŠ¤ ë°˜í™˜ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        return 0
        
    def get_contribution(self) -> WeightLayerResult:
        """ê¸°ì—¬ë„ ì •ë³´ ë°˜í™˜"""
        return WeightLayerResult(
            layer_name=self.name,
            weight_factor=1.0 + self.last_contribution,
            contribution_score=abs(self.last_contribution),
            confidence=self.confidence_score,
            metadata={'reasoning': self.last_reasoning}
        )


class AdvancedContextualWeightLayer(AdvancedWeightLayer):
    """ê³ ê¸‰ ìƒí™©ì  ë§¥ë½ ê°€ì¤‘ì¹˜ ë ˆì´ì–´"""
    
    def __init__(self, neural_predictor: NeuralWeightPredictor = None):
        super().__init__("ê³ ê¸‰ ìƒí™©ì  ë§¥ë½", neural_predictor)
        
    def _get_layer_index(self) -> int:
        return 0
        
    def _apply_rule_based_correction(self, weight: float, 
                                   context: AdvancedCalculationContext) -> float:
        """ìƒí™©ì  ë§¥ë½ ê·œì¹™ ê¸°ë°˜ ë³´ì •"""
        corrections = []
        reasoning_parts = []
        
        # ë³µì¡ë„ ê¸°ë°˜ ë³´ì •
        if hasattr(context, 'complexity_metrics'):
            complexity = context.complexity_metrics
            if complexity.get('structural_complexity', 0) > 0.1:
                correction = 1.2
                corrections.append(correction)
                reasoning_parts.append("ë†’ì€ êµ¬ì¡°ì  ë³µì¡ë„ (+20%)")
                
        # ì‚¬íšŒì  ë§¥ë½ ë³´ì •
        if hasattr(context, 'social_context'):
            social = context.social_context
            if social.get('impact_scope') == 'community':
                correction = 1.3
                corrections.append(correction)
                reasoning_parts.append("ê³µë™ì²´ ì˜í–¥ (+30%)")
                
        # ë³´ì • ì ìš©
        if corrections:
            final_correction = np.mean(corrections)
            weight *= final_correction
            
        self.last_contribution = weight - 1.0
        self.last_reasoning = " | ".join(reasoning_parts) if reasoning_parts else "ê¸°ë³¸ ë§¥ë½"
        
        return weight


class AdvancedTemporalWeightLayer(AdvancedWeightLayer):
    """ê³ ê¸‰ ì‹œê°„ì  ì˜í–¥ ê°€ì¤‘ì¹˜ ë ˆì´ì–´"""
    
    def __init__(self, neural_predictor: NeuralWeightPredictor = None):
        super().__init__("ê³ ê¸‰ ì‹œê°„ì  ì˜í–¥", neural_predictor)
        
    def _get_layer_index(self) -> int:
        return 1
        
    def _apply_rule_based_correction(self, weight: float, 
                                   context: AdvancedCalculationContext) -> float:
        """ì‹œê°„ì  ì˜í–¥ ê·œì¹™ ê¸°ë°˜ ë³´ì •"""
        corrections = []
        reasoning_parts = []
        
        # ì‹œê°„ í• ì¸ í•¨ìˆ˜ ì ìš©
        time_discount = self._calculate_temporal_discount(context.duration_seconds)
        if time_discount != 1.0:
            corrections.append(time_discount)
            reasoning_parts.append(f"ì‹œê°„ í• ì¸ ì ìš© ({(time_discount-1)*100:+.1f}%)")
            
        # ê¸´ê¸‰ì„± ê¸°ë°˜ ë³´ì •
        if hasattr(context, 'urgency_level'):
            urgency = context.urgency_level
            if urgency > 0.8:
                correction = 1.4
                corrections.append(correction)
                reasoning_parts.append("ë†’ì€ ê¸´ê¸‰ì„± (+40%)")
            elif urgency < 0.3:
                correction = 0.7
                corrections.append(correction)
                reasoning_parts.append("ë‚®ì€ ê¸´ê¸‰ì„± (-30%)")
                
        # ë³´ì • ì ìš©
        if corrections:
            final_correction = np.mean(corrections)
            weight *= final_correction
            
        self.last_contribution = weight - 1.0
        self.last_reasoning = " | ".join(reasoning_parts) if reasoning_parts else "ê¸°ë³¸ ì‹œê°„ ì˜í–¥"
        
        return weight
        
    def _calculate_temporal_discount(self, duration_seconds: float) -> float:
        """ì‹œê°„ í• ì¸ ê³„ìˆ˜ ê³„ì‚°"""
        # í•˜ì´í¼ë³¼ë¦­ í• ì¸ í•¨ìˆ˜ ì‚¬ìš©
        k = 0.01  # í• ì¸ ìƒìˆ˜
        t = duration_seconds / 3600.0  # ì‹œê°„ ë‹¨ìœ„ ë³€í™˜
        
        discount_factor = 1 / (1 + k * t)
        return min(1.2, max(0.5, discount_factor))


class AdvancedSocialWeightLayer(AdvancedWeightLayer):
    """ê³ ê¸‰ ì‚¬íšŒì  íŒŒê¸‰ ê°€ì¤‘ì¹˜ ë ˆì´ì–´"""
    
    def __init__(self, neural_predictor: NeuralWeightPredictor = None):
        super().__init__("ê³ ê¸‰ ì‚¬íšŒì  íŒŒê¸‰", neural_predictor)
        
    def _get_layer_index(self) -> int:
        return 2
        
    def _apply_rule_based_correction(self, weight: float, 
                                   context: AdvancedCalculationContext) -> float:
        """ì‚¬íšŒì  íŒŒê¸‰ ê·œì¹™ ê¸°ë°˜ ë³´ì •"""
        corrections = []
        reasoning_parts = []
        
        # ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ê³„ì‚°
        network_multiplier = self._calculate_network_effect(context.affected_count)
        if network_multiplier != 1.0:
            corrections.append(network_multiplier)
            reasoning_parts.append(f"ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ({(network_multiplier-1)*100:+.1f}%)")
            
        # ì‚¬íšŒì  ì§€ìœ„ ê³ ë ¤
        if hasattr(context, 'social_status'):
            status = context.social_status
            if status == 'influential':
                correction = 1.3
                corrections.append(correction)
                reasoning_parts.append("ì˜í–¥ë ¥ ìˆëŠ” ì§€ìœ„ (+30%)")
            elif status == 'vulnerable':
                correction = 1.4
                corrections.append(correction)
                reasoning_parts.append("ì·¨ì•½ê³„ì¸µ ë³´í˜¸ (+40%)")
                
        # ë³´ì • ì ìš©
        if corrections:
            final_correction = np.mean(corrections)
            weight *= final_correction
            
        self.last_contribution = weight - 1.0
        self.last_reasoning = " | ".join(reasoning_parts) if reasoning_parts else "ê°œì¸ì  ì˜í–¥"
        
        return weight
        
    def _calculate_network_effect(self, affected_count: int) -> float:
        """ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ê³„ì‚°"""
        # ë©±ë²•ì¹™ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ íš¨ê³¼
        if affected_count <= 1:
            return 1.0
        
        # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì¦ê°€
        network_effect = 1.0 + 0.1 * np.log10(affected_count)
        return min(2.0, network_effect)


class AdvancedEthicalWeightLayer(AdvancedWeightLayer):
    """ê³ ê¸‰ ìœ¤ë¦¬ì  ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ ë ˆì´ì–´"""
    
    def __init__(self, neural_predictor: NeuralWeightPredictor = None):
        super().__init__("ê³ ê¸‰ ìœ¤ë¦¬ì  ì¤‘ìš”ë„", neural_predictor)
        
    def _get_layer_index(self) -> int:
        return 3
        
    def _apply_rule_based_correction(self, weight: float, 
                                   context: AdvancedCalculationContext) -> float:
        """ìœ¤ë¦¬ì  ì¤‘ìš”ë„ ê·œì¹™ ê¸°ë°˜ ë³´ì •"""
        corrections = []
        reasoning_parts = []
        
        # ìœ¤ë¦¬ì  ì›ì¹™ ê¸°ë°˜ ë³´ì •
        ethical_scores = self._calculate_ethical_scores(context)
        
        for principle, score in ethical_scores.items():
            if score > 0.7:
                correction = 1.0 + score * 0.5
                corrections.append(correction)
                reasoning_parts.append(f"{principle} ë†’ìŒ (+{(correction-1)*100:.0f}%)")
            elif score < 0.3:
                correction = 1.0 - (0.3 - score) * 0.3
                corrections.append(correction)
                reasoning_parts.append(f"{principle} ë‚®ìŒ ({(correction-1)*100:.0f}%)")
                
        # ë³´ì • ì ìš©
        if corrections:
            final_correction = np.mean(corrections)
            weight *= final_correction
            
        self.last_contribution = weight - 1.0
        self.last_reasoning = " | ".join(reasoning_parts) if reasoning_parts else "ìœ¤ë¦¬ì  ì¤‘ë¦½"
        
        return weight
        
    def _calculate_ethical_scores(self, context: AdvancedCalculationContext) -> Dict[str, float]:
        """ìœ¤ë¦¬ì  ì›ì¹™ë³„ ì ìˆ˜ ê³„ì‚°"""
        scores = {}
        
        # ìƒëª…ê³¼ ì•ˆì „
        if hasattr(context, 'life_impact_level'):
            scores['ìƒëª…ê³¼ ì•ˆì „'] = context.life_impact_level
        else:
            scores['ìƒëª…ê³¼ ì•ˆì „'] = 0.5
            
        # ì •ì˜ì™€ ê³µì •ì„±
        if hasattr(context, 'justice_level'):
            scores['ì •ì˜ì™€ ê³µì •ì„±'] = context.justice_level
        else:
            scores['ì •ì˜ì™€ ê³µì •ì„±'] = 0.5
            
        # ììœ¨ì„±ê³¼ ììœ 
        if hasattr(context, 'autonomy_level'):
            scores['ììœ¨ì„±ê³¼ ììœ '] = context.autonomy_level
        else:
            scores['ììœ¨ì„±ê³¼ ììœ '] = 0.5
            
        return scores


class AdvancedEmotionalWeightLayer(AdvancedWeightLayer):
    """ê³ ê¸‰ ê°ì •ì  ê°•ë„ ê°€ì¤‘ì¹˜ ë ˆì´ì–´ - ê°ì • ê¸°ë°˜ ì •ì„±ì  ì˜ì—­ ê°•í™”"""
    
    def __init__(self, neural_predictor: NeuralWeightPredictor = None):
        super().__init__("ê³ ê¸‰ ê°ì •ì  ê°•ë„", neural_predictor)
        
        # ê°ì •ë³„ ì¾Œë½/ê³ í†µ ë§¤í•‘ (ì—°êµ¬ ê¸°ë°˜)
        self.emotion_hedonic_mapping = {
            'joy': {'valence': 0.85, 'intensity_multiplier': 1.3, 'duration_factor': 1.2},
            'trust': {'valence': 0.6, 'intensity_multiplier': 1.1, 'duration_factor': 1.4},
            'anticipation': {'valence': 0.4, 'intensity_multiplier': 1.0, 'duration_factor': 0.8},
            'surprise': {'valence': 0.1, 'intensity_multiplier': 1.4, 'duration_factor': 0.5},
            'neutral': {'valence': 0.0, 'intensity_multiplier': 1.0, 'duration_factor': 1.0},
            'disgust': {'valence': -0.6, 'intensity_multiplier': 1.2, 'duration_factor': 1.1},
            'sadness': {'valence': -0.7, 'intensity_multiplier': 1.1, 'duration_factor': 1.5},
            'anger': {'valence': -0.8, 'intensity_multiplier': 1.4, 'duration_factor': 0.9},
            'fear': {'valence': -0.9, 'intensity_multiplier': 1.5, 'duration_factor': 1.3}
        }
        
        # ê°ì • ì¡°í•© íš¨ê³¼ (ê°ì •ì´ ë³µí•©ì ì¼ ë•Œ)
        self.emotion_interaction_effects = {
            ('joy', 'trust'): 1.2,  # ê¸ì •ì  ì‹œë„ˆì§€
            ('sadness', 'fear'): 1.3,  # ë¶€ì •ì  ì¦í­
            ('anger', 'disgust'): 1.25,  # ê±°ë¶€ê° ì¦í­
            ('surprise', 'fear'): 1.15,  # ë†€ëŒê³¼ ë‘ë ¤ì›€
            ('anticipation', 'joy'): 1.1   # ê¸°ëŒ€ì™€ ê¸°ì¨
        }
        
    def _get_layer_index(self) -> int:
        return 4
        
    def _apply_rule_based_correction(self, weight: float, 
                                   context: AdvancedCalculationContext) -> float:
        """ê°ì •ì  ê°•ë„ ê·œì¹™ ê¸°ë°˜ ë³´ì • - ì •ì„±ì  ì˜ì—­ ê°•í™”"""
        corrections = []
        reasoning_parts = []
        
        if context.emotion_data:
            # 1. ê¸°ë³¸ ê°ì • ë¶„ì„
            primary_emotion = context.emotion_data.primary_emotion.value if hasattr(context.emotion_data.primary_emotion, 'value') else str(context.emotion_data.primary_emotion)
            emotion_profile = self.emotion_hedonic_mapping.get(primary_emotion, self.emotion_hedonic_mapping['neutral'])
            
            # ê°ì •ê°€(valence) ê¸°ë°˜ ë³´ì •
            valence_correction = 1.0 + (emotion_profile['valence'] * 0.3)
            corrections.append(valence_correction)
            reasoning_parts.append(f"ê°ì •ê°€ ì˜í–¥ ({emotion_profile['valence']:+.2f}): {(valence_correction-1)*100:+.1f}%")
            
            # 2. ê°ì • ê°•ë„ ì„¸ë°€ ë¶„ì„
            emotion_magnitude = np.sqrt(
                context.emotion_data.valence**2 + 
                context.emotion_data.arousal**2
            )
            
            intensity_multiplier = emotion_profile['intensity_multiplier']
            
            # í¼ì§€ ë¡œì§: ë¶€ë“œëŸ¬ìš´ ê°ì • ê°•ë„ ì „í™˜
            extreme_membership = self._fuzzy_membership(emotion_magnitude, 0.7, 1.0)
            high_membership = self._fuzzy_membership(emotion_magnitude, 0.5, 0.8)
            low_membership = self._fuzzy_membership(emotion_magnitude, 0.0, 0.4)
            
            # ì—°ì†ì  ë³´ì • ê³„ì‚° (ë”±ë”±í•œ ifë¬¸ ëŒ€ì‹ )
            extreme_correction = 1.0 + (extreme_membership * intensity_multiplier * 0.6)
            high_correction = 1.0 + (high_membership * intensity_multiplier * 0.4)
            low_correction = 1.0 - (low_membership * 0.3)
            
            # ê°€ì¤‘ ì¡°í•©
            correction = (extreme_correction * extreme_membership + 
                         high_correction * high_membership + 
                         low_correction * low_membership) / max(0.1, extreme_membership + high_membership + low_membership)
            
            corrections.append(correction)
            reasoning_parts.append(f"ì—°ì†ì  ê°ì • ê°•ë„ ({(correction-1)*100:+.0f}%)")
            
            # 3. ê°ì„±ë„(arousal) ê¸°ë°˜ ë²¤ë‹´ ë³€ìˆ˜ ì¡°ì •
            from data_models import emotion_intensity_to_float
            arousal_val = emotion_intensity_to_float(context.emotion_data.arousal)
            arousal_impact = self._calculate_arousal_impact(arousal_val, context)
            if arousal_impact != 1.0:
                corrections.append(arousal_impact)
                reasoning_parts.append(f"ê°ì„±ë„ ì¡°ì • ({(arousal_impact-1)*100:+.1f}%)")
            
            # 4. ê°ì • ì§€ì†ì„± ê³ ë ¤
            duration_factor = emotion_profile['duration_factor']
            if hasattr(context, 'duration_seconds') and context.duration_seconds:
                expected_emotion_duration = emotion_magnitude * duration_factor * 3600  # ì‹œê°„ ë‹¨ìœ„
                if context.duration_seconds > expected_emotion_duration:
                    duration_correction = 1.1
                    corrections.append(duration_correction)
                    reasoning_parts.append("ê°ì • ì§€ì†ì„± ë³´ì • (+10%)")
            
            # 5. 2ì°¨ ê°ì • íš¨ê³¼ (ë³µí•© ê°ì •)
            if hasattr(context.emotion_data, 'secondary_emotions') and context.emotion_data.secondary_emotions:
                secondary_correction = self._calculate_secondary_emotion_effects(
                    primary_emotion, context.emotion_data.secondary_emotions
                )
                if secondary_correction != 1.0:
                    corrections.append(secondary_correction)
                    reasoning_parts.append(f"ë³µí•© ê°ì • íš¨ê³¼ ({(secondary_correction-1)*100:+.1f}%)")
            
            # 6. ê°ì • ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
            confidence_weight = max(0.5, context.emotion_data.confidence)
            if context.emotion_data.confidence > 0.8:
                correction = 1.0 + (context.emotion_data.confidence - 0.8) * 0.5
                corrections.append(correction)
                reasoning_parts.append(f"ë†’ì€ ê°ì • ì‹ ë¢°ë„ (+{(correction-1)*100:.0f}%)")
            elif context.emotion_data.confidence < 0.5:
                correction = 0.8 + context.emotion_data.confidence * 0.4
                corrections.append(correction)
                reasoning_parts.append(f"ë‚®ì€ ê°ì • ì‹ ë¢°ë„ ({(correction-1)*100:.0f}%)")
            
            # 7. ë¬¸í™”ì  ê°ì • ìš”ì†Œ (í•œêµ­ì–´ íŠ¹í™”)
            if hasattr(context.emotion_data, 'language') and context.emotion_data.language == 'ko':
                cultural_correction = self._apply_korean_cultural_emotion_correction(context)
                if cultural_correction != 1.0:
                    corrections.append(cultural_correction)
                    reasoning_parts.append(f"í•œêµ­ ë¬¸í™”ì  ê°ì • ({(cultural_correction-1)*100:+.1f}%)")
                
        # ë³´ì • ì ìš© (ê°€ì¤‘ í‰ê· )
        if corrections:
            # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ í‰ê· 
            weights = [1.0] * len(corrections)
            if context.emotion_data and hasattr(context.emotion_data, 'confidence'):
                # ì‹ ë¢°ë„ê°€ ë†’ì„ìˆ˜ë¡ ë” ê°•í•œ ë³´ì • ì ìš©
                confidence_factor = context.emotion_data.confidence
                weights = [w * confidence_factor for w in weights]
            
            final_correction = np.average(corrections, weights=weights)
            weight *= final_correction
            
        self.last_contribution = weight - 1.0
        self.last_reasoning = " | ".join(reasoning_parts) if reasoning_parts else "ì¤‘ê°„ ê°ì • ê°•ë„"
        
        return weight
    
    def _calculate_arousal_impact(self, arousal: float, context: AdvancedCalculationContext) -> float:
        """ê°ì„±ë„ê°€ ë²¤ë‹´ ë³€ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ê³„ì‚°"""
        # ê°ì„±ë„ì— ë”°ë¥¸ ë²¤ë‹´ ë³€ìˆ˜ë³„ ì˜í–¥
        if arousal > 0.7:  # ë†’ì€ ê°ì„±ë„
            # ê°•ë„(intensity)ì™€ í™•ì‹¤ì„±(certainty) ì¦ê°€, ì§€ì†ì„±(duration) ê°ì†Œ
            return 1.2
        elif arousal < -0.3:  # ë‚®ì€ ê°ì„±ë„
            # ê°•ë„ ê°ì†Œ, ì§€ì†ì„± ì¦ê°€
            return 0.9
        else:
            return 1.0
    
    def _calculate_secondary_emotion_effects(self, primary_emotion: str, 
                                           secondary_emotions: dict) -> float:
        """2ì°¨ ê°ì •ë“¤ì˜ ë³µí•© íš¨ê³¼ ê³„ì‚°"""
        interaction_effects = []
        
        for secondary_emotion, intensity in secondary_emotions.items():
            if hasattr(secondary_emotion, 'value'):
                secondary_name = secondary_emotion.value
            else:
                secondary_name = str(secondary_emotion)
                
            # ê°ì • ì¡°í•© íš¨ê³¼ í™•ì¸
            emotion_pair = tuple(sorted([primary_emotion, secondary_name]))
            if emotion_pair in self.emotion_interaction_effects:
                effect = self.emotion_interaction_effects[emotion_pair]
                weighted_effect = 1.0 + (effect - 1.0) * intensity
                interaction_effects.append(weighted_effect)
        
        if interaction_effects:
            return np.mean(interaction_effects)
        else:
            return 1.0
    
    def _apply_korean_cultural_emotion_correction(self, context: AdvancedCalculationContext) -> float:
        """í•œêµ­ ë¬¸í™”ì  ê°ì • ìš”ì†Œ ë³´ì •"""
        # í•œêµ­ ë¬¸í™” íŠ¹ìœ ì˜ ê°ì • (í•œ, ì •, ì²´ë©´, ëˆˆì¹˜ ë“±)ì„ ê³ ë ¤
        cultural_factors = []
        
        if hasattr(context, 'cultural_emotions'):
            # í•œ(æ¨) - ê¹Šì€ ìŠ¬í””ê³¼ ì›ë§
            if context.cultural_emotions.get('han', 0) > 0.5:
                cultural_factors.append(1.3)  # ê°•í•œ ë¶€ì •ì  ê°ì • ì¦í­
            
            # ì •(æƒ…) - ë”°ëœ»í•œ ì¸ê°„ì  ì •ì„œ
            if context.cultural_emotions.get('jeong', 0) > 0.5:
                cultural_factors.append(1.15)  # ê¸ì •ì  ê°ì • ì¦í­
            
            # ì²´ë©´ - ì‚¬íšŒì  ìì¡´ì‹¬
            if context.cultural_emotions.get('chemyeon', 0) > 0.5:
                cultural_factors.append(1.1)  # ì‚¬íšŒì  ì˜í–¥ ì¦ê°€
            
        if cultural_factors:
            return np.mean(cultural_factors)
        else:
            return 1.0
    
    def _fuzzy_membership(self, value: float, center: float, width: float) -> float:
        """í¼ì§€ ë©¤ë²„ì‹­ í•¨ìˆ˜ (ì‚¼ê°í˜• ë¶„í¬)"""
        if width <= 0:
            return 1.0 if value == center else 0.0
        
        distance = abs(value - center)
        if distance >= width:
            return 0.0
        else:
            return 1.0 - (distance / width)


class AdvancedCognitiveWeightLayer(AdvancedWeightLayer):
    """ê³ ê¸‰ ì¸ì§€ì  ë³µì¡ë„ ê°€ì¤‘ì¹˜ ë ˆì´ì–´"""
    
    def __init__(self, neural_predictor: NeuralWeightPredictor = None):
        super().__init__("ê³ ê¸‰ ì¸ì§€ì  ë³µì¡ë„", neural_predictor)
        
    def _get_layer_index(self) -> int:
        return 5
        
    def _apply_rule_based_correction(self, weight: float, 
                                   context: AdvancedCalculationContext) -> float:
        """ì¸ì§€ì  ë³µì¡ë„ ê·œì¹™ ê¸°ë°˜ ë³´ì •"""
        corrections = []
        reasoning_parts = []
        
        # ì¸ì§€ ë¶€í•˜ ê³„ì‚°
        cognitive_load = self._calculate_cognitive_load(context)
        
        if cognitive_load > 0.8:
            correction = 0.8
            corrections.append(correction)
            reasoning_parts.append("ë†’ì€ ì¸ì§€ ë¶€í•˜ (-20%)")
        elif cognitive_load < 0.3:
            correction = 1.2
            corrections.append(correction)
            reasoning_parts.append("ë‚®ì€ ì¸ì§€ ë¶€í•˜ (+20%)")
            
        # ë¶ˆí™•ì‹¤ì„± ë³´ì •
        if context.uncertainty_level > 0.7:
            correction = 0.9
            corrections.append(correction)
            reasoning_parts.append("ë†’ì€ ë¶ˆí™•ì‹¤ì„± (-10%)")
        elif context.uncertainty_level < 0.3:
            correction = 1.1
            corrections.append(correction)
            reasoning_parts.append("ë‚®ì€ ë¶ˆí™•ì‹¤ì„± (+10%)")
            
        # ë³´ì • ì ìš©
        if corrections:
            final_correction = np.mean(corrections)
            weight *= final_correction
            
        self.last_contribution = weight - 1.0
        self.last_reasoning = " | ".join(reasoning_parts) if reasoning_parts else "ë³´í†µ ì¸ì§€ ë³µì¡ë„"
        
        return weight
        
    def _calculate_cognitive_load(self, context: AdvancedCalculationContext) -> float:
        """ì¸ì§€ ë¶€í•˜ ê³„ì‚°"""
        load_factors = []
        
        # ë³€ìˆ˜ ìˆ˜ ê¸°ë°˜ ë¶€í•˜ (Bentham v2 í™•ì¥: 10ê°œ ë³€ìˆ˜)
        non_default_vars = len([v for v in context.input_values.values() if v != 0.5])
        load_factors.append(non_default_vars / 10.0)
        
        # ë³µì¡ë„ ë©”íŠ¸ë¦­ ê¸°ë°˜ ë¶€í•˜
        if hasattr(context, 'complexity_metrics'):
            complexity = context.complexity_metrics
            lexical_complexity = complexity.get('lexical_diversity', 0.5)
            structural_complexity = complexity.get('structural_complexity', 0.1) * 10
            load_factors.extend([lexical_complexity, structural_complexity])
            
        # ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ë¶€í•˜
        load_factors.append(context.uncertainty_level)
        
        return float(np.mean(load_factors))


class AdvancedBenthamCalculator:
    """ê³ ê¸‰ ë²¤ë‹´ ì¾Œë½ ê³„ì‚°ê¸° - Linux ì „ìš© AI ê°•í™” ë²„ì „"""
    
    def __init__(self):
        if not ADVANCED_LIBS_AVAILABLE:
            raise ImportError("ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
        self.logger = logger
        self.device = DEVICE
        
        # ë ˆì´ì§€ ë¡œë”©ì„ ìœ„í•œ í”Œë˜ê·¸
        self._neural_predictor = None
        self._context_analyzer = None
        self._weight_layers = None
        self._models_loaded = False
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
        self._memory_usage = 0
        self._max_memory_mb = 8192  # 8GB ì œí•œ
        
        # ë°°ì¹˜ í¬ê¸° ë™ì  ì¡°ì • ì„¤ì •
        self._base_batch_size = 32
        self._min_batch_size = 4
        self._max_batch_size = 128
        self._current_batch_size = self._base_batch_size
        
        # ê³ ê¸‰ ê³„ì‚° ì„¤ì •
        self.advanced_config = {
            'use_neural_prediction': True,
            'use_transformer_analysis': True,
            'use_ml_enhancement': True,
            'extreme_pleasure_threshold': 0.8,
            'extreme_pain_threshold': -0.8,
            'neural_confidence_threshold': 0.7,
            'batch_processing': True,
            'optimization_enabled': True
        }
        
        # ìµœì í™” ì„¤ì •
        self.optimization_params = {
            'method': 'bounded',
            'bounds': (0.3, 2.5),
            'tolerance': 1e-6
        }
        
        # ìºì‹± ì‹œìŠ¤í…œ
        self.calculation_cache = {}
        self.cache_lock = threading.Lock()
        
        # MoE ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.moe_enabled = True
        
        # ë²¤ë‹´ í•„ìˆ˜ í‚¤ ì •ì˜ (GPT ì œì•ˆ)
        self.BENTHAM_KEYS = ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']
        
        # =====================================================
        # ê°•í™” ëª¨ë“ˆ í†µí•© (42.5M ì¶”ê°€ â†’ ì´ 45M)
        # =====================================================
        base_dim = 768
        
        # 1. ì‹¬ì¸µ ìœ¤ë¦¬ ì¶”ë¡  ë„¤íŠ¸ì›Œí¬ (12M)
        self.deep_ethics = nn.ModuleDict({
            'philosophical': nn.Sequential(
                nn.Linear(base_dim, 1024),
                nn.LayerNorm(1024),
                nn.GELU(),
                nn.Dropout(0.1),
                nn.Linear(1024, 768),
                nn.LayerNorm(768),
                nn.GELU(),
                nn.Linear(768, 512),
                nn.Linear(512, 10)  # ë²¤ë‹´ 10ìš”ì†Œ
            ),
            'deontological': nn.Sequential(
                nn.Linear(base_dim, 768),
                nn.LayerNorm(768),
                nn.GELU(),
                nn.Linear(768, 512),
                nn.Linear(512, 5)  # ì˜ë¬´ë¡ ì  ì›ì¹™ 5ê°œ
            ),
            'virtue_ethics': nn.Sequential(
                nn.Linear(base_dim, 768),
                nn.LayerNorm(768),
                nn.GELU(),
                nn.Linear(768, 512),
                nn.Linear(512, 7)  # ë• ìœ¤ë¦¬ 7ê°œ
            ),
            'integrator': nn.Sequential(
                nn.Linear(22, 128),
                nn.GELU(),
                nn.Linear(128, 10)
            )
        }).to(self.device)
        
        # 2. ì‚¬íšŒì  ì˜í–¥ í‰ê°€ (10M)
        self.social_impact = nn.ModuleDict({
            'individual': nn.LSTM(base_dim, base_dim // 2, 2, batch_first=True, bidirectional=True),
            'group': nn.LSTM(base_dim, base_dim // 2, 2, batch_first=True, bidirectional=True),
            'society': nn.LSTM(base_dim, base_dim // 2, 2, batch_first=True, bidirectional=True),
            'global': nn.LSTM(base_dim, base_dim // 2, 2, batch_first=True, bidirectional=True),
            'impact_aggregator': nn.Sequential(
                nn.Linear(base_dim * 4, base_dim * 2),
                nn.LayerNorm(base_dim * 2),
                nn.GELU(),
                nn.Linear(base_dim * 2, base_dim),
                nn.Linear(base_dim, 10)
            )
        }).to(self.device)
        
        # 3. ì¥ê¸° ê²°ê³¼ ì˜ˆì¸¡ (10M)
        self.long_term_predictor = nn.ModuleDict({
            'temporal_encoder': nn.TransformerEncoder(
                nn.TransformerEncoderLayer(base_dim, 8, base_dim * 2, dropout=0.1, batch_first=True),
                num_layers=3
            ),
            'outcome_predictor': nn.Sequential(
                nn.Linear(base_dim, 1024),
                nn.LayerNorm(1024),
                nn.GELU(),
                nn.Linear(1024, 512),
                nn.Linear(512, 256),
                nn.Linear(256, 10)  # 10ê°œ ì‹œê°„ëŒ€ë³„ ê²°ê³¼
            ),
            'uncertainty_estimator': nn.Sequential(
                nn.Linear(base_dim, 256),
                nn.GELU(),
                nn.Linear(256, 10),
                nn.Softplus()
            )
        }).to(self.device)
        
        # 4. ë¬¸í™”ê°„ ìœ¤ë¦¬ ë¹„êµ (10.5M + 3M ì¶”ê°€ = 13.5M)
        self.cross_cultural = nn.ModuleDict({
            'western': self._create_cultural_ethics_network(base_dim),
            'eastern': self._create_cultural_ethics_network(base_dim),
            'korean': self._create_cultural_ethics_network(base_dim),
            'islamic': self._create_cultural_ethics_network(base_dim),
            'african': self._create_cultural_ethics_network(base_dim),
            'fusion': nn.Sequential(
                nn.Linear(base_dim * 5, base_dim * 3),
                nn.LayerNorm(base_dim * 3),
                nn.GELU(),
                nn.Linear(base_dim * 3, base_dim),
                nn.LayerNorm(base_dim),
                nn.Linear(base_dim, 10)
            ),
            # ì¶”ê°€ ë ˆì´ì–´ (3M)
            'deep_cultural': nn.Sequential(
                nn.Linear(base_dim, 1024),
                nn.LayerNorm(1024),
                nn.GELU(),
                nn.Dropout(0.1),
                nn.Linear(1024, 768),
                nn.LayerNorm(768),
                nn.GELU(),
                nn.Linear(768, base_dim)
            )
        }).to(self.device)
        
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        total_params = sum(p.numel() for p in [
            *self.deep_ethics.parameters(),
            *self.social_impact.parameters(),
            *self.long_term_predictor.parameters(),
            *self.cross_cultural.parameters()
        ])
        logger.info(f"âœ… ë²¤ë‹´ ê³„ì‚°ê¸° ê°•í™” ëª¨ë“ˆ í†µí•©: {total_params/1e6:.1f}M íŒŒë¼ë¯¸í„° ì¶”ê°€")
        if self.moe_enabled:
            try:
                # ìœ¤ë¦¬ ë¶„ì„ìš© MoE ì´ˆê¸°í™”
                ethics_input_dim = 512  # ìœ¤ë¦¬ ë§¥ë½ ì„ë² ë”© ì°¨ì›
                ethics_output_dim = 6   # ìœ¤ë¦¬ ê°€ì¹˜ ìˆ˜ (care_harm, fairness, loyalty, authority, sanctity, liberty)
                
                self.ethics_moe = create_ethics_moe(
                    input_dim=ethics_input_dim,
                    output_dim=ethics_output_dim,
                    num_experts=4  # ê³µë¦¬ì£¼ì˜, ì˜ë¬´ë¡ , ë•ìœ¤ë¦¬, ëŒë´„ìœ¤ë¦¬
                )
                
                # ë””ë²„ê¹…: ì‹¤ì œ ìƒì„±ëœ ì°¨ì› í™•ì¸
                if hasattr(self.ethics_moe, 'gating_network'):
                    actual_input_dim = self.ethics_moe.gating_network.input_dim
                    self.logger.info(f"ë²¤ë‹´ ê³„ì‚°ê¸° ìœ¤ë¦¬ MoE ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (4ê°œ ì „ë¬¸ê°€, input_dim={actual_input_dim})")
                else:
                    self.logger.info("ë²¤ë‹´ ê³„ì‚°ê¸° ìœ¤ë¦¬ MoE ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (4ê°œ ì „ë¬¸ê°€)")
            except Exception as e:
                self.logger.warning(f"ë²¤ë‹´ ìœ¤ë¦¬ MoE ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ë³¸ ì‹œìŠ¤í…œ ì‚¬ìš©: {e}")
                self.moe_enabled = False
        
        # 3ë·° ì‹œë‚˜ë¦¬ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.scenario_system_enabled = True
        if self.scenario_system_enabled:
            try:
                self.three_view_system = ThreeViewScenarioSystem(device=self.device)
                self.logger.info("ë²¤ë‹´ ê³„ì‚°ê¸° 3ë·° ì‹œë‚˜ë¦¬ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"3ë·° ì‹œë‚˜ë¦¬ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.scenario_system_enabled = False
        
        # PhaseController Hook ì´ˆê¸°í™”
        self.phase_controller_enabled = True
        if self.phase_controller_enabled:
            try:
                # ë²¤ë‹´ ê³„ì‚°ê¸° ëª¨ë¸ë“¤ ìˆ˜ì§‘
                models = {}
                if hasattr(self, 'neural_predictor') and self.neural_predictor:
                    models['neural_predictor'] = self.neural_predictor
                if hasattr(self, 'ethics_moe') and self.ethics_moe:
                    models['ethics_moe'] = self.ethics_moe
                
                self.phase_controller = PhaseControllerHook(
                    models=models,
                    performance_threshold=0.8,
                    error_threshold=0.1
                )
                
                # ëª¨ë‹ˆí„°ë§ ì‹œì‘
                self.phase_controller.start_monitoring()
                
                self.logger.info("ë²¤ë‹´ ê³„ì‚°ê¸° PhaseController Hook ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"PhaseController Hook ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.phase_controller_enabled = False
        
        # ë²•ë¥  ì „ë¬¸ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.legal_expert_enabled = True
        if self.legal_expert_enabled:
            try:
                self.legal_expert = get_legal_expert_system(device=self.device)
                
                # ê¸°ë³¸ì ìœ¼ë¡œ ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì • (í•„ìš”ì‹œ í•™ìŠµ ëª¨ë“œë¡œ ë³€ê²½ ê°€ëŠ¥)
                self.legal_expert.set_operation_mode(OperationMode.INFERENCE)
                
                self.logger.info("ë²¤ë‹´ ê³„ì‚°ê¸° ë²•ë¥  ì „ë¬¸ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"ë²•ë¥  ì „ë¬¸ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.legal_expert_enabled = False
        
        self.logger.info("ê³ ê¸‰ ë²¤ë‹´ ì¾Œë½ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ë ˆì´ì§€ ë¡œë”© í™œì„±í™”)")
        
        # ë“±ë¡ ë‹¨ê³„ì—ì„œ get_pytorch_networkê°€ ì‘ë™í•˜ë„ë¡ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ë³´ì¥
        self._ensure_default_network()
    
    def _ensure_default_network(self):
        """ìµœì†Œ í•˜ë‚˜ì˜ PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì¡´ì¬í•˜ë„ë¡ ë³´ì¥"""
        # ë ˆì´ì§€ ë¡œë”©ì´ë¼ ì´ˆê¸°ì—ëŠ” ë¹„ì–´ìˆìœ¼ë¯€ë¡œ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„±
        logger.info("ğŸ”¨ ë²¤ë‹´ ê³„ì‚°ê¸° ê¸°ë³¸ PyTorch ë„¤íŠ¸ì›Œí¬ ìƒì„± ì¤‘...")
        self._build_default_network()
    
    def _build_default_network(self):
        """
        ê¸°ë³¸ PyTorch ë„¤íŠ¸ì›Œí¬ ìƒì„±
        - ë“±ë¡/í—¤ë“œ ë°”ì¸ë”©ì„ ìœ„í•œ ìµœì†Œ ë„¤íŠ¸ì›Œí¬
        - ê°€ë³ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
        """
        import torch.nn as nn
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        
        # ê°„ë‹¨í•œ ì¾Œë½ ì˜ˆì¸¡ ë„¤íŠ¸ì›Œí¬
        class DefaultBenthamNetwork(nn.Module):
            def __init__(self):
                super().__init__()
                # 7ê°€ì§€ ë³€ìˆ˜ ì…ë ¥
                self.input_fc = nn.Linear(7, 64)
                self.hidden = nn.Sequential(
                    nn.ReLU(),
                    nn.Linear(64, 32),
                    nn.ReLU(),
                    nn.Linear(32, 16),
                    nn.ReLU()
                )
                self.output_fc = nn.Linear(16, 1)  # ì¾Œë½ ì ìˆ˜ ì¶œë ¥
                
            def forward(self, x):
                x = self.input_fc(x)
                x = self.hidden(x)
                return self.output_fc(x)
        
        # ë„¤íŠ¸ì›Œí¬ ìƒì„± ë° ì„¤ì •
        self.default_network = DefaultBenthamNetwork().to(device)
        self._primary_nn = self.default_network
        
        # neural_predictorê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ë¡œ ì„¤ì •
        if self._neural_predictor is None:
            self._neural_predictor = self.default_network
            logger.info("ğŸ”— _neural_predictorë¥¼ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ë¡œ ì„¤ì •")
        
        logger.info(f"âœ… ë²¤ë‹´ ê³„ì‚°ê¸° ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì™„ë£Œ (device: {device})")
        logger.info(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in self.default_network.parameters()):,}")
    
    @property
    def neural_predictor(self):
        """ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ ì˜ˆì¸¡ê¸° (ë ˆì´ì§€ ë¡œë”©)"""
        if self._neural_predictor is None:
            self._check_memory_usage()
            self.logger.info("ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ ì˜ˆì¸¡ê¸° ë¡œë”© ì¤‘...")
            predictor_device = get_smart_device(memory_required_mb=100)
            self._neural_predictor = NeuralWeightPredictor().to(predictor_device)
            self.logger.info(f"ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ ì˜ˆì¸¡ê¸° ë¡œë“œ: {predictor_device} (100MB)")
            self._update_memory_usage()
        return self._neural_predictor
    
    @property
    def context_analyzer(self):
        """íŠ¸ëœìŠ¤í¬ë¨¸ ë§¥ë½ ë¶„ì„ê¸° (ë ˆì´ì§€ ë¡œë”©)"""
        if self._context_analyzer is None:
            self._check_memory_usage()
            self.logger.info("íŠ¸ëœìŠ¤í¬ë¨¸ ë§¥ë½ ë¶„ì„ê¸° ë¡œë”© ì¤‘...")
            self._context_analyzer = TransformerContextAnalyzer()
            self._update_memory_usage()
        return self._context_analyzer
    
    @property
    def weight_layers(self):
        """6ê°œ ê³ ê¸‰ ê°€ì¤‘ì¹˜ ë ˆì´ì–´ (ë ˆì´ì§€ ë¡œë”©)"""
        if self._weight_layers is None:
            self._check_memory_usage()
            self.logger.info("ê°€ì¤‘ì¹˜ ë ˆì´ì–´ë“¤ ë¡œë”© ì¤‘...")
            self._weight_layers = [
                AdvancedContextualWeightLayer(self.neural_predictor),
                AdvancedTemporalWeightLayer(self.neural_predictor),
                AdvancedSocialWeightLayer(self.neural_predictor),
                AdvancedEthicalWeightLayer(self.neural_predictor),
                AdvancedEmotionalWeightLayer(self.neural_predictor),
                AdvancedCognitiveWeightLayer(self.neural_predictor)
            ]
            self._update_memory_usage()
        return self._weight_layers
    
    def _check_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬"""
        import psutil
        
        # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ í™•ì¸
        memory = psutil.virtual_memory()
        memory_usage_percent = memory.percent
        available_mb = memory.available / (1024 * 1024)
        
        # ìë™ ë©”ëª¨ë¦¬ ì•ˆì „ì¥ì¹˜ (80% ì´ìƒ)
        if memory_usage_percent >= 80:
            self.logger.critical(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ìœ„í—˜ ìˆ˜ì¤€: {memory_usage_percent:.1f}%")
            self._emergency_memory_optimization()
        elif available_mb < 4096:  # 4GB ë¯¸ë§Œ
            self.logger.warning(f"ë©”ëª¨ë¦¬ ë¶€ì¡±: {available_mb:.0f}MB ë‚¨ìŒ")
            self._optimize_memory_usage()
        
        # GPU ë©”ëª¨ë¦¬ í™•ì¸ (ê°€ëŠ¥í•œ ê²½ìš°)
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 * 1024)
            gpu_allocated = torch.cuda.memory_allocated(0) / (1024 * 1024)
            gpu_available = gpu_memory - gpu_allocated
            gpu_usage_percent = (gpu_allocated / gpu_memory) * 100
            
            # GPU ë©”ëª¨ë¦¬ ì•ˆì „ì¥ì¹˜ (80% ì´ìƒ)
            if gpu_usage_percent >= 80:
                self.logger.critical(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ìœ„í—˜ ìˆ˜ì¤€: {gpu_usage_percent:.1f}%")
                self._emergency_gpu_optimization()
            elif gpu_available < 2048:  # 2GB ë¯¸ë§Œ
                self.logger.warning(f"GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: {gpu_available:.0f}MB ë‚¨ìŒ")
                torch.cuda.empty_cache()
    
    def _update_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸"""
        import psutil
        
        process = psutil.Process()
        self._memory_usage = process.memory_info().rss / (1024 * 1024)  # MB
        
        if torch.cuda.is_available():
            gpu_usage = torch.cuda.memory_allocated(0) / (1024 * 1024)
            self.logger.info(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: RAM {self._memory_usage:.0f}MB, GPU {gpu_usage:.0f}MB")
        else:
            self.logger.info(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: RAM {self._memory_usage:.0f}MB")
    
    def _optimize_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
        # ìºì‹œ ì •ë¦¬
        if hasattr(self, 'calculation_cache'):
            self.calculation_cache.clear()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
        import gc
        gc.collect()
        
        self.logger.info("ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")

    def _emergency_memory_optimization(self):
        """ê¸´ê¸‰ ë©”ëª¨ë¦¬ ìµœì í™” (80% ì´ìƒ ì‚¬ìš© ì‹œ)"""
        self.logger.critical("ê¸´ê¸‰ ë©”ëª¨ë¦¬ ìµœì í™” ì‹œì‘")
        
        # 1. ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ
        self.unload_models()
        
        # 2. ê³„ì‚° ìºì‹œ ì™„ì „ ì‚­ì œ
        if hasattr(self, 'calculation_cache'):
            self.calculation_cache.clear()
        
        # 3. ë°°ì¹˜ í¬ê¸° ìµœì†Œí™”
        self._current_batch_size = self._min_batch_size
        
        # 4. ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        import gc
        gc.collect()
        
        # 5. GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        self.logger.critical("ê¸´ê¸‰ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")

    def _emergency_gpu_optimization(self):
        """ê¸´ê¸‰ GPU ë©”ëª¨ë¦¬ ìµœì í™” (80% ì´ìƒ ì‚¬ìš© ì‹œ)"""
        self.logger.critical("ê¸´ê¸‰ GPU ë©”ëª¨ë¦¬ ìµœì í™” ì‹œì‘")
        
        # 1. GPU ìºì‹œ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # 2. ëª¨ë¸ì„ CPUë¡œ ì´ë™ (ì¼ì‹œì )
        if self._neural_predictor is not None:
            self._neural_predictor = self._neural_predictor.cpu()
        
        # 3. ë°°ì¹˜ í¬ê¸° ìµœì†Œí™”
        self._current_batch_size = self._min_batch_size
        
        # 4. ê°•ì œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        import gc
        gc.collect()
        
        self.logger.critical("ê¸´ê¸‰ GPU ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")

    def _adjust_batch_size(self):
        """ë©”ëª¨ë¦¬ ìƒí™©ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ë™ì  ì¡°ì •"""
        import psutil
        
        # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸
        memory = psutil.virtual_memory()
        memory_usage_percent = memory.percent
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ì¡°ì •
        if memory_usage_percent > 85:  # 85% ì´ìƒ
            self._current_batch_size = max(self._min_batch_size, self._current_batch_size // 2)
            self.logger.warning(f"ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ({memory_usage_percent:.1f}%), ë°°ì¹˜ í¬ê¸° ê°ì†Œ: {self._current_batch_size}")
        elif memory_usage_percent < 60:  # 60% ë¯¸ë§Œ
            self._current_batch_size = min(self._max_batch_size, self._current_batch_size * 2)
            self.logger.info(f"ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ({memory_usage_percent:.1f}%), ë°°ì¹˜ í¬ê¸° ì¦ê°€: {self._current_batch_size}")
        
        # GPU ë©”ëª¨ë¦¬ë„ ê³ ë ¤ (ê°€ëŠ¥í•œ ê²½ìš°)
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory
            gpu_allocated = torch.cuda.memory_allocated(0)
            gpu_usage_percent = (gpu_allocated / gpu_memory) * 100
            
            if gpu_usage_percent > 80:  # GPU ë©”ëª¨ë¦¬ 80% ì´ìƒ
                self._current_batch_size = max(self._min_batch_size, self._current_batch_size // 2)
                self.logger.warning(f"ë†’ì€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ({gpu_usage_percent:.1f}%), ë°°ì¹˜ í¬ê¸° ê°ì†Œ: {self._current_batch_size}")
        
        return self._current_batch_size
    
    def get_optimal_batch_size(self) -> int:
        """ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸° ë°˜í™˜"""
        return self._adjust_batch_size()
    
    def unload_models(self):
        """ëª¨ë¸ ì–¸ë¡œë“œ ë° ë©”ëª¨ë¦¬ í•´ì œ"""
        if self._neural_predictor is not None:
            del self._neural_predictor
            self._neural_predictor = None
        
        if self._context_analyzer is not None:
            del self._context_analyzer
            self._context_analyzer = None
        
        if self._weight_layers is not None:
            del self._weight_layers
            self._weight_layers = None
        
        self._models_loaded = False
        self._optimize_memory_usage()
        self.logger.info("ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ")
        
    def _create_cultural_ethics_network(self, dim: int) -> nn.Module:
        """ë¬¸í™”ë³„ ìœ¤ë¦¬ í•´ì„ ë„¤íŠ¸ì›Œí¬"""
        return nn.Sequential(
            nn.Linear(dim, dim),
            nn.LayerNorm(dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(dim, dim // 2),
            nn.LayerNorm(dim // 2),
            nn.GELU(),
            nn.Linear(dim // 2, dim)
        )
        
    def calculate_with_ethical_reasoning(self,
                                       input_data: Dict[str, Any],
                                       community_emotion: Optional['EmotionData'] = None,
                                       other_emotion: Optional['EmotionData'] = None,
                                       self_emotion: Optional['EmotionData'] = None,
                                       past_regret_memory: Optional[Dict[str, float]] = None,
                                       use_cache: bool = True) -> EnhancedHedonicResult:
        """ì¸ê°„ì  ìœ¤ë¦¬ ì¶”ë¡  ê³¼ì •ì„ ë”°ë¥¸ ë²¤ë‹´ ê³„ì‚° (3ë·° ì‹œë‚˜ë¦¬ì˜¤ í†µí•©)"""
        
        # 1ë‹¨ê³„: ê°ì • ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ í†µí•© (ê³µë™ì²´ > íƒ€ì > ìì•„)
        integrated_emotion = self._integrate_emotion_hierarchy(
            community_emotion, other_emotion, self_emotion
        )
        
        # 2ë‹¨ê³„: ê°ì • ê¸°ë°˜ ìœ¤ë¦¬ì  ê°€ì¹˜ ì¶”ë¡ 
        ethical_values = self._perform_ethical_reasoning(integrated_emotion, input_data)
        
        # 3ë‹¨ê³„: ìœ¤ë¦¬ì  ê°€ì¹˜ë¥¼ ë°˜ì˜í•œ ë²¤ë‹´ ê³„ì‚°
        input_data['emotion_data'] = integrated_emotion
        input_data['ethical_values'] = ethical_values
        
        # 4ë‹¨ê³„: ê³¼ê±° í›„íšŒëŠ” ë¯¸ë¬˜í•œ í•™ìŠµ íš¨ê³¼ë¡œë§Œ ë°˜ì˜ (ì§ì ‘ ê°œì… ì•„ë‹˜)
        if past_regret_memory:
            input_data['learning_bias'] = self._extract_learning_bias(past_regret_memory)
        
        # 5ë‹¨ê³„: 3ë·° ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ í†µí•©
        if self.scenario_system_enabled:
            try:
                # 3ë·° ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ìˆ˜í–‰ - ì´ë²¤íŠ¸ ë£¨í”„ ë¬¸ì œ í•´ê²°
                # í”„ë¡œì íŠ¸ ê·œì¹™: ê·¼ë³¸ì  í•´ê²° - run_async_safely ì‚¬ìš©
                from config import run_async_safely
                scenario_analysis = run_async_safely(
                    self.three_view_system.analyze_three_view_scenarios(input_data),
                    timeout=120.0
                )
                
                # ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼ë¥¼ ë²¤ë‹´ ê³„ì‚°ì— í†µí•©
                enhanced_result = self._integrate_scenario_analysis(input_data, scenario_analysis, use_cache)
                
                self.logger.debug(f"3ë·° ì‹œë‚˜ë¦¬ì˜¤ ë²¤ë‹´ ê³„ì‚° ì™„ë£Œ: í•©ì˜ íš¨ìš© {scenario_analysis.consensus_utility:.3f}")
                return enhanced_result
                
            except Exception as e:
                self.logger.warning(f"3ë·° ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ ê³„ì‚° ì‚¬ìš©: {e}")
                return self.calculate_with_advanced_layers(input_data, use_cache)
        else:
            return self.calculate_with_advanced_layers(input_data, use_cache)
    
    def _integrate_scenario_analysis(self, input_data: Dict[str, Any], 
                                   scenario_analysis, use_cache: bool = True) -> EnhancedHedonicResult:
        """ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ì„ ë²¤ë‹´ ê³„ì‚°ì— í†µí•©"""
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ë²¤ë‹´ ê³„ì‚° ìˆ˜í–‰
        scenario_results = {}
        
        for scenario_name, scenario_metrics in [
            ('optimistic', scenario_analysis.optimistic_scenario),
            ('neutral', scenario_analysis.neutral_scenario),
            ('pessimistic', scenario_analysis.pessimistic_scenario)
        ]:
            # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì…ë ¥ ë°ì´í„° ì¡°ì •
            scenario_input = input_data.copy()
            
            # ì‹œë‚˜ë¦¬ì˜¤ íŠ¹ì„±ì„ ë²¤ë‹´ ë³€ìˆ˜ì— ë°˜ì˜
            scenario_input['intensity'] = scenario_input.get('intensity', 0.5) * (1 + scenario_metrics.expected_pleasure - scenario_metrics.expected_pain)
            scenario_input['duration'] = scenario_input.get('duration', 60) * scenario_metrics.probability_weight
            scenario_input['certainty'] = scenario_input.get('certainty', 0.5) * scenario_metrics.confidence_level
            
            # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìœ¤ë¦¬ì  ê°€ì¹˜ ë°˜ì˜
            if scenario_metrics.ethical_implications:
                scenario_input['ethical_values'] = scenario_metrics.ethical_implications
            
            # ì‹œë‚˜ë¦¬ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            scenario_input['scenario_type'] = scenario_name
            scenario_input['scenario_weight'] = scenario_metrics.probability_weight
            scenario_input['regret_potential'] = scenario_metrics.regret_potential
            
            # ë²¤ë‹´ ê³„ì‚° ìˆ˜í–‰
            scenario_result = self.calculate_with_advanced_layers(scenario_input, use_cache)
            scenario_results[scenario_name] = scenario_result
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ê³„ì‚°
        final_result = self._calculate_weighted_bentham_result(scenario_results, scenario_analysis)
        
        return final_result
    
    def _calculate_weighted_bentham_result(self, scenario_results: Dict[str, EnhancedHedonicResult],
                                         scenario_analysis) -> EnhancedHedonicResult:
        """ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²°ê³¼ë¥¼ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ í†µí•©"""
        
        # ê°€ì¤‘ì¹˜ ê³„ì‚°
        weights = {
            'optimistic': scenario_analysis.optimistic_scenario.probability_weight,
            'neutral': scenario_analysis.neutral_scenario.probability_weight,
            'pessimistic': scenario_analysis.pessimistic_scenario.probability_weight
        }
        
        total_weight = sum(weights.values())
        if total_weight == 0:
            # í”„ë¡œì íŠ¸ ê·œì¹™: fallback ì—†ëŠ” ìˆœìˆ˜ ì¬ì‹œë„ ë°©ì‹
            retry_count = 0
            max_retries = 3
            while retry_count < max_retries:
                retry_count += 1
                self.logger.info(f"ê°€ì¤‘ì¹˜ ì¬ê³„ì‚° ì¬ì‹œë„ {retry_count}/{max_retries}")
                try:
                    # ìµœì†Œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì¬ê³„ì‚°
                    weights['optimistic'] = max(0.1, scenario_analysis.optimistic_scenario.probability_weight)
                    weights['neutral'] = max(0.4, scenario_analysis.neutral_scenario.probability_weight)  
                    weights['pessimistic'] = max(0.1, scenario_analysis.pessimistic_scenario.probability_weight)
                    total_weight = sum(weights.values())
                    if total_weight > 0:
                        self.logger.info(f"ê°€ì¤‘ì¹˜ ì¬ê³„ì‚° ì„±ê³µ: total_weight={total_weight}")
                        break
                except Exception as retry_error:
                    self.logger.error(f"ê°€ì¤‘ì¹˜ ì¬ê³„ì‚° ì¬ì‹œë„ {retry_count} ì‹¤íŒ¨: {retry_error}")
                    if retry_count >= max_retries:
                        self.logger.error("ê°€ì¤‘ì¹˜ ê³„ì‚° ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì •ì§€")
                        raise RuntimeError(f"ê°€ì¤‘ì¹˜ ê³„ì‚° ìµœì¢… ì‹¤íŒ¨: {retry_error}")
                    import time
                    time.sleep(0.1)
            
            if total_weight == 0:
                self.logger.error("ê°€ì¤‘ì¹˜ ì¬ê³„ì‚° í›„ì—ë„ total_weightê°€ 0 - ì‹œìŠ¤í…œ ì •ì§€")
                raise RuntimeError("ì‹œë‚˜ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€")
        
        # ì •ê·œí™”
        for key in weights:
            weights[key] /= total_weight
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_total_score = sum(
            scenario_results[scenario].final_score * weights[scenario]
            for scenario in scenario_results
        )
        
        weighted_base_score = sum(
            scenario_results[scenario].base_score * weights[scenario]
            for scenario in scenario_results
        )
        
        # ëŒ€í‘œ ê²°ê³¼ ì„ íƒ (ì¤‘ë„ì  ì‹œë‚˜ë¦¬ì˜¤ ê¸°ì¤€)
        base_result = scenario_results['neutral']
        
        # í–¥ìƒëœ ê²°ê³¼ ìƒì„±
        enhanced_result = EnhancedHedonicResult(
            final_score=weighted_total_score,
            base_score=weighted_base_score,
            hedonic_values=base_result.hedonic_values,
            layer_contributions=base_result.layer_contributions,  # weight_layers ëŒ€ì‹  layer_contributions ì‚¬ìš©
            confidence_score=base_result.confidence_score * scenario_analysis.consensus_strength,
            extreme_adjustment_applied=base_result.extreme_adjustment_applied,
            adjustment_factor=base_result.adjustment_factor,
            processing_time=base_result.processing_time + (scenario_analysis.analysis_duration_ms / 1000.0),
            metadata={
                **base_result.metadata,
                'calculation_context': getattr(base_result, 'calculation_context', {}),
                'cache_hit': getattr(base_result, 'cache_hit', False),
                'scenario_analysis': {
                    'consensus_utility': scenario_analysis.consensus_utility,
                    'consensus_regret': scenario_analysis.consensus_regret,
                    'uncertainty_range': scenario_analysis.uncertainty_range,
                    'scenario_diversity': scenario_analysis.scenario_diversity,
                    'consensus_strength': scenario_analysis.consensus_strength,
                    'recommended_decision': scenario_analysis.recommended_decision
                },
                'scenario_weights': weights,
                'scenario_scores': {
                    scenario: result.final_score
                    for scenario, result in scenario_results.items()
                }
            }
        )
        
        # PhaseController Hookì— ì„±ëŠ¥ ê¸°ë¡
        if self.phase_controller_enabled:
            try:
                # ë²¤ë‹´ ê³„ì‚° ì˜¤ì°¨ ì¶”ì •
                score_variance = np.var([result.final_score for result in scenario_results.values()])
                calculation_error = score_variance / (abs(weighted_total_score) + 1e-8)
                
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ êµ¬ì„±
                performance_metrics = {
                    'bentham_calculation_error': calculation_error,
                    'processing_time_ms': enhanced_result.processing_time * 1000,  # seconds to ms
                    'confidence_score': enhanced_result.confidence_score,
                    'scenario_diversity': scenario_analysis.scenario_diversity,
                    'consensus_strength': scenario_analysis.consensus_strength
                }
                
                # ëª¨ë¸ë³„ ì„±ëŠ¥ (MoE ê´€ë ¨)
                model_performances = {}
                if hasattr(scenario_analysis, 'metadata') and 'expert_usage' in scenario_analysis.metadata:
                    model_performances['ethics_moe'] = scenario_analysis.metadata['expert_usage']
                
                # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
                context = {
                    'calculation_type': 'bentham_with_scenarios',
                    'scenario_count': 3,
                    'cache_hit': getattr(enhanced_result, 'cache_hit', False),
                    'total_score': weighted_total_score
                }
                
                # ì„±ëŠ¥ ê¸°ë¡
                self.phase_controller.record_performance(
                    phase_type=PhaseType.INFERENCE,
                    metrics=performance_metrics,
                    model_performances=model_performances,
                    context=context
                )
                
            except Exception as e:
                self.logger.warning(f"PhaseController ì„±ëŠ¥ ê¸°ë¡ ì‹¤íŒ¨: {e}")
        
        return enhanced_result
    
    def _integrate_emotion_hierarchy(self, 
                                   community_emotion: Optional['EmotionData'],
                                   other_emotion: Optional['EmotionData'], 
                                   self_emotion: Optional['EmotionData']) -> 'EmotionData':
        """ê³ ê¸‰ ê°ì • í†µí•©: ì¹˜ëª…ì  ì†ì‹¤ ë°©ì§€ì™€ ë§¥ë½ ì ì‘í˜• ìš°ì„ ìˆœìœ„"""
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if not any([community_emotion, other_emotion, self_emotion]):
            from data_models import EmotionData, EmotionState, EmotionIntensity
            return EmotionData(
                primary_emotion=EmotionState.NEUTRAL,
                intensity=EmotionIntensity.MODERATE,
                confidence=0.5,
                dominance=0.5
            )
        
        # 1ë‹¨ê³„: ì¹˜ëª…ì  ê°ì • ì†ì‹¤ íƒì§€
        critical_loss_detected = self._detect_critical_emotional_loss(
            community_emotion, other_emotion, self_emotion
        )
        
        # 2ë‹¨ê³„: ë§¥ë½ ì ì‘ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
        base_weights = self._calculate_contextual_weights(
            community_emotion, other_emotion, self_emotion, critical_loss_detected
        )
        
        # 3ë‹¨ê³„: ê°ì • ê°•ë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì¬ì¡°ì •
        adjusted_weights = self._adjust_weights_by_intensity(
            base_weights, community_emotion, other_emotion, self_emotion
        )
        
        # 4ë‹¨ê³„: ê°ì • ì¶©ëŒ í•´ê²° (ì†ì‹¤ ì–µì œ ìš°ì„ )
        resolved_emotion = self._resolve_emotion_conflicts(
            community_emotion, other_emotion, self_emotion, 
            adjusted_weights, critical_loss_detected
        )
        
        return resolved_emotion
    
    def _detect_critical_emotional_loss(self, 
                                      community_emotion: Optional['EmotionData'],
                                      other_emotion: Optional['EmotionData'], 
                                      self_emotion: Optional['EmotionData']) -> Dict[str, bool]:
        """ì¹˜ëª…ì  ê°ì • ì†ì‹¤ íƒì§€ (ì˜êµ¬ ì†ì‹¤ ì›ë¦¬)"""
        
        critical_loss = {
            'community_loss': False,
            'other_loss': False,
            'self_loss': False,
            'any_critical': False
        }
        
        # ì¹˜ëª…ì  ì†ì‹¤ ê°ì •ë“¤ (sadness, fear, disgust + ë†’ì€ ê°•ë„)
        loss_emotions = {'sadness', 'fear', 'disgust', 'anger'}
        critical_threshold = 0.7  # ê°•ë„ ì„ê³„ê°’
        
        def _is_critical_loss(emotion_data):
            if not emotion_data:
                return False
            emotion_name = emotion_data.primary_emotion.value if hasattr(emotion_data.primary_emotion, 'value') else str(emotion_data.primary_emotion)
            if hasattr(emotion_data.intensity, 'value'):
                intensity_value = float(emotion_data.intensity.value) / 4.0
            else:
                from data_models import emotion_intensity_to_float
                intensity_value = emotion_intensity_to_float(emotion_data.arousal)
            return emotion_name in loss_emotions and intensity_value > critical_threshold
        
        # ê° ë ˆë²¨ë³„ ì¹˜ëª…ì  ì†ì‹¤ í™•ì¸
        critical_loss['community_loss'] = _is_critical_loss(community_emotion)
        critical_loss['other_loss'] = _is_critical_loss(other_emotion)
        critical_loss['self_loss'] = _is_critical_loss(self_emotion)
        critical_loss['any_critical'] = any([
            critical_loss['community_loss'], 
            critical_loss['other_loss'], 
            critical_loss['self_loss']
        ])
        
        return critical_loss
    
    def _calculate_contextual_weights(self, 
                                    community_emotion: Optional['EmotionData'],
                                    other_emotion: Optional['EmotionData'], 
                                    self_emotion: Optional['EmotionData'],
                                    critical_loss: Dict[str, bool]) -> Dict[str, float]:
        """ë§¥ë½ ì ì‘ì  ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        
        # ê¸°ë³¸ ê°€ì¤‘ì¹˜ (ë¯¼ì£¼ì  ê³µë¦¬ì£¼ì˜)
        base_weights = {'community': 0.5, 'other': 0.3, 'self': 0.2}
        
        # ì¹˜ëª…ì  ì†ì‹¤ ë°œìƒ ì‹œ ìš°ì„ ìˆœìœ„ ì¬ì¡°ì •
        if critical_loss['any_critical']:
            # ì†ì‹¤ì´ ìˆëŠ” ì£¼ì²´ë“¤ì—ê²Œ ë” ë†’ì€ ê°€ì¤‘ì¹˜ (ì†Œìˆ˜ ë³´í˜¸)
            if critical_loss['other_loss'] or critical_loss['community_loss']:
                # íƒ€ìë‚˜ ê³µë™ì²´ì— ì¹˜ëª…ì  ì†ì‹¤ì´ ìˆìœ¼ë©´ ìì•„ ìš°ì„ ìˆœìœ„ í•˜ë½
                base_weights = {'community': 0.4, 'other': 0.4, 'self': 0.2}
                
                if critical_loss['community_loss']:
                    base_weights['community'] += 0.1  # ê³µë™ì²´ ì†ì‹¤ ìš°ì„ 
                if critical_loss['other_loss']:
                    base_weights['other'] += 0.1    # íƒ€ì ì†ì‹¤ ìš°ì„ 
                    
                # ìì•„ ê°€ì¤‘ì¹˜ ì¬ë¶„ë°°
                total_boost = (base_weights['community'] + base_weights['other']) - 0.8
                base_weights['self'] = max(0.1, 0.2 - total_boost)
        
        # ë§¥ë½ë³„ ì¶”ê°€ ì¡°ì • (ê°€ìƒì˜ ë§¥ë½ ì •ë³´ í™œìš©)
        # ì‹¤ì œë¡œëŠ” input_dataì—ì„œ ë§¥ë½ ì •ë³´ë¥¼ ë°›ì•„ì˜¬ ê²ƒ
        
        return base_weights
    
    def _adjust_weights_by_intensity(self, 
                                   base_weights: Dict[str, float],
                                   community_emotion: Optional['EmotionData'],
                                   other_emotion: Optional['EmotionData'], 
                                   self_emotion: Optional['EmotionData']) -> Dict[str, float]:
        """ê°ì • ê°•ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¬ì¡°ì •"""
        
        adjusted_weights = base_weights.copy()
        
        # ê° ê°ì •ì˜ ê°•ë„ ê³„ì‚°
        def _get_intensity(emotion_data):
            if not emotion_data:
                return 0.0
            if hasattr(emotion_data.intensity, 'value'):
                return float(emotion_data.intensity.value) / 4.0
            else:
                return abs(emotion_data.arousal) if hasattr(emotion_data, 'arousal') else 0.5
        
        intensities = {
            'community': _get_intensity(community_emotion),
            'other': _get_intensity(other_emotion),
            'self': _get_intensity(self_emotion)
        }
        
        # ê·¹ë‹¨ì ìœ¼ë¡œ ê°•í•œ ê°ì •ì´ ìˆëŠ” ê²½ìš° ê°€ì¤‘ì¹˜ ì¬ë¶„ë°°
        max_intensity = max(intensities.values())
        if max_intensity > 0.8:  # ë§¤ìš° ê°•í•œ ê°ì •
            for source, intensity in intensities.items():
                if intensity == max_intensity:
                    # ê°€ì¥ ê°•í•œ ê°ì •ì— ì¶”ê°€ ê°€ì¤‘ì¹˜ (+20%ê¹Œì§€)
                    boost = min(0.2, (intensity - 0.6) * 0.5)
                    adjusted_weights[source] += boost
                    
                    # ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë“¤ì„ ë¹„ë¡€ì ìœ¼ë¡œ ê°ì†Œ
                    total_reduction = boost
                    other_sources = [s for s in adjusted_weights.keys() if s != source]
                    for other_source in other_sources:
                        adjusted_weights[other_source] -= total_reduction / len(other_sources)
                        adjusted_weights[other_source] = max(0.1, adjusted_weights[other_source])
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total = sum(adjusted_weights.values())
        for key in adjusted_weights:
            adjusted_weights[key] /= total
            
        return adjusted_weights
    
    def _resolve_emotion_conflicts(self, 
                                 community_emotion: Optional['EmotionData'],
                                 other_emotion: Optional['EmotionData'], 
                                 self_emotion: Optional['EmotionData'],
                                 weights: Dict[str, float],
                                 critical_loss: Dict[str, bool]) -> 'EmotionData':
        """ê°ì • ì¶©ëŒ í•´ê²°: ì†ì‹¤ ì–µì œ ìš°ì„  ì›ì¹™"""
        
        from data_models import EmotionData, EmotionState, EmotionIntensity
        
        # ì¡´ì¬í•˜ëŠ” ê°ì •ë“¤ë§Œ ìˆ˜ì§‘
        emotions = []
        emotion_sources = []
        emotion_weights = []
        
        if community_emotion:
            emotions.append(community_emotion)
            emotion_sources.append('community')
            emotion_weights.append(weights['community'])
            
        if other_emotion:
            emotions.append(other_emotion)
            emotion_sources.append('other')
            emotion_weights.append(weights['other'])
            
        if self_emotion:
            emotions.append(self_emotion)
            emotion_sources.append('self')
            emotion_weights.append(weights['self'])
        
        if not emotions:
            return EmotionData(
                primary_emotion=EmotionState.NEUTRAL,
                intensity=EmotionIntensity.MODERATE,
                confidence=0.5,
                dominance=0.5
            )
        
        # ê°ì • ì¶©ëŒ ë§¤íŠ¸ë¦­ìŠ¤ ì ìš©
        if len(emotions) > 1:
            resolved_emotion = self._apply_conflict_resolution_matrix(
                emotions, emotion_sources, emotion_weights, critical_loss
            )
        else:
            resolved_emotion = emotions[0]
        
        return resolved_emotion
    
    def _apply_conflict_resolution_matrix(self, 
                                        emotions: List['EmotionData'],
                                        sources: List[str],
                                        weights: List[float],
                                        critical_loss: Dict[str, bool]) -> 'EmotionData':
        """ê°ì • ì¶©ëŒ í•´ê²° ë§¤íŠ¸ë¦­ìŠ¤ - ì†ì‹¤ ì–µì œ ìš°ì„ """
        
        from data_models import EmotionData, EmotionState, EmotionIntensity
        
        # ì†ì‹¤ ê°ì •ê³¼ ê¸°ì¨ ê°ì • ë¶„ë¦¬
        loss_emotions = {'sadness', 'fear', 'disgust', 'anger'}
        joy_emotions = {'joy', 'trust', 'anticipation', 'surprise'}
        
        loss_emotion_candidates = []
        joy_emotion_candidates = []
        neutral_emotion_candidates = []
        
        for i, emotion in enumerate(emotions):
            emotion_name = emotion.primary_emotion.value if hasattr(emotion.primary_emotion, 'value') else str(emotion.primary_emotion)
            
            if emotion_name in loss_emotions:
                loss_emotion_candidates.append((emotion, sources[i], weights[i]))
            elif emotion_name in joy_emotions:
                joy_emotion_candidates.append((emotion, sources[i], weights[i]))
            else:
                neutral_emotion_candidates.append((emotion, sources[i], weights[i]))
        
        # ì¶©ëŒ í•´ê²° ê·œì¹™
        if loss_emotion_candidates and joy_emotion_candidates:
            # ì†ì‹¤ vs ê¸°ì¨ ì¶©ëŒ: ì†ì‹¤ ìš°ì„  (ì˜êµ¬ ì†ì‹¤ ì›ë¦¬)
            if critical_loss['any_critical']:
                # ì¹˜ëª…ì  ì†ì‹¤ì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì†ì‹¤ ê°ì • ìš°ì„ 
                strongest_loss = max(loss_emotion_candidates, key=lambda x: x[2])  # ê°€ì¤‘ì¹˜ ê¸°ì¤€
                return strongest_loss[0]
            else:
                # ì¼ë°˜ì  ì†ì‹¤ì˜ ê²½ìš° ê°€ì¤‘ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ê²°ì •í•˜ë˜ ì†ì‹¤ì— ì•½ê°„ì˜ ìš°ì„ ê¶Œ
                loss_total_weight = sum(x[2] for x in loss_emotion_candidates) * 1.2  # 20% ë³´ë„ˆìŠ¤
                joy_total_weight = sum(x[2] for x in joy_emotion_candidates)
                
                if loss_total_weight > joy_total_weight:
                    strongest_loss = max(loss_emotion_candidates, key=lambda x: x[2])
                    return strongest_loss[0]
                else:
                    strongest_joy = max(joy_emotion_candidates, key=lambda x: x[2])
                    return strongest_joy[0]
        
        elif loss_emotion_candidates:
            # ì†ì‹¤ ê°ì •ë§Œ ìˆëŠ” ê²½ìš°
            strongest_loss = max(loss_emotion_candidates, key=lambda x: x[2])
            return strongest_loss[0]
            
        elif joy_emotion_candidates:
            # ê¸°ì¨ ê°ì •ë§Œ ìˆëŠ” ê²½ìš°
            strongest_joy = max(joy_emotion_candidates, key=lambda x: x[2])
            return strongest_joy[0]
            
        else:
            # ì¤‘ì„± ê°ì •ë“¤ë§Œ ìˆëŠ” ê²½ìš°
            if neutral_emotion_candidates:
                strongest_neutral = max(neutral_emotion_candidates, key=lambda x: x[2])
                return strongest_neutral[0]
            else:
                # í´ë°±
                return EmotionData(
                    primary_emotion=EmotionState.NEUTRAL,
                    intensity=EmotionIntensity.MODERATE,
                    confidence=0.5
                )
    
    def _perform_ethical_reasoning(self, emotion_data: 'EmotionData', 
                                 input_data: Dict[str, Any]) -> Dict[str, float]:
        """MoE ê¸°ë°˜ ìœ¤ë¦¬ì  ê°€ì¹˜ ì¶”ë¡ """
        
        # ê¸°ë³¸ ìœ¤ë¦¬ ê°€ì¹˜ (fallback)
        ethical_values = {
            'care_harm': 0.5,      # ëŒë´„/í•´ì•… ë°©ì§€
            'fairness': 0.5,       # ê³µì •ì„±
            'loyalty': 0.5,        # ì¶©ì„±/ë°°ì‹ 
            'authority': 0.5,      # ê¶Œìœ„/ì¡´ì¤‘
            'sanctity': 0.5,       # ì‹ ì„±/ìˆœìˆ˜
            'liberty': 0.5         # ììœ /ì–µì••
        }
        
        if not emotion_data:
            return ethical_values
        
        # MoE ì‹œìŠ¤í…œì„ í†µí•œ ê³ ê¸‰ ìœ¤ë¦¬ì  ì¶”ë¡ 
        if self.moe_enabled:
            try:
                # ìœ¤ë¦¬ì  ë§¥ë½ ì„ë² ë”© ìƒì„±
                ethics_embedding = self._create_ethics_embedding(emotion_data, input_data)
                
                # MoE ì‹œìŠ¤í…œì„ í†µí•œ ìœ¤ë¦¬ì  ë¶„ì„ (ì•ˆì „í•œ ì°¨ì› ì²˜ë¦¬)
                if ethics_embedding.dim() == 1:
                    ethics_input = ethics_embedding.unsqueeze(0)
                else:
                    ethics_input = ethics_embedding
                
                # ethics_moeì˜ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                if hasattr(self.ethics_moe, 'gating_network'):
                    moe_device = next(self.ethics_moe.gating_network.parameters()).device
                    ethics_input = ethics_input.to(moe_device)
                
                moe_result = self.ethics_moe(ethics_input, return_expert_outputs=True)
                
                # ì „ë¬¸ê°€ë³„ ìœ¤ë¦¬ì  ê´€ì  í†µí•©
                ethical_values = self._integrate_expert_ethics(moe_result, emotion_data, input_data)
                
                self.logger.debug(f"MoE ìœ¤ë¦¬ ì¶”ë¡  ì™„ë£Œ: {len(moe_result.expert_outputs)}ê°œ ì „ë¬¸ê°€, "
                                f"ë‹¤ì–‘ì„±: {moe_result.diversity_score:.3f}")
                
            except Exception as e:
                # í”„ë¡œì íŠ¸ ê·œì¹™: fallback ì—†ëŠ” ìˆœìˆ˜ ì¬ì‹œë„ ë°©ì‹
                retry_count = 0
                max_retries = 3
                ethical_values = None
                while retry_count < max_retries:
                    retry_count += 1
                    self.logger.info(f"MoE ìœ¤ë¦¬ ì¶”ë¡  ì¬ì‹œë„ {retry_count}/{max_retries}")
                    try:
                        # ìœ¤ë¦¬ì  ë§¥ë½ ì„ë² ë”© ì¬ìƒì„±
                        ethics_embedding = self._create_ethics_embedding(emotion_data, input_data)
                        
                        # MoE ì‹œìŠ¤í…œì„ í†µí•œ ìœ¤ë¦¬ì  ë¶„ì„ ì¬ì‹œë„ (ì•ˆì „í•œ ì°¨ì› ì²˜ë¦¬)
                        if ethics_embedding.dim() == 1:
                            ethics_input = ethics_embedding.unsqueeze(0)
                        else:
                            ethics_input = ethics_embedding
                        
                        # ethics_moeì˜ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                        if hasattr(self.ethics_moe, 'gating_network'):
                            moe_device = next(self.ethics_moe.gating_network.parameters()).device
                            ethics_input = ethics_input.to(moe_device)
                        
                        moe_result = self.ethics_moe(ethics_input, return_expert_outputs=True)
                        
                        # ì „ë¬¸ê°€ë³„ ìœ¤ë¦¬ì  ê´€ì  í†µí•©
                        ethical_values = self._integrate_expert_ethics(moe_result, emotion_data, input_data)
                        
                        self.logger.info(f"MoE ìœ¤ë¦¬ ì¶”ë¡  ì¬ì‹œë„ ì„±ê³µ: {len(moe_result.expert_outputs)}ê°œ ì „ë¬¸ê°€")
                        break
                    except Exception as retry_error:
                        self.logger.error(f"MoE ìœ¤ë¦¬ ì¶”ë¡  ì¬ì‹œë„ {retry_count} ì‹¤íŒ¨: {retry_error}")
                        if retry_count >= max_retries:
                            self.logger.error("MoE ìœ¤ë¦¬ ì¶”ë¡  ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì •ì§€")
                            raise RuntimeError(f"MoE ìœ¤ë¦¬ ì¶”ë¡  ìµœì¢… ì‹¤íŒ¨: {retry_error}")
                        import time
                        time.sleep(0.5)
                
                if ethical_values is None:
                    self.logger.error("MoE ìœ¤ë¦¬ ì¶”ë¡  ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì •ì§€")
                    raise RuntimeError("MoE ìœ¤ë¦¬ ì¶”ë¡  ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€")
        else:
            # ê¸°ë³¸ ê°ì • ê¸°ë°˜ ìœ¤ë¦¬ ì¶”ë¡ 
            ethical_values = self._basic_ethical_reasoning(emotion_data, input_data)
        
        # ë²•ë¥  ì „ë¬¸ê°€ ì‹œìŠ¤í…œ í†µí•©
        if self.legal_expert_enabled:
            try:
                legal_analysis = self._apply_legal_expert_analysis(input_data, ethical_values)
                if legal_analysis:
                    # ë²•ë¥  ë¶„ì„ ê²°ê³¼ë¥¼ ìœ¤ë¦¬ì  ê°€ì¹˜ì— ë°˜ì˜
                    ethical_values = self._integrate_legal_analysis(ethical_values, legal_analysis)
                    
                    self.logger.debug(f"ë²•ë¥  ë¶„ì„ í†µí•© ì™„ë£Œ: ìœ„í—˜ë„ {legal_analysis.risk_level.value}")
                    
            except Exception as e:
                self.logger.warning(f"ë²•ë¥  ì „ë¬¸ê°€ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return ethical_values
    
    def _create_ethics_embedding(self, emotion_data: 'EmotionData', input_data: Dict[str, Any]) -> torch.Tensor:
        """ìœ¤ë¦¬ì  ë§¥ë½ ì„ë² ë”© ìƒì„±"""
        features = []
        
        # 1. ê°ì • íŠ¹ì„± (8ì°¨ì›)
        if emotion_data:
            primary_emotion = emotion_data.primary_emotion.value if hasattr(emotion_data.primary_emotion, 'value') else str(emotion_data.primary_emotion)
            emotion_mapping = {
                'joy': [1, 0, 0, 0, 0, 0, 0, 0],
                'sadness': [0, 1, 0, 0, 0, 0, 0, 0],
                'anger': [0, 0, 1, 0, 0, 0, 0, 0],
                'fear': [0, 0, 0, 1, 0, 0, 0, 0],
                'trust': [0, 0, 0, 0, 1, 0, 0, 0],
                'disgust': [0, 0, 0, 0, 0, 1, 0, 0],
                'surprise': [0, 0, 0, 0, 0, 0, 1, 0],
                'anticipation': [0, 0, 0, 0, 0, 0, 0, 1]
            }
            emotion_vec = emotion_mapping.get(primary_emotion, [0, 0, 0, 0, 0, 0, 0, 0])
            features.extend(emotion_vec)
            
            # ê°ì • ê°•ë„ ë° ê¸°íƒ€ íŠ¹ì„±
            intensity = emotion_data.intensity.value if hasattr(emotion_data.intensity, 'value') else 3
            features.extend([
                intensity / 6.0,  # ì •ê·œí™”ëœ ê°•ë„
                getattr(emotion_data, 'confidence', 0.5),
                getattr(emotion_data, 'dominance', 0.5)
            ])
        else:
            features.extend([0] * 11)  # ê°ì • ë°ì´í„° ì—†ìŒ
        
        # 2. ë§¥ë½ íŠ¹ì„± (20ì°¨ì›)
        context_features = []
        
        # ì‹œê°„ì  ë§¥ë½
        duration = input_data.get('duration', 60)  # ê¸°ë³¸ 60ì´ˆ
        context_features.append(min(duration / 3600, 1.0))  # ì‹œê°„ ì •ê·œí™” (ìµœëŒ€ 1ì‹œê°„)
        
        # í™•ì‹¤ì„±
        certainty = input_data.get('certainty', 0.5)
        context_features.append(certainty)
        
        # ê·¼ì ‘ì„±
        propinquity = input_data.get('propinquity', 0.5)
        context_features.append(propinquity)
        
        # ìƒì‚°ì„±
        productivity = input_data.get('productivity', 0.5)
        context_features.append(productivity)
        
        # ìˆœìˆ˜ì„±
        purity = input_data.get('purity', 0.5)
        context_features.append(purity)
        
        # ë²”ìœ„ (ëª‡ ëª…ì—ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€)
        affected_people = input_data.get('affected_people', 1)
        context_features.append(min(affected_people / 100, 1.0))  # ìµœëŒ€ 100ëª…ìœ¼ë¡œ ì •ê·œí™”
        
        # í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ¤ë¦¬ì  ë‹¨ì„œ (14ì°¨ì›)
        text = input_data.get('text', '') or input_data.get('description', '')
        if text:
            text_lower = text.lower()
            
            # ê° ìœ¤ë¦¬ì  ì°¨ì›ì˜ í‚¤ì›Œë“œ ì¡´ì¬ ì—¬ë¶€
            care_keywords = ['ëŒë´„', 'ë³´í˜¸', 'ì•ˆì „', 'ê±´ê°•', 'ë³µì§€']
            fairness_keywords = ['ê³µì •', 'í‰ë“±', 'ì •ì˜', 'ê· í˜•', 'ê³µí‰']
            loyalty_keywords = ['ì¶©ì„±', 'ì‹ ë¢°', 'ë°°ì‹ ', 'ì†Œì†', 'ê·¸ë£¹']
            authority_keywords = ['ê¶Œìœ„', 'ì¡´ì¤‘', 'ì§ˆì„œ', 'ê·œì¹™', 'ì „í†µ']
            sanctity_keywords = ['ì‹ ì„±', 'ìˆœìˆ˜', 'ë”ëŸ½í˜', 'ê±°ë£©', 'ì •ê²°']
            liberty_keywords = ['ììœ ', 'ì–µì••', 'ë…ë¦½', 'ì„ íƒ', 'ììœ¨']
            
            for keywords in [care_keywords, fairness_keywords, loyalty_keywords, 
                           authority_keywords, sanctity_keywords, liberty_keywords]:
                keyword_score = sum(1 for keyword in keywords if keyword in text_lower)
                context_features.append(min(keyword_score / len(keywords), 1.0))
            
            # ì¶”ê°€ì ì¸ ë§¥ë½ íŠ¹ì„± (8ì°¨ì›)
            context_features.extend([
                float('ìœ„í—˜' in text_lower),  # ìœ„í—˜ ì¡´ì¬
                float('ì´ìµ' in text_lower),  # ì´ìµ ì¡´ì¬
                float('ê°ˆë“±' in text_lower),  # ê°ˆë“± ì¡´ì¬
                float('ë„ë•' in text_lower),  # ë„ë•ì  ì–¸ê¸‰
                float('ì‚¬íšŒ' in text_lower),  # ì‚¬íšŒì  ë§¥ë½
                float('ê°œì¸' in text_lower),  # ê°œì¸ì  ë§¥ë½
                float('ê¸´ê¸‰' in text_lower),  # ê¸´ê¸‰ì„±
                float('ì¥ê¸°' in text_lower)   # ì¥ê¸°ì  ì˜í–¥
            ])
        else:
            context_features.extend([0] * 14)
        
        features.extend(context_features)
        
        # 3. íŒ¨ë”©í•˜ì—¬ 512ì°¨ì›ìœ¼ë¡œ ë§ì¶¤
        while len(features) < 512:
            features.append(0.0)
        
        return torch.tensor(features[:512], dtype=torch.float32, device=self.device)
    
    def _integrate_expert_ethics(self, moe_result, emotion_data: 'EmotionData', 
                               input_data: Dict[str, Any]) -> Dict[str, float]:
        """ì „ë¬¸ê°€ë³„ ìœ¤ë¦¬ì  ê´€ì  í†µí•©"""
        
        # ê¸°ë³¸ ìœ¤ë¦¬ ê°€ì¹˜
        ethical_values = {
            'care_harm': 0.5,
            'fairness': 0.5,
            'loyalty': 0.5,
            'authority': 0.5,
            'sanctity': 0.5,
            'liberty': 0.5
        }
        
        # ì „ë¬¸ê°€ë³„ íŠ¹í™” ë¶„ì„
        expert_contributions = {}
        
        for expert_output in moe_result.expert_outputs:
            expert_id = expert_output.expert_id
            confidence = expert_output.confidence
            weight = expert_output.weight
            output = expert_output.output
            
            # ì „ë¬¸ê°€ ìœ í˜•ë³„ ìœ¤ë¦¬ì  í•´ì„
            if 'utilitarian' in expert_id:
                # ê³µë¦¬ì£¼ì˜: ìµœëŒ€ í–‰ë³µ ì›ì¹™
                expert_contributions['utilitarian'] = {
                    'care_harm': output[0].item() * 1.2,  # í•´ì•… ë°©ì§€ ì¤‘ì‹œ
                    'fairness': output[1].item() * 1.0,
                    'loyalty': output[2].item() * 0.8,
                    'authority': output[3].item() * 0.7,
                    'sanctity': output[4].item() * 0.6,
                    'liberty': output[5].item() * 1.1,
                    'weight': weight,
                    'confidence': confidence
                }
            elif 'deontological' in expert_id:
                # ì˜ë¬´ë¡ : ì˜ë¬´ì™€ ê·œì¹™ ì¤‘ì‹œ
                expert_contributions['deontological'] = {
                    'care_harm': output[0].item() * 1.0,
                    'fairness': output[1].item() * 1.3,  # ê³µì •ì„± ì¤‘ì‹œ
                    'loyalty': output[2].item() * 0.9,
                    'authority': output[3].item() * 1.2,  # ê¶Œìœ„ ì¤‘ì‹œ
                    'sanctity': output[4].item() * 1.1,
                    'liberty': output[5].item() * 0.8,
                    'weight': weight,
                    'confidence': confidence
                }
            elif 'virtue_ethics' in expert_id:
                # ë•ìœ¤ë¦¬: ì¸ê²©ê³¼ ë•ëª© ì¤‘ì‹œ
                expert_contributions['virtue_ethics'] = {
                    'care_harm': output[0].item() * 1.1,
                    'fairness': output[1].item() * 1.1,
                    'loyalty': output[2].item() * 1.2,  # ì¶©ì„± ì¤‘ì‹œ
                    'authority': output[3].item() * 1.0,
                    'sanctity': output[4].item() * 1.3,  # ìˆœìˆ˜ì„± ì¤‘ì‹œ
                    'liberty': output[5].item() * 0.9,
                    'weight': weight,
                    'confidence': confidence
                }
            elif 'care_ethics' in expert_id:
                # ëŒë´„ìœ¤ë¦¬: ê´€ê³„ì™€ ëŒë´„ ì¤‘ì‹œ
                expert_contributions['care_ethics'] = {
                    'care_harm': output[0].item() * 1.4,  # ëŒë´„ ìµœìš°ì„ 
                    'fairness': output[1].item() * 0.9,
                    'loyalty': output[2].item() * 1.3,  # ê´€ê³„ ì¤‘ì‹œ
                    'authority': output[3].item() * 0.7,
                    'sanctity': output[4].item() * 0.8,
                    'liberty': output[5].item() * 1.0,
                    'weight': weight,
                    'confidence': confidence
                }
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ìœ¤ë¦¬ ê°€ì¹˜ ê³„ì‚°
        if expert_contributions:
            total_weight = sum(contrib['weight'] for contrib in expert_contributions.values())
            
            if total_weight > 0:
                for value_key in ethical_values.keys():
                    weighted_sum = sum(
                        contrib[value_key] * contrib['weight'] 
                        for contrib in expert_contributions.values()
                    )
                    ethical_values[value_key] = max(0.1, min(0.9, weighted_sum / total_weight))
        
        return ethical_values
    
    def _basic_ethical_reasoning(self, emotion_data: 'EmotionData', 
                               input_data: Dict[str, Any]) -> Dict[str, float]:
        """ê¸°ë³¸ ê°ì • ê¸°ë°˜ ìœ¤ë¦¬ ì¶”ë¡  (fallback)"""
        
        ethical_values = {
            'care_harm': 0.5,
            'fairness': 0.5,
            'loyalty': 0.5,
            'authority': 0.5,
            'sanctity': 0.5,
            'liberty': 0.5
        }
        
        if not emotion_data:
            return ethical_values
            
        # ê°ì •ì— ë”°ë¥¸ ìœ¤ë¦¬ì  ê°€ì¹˜ ì¡°ì • (ë¯¸ë¬˜í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ)
        primary_emotion = emotion_data.primary_emotion.value if hasattr(emotion_data.primary_emotion, 'value') else str(emotion_data.primary_emotion)
        
        if primary_emotion == 'joy':
            ethical_values['care_harm'] += 0.1  # ê¸°ì  ë•Œ ë” ëŒë´„ ì§€í–¥
            ethical_values['fairness'] += 0.05
        elif primary_emotion == 'sadness':
            ethical_values['care_harm'] += 0.15  # ìŠ¬í”Œ ë•Œ í•´ì•… ë°©ì§€ ì¤‘ì‹œ
            ethical_values['loyalty'] += 0.1
        elif primary_emotion == 'anger':
            ethical_values['fairness'] += 0.2   # í™”ë‚  ë•Œ ê³µì •ì„± ì¤‘ì‹œ
            ethical_values['authority'] -= 0.1
        elif primary_emotion == 'fear':
            ethical_values['care_harm'] += 0.2  # ë‘ë ¤ìš¸ ë•Œ ì•ˆì „ ìµœìš°ì„ 
            ethical_values['authority'] += 0.1
        elif primary_emotion == 'trust':
            ethical_values['loyalty'] += 0.15
            ethical_values['fairness'] += 0.1
        
        return ethical_values
    
    def _apply_legal_expert_analysis(self, input_data: Dict[str, Any], 
                                   ethical_values: Dict[str, float]):
        """ë²•ë¥  ì „ë¬¸ê°€ ë¶„ì„ ì ìš©"""
        
        # ë„ë©”ì¸ ì‹ë³„
        domain = self._identify_legal_domain(input_data)
        
        # ë²•ë¥  ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° êµ¬ì„±
        context_data = {
            'urgency': input_data.get('urgency', 0.5),
            'impact_level': input_data.get('impact_level', 0.5),
            'public_interest': ethical_values.get('care_harm', 0.5),
            'stakeholder_count': input_data.get('affected_people', 1),
            'financial_impact': input_data.get('financial_impact', 0)
        }
        
        # ë²•ë¥  ë¶„ì„ ìˆ˜í–‰
        text = input_data.get('text', '') or input_data.get('description', '')
        legal_analysis = self.legal_expert.analyze_legal_context(
            domain=domain,
            text=text,
            context_data=context_data
        )
        
        return legal_analysis
    
    def _identify_legal_domain(self, input_data: Dict[str, Any]) -> LegalDomain:
        """ë²•ë¥  ë„ë©”ì¸ ì‹ë³„"""
        
        text = input_data.get('text', '') or input_data.get('description', '')
        if not text:
            return LegalDomain.LIFE  # ê¸°ë³¸ê°’
        
        text_lower = text.lower()
        
        # ë„ë©”ì¸ë³„ í‚¤ì›Œë“œ ë§¤ì¹­
        domain_keywords = {
            LegalDomain.EDUCATION: ['í•™êµ', 'êµìœ¡', 'í•™ìƒ', 'êµì‚¬', 'ìˆ˜ì—…', 'í•™ìŠµ', 'ì‹œí—˜'],
            LegalDomain.BUSINESS: ['íšŒì‚¬', 'ì‚¬ì—…', 'ê·¼ë¬´', 'ì§ì›', 'ê³„ì•½', 'ê±°ë˜', 'ë§¤ì¶œ'],
            LegalDomain.SOCIAL: ['ì‚¬íšŒ', 'ê³µë™ì²´', 'ê´€ê³„', 'ì‚¬ëŒ', 'ì»¤ë®¤ë‹ˆí‹°', 'ë‹¨ì²´'],
            LegalDomain.POLITICS: ['ì •ì¹˜', 'ì •ë¶€', 'ì„ ê±°', 'ì •ì±…', 'ë²•ë¥ ', 'í–‰ì •', 'ê³µë¬´ì›'],
            LegalDomain.LIFE: ['ìƒí™œ', 'ì¼ìƒ', 'ê°œì¸', 'ê°€ì¡±', 'ê±´ê°•', 'ì†Œë¹„', 'ì£¼ê±°']
        }
        
        domain_scores = {}
        for domain, keywords in domain_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            domain_scores[domain] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë„ë©”ì¸ ë°˜í™˜
        best_domain = max(domain_scores, key=domain_scores.get)
        return best_domain if domain_scores[best_domain] > 0 else LegalDomain.LIFE
    
    def _integrate_legal_analysis(self, ethical_values: Dict[str, float], 
                                legal_analysis) -> Dict[str, float]:
        """ë²•ë¥  ë¶„ì„ ê²°ê³¼ë¥¼ ìœ¤ë¦¬ì  ê°€ì¹˜ì— í†µí•©"""
        
        enhanced_values = ethical_values.copy()
        
        # ìœ„í—˜ ìˆ˜ì¤€ì— ë”°ë¥¸ ìœ¤ë¦¬ì  ê°€ì¹˜ ì¡°ì •
        risk_level = legal_analysis.risk_level
        
        if risk_level.value == 'critical':
            # ì‹¬ê°í•œ ë²•ì  ìœ„í—˜ â†’ ì•ˆì „ì„± ìš°ì„ 
            enhanced_values['care_harm'] = min(0.9, enhanced_values['care_harm'] * 1.3)
            enhanced_values['authority'] = min(0.9, enhanced_values['authority'] * 1.2)
            enhanced_values['liberty'] = max(0.1, enhanced_values['liberty'] * 0.7)
            
        elif risk_level.value == 'high':
            # ë†’ì€ ë²•ì  ìœ„í—˜ â†’ ì‹ ì¤‘í•œ ì ‘ê·¼
            enhanced_values['care_harm'] = min(0.9, enhanced_values['care_harm'] * 1.2)
            enhanced_values['authority'] = min(0.9, enhanced_values['authority'] * 1.1)
            enhanced_values['fairness'] = min(0.9, enhanced_values['fairness'] * 1.1)
            
        elif risk_level.value == 'medium':
            # ì¤‘ê°„ ë²•ì  ìœ„í—˜ â†’ ê· í˜• ì¡°ì •
            enhanced_values['fairness'] = min(0.9, enhanced_values['fairness'] * 1.1)
            enhanced_values['authority'] = min(0.9, enhanced_values['authority'] * 1.05)
            
        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
        confidence_factor = legal_analysis.confidence
        
        # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ì¡°ì • í­ì„ ì¤„ì„
        if confidence_factor < 0.7:
            adjustment_factor = 0.5 + confidence_factor * 0.5
            
            for key in enhanced_values:
                original_value = ethical_values[key]
                adjusted_value = enhanced_values[key]
                enhanced_values[key] = original_value + (adjusted_value - original_value) * adjustment_factor
        
        # ë²•ë¥  ë¶„ì„ ë©”íƒ€ë°ì´í„°ëŠ” ë³„ë„ë¡œ ì €ì¥ (ethical_valuesëŠ” floatë§Œ í¬í•¨í•´ì•¼ í•¨)
        self.last_legal_metadata = {
            'risk_level': risk_level.value,
            'confidence': confidence_factor,
            'relevant_laws': legal_analysis.relevant_laws,
            'recommendations': legal_analysis.recommendations[:3]  # ìƒìœ„ 3ê°œë§Œ
        }
        
        return enhanced_values
    
    def _extract_learning_bias(self, past_regret_memory: Dict[str, float]) -> Dict[str, float]:
        """ê³¼ê±° í›„íšŒì—ì„œ ë¯¸ë¬˜í•œ í•™ìŠµ í¸í–¥ ì¶”ì¶œ (ì§ì ‘ ê°œì… ì•„ë‹˜)"""
        
        # í›„íšŒëŠ” ì§ì ‘ì ì´ì§€ ì•Šê³  í•™ìŠµëœ í¸í–¥ìœ¼ë¡œë§Œ ì‘ìš©
        learning_bias = {
            'risk_aversion': 0.0,    # ìœ„í—˜ íšŒí”¼ ì„±í–¥
            'time_preference': 0.0,   # ì‹œê°„ ì„ í˜¸
            'social_weight': 0.0      # ì‚¬íšŒì  ê³ ë ¤ ê°€ì¤‘ì¹˜
        }
        
        # ê³¼ê±° í›„íšŒ íŒ¨í„´ì—ì„œ í•™ìŠµëœ í¸í–¥ ì¶”ì¶œ (ë§¤ìš° ë¯¸ë¬˜í•˜ê²Œ)
        avg_regret = past_regret_memory.get('average_regret', 0.0)
        
        if avg_regret > 0.7:  # ë†’ì€ í›„íšŒ ê²½í—˜ ì‹œ
            learning_bias['risk_aversion'] = 0.1   # ì•½ê°„ ë” ì‹ ì¤‘í•˜ê²Œ
            learning_bias['time_preference'] = 0.05  # ì¥ê¸°ì  ê´€ì  ì¦ê°€
        elif avg_regret < 0.3:  # ë‚®ì€ í›„íšŒ ê²½í—˜ ì‹œ  
            learning_bias['risk_aversion'] = -0.05  # ì•½ê°„ ë” ëŒ€ë‹´í•˜ê²Œ
            
        return learning_bias
    
    async def _search_similar_experiences(self, input_data: Dict[str, Any], 
                                        experience_db) -> List[Dict[str, Any]]:
        """ê²½í—˜ ë©”ëª¨ë¦¬ì—ì„œ ìœ ì‚¬ ìƒí™© ê²€ìƒ‰"""
        try:
            from advanced_experience_database import ExperienceQuery
            
            # ì¿¼ë¦¬ êµ¬ì„±
            scenario_text = input_data.get('text_description', '')
            query = ExperienceQuery(
                query_text=scenario_text,
                category_filter='ethical_decision',
                max_results=5,
                similarity_threshold=0.7
            )
            
            # ìœ ì‚¬ ê²½í—˜ ê²€ìƒ‰
            similar_experiences = await experience_db.search_experiences(query)
            return similar_experiences
            
        except Exception as e:
            self.logger.warning(f"ìœ ì‚¬ ê²½í—˜ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _extract_experience_adjustments(self, similar_experiences: List[Dict[str, Any]]) -> Dict[str, float]:
        """ìœ ì‚¬ ê²½í—˜ì—ì„œ ë²¤ë‹´ ê³„ì‚° ì¡°ì •ê°’ ì¶”ì¶œ"""
        adjustments = {
            'intensity_bias': 0.0,
            'duration_bias': 0.0,
            'certainty_bias': 0.0,
            'risk_aversion_bias': 0.0,
            'social_weight_bias': 0.0
        }
        
        if not similar_experiences:
            return adjustments
            
        # ê²½í—˜ë³„ í›„íšŒ ì •ë³´ ë¶„ì„
        total_weight = 0.0
        for exp in similar_experiences:
            exp_weight = exp.get('similarity_score', 0.5)
            regret_level = exp.get('regret_level', 0.5)
            outcome_satisfaction = exp.get('outcome_satisfaction', 0.5)
            
            # í›„íšŒê°€ ë†’ì•˜ë˜ ê²½ìš° -> ë” ì‹ ì¤‘í•˜ê²Œ
            if regret_level > 0.6:
                adjustments['certainty_bias'] += exp_weight * 0.1
                adjustments['risk_aversion_bias'] += exp_weight * 0.15
            
            # ë§Œì¡±ë„ê°€ ë‚®ì•˜ë˜ ê²½ìš° -> ë” ë³´ìˆ˜ì ìœ¼ë¡œ  
            if outcome_satisfaction < 0.4:
                adjustments['intensity_bias'] += exp_weight * 0.05
                adjustments['duration_bias'] += exp_weight * 0.1
                
            total_weight += exp_weight
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì •ê·œí™”
        if total_weight > 0:
            for key in adjustments:
                adjustments[key] = max(-0.2, min(0.2, adjustments[key] / total_weight))
                
        return adjustments
    
    def _apply_experience_adjustments(self, input_data: Dict[str, Any], 
                                    adjustments: Dict[str, float]) -> Dict[str, Any]:
        """ê²½í—˜ ê¸°ë°˜ ì¡°ì •ê°’ì„ ì…ë ¥ ë°ì´í„°ì— ì ìš©"""
        adjusted_input = input_data.copy()
        
        # ë²¤ë‹´ ë³€ìˆ˜ë“¤ ì¡°ì •
        if 'input_values' in adjusted_input:
            bentham_values = adjusted_input['input_values'].copy()
            
            # intensity ì¡°ì •
            if 'intensity' in bentham_values:
                bentham_values['intensity'] = max(0.0, min(1.0, 
                    bentham_values['intensity'] + adjustments.get('intensity_bias', 0.0)))
            
            # duration ì¡°ì •  
            if 'duration' in bentham_values:
                bentham_values['duration'] = max(0.0, min(1.0,
                    bentham_values['duration'] + adjustments.get('duration_bias', 0.0)))
                    
            # certainty ì¡°ì •
            if 'certainty' in bentham_values:
                bentham_values['certainty'] = max(0.0, min(1.0,
                    bentham_values['certainty'] + adjustments.get('certainty_bias', 0.0)))
            
            adjusted_input['input_values'] = bentham_values
        
        # ê°€ì¤‘ì¹˜ ë ˆì´ì–´ ì¡°ì •
        if 'weight_adjustments' not in adjusted_input:
            adjusted_input['weight_adjustments'] = {}
            
        weight_adj = adjusted_input['weight_adjustments']
        weight_adj['risk_aversion'] = adjustments.get('risk_aversion_bias', 0.0)
        weight_adj['social_emphasis'] = adjustments.get('social_weight_bias', 0.0)
        
        return adjusted_input
    
    async def calculate_with_experience_integration(self,
                                                  input_data: Dict[str, Any],
                                                  experience_db = None,
                                                  use_cache: bool = True) -> EnhancedHedonicResult:
        """ê²½í—˜ ë©”ëª¨ë¦¬ í†µí•© ë²¤ë‹´ ê³„ì‚° - ìœ ì‚¬ ìƒí™© ê¸°ë°˜ íŒë‹¨ ê°œì„ """
        
        # ìºì‹œ í™•ì¸
        cache_key = self._generate_cache_key(input_data)
        if use_cache and cache_key in self.calculation_cache:
            return self.calculation_cache[cache_key]
        
        try:
            # 1. ê²½í—˜ ë©”ëª¨ë¦¬ì—ì„œ ìœ ì‚¬ ìƒí™© ê²€ìƒ‰
            experience_adjustments = {}
            if experience_db:
                similar_experiences = await self._search_similar_experiences(
                    input_data, experience_db
                )
                experience_adjustments = self._extract_experience_adjustments(
                    similar_experiences
                )
            
            # 2. ê²½í—˜ ê¸°ë°˜ ì…ë ¥ ë°ì´í„° ì¡°ì •
            adjusted_input = self._apply_experience_adjustments(
                input_data, experience_adjustments
            )
            
            # 3. ê¸°ì¡´ ê³ ê¸‰ ê³„ì‚° ìˆ˜í–‰
            result = self.calculate_with_advanced_layers(adjusted_input, use_cache=False)
            
            # 4. ê²½í—˜ ë©”ëª¨ë¦¬ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            result.metadata['experience_influence'] = experience_adjustments
            result.metadata['similar_cases_count'] = len(experience_adjustments)
            
            # 5. ìºì‹œ ì €ì¥
            if use_cache:
                self.calculation_cache[cache_key] = result
                
            return result
            
        except Exception as e:
            self.logger.error(f"ê²½í—˜ í†µí•© ë²¤ë‹´ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # fallback to regular calculation
            return self.calculate_with_advanced_layers(input_data, use_cache)

    def calculate_with_advanced_layers(self, 
                                     input_data: Dict[str, Any],
                                     use_cache: bool = True) -> EnhancedHedonicResult:
        """ê³ ê¸‰ ë‹¤ì¸µ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ì¾Œë½ ê³„ì‚°"""
        
        # ìºì‹œ í™•ì¸
        cache_key = self._generate_cache_key(input_data)
        if use_cache and cache_key in self.calculation_cache:
            self.logger.debug("ìºì‹œëœ ê²°ê³¼ ë°˜í™˜")
            return self.calculation_cache[cache_key]
            
        try:
            # 1. ê³ ê¸‰ ë§¥ë½ ë¶„ì„
            context = self._prepare_advanced_context(input_data)
            
            # ì •ê·œí™” ë³´ì¥ (GPT ì œì•ˆ)
            self._normalize_input_values(context)
            
            # 2. ê¸°ë³¸ ê³„ì‚°
            base_score = self._calculate_base_advanced(context)
            
            # 3. ì‹ ê²½ë§ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì˜ˆì¸¡
            if self.advanced_config['use_neural_prediction']:
                neural_weights = self._predict_neural_weights(context)
            else:
                neural_weights = None
                
            # 4. ê° ë ˆì´ì–´ ì ìš© (ë™ì  ë©€í‹°ë ˆì´ì–´ AI ì‹œìŠ¤í…œ)
            layered_score = base_score
            layer_results = []
            layer_interactions = []  # ë ˆì´ì–´ê°„ ìƒí˜¸ì‘ìš© ì¶”ì 
            
            for i, layer in enumerate(self.weight_layers):
                try:
                    # ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)
                    if neural_weights is not None:
                        layer_weight = neural_weights[i].item()
                    else:
                        layer_weight = layer.compute_weight(context)
                    
                    # ë™ì  ì¡°ì •: ë³µì¡í•œ ìƒí™©ì—ì„œ ë” ë„“ì€ ë²”ìœ„ í—ˆìš©
                    context_complexity = self._calculate_context_complexity(context)
                    if context_complexity > 0.7:  # ë³µì¡í•œ ìƒí™©
                        layer_weight = max(0.3, min(2.5, layer_weight))  # ë” ë„“ì€ ë²”ìœ„
                    else:  # ì¼ë°˜ì  ìƒí™©
                        layer_weight = max(0.7, min(1.5, layer_weight))  # ì•ˆì •ì  ë²”ìœ„
                    
                    # ë ˆì´ì–´ ìƒí˜¸ì‘ìš© ê³„ì‚°
                    if i > 0:
                        interaction_factor = self._calculate_layer_interaction(
                            layer_results[-1], layer, context
                        )
                        layer_weight *= interaction_factor
                        layer_interactions.append(interaction_factor)
                    
                    # ì ì§„ì  ê³±ì…ˆ ì ìš© (ì›ë³¸ ë©€í‹°ë ˆì´ì–´ ì„¤ê³„)
                    layered_score *= layer_weight
                    
                    layer_contribution = layer.get_contribution()
                    layer_contribution.weight_factor = layer_weight
                    layer_results.append(layer_contribution)
                    
                    self.logger.debug(f"{layer.name}: {layer_weight:.3f} -> ëˆ„ì  ì ìˆ˜: {layered_score:.3f}")
                    
                except Exception as e:
                    self.logger.error(f"{layer.name} ë ˆì´ì–´ ì ìš© ì‹¤íŒ¨: {e}")
                    # ì¤‘ë¦½ ê°€ì¤‘ì¹˜ ì ìš© (ì‹œìŠ¤í…œ ì§€ì†ì„± ë³´ì¥)
                    layered_score *= 1.0
                    layer_results.append(WeightLayerResult(
                        layer_name=layer.name,
                        weight_factor=1.0,
                        contribution_score=0.0,
                        confidence=0.5,
                        metadata={'reasoning': f"ì¤‘ë¦½ ê°€ì¤‘ì¹˜ ì ìš©: {str(e)}"}
                    ))
            
            # ì§€ëŠ¥ì  ì ìˆ˜ ì •ê·œí™” (ë™ì  ë²”ìœ„ ì¡°ì •)
            layered_score = self._smart_score_normalization(layered_score, context, layer_interactions)
            
            # 5. ê³ ê¸‰ ê·¹ë‹¨ê°’ ë³´ì •
            adjustment_result = self._apply_advanced_extreme_adjustment(
                layered_score, context
            )
            
            # 6. ìµœì í™” (ì„ íƒì )
            if self.advanced_config['optimization_enabled']:
                final_score = self._optimize_final_score(
                    adjustment_result['score'], context
                )
            else:
                final_score = adjustment_result['score']
            
            # ìµœì¢… ì ìˆ˜ ì•ˆì „ì„± ê²€ì¦ ë° ì •ê·œí™”
            final_score = self._ensure_score_bounds(final_score)
                
            # 7. ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_comprehensive_confidence(
                context, layer_results, neural_weights
            )
            
            # 8. ìƒì„¸ ë¶„ì„ ê²°ê³¼
            calculation_breakdown = self._generate_detailed_breakdown(
                base_score, layer_results, adjustment_result, context
            )
            
            # 9. HedonicValues ê°ì²´ ìƒì„± (ë²¤ë‹´ì˜ 7ê°€ì§€ ë³€ìˆ˜ ì‹¤ì œ ê³„ì‚°)
            hedonic_values = self._calculate_hedonic_values(context, final_score, base_score)
            
            # ê²°ê³¼ ìƒì„±
            result = EnhancedHedonicResult(
                final_score=final_score,
                base_score=base_score,
                hedonic_values=hedonic_values,  # ì‹¤ì œ ë²¤ë‹´ ê°’ë“¤ í¬í•¨
                layer_contributions=layer_results,
                extreme_adjustment_applied=adjustment_result['applied'],
                adjustment_factor=adjustment_result['factor'],
                confidence_score=confidence,
                processing_time=time.time() - context.start_time if hasattr(context, 'start_time') else 0.0,
                context_analysis={
                    'calculation_breakdown': calculation_breakdown,
                    'neural_prediction_used': neural_weights is not None,
                    'optimization_applied': self.advanced_config['optimization_enabled']
                }
            )
            
            # ìºì‹œ ì €ì¥
            if use_cache:
                with self.cache_lock:
                    self.calculation_cache[cache_key] = result
                    
            return result
            
        except Exception as e:
            self.logger.error(f"ê³ ê¸‰ ê³„ì‚° ì‹¤íŒ¨: {e}")
            raise RuntimeError(
                f"ê³ ê¸‰ ë²¤ë‹´ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}. "
                f"ì‹ ê²½ë§ ì˜ˆì¸¡, íŠ¸ëœìŠ¤í¬ë¨¸ ë¶„ì„, ë˜ëŠ” ê°€ì¤‘ì¹˜ ë ˆì´ì–´ ì¤‘ í•˜ë‚˜ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
                f"ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì˜¬ë°”ë¥´ê²Œ ì´ˆê¸°í™”ë˜ê³  í›ˆë ¨ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. "
                f"ëŒ€ì²´ ê³„ì‚° ë°©ë²•ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì •í™•í•œ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
            
    def _calculate_hedonic_values(self, context: AdvancedCalculationContext, final_score: float, base_score: float) -> HedonicValues:
        """ë²¤ë‹´ì˜ 7ê°€ì§€ ë³€ìˆ˜ë¥¼ ì‹¤ì œ ê³„ì‚°í•˜ì—¬ HedonicValues ê°ì²´ ìƒì„±"""
        from data_models import HedonicValues
        
        try:
            # ê¸°ë³¸ ë§¥ë½ ë°ì´í„° ì¶”ì¶œ
            emotion_data = context.emotion_data
            affected_count = context.affected_count
            duration_seconds = context.duration_seconds
            uncertainty_level = context.uncertainty_level
            information_quality = context.information_quality
            
            # 1. ê°•ë„ (Intensity) - ê°ì • ê°•ë„ì™€ ìµœì¢… ì ìˆ˜ ê¸°ë°˜
            intensity = final_score
            if emotion_data and hasattr(emotion_data, 'arousal'):
                from data_models import safe_float_operation
                intensity = safe_float_operation(final_score, emotion_data.arousal, 'add') / 2.0
            intensity = max(0.0, min(1.0, intensity))
            
            # 2. ì§€ì†ì„± (Duration) - ì‹œê°„ ê¸°ë°˜ ê³„ì‚°
            duration = min(1.0, duration_seconds / 3600.0)  # 1ì‹œê°„ì„ ìµœëŒ€ê°’ìœ¼ë¡œ ì •ê·œí™”
            if duration_seconds > 86400:  # í•˜ë£¨ ì´ìƒ
                duration = 1.0
            elif duration_seconds < 60:  # 1ë¶„ ë¯¸ë§Œ
                duration = duration_seconds / 60.0
                
            # 3. í™•ì‹¤ì„± (Certainty) - ì •ë³´ í’ˆì§ˆê³¼ ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜
            certainty = information_quality * (1.0 - uncertainty_level)
            certainty = max(0.0, min(1.0, certainty))
            
            # 4. ê·¼ì ‘ì„± (Propinquity) - ì˜í–¥ ë²”ìœ„ì™€ ì‹œê°„ ê¸°ë°˜
            propinquity = 1.0 / (1.0 + duration_seconds / 3600.0)  # ì‹œê°„ì´ ë©€ìˆ˜ë¡ ê°ì†Œ
            propinquity = max(0.1, min(1.0, propinquity))
            
            # 5. ë‹¤ì‚°ì„± (Fecundity) - ì˜í–¥ ë²”ìœ„ì™€ ê°ì • ê°•ë„ ê¸°ë°˜
            fecundity = (affected_count / 100.0) * intensity  # 100ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
            fecundity = max(0.0, min(1.0, fecundity))
            
            # 6. ìˆœìˆ˜ì„± (Purity) - í™•ì‹¤ì„±ê³¼ ê°•ë„ì˜ ì¡°í•©
            purity = certainty * intensity
            purity = max(0.0, min(1.0, purity))
            
            # 7. ë²”ìœ„ (Extent) - ì˜í–¥ë°›ëŠ” ì‚¬ëŒ ìˆ˜ ê¸°ë°˜
            extent = min(1.0, affected_count / 1000.0)  # 1000ëª…ì„ ìµœëŒ€ê°’ìœ¼ë¡œ ì •ê·œí™”
            if affected_count < 1:
                extent = 0.1  # ìµœì†Œê°’
                
            # ì´ ì¾Œë½ê°’ ê³„ì‚° (ë²¤ë‹´ì˜ ì›ë˜ ê³µì‹: ê°•ë„ Ã— ì§€ì†ì„± Ã— í™•ì‹¤ì„± Ã— ê·¼ì ‘ì„± Ã— ë‹¤ì‚°ì„± Ã— ìˆœìˆ˜ì„± Ã— ë²”ìœ„)
            hedonic_total = intensity * duration * certainty * propinquity * fecundity * purity * extent
            hedonic_total = max(0.0, min(1.0, hedonic_total))
            
            # HedonicValues ê°ì²´ ìƒì„±
            hedonic_values = HedonicValues(
                intensity=intensity,
                duration=duration,
                certainty=certainty,
                propinquity=propinquity,
                fecundity=fecundity,
                purity=purity,
                extent=extent,
                hedonic_total=hedonic_total
            )
            
            self.logger.debug(f"ë²¤ë‹´ ê°’ ê³„ì‚° ì™„ë£Œ: ê°•ë„={intensity:.3f}, ì§€ì†ì„±={duration:.3f}, í™•ì‹¤ì„±={certainty:.3f}, ì´ê°’={hedonic_total:.3f}")
            
            return hedonic_values
            
        except Exception as e:
            self.logger.error(f"HedonicValues ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜í•˜ì§€ ì•Šê³  ì˜ˆì™¸ ë°œìƒ
            raise RuntimeError(f"ë²¤ë‹´ ì„¸ë¶€ê°’ ê³„ì‚° ì‹¤íŒ¨ - fallback ë¹„í™œì„±í™”: {str(e)}")
    
            
    def _prepare_advanced_context(self, input_data: Dict[str, Any]) -> AdvancedCalculationContext:
        """ê³ ê¸‰ ê³„ì‚° ë§¥ë½ ì¤€ë¹„"""
        # VERBOSE ë¡œê·¸ ì¶”ê°€ - ì •í™•í•œ ë¬¸ì œ íŒŒì•…
        self.logger.info(f"[VERBOSE] _prepare_advanced_context ì‹œì‘")
        self.logger.info(f"[VERBOSE] input_data keys: {list(input_data.keys())}")
        
        context = AdvancedCalculationContext()
        context.start_time = time.time()
        
        # ê¸°ë³¸ ì •ë³´ - listâ†’dict ë³€í™˜ (o3 ì œì•ˆ ì ìš©)
        # input_values í‚¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ input_data ìì²´ì—ì„œ ë²¤ë‹´ í‚¤ ì¶”ì¶œ
        input_vals = input_data.get('input_values', None)
        
        if input_vals is not None:
            # input_values í‚¤ê°€ ìˆëŠ” ê²½ìš°
            if isinstance(input_vals, list):
                if len(input_vals) == 7:
                    keys = ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']
                    context.input_values = {k: float(v) for k, v in zip(keys, input_vals)}
                    self.logger.info("   âœ… _prepare_advanced_context: input_valuesë¥¼ listâ†’dictë¡œ ë³€í™˜")
                else:
                    self.logger.error(f"input_values list ê¸¸ì´ê°€ 7ì´ ì•„ë‹˜: {len(input_vals)}")
                    raise ValueError(f"input_values must be dict or list(len=7), got list(len={len(input_vals)})")
            elif isinstance(input_vals, dict):
                context.input_values = input_vals
            else:
                self.logger.warning(f"input_values íƒ€ì… ì˜ˆì™¸: {type(input_vals).__name__}, ë¹ˆ dict ì‚¬ìš©")
                context.input_values = {}
        else:
            # input_values í‚¤ê°€ ì—†ëŠ” ê²½ìš° - input_dataì—ì„œ ì§ì ‘ ë²¤ë‹´ í‚¤ë“¤ì„ ì¶”ì¶œ
            bentham_keys = ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']
            context.input_values = {}
            for key in bentham_keys:
                if key in input_data:
                    val = input_data[key]
                    # ê°’ì´ Noneì´ê±°ë‚˜ 0ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì • (NO FALLBACK ì›ì¹™ì— ë”°ë¼ ì‘ì€ ê°’ ì‚¬ìš©)
                    if val is None or val == 0:
                        context.input_values[key] = 0.01  # ë§¤ìš° ì‘ì€ ê°’ìœ¼ë¡œ ì„¤ì •
                        self.logger.debug(f"   ë²¤ë‹´ í‚¤ '{key}' ê°’ì´ {val}ì´ë¯€ë¡œ 0.01ë¡œ ì„¤ì •")
                    else:
                        context.input_values[key] = float(val)
                else:
                    # í‚¤ê°€ ì—†ìœ¼ë©´ ì‘ì€ ê¸°ë³¸ê°’ (NO FALLBACKì´ì§€ë§Œ í‚¤ê°€ ì—†ëŠ” ê²ƒë³´ë‹¤ëŠ” ë‚«ë‹¤)
                    context.input_values[key] = 0.01
                    self.logger.debug(f"   ë²¤ë‹´ í‚¤ '{key}' ì—†ìŒ, 0.01ë¡œ ì„¤ì •")
            
            self.logger.info(f"   âœ… input_dataì—ì„œ ë²¤ë‹´ í‚¤ ì§ì ‘ ì¶”ì¶œ: {list(context.input_values.keys())}")
        context.emotion_data = input_data.get('emotion_data')
        context.affected_count = input_data.get('affected_count', 1)
        context.duration_seconds = input_data.get('duration_seconds', 60)
        context.information_quality = input_data.get('information_quality', 0.7)
        context.uncertainty_level = input_data.get('uncertainty_level', 0.3)
        
        # ë§¥ë½ ë¶„ì„
        if self.advanced_config['use_transformer_analysis']:
            text_input = input_data.get('text_description', "")
            if text_input:
                language = input_data.get('language', 'ko')
                analysis_result = self.context_analyzer.analyze_context(text_input, language)
                
                context.context_embedding = analysis_result.get('context_embedding')
                # í”„ë¡œì íŠ¸ ê·œì¹™: NO FALLBACK - íƒ€ì… ê²€ì¦ ê°•í™”
                complexity_data = analysis_result.get('complexity', {})
                
                # VERBOSE ë¡œê·¸ ì¶”ê°€
                self.logger.info(f"[VERBOSE] analysis_result keys: {list(analysis_result.keys())}")
                self.logger.info(f"[VERBOSE] complexity_data type: {type(complexity_data).__name__}")
                self.logger.info(f"[VERBOSE] complexity_data ê°’: {complexity_data}")
                
                if not isinstance(complexity_data, dict):
                    self.logger.error(f"analyze_contextê°€ ì˜ëª»ëœ complexity íƒ€ì… ë°˜í™˜: {type(complexity_data).__name__}, ê°’: {complexity_data}")
                    raise TypeError(f"analyze_context must return dict for complexity, got {type(complexity_data).__name__}")
                context.complexity_metrics = complexity_data
                context.ethical_analysis = analysis_result.get('ethical_aspects', {})
                context.emotion_analysis = analysis_result.get('emotions', [])
                
        # ì¶”ê°€ ë§¥ë½ ì •ë³´
        context.social_context = input_data.get('social_context', {})
        context.temporal_context = input_data.get('temporal_context', {})
        context.ethical_context = input_data.get('ethical_context', {})
        context.cognitive_context = input_data.get('cognitive_context', {})
        
        # ìœ¤ë¦¬ì  ê°€ì¹˜ ì •ë³´
        context.ethical_values = input_data.get('ethical_values', {})
        
        # í•™ìŠµ í¸í–¥ ì •ë³´ (ê³¼ê±° í›„íšŒ ê²½í—˜ì—ì„œ í•™ìŠµëœ)
        context.learning_bias = input_data.get('learning_bias', {})
        
        return context
        
    def _calculate_base_advanced(self, context: AdvancedCalculationContext) -> float:
        """ê³ ê¸‰ ê¸°ë³¸ ê³„ì‚°"""
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ê³„ì‚° (Bentham v2 í™•ì¥)
        weights = {
            'intensity': 0.20, 'duration': 0.12, 'certainty': 0.12,
            'propinquity': 0.08, 'fecundity': 0.08, 'purity': 0.08, 'extent': 0.12,
            # Bentham v2 ì¶”ê°€ ë³€ìˆ˜ë“¤
            'external_cost': 0.10,           # ì™¸ë¶€ë¹„ìš© (ì¤‘ìš”ë„ ë†’ìŒ)
            'redistribution_effect': 0.05,   # ì¬ë¶„ë°°íš¨ê³¼ (ì¤‘ê°„ ì¤‘ìš”ë„)
            'self_damage': 0.05             # ìì•„ì†ìƒ (ì¤‘ê°„ ì¤‘ìš”ë„)
        }
        
        total_score = 0.0
        
        # Bentham v2 ìƒˆë¡œìš´ ë³€ìˆ˜ë“¤ ê³„ì‚° (ì•ˆì „í•œ í˜¸ì¶œ)
        try:
            bentham_v2_vars = bentham_v2_calculator.calculate_bentham_v2_variables(
                context.__dict__, getattr(context, 'surd_graph', None)
            )
            # ìƒˆë¡œìš´ ë³€ìˆ˜ë“¤ì„ contextì— ì¶”ê°€
            context.input_values.update(bentham_v2_vars.to_dict())
        except Exception as e:
            self.logger.warning(f"Bentham v2 ë³€ìˆ˜ ê³„ì‚° ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            context.input_values.update({
                'external_cost': 0.5,
                'redistribution_effect': 0.5, 
                'self_damage': 0.5
            })
        
        for variable, weight in weights.items():
            # í•„ìˆ˜ í‚¤ ê²€ì¦ (NO FALLBACK)
            if variable not in context.input_values:
                raise KeyError(f"_calculate_base_advanced: í•„ìˆ˜ ë³€ìˆ˜ ëˆ„ë½ - {variable}")
            value = context.input_values[variable]
            # ë¹„ì„ í˜• ë³€í™˜ ì ìš©
            transformed_value = self._apply_nonlinear_transform(value, variable)
            total_score += transformed_value * weight
            
        # ê°ì • ë°ì´í„° ë³´ì • (ìŠ¤ì¼€ì¼ë§ ë¬¸ì œ ìˆ˜ì •)
        if context.emotion_data:
            # EmotionIntensity Enumì„ ì•ˆì „í•˜ê²Œ floatë¡œ ë³€í™˜
            intensity_value = getattr(context.emotion_data.intensity, 'value', 2) if hasattr(context.emotion_data.intensity, 'value') else 2
            # ì •ê·œí™”ëœ ê°•ë„ (0.0-1.0 ë²”ìœ„)
            normalized_intensity = min(max(float(intensity_value) / 4.0, 0.0), 1.0)
            
            from data_models import emotion_intensity_to_float
            valence_val = emotion_intensity_to_float(context.emotion_data.valence)
            arousal_val = emotion_intensity_to_float(context.emotion_data.arousal)
            
            emotion_factor = (
                valence_val * 0.4 + 
                arousal_val * 0.3 + 
                normalized_intensity * 0.3
            )
            # ê°ì • ë³´ì •ì„ ë§ì…ˆìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ìŠ¤ì¼€ì¼ë§ ë¬¸ì œ ë°©ì§€
            total_score = total_score + (emotion_factor * 0.1)
        
        # í•™ìŠµ í¸í–¥ ë°˜ì˜ (ê³¼ê±° ê²½í—˜ì—ì„œ ì˜¨ ë¯¸ë¬˜í•œ ì¡°ì •)
        if hasattr(context, 'learning_bias') and context.learning_bias:
            learning_factor = self._apply_learning_bias(context.learning_bias, context)
            total_score = total_score * learning_factor
        
        # ìœ¤ë¦¬ì  ê°€ì¹˜ ê¸°ë°˜ ì¡°ì •
        if hasattr(context, 'ethical_values') and context.ethical_values:
            ethical_factor = self._apply_ethical_values(context.ethical_values, context)
            total_score = total_score * ethical_factor
            
        return total_score
    
    def _apply_learning_bias(self, learning_bias: Dict[str, float], 
                           context: AdvancedCalculationContext) -> float:
        """ê³¼ê±° ê²½í—˜ì—ì„œ í•™ìŠµëœ í¸í–¥ì„ ë¯¸ë¬˜í•˜ê²Œ ë°˜ì˜ (í¼ì§€ ì ì‘)"""
        
        bias_factor = 1.0
        
        # ìœ„í—˜ íšŒí”¼ ì„±í–¥ (í¼ì§€ ì ì‘)
        risk_aversion = learning_bias.get('risk_aversion', 0.0)
        if risk_aversion != 0.0:
            uncertainty = context.uncertainty_level
            # í¼ì§€ ì ì‘: ë¶ˆí™•ì‹¤ì„±ì— ë”°ë¥¸ ì—°ì†ì  ì¡°ì •
            fuzzy_uncertainty = self._adaptive_fuzzy_adjustment(uncertainty, risk_aversion)
            bias_factor *= (1.0 + fuzzy_uncertainty * 0.1)
        
        # ì‹œê°„ ì„ í˜¸ í¸í–¥ (í¼ì§€ ì ì‘)
        time_preference = learning_bias.get('time_preference', 0.0)
        if time_preference != 0.0 and hasattr(context, 'duration_seconds'):
            time_factor = min(context.duration_seconds / 86400.0, 1.0)
            # ê°ì • ìƒíƒœì— ë”°ë¥¸ ì‹œê°„ ì¸ì‹ ì¡°ì •
            emotion_time_modifier = self._emotion_time_perception_modifier(context)
            adjusted_time_factor = time_factor * emotion_time_modifier
            bias_factor *= (1.0 + time_preference * adjusted_time_factor * 0.05)
        
        # ì‚¬íšŒì  ê³ ë ¤ ê°€ì¤‘ì¹˜ (í¼ì§€ ì ì‘)
        social_weight = learning_bias.get('social_weight', 0.0)
        if social_weight != 0.0:
            social_factor = min(context.affected_count / 100.0, 1.0)
            # ê°ì •ì— ë”°ë¥¸ ì‚¬íšŒì  ë¯¼ê°ë„ ì¡°ì •
            emotion_social_modifier = self._emotion_social_sensitivity(context)
            adjusted_social_factor = social_factor * emotion_social_modifier
            bias_factor *= (1.0 + social_weight * adjusted_social_factor * 0.05)
        
        # í¼ì§€ ê²½ê³„ë¥¼ í†µí•œ ë¶€ë“œëŸ¬ìš´ ì œí•œ
        return self._fuzzy_boundary_clamp(bias_factor, 0.95, 1.05)
    
    def _adaptive_fuzzy_adjustment(self, uncertainty: float, bias_strength: float) -> float:
        """ë¶ˆí™•ì‹¤ì„±ì— ë”°ë¥¸ í¼ì§€ ì ì‘ ì¡°ì •"""
        # ë¶ˆí™•ì‹¤ì„±ì´ ë†’ì„ ë•Œ í¸í–¥ì´ ë” ê°•í•˜ê²Œ ì‘ìš©
        # í•˜ì§€ë§Œ ë¶€ë“œëŸ½ê²Œ ì „í™˜
        uncertainty_amplifier = np.tanh(uncertainty * 2)  # 0~1 ë¶€ë“œëŸ¬ìš´ ì¦í­
        return bias_strength * uncertainty_amplifier
    
    def _emotion_time_perception_modifier(self, context: AdvancedCalculationContext) -> float:
        """ê°ì • ìƒíƒœì— ë”°ë¥¸ ì‹œê°„ ì¸ì‹ ì¡°ì •"""
        if not context.emotion_data:
            return 1.0
        
        # ê°ì •ì— ë”°ë¥¸ ì‹œê°„ ì¸ì‹ ë³€í™” (ì—°êµ¬ ê¸°ë°˜)
        emotion_name = context.emotion_data.primary_emotion.value if hasattr(context.emotion_data.primary_emotion, 'value') else str(context.emotion_data.primary_emotion)
        
        time_perception_map = {
            'fear': 0.7,     # ë‘ë ¤ì›€: ì‹œê°„ì´ ë¹ ë¥´ê²Œ ëŠê»´ì§
            'anger': 0.8,    # ë¶„ë…¸: ê¸‰í•˜ê²Œ ëŠê»´ì§
            'joy': 1.2,      # ê¸°ì¨: ì‹œê°„ì´ ëŠë¦¬ê²Œ ëŠê»´ì§
            'sadness': 1.3,  # ìŠ¬í””: ì‹œê°„ì´ ë” ëŠë¦¬ê²Œ ëŠê»´ì§
            'neutral': 1.0
        }
        
        return time_perception_map.get(emotion_name, 1.0)
    
    def _emotion_social_sensitivity(self, context: AdvancedCalculationContext) -> float:
        """ê°ì • ìƒíƒœì— ë”°ë¥¸ ì‚¬íšŒì  ë¯¼ê°ë„ ì¡°ì •"""
        if not context.emotion_data:
            return 1.0
        
        emotion_name = context.emotion_data.primary_emotion.value if hasattr(context.emotion_data.primary_emotion, 'value') else str(context.emotion_data.primary_emotion)
        
        social_sensitivity_map = {
            'fear': 1.3,     # ë‘ë ¤ì›€: ì‚¬íšŒì  ì§€ì§€ ë” ì¤‘ìš”
            'sadness': 1.4,  # ìŠ¬í””: íƒ€ì¸ì˜ ë°˜ì‘ì— ë¯¼ê°
            'anger': 0.8,    # ë¶„ë…¸: ì‚¬íšŒì  ê³ ë ¤ ê°ì†Œ
            'joy': 1.1,      # ê¸°ì¨: ë‚˜ëˆ” ì˜ì‹ ì¦ê°€
            'neutral': 1.0
        }
        
        return social_sensitivity_map.get(emotion_name, 1.0)
    
    def _fuzzy_boundary_clamp(self, value: float, min_val: float, max_val: float) -> float:
        """í¼ì§€ ê²½ê³„ë¥¼ í†µí•œ ë¶€ë“œëŸ¬ìš´ í´ë˜í•‘"""
        # í•˜ë“œ í´ë˜í•‘ ëŒ€ì‹  ì‹œê·¸ëª¨ì´ë“œ ë³€í™˜ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ
        if value < min_val:
            excess = min_val - value
            return min_val - excess * np.exp(-excess * 10)  # ë¶€ë“œëŸ¬ìš´ í•˜í•œ
        elif value > max_val:
            excess = value - max_val
            return max_val + excess * np.exp(-excess * 10)  # ë¶€ë“œëŸ¬ìš´ ìƒí•œ
        else:
            return value
    
    def _apply_ethical_values(self, ethical_values: Dict[str, float], 
                            context: AdvancedCalculationContext) -> float:
        """ìœ¤ë¦¬ì  ê°€ì¹˜ ê¸°ë°˜ ë²¤ë‹´ ê³„ì‚° ì¡°ì •"""
        
        # ì£¼ìš” ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ë“¤
        care_harm = ethical_values.get('care_harm', 0.5)
        fairness = ethical_values.get('fairness', 0.5)
        loyalty = ethical_values.get('loyalty', 0.5)
        
        # ì‹œë‚˜ë¦¬ì˜¤ íŠ¹ì„±ì— ë”°ë¥¸ ìœ¤ë¦¬ì  ê°€ì¤‘ì¹˜ ì ìš©
        ethical_factor = 1.0
        
        # í•´ì•… ë°©ì§€ ê³ ë ¤
        if care_harm > 0.6:
            # ì•ˆì „/ëŒë´„ì´ ì¤‘ìš”í•œ ê²½ìš° í™•ì‹¤ì„±ê³¼ ì§€ì†ì„± ì¤‘ì‹œ
            if 'certainty' not in context.input_values:
                raise KeyError("ìœ¤ë¦¬ì  ì¡°ì •ì— í•„ìš”í•œ 'certainty' í‚¤ ëˆ„ë½")
            certainty_boost = context.input_values['certainty'] * 0.1
            ethical_factor += certainty_boost
        
        # ê³µì •ì„± ê³ ë ¤  
        if fairness > 0.6:
            # ê³µì •ì„±ì´ ì¤‘ìš”í•œ ê²½ìš° ë²”ìœ„(extent) ê°€ì¤‘ì¹˜ ì¦ê°€
            if 'extent' not in context.input_values:
                raise KeyError("ìœ¤ë¦¬ì  ì¡°ì •ì— í•„ìš”í•œ 'extent' í‚¤ ëˆ„ë½")
            extent_boost = context.input_values['extent'] * 0.1
            ethical_factor += extent_boost
        
        # ì¶©ì„±/ê´€ê³„ ê³ ë ¤
        if loyalty > 0.6:
            # ê´€ê³„ê°€ ì¤‘ìš”í•œ ê²½ìš° ê·¼ì ‘ì„±(propinquity) ê°€ì¤‘ì¹˜ ì¦ê°€
            if 'propinquity' not in context.input_values:
                raise KeyError("ìœ¤ë¦¬ì  ì¡°ì •ì— í•„ìš”í•œ 'propinquity' í‚¤ ëˆ„ë½")
            propinquity_boost = context.input_values['propinquity'] * 0.1
            ethical_factor += propinquity_boost
        
        # ìœ¤ë¦¬ì  ì¡°ì •ë„ ë¯¸ë¬˜í•˜ê²Œ ì œí•œ (Â±10% ì´ë‚´)
        return max(0.9, min(1.1, ethical_factor))
        
    def _apply_nonlinear_transform(self, value: float, variable: str) -> float:
        """ë¹„ì„ í˜• ë³€í™˜ ì ìš©"""
        if variable in ['intensity', 'extent']:
            # ê°•ë„ì™€ ë²”ìœ„ëŠ” ì œê³±ê·¼ ë³€í™˜
            return np.sqrt(value)
        elif variable in ['duration', 'fecundity']:
            # ì§€ì†ì„±ê³¼ ìƒì‚°ì„±ì€ ë¡œê·¸ ë³€í™˜
            return np.log1p(value)
        else:
            # ê¸°íƒ€ëŠ” ì‹œê·¸ëª¨ì´ë“œ ë³€í™˜
            return 1 / (1 + np.exp(-10 * (value - 0.5)))
            
    def _normalize_context(self, context) -> dict:
        """contextë¥¼ dictë¡œ ì •ê·œí™”"""
        if isinstance(context, dict):
            return context
        if isinstance(context, str):
            return {'text': context}
        if isinstance(context, list):
            if context and isinstance(context[0], dict):
                # list of dict -> merge
                merged = {}
                for d in context:
                    if isinstance(d, dict):
                        merged.update(d)
                return merged
            # list of other -> convert to dict
            return {'sequence': context, 'text': ' '.join(map(str, context))}
        if hasattr(context, '__dict__'):
            return context.__dict__
        raise TypeError(f"context must be dict/list/str/object, got {type(context).__name__}")
    
    def _normalize_input_values(self, context: AdvancedCalculationContext) -> None:
        """ì…ë ¥ê°’ ì •ê·œí™” - ëª¨ë“  ì§„ì…ì ì—ì„œ ê°•ì œ (GPT ì œì•ˆ)"""
        if not hasattr(context, 'input_values'):
            raise AttributeError("contextì— input_valuesê°€ ì—†ìŒ")
        
        iv = context.input_values
        if isinstance(iv, list):
            if len(iv) != 7:
                raise ValueError(f"input_valuesëŠ” ê¸¸ì´ 7 ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨, ì‹¤ì œ: {len(iv)}")
            context.input_values = {k: float(v) for k, v in zip(self.BENTHAM_KEYS, iv)}
            self.logger.debug(f"input_values ì •ê·œí™”: list â†’ dict")
        elif isinstance(iv, dict):
            missing = [k for k in self.BENTHAM_KEYS if k not in iv]
            if missing:
                raise KeyError(f"í•„ìˆ˜ ë²¤ë‹´ í‚¤ ëˆ„ë½ (NO FALLBACK): {missing}")
        else:
            raise TypeError(f"input_valuesëŠ” dict ë˜ëŠ” ê¸¸ì´ 7 ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨, ì‹¤ì œ: {type(iv).__name__}")
    
    def _predict_neural_weights(self, context: AdvancedCalculationContext) -> torch.Tensor:
        """ì‹ ê²½ë§ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì˜ˆì¸¡"""
        import traceback
        
        # ì •ê·œí™” ê°•ì œ (GPT ì œì•ˆ)
        try:
            self._normalize_input_values(context)
        except Exception as e:
            self.logger.error(f"_predict_neural_weights ì…ë ¥ ì •ê·œí™” ì‹¤íŒ¨:\n{traceback.format_exc()}")
            return None
        
        try:
            # contextëŠ” ë°˜ë“œì‹œ AdvancedCalculationContextì—¬ì•¼ í•¨
            if not isinstance(context, AdvancedCalculationContext):
                self.logger.error(f"_predict_neural_weights: Invalid context type: {type(context).__name__}")
                return None
            
            features = self._extract_neural_features(context)
            # Neural predictorì™€ ê°™ì€ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            predictor_device = next(self.neural_predictor.parameters()).device
            features_tensor = torch.tensor(features, dtype=TORCH_DTYPE).to(predictor_device)
            
            with torch.no_grad():
                weights = self.neural_predictor(features_tensor.unsqueeze(0))
                
            return weights.squeeze(0)
            
        except Exception as e:
            self.logger.error(f"ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return None
            
    def _extract_neural_features(self, context: AdvancedCalculationContext) -> np.ndarray:
        """ì‹ ê²½ë§ìš© íŠ¹ì„± ì¶”ì¶œ"""
        features = []
        
        # VERBOSE ë¡œê·¸ ì¶”ê°€ - ì •í™•í•œ ë¬¸ì œ íŒŒì•…
        self.logger.info(f"[VERBOSE] _extract_neural_features ì‹œì‘")
        self.logger.info(f"[VERBOSE] context type: {type(context).__name__}")
        self.logger.info(f"[VERBOSE] context.complexity_metrics ì¡´ì¬: {hasattr(context, 'complexity_metrics')}")
        if hasattr(context, 'complexity_metrics'):
            self.logger.info(f"[VERBOSE] complexity_metrics type: {type(context.complexity_metrics).__name__}")
            self.logger.info(f"[VERBOSE] complexity_metrics ê°’: {context.complexity_metrics}")
        
        # contextê°€ AdvancedCalculationContextê°€ ì•„ë‹Œ ê²½ìš° ì¦‰ì‹œ ì—ëŸ¬
        if not isinstance(context, AdvancedCalculationContext):
            self.logger.error(f"_extract_neural_features: context must be AdvancedCalculationContext, got {type(context).__name__}")
            raise TypeError(f"context must be AdvancedCalculationContext, not {type(context).__name__}")
        
        # input_values ì†ì„± í™•ì¸ ë° listâ†’dict ë³€í™˜
        if not hasattr(context, 'input_values'):
            # input_valuesê°€ ì—†ìœ¼ë©´ ê° ì†ì„±ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ë˜, ì—†ìœ¼ë©´ ì—ëŸ¬
            context.input_values = {}
            for var in ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']:
                if hasattr(context, var):
                    context.input_values[var] = getattr(context, var)
                else:
                    self.logger.error(f"_extract_neural_features: Missing required attribute: {var}")
                    raise AttributeError(f"AdvancedCalculationContext missing required attribute: {var}")
        elif isinstance(context.input_values, list):
            # listì¸ ê²½ìš° dictë¡œ ë³€í™˜ (o3 ì œì•ˆ)
            vals = context.input_values
            if isinstance(vals, list) and len(vals) == 7:
                keys = ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']
                context.input_values = {k: float(v) for k, v in zip(keys, vals)}
                self.logger.info(f"   âœ… input_valuesë¥¼ listâ†’dictë¡œ ë³€í™˜ ì™„ë£Œ")
            else:
                self.logger.error(f"input_values list ê¸¸ì´ê°€ 7ì´ ì•„ë‹˜: {len(vals)}")
                raise ValueError(f"input_values must be dict or list(len=7), got list(len={len(vals)})")
        elif not isinstance(context.input_values, dict):
            # dictë„ listë„ ì•„ë‹Œ ê²½ìš° ì—ëŸ¬
            self.logger.error(f"input_values íƒ€ì… ì—ëŸ¬: {type(context.input_values).__name__}")
            raise TypeError(f"input_values must be dict or list(len=7), got {type(context.input_values).__name__}")
        
        # ê¸°ë³¸ ë²¤ë‹´ ë³€ìˆ˜ë“¤ (ê¸°ë³¸ê°’ ì—†ì´)
        for var in ['intensity', 'duration', 'certainty', 'propinquity', 
                   'fecundity', 'purity', 'extent']:
            if var not in context.input_values:
                self.logger.error(f"_extract_neural_features: Missing required value: {var}")
                raise KeyError(f"input_values missing required key: {var}")
            features.append(context.input_values[var])
            
        # ê°ì • íŠ¹ì„±
        if context.emotion_data:
            from data_models import emotion_intensity_to_float
            valence_val = emotion_intensity_to_float(context.emotion_data.valence)
            arousal_val = emotion_intensity_to_float(context.emotion_data.arousal)
            intensity_val = float(context.emotion_data.intensity.value) / 4.0 if hasattr(context.emotion_data.intensity, 'value') else emotion_intensity_to_float(context.emotion_data.intensity)
            confidence_val = emotion_intensity_to_float(context.emotion_data.confidence)
            
            features.extend([
                valence_val,
                arousal_val,
                intensity_val,
                confidence_val
            ])
        else:
            features.extend([0.0, 0.0, 0.5, 0.5])
            
        # ë§¥ë½ ì„ë² ë”© ìš”ì•½ (ì£¼ì„±ë¶„ ë¶„ì„)
        if hasattr(context, 'context_embedding') and context.context_embedding is not None:
            # numpy arrayë¡œ í™•ì‹¤íˆ ë³€í™˜
            if isinstance(context.context_embedding, list):
                embedding = np.array(context.context_embedding)
            else:
                embedding = context.context_embedding
            
            # flatten ì²˜ë¦¬
            if hasattr(embedding, 'flatten'):
                embedding = embedding.flatten()
            else:
                embedding = np.array(embedding).flatten()
            
            # PCA ì°¨ì› ì¶•ì†Œ (ì²˜ìŒ 20ì°¨ì› ì‚¬ìš©)
            embedding_summary = embedding[:20] if len(embedding) >= 20 else np.pad(embedding, (0, 20-len(embedding)))
            features.extend(embedding_summary.tolist())
        else:
            features.extend([0.0] * 20)
            
        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        features.extend([
            np.log1p(context.affected_count) / 10.0,  # ë¡œê·¸ ìŠ¤ì¼€ì¼ë§
            min(context.duration_seconds / 86400.0, 1.0),  # ì¼ ë‹¨ìœ„ ì •ê·œí™”
            context.information_quality,
            context.uncertainty_level,
            len(context.input_values) / 7.0,  # ì™„ì „ì„± ì§€í‘œ
        ])
        
        # ë³µì¡ë„ ë©”íŠ¸ë¦­
        if hasattr(context, 'complexity_metrics'):
            complexity = context.complexity_metrics
            # í”„ë¡œì íŠ¸ ê·œì¹™: NO FALLBACK - dictê°€ ì•„ë‹ˆë©´ ì—ëŸ¬
            if not isinstance(complexity, dict):
                self.logger.error(f"complexity_metricsëŠ” dictì—¬ì•¼ í•¨, ì‹¤ì œ: {type(complexity).__name__}, ê°’: {complexity}")
                raise TypeError(f"complexity_metrics must be dict, got {type(complexity).__name__}")
            
            features.extend([
                complexity.get('lexical_diversity', 0.5),
                complexity.get('structural_complexity', 0.1) * 10,
                min(complexity.get('word_count', 10) / 100.0, 1.0)
            ])
            
        # ìœ¤ë¦¬ì  ì ìˆ˜
        if hasattr(context, 'ethical_analysis'):
            ethical = context.ethical_analysis
            if isinstance(ethical, dict) and 'scores' in ethical:
                max_ethical_score = max(ethical['scores']) if ethical['scores'] else 0.5
                features.append(max_ethical_score)
            else:
                features.append(0.5)
        else:
            features.append(0.5)
            
        # ê°ì • ë¶„ì„ ê²°ê³¼
        if hasattr(context, 'emotion_analysis'):
            emotions = context.emotion_analysis
            if emotions and isinstance(emotions, list):
                # ì´ì œ í‰íƒ„í™”ëœ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨ [{'label': 'joy', 'score': 0.8}, ...]
                max_emotion_score = max([e.get('score', 0.5) for e in emotions if isinstance(e, dict)])
                features.append(max_emotion_score)
            else:
                features.append(0.5)
        else:
            features.append(0.5)
            
        # ì´ 50ì°¨ì›ìœ¼ë¡œ ë§ì¶¤
        while len(features) < 50:
            features.append(0.0)
            
        return np.array(features[:50], dtype=np.float32)
        
    def _ensure_score_bounds(self, score: float) -> float:
        """ìµœì¢… ì ìˆ˜ê°€ í•©ë¦¬ì ì¸ ë²”ìœ„ ë‚´ì— ìˆë„ë¡ ë³´ì¥"""
        if not isinstance(score, (int, float)) or np.isnan(score) or np.isinf(score):
            self.logger.warning(f"ì˜ëª»ëœ ì ìˆ˜ ê°’ ê°ì§€: {score}, ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©")
            return 0.5
            
        # 0-1 ë²”ìœ„ë¡œ ê°•ì œ ì œí•œ
        bounded_score = max(0.0, min(1.0, score))
        
        if bounded_score != score:
            self.logger.info(f"ì ìˆ˜ ë²”ìœ„ ì¡°ì •: {score:.3f} -> {bounded_score:.3f}")
            
        return bounded_score
        
    def _apply_advanced_extreme_adjustment(self, score: float, 
                                         context: AdvancedCalculationContext) -> Dict[str, Any]:
        """ê³ ê¸‰ ê·¹ë‹¨ê°’ ë³´ì • - ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”"""
        adjustment_factor = 1.0
        applied = False
        adjustment_type = "none"
        original_score = score
        
        # ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        if score > 1.0:
            # 1ì„ ì´ˆê³¼í•˜ëŠ” ì ìˆ˜ë¥¼ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¡œ ì••ì¶•
            final_score = 1.0 / (1.0 + np.exp(-(score - 1.0)))
            final_score = 0.5 + (final_score - 0.5) * 0.5  # 0.5-1.0 ë²”ìœ„ë¡œ ë§¤í•‘
            adjustment_factor = final_score / score if score != 0 else 1.0
            applied = True
            adjustment_type = "upper_normalization"
            
        elif score < 0.0:
            # 0 ë¯¸ë§Œì˜ ì ìˆ˜ë¥¼ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¡œ ì••ì¶•
            final_score = 1.0 / (1.0 + np.exp(-score))
            final_score = final_score * 0.5  # 0.0-0.5 ë²”ìœ„ë¡œ ë§¤í•‘
            adjustment_factor = final_score / score if score != 0 else 1.0
            applied = True
            adjustment_type = "lower_normalization"
            
        else:
            # ì´ë¯¸ 0-1 ë²”ìœ„ ë‚´ì˜ ì ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
            final_score = score
        
        return {
            'score': final_score,
            'factor': adjustment_factor,
            'applied': applied,
            'type': adjustment_type,
            'dynamic_threshold': self._calculate_dynamic_threshold(context)
        }
        
    def _calculate_context_complexity(self, context: AdvancedCalculationContext) -> float:
        """ìƒí™© ë³µì¡ë„ ê³„ì‚°"""
        complexity_factors = []
        
        # í…ìŠ¤íŠ¸ ë³µì¡ë„
        if hasattr(context, 'text_description') and context.text_description:
            text_complexity = len(context.text_description.split()) / 100.0
            complexity_factors.append(min(1.0, text_complexity))
        
        # ì˜í–¥ë°›ëŠ” ì‚¬ëŒ ìˆ˜
        if hasattr(context, 'affected_count'):
            people_complexity = min(1.0, context.affected_count / 20.0)
            complexity_factors.append(people_complexity)
        
        # ë¶ˆí™•ì‹¤ì„± ìˆ˜ì¤€
        if hasattr(context, 'uncertainty_level'):
            complexity_factors.append(context.uncertainty_level)
        
        return np.mean(complexity_factors) if complexity_factors else 0.5
    
    def _calculate_layer_interaction(self, prev_layer_result, current_layer, context) -> float:
        """ë ˆì´ì–´ê°„ ìƒí˜¸ì‘ìš© ê³„ì‚°"""
        # ì´ì „ ë ˆì´ì–´ ì‹ ë¢°ë„ ê¸°ë°˜ ìƒí˜¸ì‘ìš©
        interaction_factor = 1.0
        
        if hasattr(prev_layer_result, 'confidence'):
            # ë†’ì€ ì‹ ë¢°ë„ëŠ” ë‹¤ìŒ ë ˆì´ì–´ë¥¼ ê°•í™”
            confidence_boost = 0.8 + (prev_layer_result.confidence * 0.4)
            interaction_factor *= confidence_boost
        
        # ë ˆì´ì–´ íƒ€ì…ë³„ ìƒí˜¸ì‘ìš©
        if hasattr(current_layer, 'layer_type'):
            layer_synergy = self._get_layer_synergy(prev_layer_result, current_layer)
            interaction_factor *= layer_synergy
        
        return max(0.5, min(1.8, interaction_factor))
    
    def _get_layer_synergy(self, prev_result, current_layer) -> float:
        """ë ˆì´ì–´ ì‹œë„ˆì§€ ê³„ì‚°"""
        # ë ˆì´ì–´ íƒ€ì…ë³„ ì‹œë„ˆì§€ ë§¤íŠ¸ë¦­ìŠ¤ (ì˜ˆì‹œ)
        synergy_matrix = {
            ('contextual', 'temporal'): 1.2,
            ('temporal', 'social'): 1.1,
            ('social', 'ethical'): 1.3,
            ('ethical', 'emotional'): 1.2,
            ('emotional', 'cognitive'): 1.1
        }
        
        prev_type = getattr(prev_result, 'layer_type', 'unknown')
        curr_type = getattr(current_layer, 'layer_type', 'unknown')
        
        return synergy_matrix.get((prev_type, curr_type), 1.0)
    
    def _smart_score_normalization(self, score: float, context: AdvancedCalculationContext, 
                                 interactions: List[float]) -> float:
        """ì§€ëŠ¥ì  ì ìˆ˜ ì •ê·œí™”"""
        # ê¸°ë³¸ 0-1 ë²”ìœ„ ì ìš©
        if score <= 1.0:
            return max(0.0, score)
        
        # ë³µì¡í•œ ìƒí™©ì—ì„œëŠ” ë” ë†’ì€ ì ìˆ˜ í—ˆìš©
        complexity = self._calculate_context_complexity(context)
        interaction_boost = np.mean(interactions) if interactions else 1.0
        
        # ë™ì  ìƒí•œì„  ê³„ì‚°
        if complexity > 0.8 and interaction_boost > 1.2:
            # ë§¤ìš° ë³µì¡í•œ ìƒí™©: 0-2 ë²”ìœ„ í—ˆìš© í›„ ì••ì¶•
            max_allowed = 2.0
            normalized = score / max_allowed
            return min(1.0, normalized)
        elif complexity > 0.6:
            # ì¤‘ê°„ ë³µì¡ë„: 0-1.5 ë²”ìœ„ í—ˆìš© í›„ ì••ì¶•
            max_allowed = 1.5
            normalized = score / max_allowed
            return min(1.0, normalized)
        else:
            # ë‹¨ìˆœí•œ ìƒí™©: 0-1 ë²”ìœ„ ê°•ì œ
            return min(1.0, max(0.0, score))

    def _calculate_dynamic_threshold(self, context: AdvancedCalculationContext) -> Dict[str, float]:
        """ë™ì  ì„ê³„ê°’ ê³„ì‚°"""
        base_pleasure = self.advanced_config['extreme_pleasure_threshold']
        base_pain = self.advanced_config['extreme_pain_threshold']
        
        # ë§¥ë½ì— ë”°ë¥¸ ì„ê³„ê°’ ì¡°ì •
        adjustments = []
        
        # ì‚¬íšŒì  ì˜í–¥ ê³ ë ¤
        if context.affected_count > 10:
            adjustments.append(-0.1)  # ë” ì—„ê²©í•œ ì„ê³„ê°’
        elif context.affected_count == 1:
            adjustments.append(0.1)   # ë” ê´€ëŒ€í•œ ì„ê³„ê°’
            
        # ì‹œê°„ì  ì˜í–¥ ê³ ë ¤
        if context.duration_seconds > 3600:  # 1ì‹œê°„ ì´ìƒ
            adjustments.append(-0.05)
            
        # ë¶ˆí™•ì‹¤ì„± ê³ ë ¤
        if context.uncertainty_level > 0.7:
            adjustments.append(0.05)  # ë¶ˆí™•ì‹¤í•  ë•Œ ë” ê´€ëŒ€í•˜ê²Œ
            
        adjustment = np.mean(adjustments) if adjustments else 0.0
        
        return {
            'pleasure': base_pleasure + adjustment,
            'pain': base_pain - adjustment  # ìŒìˆ˜ì´ë¯€ë¡œ ë¹¼ë©´ ì ˆëŒ“ê°’ì´ ì»¤ì§
        }
        
    def _optimize_final_score(self, score: float, 
                            context: AdvancedCalculationContext) -> float:
        """ìµœì¢… ì ìˆ˜ ìµœì í™” - 0-1 ë²”ìœ„ ê°•ì œ ì ìš©"""
        try:
            # ë¨¼ì € ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ì œí•œ
            bounded_score = max(0.0, min(1.0, score))
            
            # ëª©ì  í•¨ìˆ˜ ì •ì˜ (0-1 ë²”ìœ„ ë‚´ì—ì„œë§Œ ìµœì í™”)
            def objective(x):
                # ì›ë˜ ì ìˆ˜ì™€ì˜ ì°¨ì´ + ì œì•½ ì¡°ê±´ ìœ„ë°˜ í˜ë„í‹°
                deviation = abs(x - bounded_score)
                
                # 0-1 ë²”ìœ„ ìœ„ë°˜ ì‹œ ê°•í•œ í˜ë„í‹°
                penalty = 0.0
                if x < 0.0 or x > 1.0:
                    penalty += 100.0 * abs(x - np.clip(x, 0.0, 1.0))
                    
                # ê·¹ë‹¨ê°’ ì†Œí”„íŠ¸ í˜ë„í‹° (0.05-0.95 ë²”ìœ„ ì„ í˜¸)
                if x < 0.05:
                    penalty += 2.0 * (0.05 - x)
                elif x > 0.95:
                    penalty += 2.0 * (x - 0.95)
                    
                return deviation + penalty
                
            # ìµœì í™” ì‹¤í–‰
            result = minimize_scalar(
                objective,
                bounds=(-1.0, 1.0),
                method='bounded'
            )
            
            if result.success:
                return result.x
            else:
                return score
                
        except Exception as e:
            self.logger.error(f"ì ìˆ˜ ìµœì í™” ì‹¤íŒ¨: {e}")
            return score
            
    def _calculate_comprehensive_confidence(self, 
                                         context: AdvancedCalculationContext,
                                         layer_results: List[WeightLayerResult],
                                         neural_weights: torch.Tensor = None) -> float:
        """ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_factors = []
        
        # ë°ì´í„° í’ˆì§ˆ
        data_quality = context.information_quality
        confidence_factors.append(data_quality)
        
        # ë¶ˆí™•ì‹¤ì„± (ì—­ìˆ˜)
        uncertainty_factor = 1.0 - context.uncertainty_level
        confidence_factors.append(uncertainty_factor)
        
        # ë ˆì´ì–´ ì‹ ë¢°ë„ í‰ê· 
        layer_confidences = [layer.confidence for layer in layer_results]
        if layer_confidences:
            avg_layer_confidence = np.mean(layer_confidences)
            confidence_factors.append(avg_layer_confidence)
            
        # ì‹ ê²½ë§ ì˜ˆì¸¡ ì‹ ë¢°ë„
        if neural_weights is not None:
            # ê°€ì¤‘ì¹˜ ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„
            weight_variance = torch.var(neural_weights).item()
            neural_confidence = max(0.0, 1.0 - weight_variance)
            confidence_factors.append(neural_confidence)
            
        # ë§¥ë½ ì™„ì „ì„±
        if hasattr(context, 'context_embedding') and context.context_embedding is not None:
            context_completeness = 1.0
        else:
            context_completeness = 0.5
        confidence_factors.append(context_completeness)
        
        return float(np.mean(confidence_factors))
        
    def _generate_detailed_breakdown(self, 
                                   base_score: float,
                                   layer_results: List[WeightLayerResult],
                                   adjustment_result: Dict[str, Any],
                                   context: AdvancedCalculationContext) -> Dict[str, Any]:
        """ìƒì„¸ ê³„ì‚° ë¶„ì„ ìƒì„±"""
        return {
            'base_calculation': {
                'input_variables': context.input_values,
                'base_score': base_score,
                'nonlinear_transforms_applied': True
            },
            'layer_analysis': {
                'layer_count': len(layer_results),
                'layer_weights': [r.weight_factor for r in layer_results],
                'layer_confidences': [r.confidence for r in layer_results],
                'progressive_scores': self._calculate_progressive_scores(base_score, layer_results)
            },
            'neural_prediction': {
                'used': self.advanced_config['use_neural_prediction'],
                'model_architecture': str(self.neural_predictor) if hasattr(self, 'neural_predictor') else None
            },
            'extreme_adjustment': adjustment_result,
            'context_analysis': {
                'transformer_used': self.advanced_config['use_transformer_analysis'],
                'complexity_analyzed': hasattr(context, 'complexity_metrics'),
                'ethical_analyzed': hasattr(context, 'ethical_analysis'),
                'emotion_analyzed': hasattr(context, 'emotion_analysis')
            },
            'optimization': {
                'applied': self.advanced_config['optimization_enabled'],
                'method': self.optimization_params.get('method', 'none')
            },
            'performance': {
                'processing_time': getattr(context, 'processing_time', 0.0),
                'cache_used': hasattr(self, 'calculation_cache')
            }
        }
        
    def _calculate_progressive_scores(self, base_score: float, 
                                    layer_results: List[WeightLayerResult]) -> List[float]:
        """ë‹¨ê³„ë³„ ì ìˆ˜ ì§„í–‰ ê³„ì‚°"""
        scores = [base_score]
        current_score = base_score
        
        for layer_result in layer_results:
            current_score *= layer_result.weight_factor
            scores.append(current_score)
            
        return scores
        
    def _generate_cache_key(self, input_data: Dict[str, Any]) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        import hashlib
        
        # ì¤‘ìš”í•œ ì…ë ¥ ë°ì´í„°ë§Œ í•´ì‹œ
        key_data = {
            'input_values': input_data.get('input_values', {}),
            'affected_count': input_data.get('affected_count', 1),
            'duration_seconds': input_data.get('duration_seconds', 60),
            'information_quality': input_data.get('information_quality', 0.7),
            'text_description': input_data.get('text_description', "")[:100]  # ì²˜ìŒ 100ìë§Œ
        }
        
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.md5(key_str.encode()).hexdigest()
        
        
    def clear_cache(self):
        """ìºì‹œ í´ë¦¬ì–´"""
        with self.cache_lock:
            self.calculation_cache.clear()
            
    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        with self.cache_lock:
            return {
                'cache_size': len(self.calculation_cache),
                'cache_keys': list(self.calculation_cache.keys())[:10]  # ì²˜ìŒ 10ê°œë§Œ
            }
    
    def get_pytorch_network(self) -> Optional[nn.Module]:
        """
        í—¤ë“œ/ìŠ¤ì™‘ë§¤ë‹ˆì €ê°€ ì‚¬ìš©í•  ëŒ€í‘œ PyTorch ë„¤íŠ¸ì›Œí¬ë¥¼ ë°˜í™˜.
        - ê°€ëŠ¥í•œ í›„ë³´ë¥¼ ìˆœì„œëŒ€ë¡œ íƒìƒ‰í•´ì„œ nn.Moduleì„ ë°˜í™˜
        - í•œ ë²ˆ ì°¾ìœ¼ë©´ ìºì‹œ(self._primary_nn)í•´ ì¬ì‚¬ìš©
        """
        import torch.nn as nn
        
        # ìºì‹œ ìˆìœ¼ë©´ ì¦‰ì‹œ ë°˜í™˜
        if hasattr(self, "_primary_nn") and isinstance(self._primary_nn, nn.Module):
            logger.info("AdvancedBenthamCalculator: ìºì‹œëœ primary_nn ë°˜í™˜")
            return self._primary_nn
        
        candidates = []
        
        # 1) ìì£¼ ì“°ì´ëŠ” ë„¤ì´ë° ìš°ì„ 
        for name in ["neural_predictor", "bentham_model", "scoring_network", "model", "network", "default_network"]:
            if hasattr(self, name):
                obj = getattr(self, name)
                # propertyì¸ ê²½ìš° ì²˜ë¦¬
                if hasattr(obj, '__get__'):
                    try:
                        obj = obj.__get__(self, type(self))
                    except Exception:
                        obj = None
                # callableì´ë©´ í•œ ë²ˆ í˜¸ì¶œí•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ íšë“
                try:
                    if callable(obj) and not isinstance(obj, nn.Module):
                        obj = obj()
                except Exception:
                    obj = None
                if isinstance(obj, nn.Module):
                    candidates.append((name, obj))
        
        # 2) weight_layers ë‚´ë¶€ì˜ neural_predictor í™•ì¸
        if hasattr(self, 'weight_layers'):
            weight_layers = getattr(self, 'weight_layers')
            if hasattr(weight_layers, '__get__'):
                try:
                    weight_layers = weight_layers.__get__(self, type(self))
                except Exception:
                    weight_layers = None
            
            if weight_layers and isinstance(weight_layers, dict):
                for layer_name, layer in weight_layers.items():
                    if hasattr(layer, 'neural_predictor') and isinstance(layer.neural_predictor, nn.Module):
                        candidates.append((f"weight_layers.{layer_name}.neural_predictor", layer.neural_predictor))
        
        # 3) ë©¤ë²„ ì¤‘ nn.Module ìë™ íƒìƒ‰ (ë°±ì—… ê²½ë¡œ)
        if not candidates:
            try:
                for name, val in vars(self).items():
                    if isinstance(val, nn.Module):
                        candidates.append((name, val))
            except Exception:
                pass
        
        if not candidates:
            logger.warning("bentham_calculator ë‚´ë¶€ì—ì„œ nn.Module í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            logger.warning(f"  - neural_predictor: {hasattr(self, 'neural_predictor')}")
            logger.warning(f"  - weight_layers: {hasattr(self, 'weight_layers')}")
            logger.warning(f"  - default_network: {hasattr(self, 'default_network')}")
            
            # ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì‹œë„
            logger.info("ğŸ”¨ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì‹œë„ ì¤‘...")
            try:
                self._build_default_network()
                # ìƒì„± í›„ ë‹¤ì‹œ í™•ì¸
                if hasattr(self, '_primary_nn') and isinstance(self._primary_nn, nn.Module):
                    return self._primary_nn
                elif hasattr(self, 'default_network') and isinstance(self.default_network, nn.Module):
                    self._primary_nn = self.default_network
                    return self._primary_nn
            except Exception as e:
                logger.error(f"ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"bentham_calculator nn.Module ìƒì„± ì‹¤íŒ¨: {e}")
        
        # 4) ê°€ì¥ í° ë„¤íŠ¸ì›Œí¬ë¥¼ ëŒ€í‘œë¡œ ì„ íƒ(íŒŒë¼ë¯¸í„° ìˆ˜ ê¸°ì¤€)
        def num_params(m): 
            try:
                return sum(p.numel() for p in m.parameters())
            except Exception:
                return 0
        
        best_name, best_model = max(candidates, key=lambda kv: num_params(kv[1]))
        
        logger.info(f"AdvancedBenthamCalculator: {best_name}ì„(ë¥¼) primary_nnìœ¼ë¡œ ì„ íƒ (íŒŒë¼ë¯¸í„° ìˆ˜: {num_params(best_model):,})")
        
        # ìºì‹œ í›„ ë°˜í™˜
        self._primary_nn = best_model
        return self._primary_nn


def test_advanced_bentham_calculator():
    """ê³ ê¸‰ ë²¤ë‹´ ê³„ì‚°ê¸° í…ŒìŠ¤íŠ¸"""
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    try:
        # ê³„ì‚°ê¸° ì´ˆê¸°í™”
        calculator = AdvancedBenthamCalculator()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_data = {
            'input_values': {
                'intensity': 0.9,
                'duration': 0.8,
                'certainty': 0.7,
                'propinquity': 0.85,
                'fecundity': 0.6,
                'purity': 0.75,
                'extent': 0.9
            },
            'text_description': "ì´ ê²°ì •ì€ ë§ì€ ì‚¬ëŒë“¤ì˜ ìƒëª…ê³¼ ì•ˆì „ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ë©°, ì¥ê¸°ì ìœ¼ë¡œ ì‚¬íšŒ ì „ì²´ì˜ ë³µì§€ì— ì¤‘ëŒ€í•œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ê²ƒì…ë‹ˆë‹¤.",
            'language': 'ko',
            'affected_count': 1000,
            'duration_seconds': 86400,  # 24ì‹œê°„
            'information_quality': 0.85,
            'uncertainty_level': 0.25,
            'social_context': {
                'impact_scope': 'society',
                'social_status': 'influential',
                'network_effect': 'viral'
            },
            'temporal_context': {
                'immediacy': 'immediate',
                'persistence': 'permanent',
                'time_pressure': 'high'
            },
            'ethical_context': {
                'life_impact': 'critical',
                'justice_factor': 'high',
                'autonomy_impact': 'enhancing',
                'vulnerable_protection': 'critical'
            },
            'cognitive_context': {
                'cognitive_load': 'high',
                'decision_complexity': 'very_complex',
                'information_certainty': 'high',
                'predictability': 'low'
            }
        }
        
        print("=== ê³ ê¸‰ ë²¤ë‹´ ì¾Œë½ ê³„ì‚°ê¸° í…ŒìŠ¤íŠ¸ (Linux) ===\n")
        
        # ê³„ì‚° ì‹¤í–‰
        start_time = time.time()
        result = calculator.calculate_with_advanced_layers(test_data)
        processing_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        print("ğŸ“Š ê³„ì‚° ê²°ê³¼:")
        print(f"- ìµœì¢… ì ìˆ˜: {result.final_score:.4f}")
        print(f"- ê¸°ë³¸ ì ìˆ˜: {result.base_score:.4f}")
        print(f"- ê°œì„  ë¹„ìœ¨: {((result.final_score / result.base_score - 1) * 100):+.1f}%")
        print(f"- ì¢…í•© ì‹ ë¢°ë„: {result.confidence_score:.3f}")
        print(f"- ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
        neural_used = result.context_analysis.get('neural_prediction_used', False)
        opt_applied = result.context_analysis.get('optimization_applied', False)
        print(f"- ì‹ ê²½ë§ ì˜ˆì¸¡ ì‚¬ìš©: {'ì˜ˆ' if neural_used else 'ì•„ë‹ˆì˜¤'}")
        print(f"- ìµœì í™” ì ìš©: {'ì˜ˆ' if opt_applied else 'ì•„ë‹ˆì˜¤'}")
        
        print(f"\nğŸ¯ ë ˆì´ì–´ë³„ ê¸°ì—¬ë„:")
        for i, layer in enumerate(result.layer_contributions):
            print(f"{i+1}. {layer.layer_name}")
            print(f"   â€¢ ê°€ì¤‘ì¹˜: {layer.weight_factor:.3f}")
            print(f"   â€¢ ê¸°ì—¬ë„: {layer.contribution_score:.3f}")
            print(f"   â€¢ ì‹ ë¢°ë„: {layer.confidence:.3f}")
            reasoning = layer.metadata.get('reasoning', 'No reasoning available')
            print(f"   â€¢ ê·¼ê±°: {reasoning}")
            
        if result.extreme_adjustment_applied:
            print(f"\nâš¡ ê·¹ë‹¨ê°’ ë³´ì •:")
            print(f"- ë³´ì • ê³„ìˆ˜: {result.adjustment_factor:.3f}")
            extreme_adj = result.context_analysis.get('calculation_breakdown', {}).get('extreme_adjustment', {})
            if extreme_adj:
                print(f"- ë³´ì • ìœ í˜•: {extreme_adj.get('type', 'unknown')}")
            
        print(f"\nğŸ”§ ì‹œìŠ¤í…œ ì •ë³´:")
        print(f"- ë””ë°”ì´ìŠ¤: {DEVICE}")
        print(f"- GPU ì‚¬ìš©: {'ì˜ˆ' if ADVANCED_CONFIG['enable_gpu'] else 'ì•„ë‹ˆì˜¤'}")
        print(f"- ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
        
        # ìºì‹œ í†µê³„
        cache_stats = calculator.get_cache_stats()
        print(f"- ìºì‹œ í¬ê¸°: {cache_stats['cache_size']}")
        
        return result
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


@dataclass
class FrommAnalysisResult:
    """ì—ë¦¬íˆ í”„ë¡¬ ë¶„ì„ ê²°ê³¼"""
    orientation: FrommOrientation
    being_score: float  # ì¡´ì¬ ì§€í–¥ ì ìˆ˜ (0-1)
    having_score: float  # ì†Œìœ  ì§€í–¥ ì ìˆ˜ (0-1)
    authenticity_level: float  # ì§„ì •ì„± ìˆ˜ì¤€ (0-1)
    alienation_level: float  # ì†Œì™¸ ìˆ˜ì¤€ (0-1)
    creative_potential: float  # ì°½ì¡°ì  ì ì¬ë ¥ (0-1)
    social_connectedness: float  # ì‚¬íšŒì  ì—°ê²°ì„± (0-1)
    self_realization: float  # ìê¸°ì‹¤í˜„ (0-1)
    character_traits: Dict[str, float]  # ì„±ê²© íŠ¹ì„±ë“¤
    fromm_factors: Dict[str, Any]  # í”„ë¡¬ ì² í•™ ìš”ì¸ë“¤
    confidence: float = 0.8


class FrommEthicalAnalyzer:
    """
    ì—ë¦¬íˆ í”„ë¡¬ ì² í•™ ë¶„ì„ê¸° - ì†Œìœ ëƒ ì¡´ì¬ëƒ (To Have or To Be) ê¸°ë°˜
    
    2024ë…„ ì—°êµ¬ ê¸°ë°˜ êµ¬í˜„:
    - ì†Œìœ  vs ì¡´ì¬ ì§€í–¥ ë¶„ì„
    - ì§„ì •ì„± vs ì†Œì™¸ í‰ê°€
    - ì°½ì¡°ì  ì ì¬ë ¥ ì¸¡ì •
    - ì‚¬íšŒì  ì„±ê²© ë¶„ì„
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # í”„ë¡¬ ì² í•™ ê¸°ë°˜ í‰ê°€ ê¸°ì¤€
        self.fromm_criteria = {
            'being_indicators': [
                'authentic', 'creative', 'spontaneous', 'loving', 'caring',
                'growth', 'experience', 'meaningful', 'connection', 'understanding',
                'wisdom', 'compassion', 'beauty', 'truth', 'freedom'
            ],
            'having_indicators': [
                'possess', 'own', 'control', 'dominate', 'accumulate',
                'compete', 'status', 'wealth', 'power', 'prestige',
                'consume', 'acquire', 'material', 'property', 'objects'
            ],
            'alienation_indicators': [
                'isolated', 'disconnected', 'meaningless', 'empty', 'anxious',
                'conformity', 'mechanical', 'routine', 'passive', 'dependent',
                'superficial', 'artificial', 'automated', 'robotic', 'lost'
            ],
            'authenticity_indicators': [
                'genuine', 'real', 'honest', 'sincere', 'true',
                'original', 'unique', 'individual', 'personal', 'intimate',
                'deep', 'heartfelt', 'spontaneous', 'natural', 'organic'
            ]
        }
        
        # ì‚¬íšŒì  ì„±ê²© ìœ í˜• (í”„ë¡¬ì˜ 5ê°€ì§€ ì„±ê²© ìœ í˜•)
        self.character_types = {
            'receptive': {  # ìˆ˜ìš©ì  ì„±ê²©
                'indicators': ['passive', 'dependent', 'submissive', 'loyal', 'accepting'],
                'description': 'ì™¸ë¶€ë¡œë¶€í„° ë°›ëŠ” ê²ƒì— ì˜ì¡´í•˜ëŠ” ì„±ê²©'
            },
            'exploitative': {  # ì°©ì·¨ì  ì„±ê²©  
                'indicators': ['aggressive', 'dominating', 'taking', 'competitive', 'cynical'],
                'description': 'íƒ€ì¸ì„ ì°©ì·¨í•˜ì—¬ ì–»ìœ¼ë ¤ëŠ” ì„±ê²©'
            },
            'hoarding': {  # ì €ì¶•ì  ì„±ê²©
                'indicators': ['saving', 'possessive', 'cautious', 'orderly', 'rigid'],
                'description': 'ì†Œìœ ë¬¼ì„ ì¶•ì í•˜ê³  ë³´ì¡´í•˜ë ¤ëŠ” ì„±ê²©'
            },
            'marketing': {  # ì‹œì¥ì  ì„±ê²©
                'indicators': ['adaptable', 'flexible', 'opportunistic', 'changeable', 'modern'],
                'description': 'ìì‹ ì„ ìƒí’ˆì²˜ëŸ¼ íŒë§¤í•˜ë ¤ëŠ” ì„±ê²©'
            },
            'productive': {  # ìƒì‚°ì  ì„±ê²©
                'indicators': ['creative', 'loving', 'reasoning', 'working', 'authentic'],
                'description': 'ìì‹ ì˜ ì ì¬ë ¥ì„ ì‹¤í˜„í•˜ëŠ” ê±´ê°•í•œ ì„±ê²©'
            }
        }
        
    async def analyze_fromm_orientation(self, text: str, context: Dict[str, Any] = None) -> FrommAnalysisResult:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì—ë¦¬íˆ í”„ë¡¬ì˜ ì² í•™ì  ì§€í–¥ì„± ë¶„ì„
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            í”„ë¡¬ ë¶„ì„ ê²°ê³¼
        """
        context = context or {}
        
        try:
            # 1. ì¡´ì¬ vs ì†Œìœ  ì§€í–¥ ë¶„ì„
            being_score = await self._analyze_being_orientation(text)
            having_score = await self._analyze_having_orientation(text)
            
            # 2. ì§„ì •ì„± vs ì†Œì™¸ ë¶„ì„
            authenticity_level = await self._analyze_authenticity(text)
            alienation_level = await self._analyze_alienation(text)
            
            # 3. ì°½ì¡°ì  ì ì¬ë ¥ ë¶„ì„
            creative_potential = await self._analyze_creative_potential(text)
            
            # 4. ì‚¬íšŒì  ì—°ê²°ì„± ë¶„ì„
            social_connectedness = await self._analyze_social_connectedness(text)
            
            # 5. ìê¸°ì‹¤í˜„ ë¶„ì„
            self_realization = await self._analyze_self_realization(text)
            
            # 6. ì„±ê²© ìœ í˜• ë¶„ì„
            character_traits = await self._analyze_character_types(text)
            
            # 7. í”„ë¡¬ ìš”ì¸ë“¤ ì¢…í•© ë¶„ì„
            fromm_factors = await self._analyze_fromm_factors(text, context)
            
            # 8. ì „ì²´ ì§€í–¥ì„± ê²°ì •
            orientation = await self._determine_overall_orientation(being_score, having_score)
            
            # 9. ì‹ ë¢°ë„ ê³„ì‚°
            confidence = await self._calculate_analysis_confidence(
                text, being_score, having_score, authenticity_level, alienation_level
            )
            
            return FrommAnalysisResult(
                orientation=orientation,
                being_score=being_score,
                having_score=having_score,
                authenticity_level=authenticity_level,
                alienation_level=alienation_level,
                creative_potential=creative_potential,
                social_connectedness=social_connectedness,
                self_realization=self_realization,
                character_traits=character_traits,
                fromm_factors=fromm_factors,
                confidence=confidence
            )
            
        except Exception as e:
            # í”„ë¡œì íŠ¸ ê·œì¹™: fallback ì—†ëŠ” ìˆœìˆ˜ ì¬ì‹œë„ ë°©ì‹
            retry_count = 0
            max_retries = 3
            analysis_result = None
            while retry_count < max_retries:
                retry_count += 1
                self.logger.info(f"í”„ë¡¬ ë¶„ì„ ì¬ì‹œë„ {retry_count}/{max_retries}")
                try:
                    # ì „ì²´ í”„ë¡¬ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì¬ì‹œë„
                    # 1. ì¡´ì¬ vs ì†Œìœ  ì§€í–¥ ë¶„ì„
                    being_score = await self._analyze_being_orientation(text)
                    having_score = await self._analyze_having_orientation(text)
                    
                    # 2. ì§„ì •ì„± vs ì†Œì™¸ ë¶„ì„
                    authenticity_level = await self._analyze_authenticity(text)
                    alienation_level = await self._analyze_alienation(text)
                    
                    # 3. ì°½ì¡°ì  ì ì¬ë ¥ ë¶„ì„
                    creative_potential = await self._analyze_creative_potential(text)
                    
                    # 4. ì‚¬íšŒì  ì—°ê²°ì„± ë¶„ì„
                    social_connectedness = await self._analyze_social_connectedness(text)
                    
                    # 5. ìê¸°ì‹¤í˜„ ë¶„ì„
                    self_realization = await self._analyze_self_realization(text)
                    
                    # 6. ì„±ê²© ìœ í˜• ë¶„ì„
                    character_traits = await self._analyze_character_types(text)
                    
                    # 7. í”„ë¡¬ ìš”ì¸ë“¤ ì¢…í•© ë¶„ì„
                    fromm_factors = await self._analyze_fromm_factors(text, context)
                    
                    # 8. ì „ì²´ ì§€í–¥ì„± ê²°ì •
                    orientation = self._determine_overall_orientation(being_score, having_score)
                    
                    # 9. ì‹ ë¢°ë„ ê³„ì‚°
                    confidence = self._calculate_fromm_confidence(text, being_score, having_score, 
                                                               authenticity_level, alienation_level)
                    
                    # ê²°ê³¼ ìƒì„±
                    analysis_result = FrommAnalysisResult(
                        orientation=orientation,
                        being_score=being_score,
                        having_score=having_score,
                        authenticity_level=authenticity_level,
                        alienation_level=alienation_level,
                        creative_potential=creative_potential,
                        social_connectedness=social_connectedness,
                        self_realization=self_realization,
                        character_traits=character_traits,
                        fromm_factors=fromm_factors,
                        confidence=confidence
                    )
                    
                    self.logger.info(f"í”„ë¡¬ ë¶„ì„ ì¬ì‹œë„ ì„±ê³µ: ì§€í–¥ì„±={orientation}")
                    return analysis_result
                    
                except Exception as retry_error:
                    self.logger.error(f"í”„ë¡¬ ë¶„ì„ ì¬ì‹œë„ {retry_count} ì‹¤íŒ¨: {retry_error}")
                    if retry_count >= max_retries:
                        self.logger.error("í”„ë¡¬ ë¶„ì„ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì •ì§€")
                        raise RuntimeError(f"í”„ë¡¬ ë¶„ì„ ìµœì¢… ì‹¤íŒ¨: {retry_error}")
                    import asyncio
                    await asyncio.sleep(0.5)
            
            if analysis_result is None:
                self.logger.error("í”„ë¡¬ ë¶„ì„ ì¬ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì •ì§€")
                raise RuntimeError("í”„ë¡¬ ë¶„ì„ ì‹¤íŒ¨ - fallback ê¸ˆì§€ë¡œ ì‹œìŠ¤í…œ ì •ì§€")
    
    async def _analyze_being_orientation(self, text: str) -> float:
        """ì¡´ì¬ ì§€í–¥ì„± ë¶„ì„"""
        text_lower = text.lower()
        being_count = 0
        
        for indicator in self.fromm_criteria['being_indicators']:
            if indicator in text_lower:
                being_count += 1
        
        # ì¡´ì¬ ì§€í–¥ì  ë¬¸êµ¬ íŒ¨í„´ ë¶„ì„
        being_patterns = [
            'who i am', 'authentic self', 'true meaning', 'deep connection',
            'creative expression', 'genuine feeling', 'real experience',
            'meaningful relationship', 'inner growth', 'spiritual development'
        ]
        
        pattern_count = sum(1 for pattern in being_patterns if pattern in text_lower)
        
        # ì •ê·œí™”ëœ ì ìˆ˜ ê³„ì‚°
        raw_score = (being_count + pattern_count * 2) / (len(self.fromm_criteria['being_indicators']) + len(being_patterns) * 2)
        return min(1.0, raw_score)
    
    async def _analyze_having_orientation(self, text: str) -> float:
        """ì†Œìœ  ì§€í–¥ì„± ë¶„ì„"""
        text_lower = text.lower()
        having_count = 0
        
        for indicator in self.fromm_criteria['having_indicators']:
            if indicator in text_lower:
                having_count += 1
        
        # ì†Œìœ  ì§€í–¥ì  ë¬¸êµ¬ íŒ¨í„´ ë¶„ì„
        having_patterns = [
            'i have', 'i own', 'my possessions', 'accumulate wealth',
            'status symbol', 'material success', 'competitive advantage',
            'market value', 'profit margin', 'consumer goods'
        ]
        
        pattern_count = sum(1 for pattern in having_patterns if pattern in text_lower)
        
        # ì •ê·œí™”ëœ ì ìˆ˜ ê³„ì‚°
        raw_score = (having_count + pattern_count * 2) / (len(self.fromm_criteria['having_indicators']) + len(having_patterns) * 2)
        return min(1.0, raw_score)
    
    async def _analyze_authenticity(self, text: str) -> float:
        """ì§„ì •ì„± ìˆ˜ì¤€ ë¶„ì„"""
        text_lower = text.lower()
        authenticity_count = 0
        
        for indicator in self.fromm_criteria['authenticity_indicators']:
            if indicator in text_lower:
                authenticity_count += 1
        
        # ì§„ì •ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì–¸ì–´ì  íŠ¹ì§•
        authenticity_features = [
            len([word for word in text.split() if word.startswith('I ')]) / len(text.split()) if text.split() else 0,  # ì£¼ì²´ì  í‘œí˜„
            text.count('feel') + text.count('believe') + text.count('think'),  # ê°œì¸ì  ê²¬í•´ í‘œí˜„
            text.count('?') / len(text) if text else 0,  # ì„±ì°°ì  ì§ˆë¬¸
        ]
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì§„ì •ì„± ì ìˆ˜ ê³„ì‚°
        base_score = authenticity_count / len(self.fromm_criteria['authenticity_indicators'])
        feature_score = np.mean(authenticity_features)
        
        return min(1.0, (base_score * 0.7 + feature_score * 0.3))
    
    async def _analyze_alienation(self, text: str) -> float:
        """ì†Œì™¸ ìˆ˜ì¤€ ë¶„ì„"""
        text_lower = text.lower()
        alienation_count = 0
        
        for indicator in self.fromm_criteria['alienation_indicators']:
            if indicator in text_lower:
                alienation_count += 1
        
        # ì†Œì™¸ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì–¸ì–´ì  íŒ¨í„´
        alienation_patterns = [
            'feel disconnected', 'no meaning', 'empty inside', 'going through motions',
            'just a number', 'nobody understands', 'all the same', 'pointless'
        ]
        
        pattern_count = sum(1 for pattern in alienation_patterns if pattern in text_lower)
        
        raw_score = (alienation_count + pattern_count * 1.5) / (len(self.fromm_criteria['alienation_indicators']) + len(alienation_patterns) * 1.5)
        return min(1.0, raw_score)
    
    async def _analyze_creative_potential(self, text: str) -> float:
        """ì°½ì¡°ì  ì ì¬ë ¥ ë¶„ì„"""
        text_lower = text.lower()
        
        creativity_words = [
            'create', 'innovate', 'imagine', 'invent', 'design', 'artistic',
            'original', 'unique', 'new', 'experiment', 'explore', 'discover'
        ]
        
        creativity_score = sum(1 for word in creativity_words if word in text_lower)
        
        # ì°½ì¡°ì  í‘œí˜„ì˜ ì–¸ì–´ì  íŠ¹ì§•
        linguistic_creativity = [
            len(set(text.split())) / len(text.split()) if text.split() else 0,  # ì–´íœ˜ ë‹¤ì–‘ì„±
            text.count('!') / len(text) if text else 0,  # ê°ì •ì  í‘œí˜„
            len([word for word in text.split() if len(word) > 8]) / len(text.split()) if text.split() else 0  # ë³µì¡í•œ ì–´íœ˜
        ]
        
        base_score = creativity_score / len(creativity_words)
        linguistic_score = np.mean(linguistic_creativity)
        
        return min(1.0, (base_score * 0.6 + linguistic_score * 0.4))
    
    async def _analyze_social_connectedness(self, text: str) -> float:
        """ì‚¬íšŒì  ì—°ê²°ì„± ë¶„ì„"""
        text_lower = text.lower()
        
        social_words = [
            'we', 'us', 'together', 'community', 'relationship', 'friend',
            'family', 'share', 'connect', 'belong', 'care', 'love'
        ]
        
        social_count = sum(1 for word in social_words if word in text_lower)
        
        # ê´€ê³„ì  ì–¸ì–´ íŒ¨í„´
        relational_patterns = [
            'with others', 'feel close', 'meaningful relationship', 'deep connection',
            'mutual understanding', 'shared experience', 'together we', 'part of'
        ]
        
        pattern_count = sum(1 for pattern in relational_patterns if pattern in text_lower)
        
        raw_score = (social_count + pattern_count * 1.5) / (len(social_words) + len(relational_patterns) * 1.5)
        return min(1.0, raw_score)
    
    async def _analyze_self_realization(self, text: str) -> float:
        """ìê¸°ì‹¤í˜„ ë¶„ì„"""
        text_lower = text.lower()
        
        self_realization_words = [
            'growth', 'develop', 'potential', 'fulfill', 'achieve', 'realize',
            'become', 'transform', 'evolve', 'improve', 'better', 'progress'
        ]
        
        realization_count = sum(1 for word in self_realization_words if word in text_lower)
        
        # ìê¸°ì‹¤í˜„ì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸êµ¬
        realization_phrases = [
            'true potential', 'personal growth', 'self development', 'inner journey',
            'becoming myself', 'finding purpose', 'life mission', 'authentic path'
        ]
        
        phrase_count = sum(1 for phrase in realization_phrases if phrase in text_lower)
        
        raw_score = (realization_count + phrase_count * 2) / (len(self_realization_words) + len(realization_phrases) * 2)
        return min(1.0, raw_score)
    
    async def _analyze_character_types(self, text: str) -> Dict[str, float]:
        """í”„ë¡¬ì˜ 5ê°€ì§€ ì„±ê²© ìœ í˜• ë¶„ì„"""
        text_lower = text.lower()
        character_scores = {}
        
        for char_type, char_data in self.character_types.items():
            indicators = char_data['indicators']
            type_score = sum(1 for indicator in indicators if indicator in text_lower)
            character_scores[char_type] = type_score / len(indicators)
        
        return character_scores
    
    async def _analyze_fromm_factors(self, text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """í”„ë¡¬ ì² í•™ ìš”ì¸ë“¤ ì¢…í•© ë¶„ì„"""
        factors = {}
        
        # ììœ  vs ë„í”¼ (Freedom vs Escape)
        factors['freedom_level'] = await self._analyze_freedom_orientation(text)
        factors['escape_tendency'] = await self._analyze_escape_tendency(text)
        
        # ì‚¬ë‘ì˜ ëŠ¥ë ¥ (Capacity for Love)
        factors['love_capacity'] = await self._analyze_love_capacity(text)
        
        # íŒŒê´´ì„± vs ì°½ì¡°ì„± (Destructiveness vs Creativity)
        factors['destructive_tendency'] = await self._analyze_destructive_tendency(text)
        factors['constructive_tendency'] = await self._analyze_constructive_tendency(text)
        
        # ê¶Œìœ„ì£¼ì˜ vs ììœ ì£¼ì˜ ì„±í–¥
        factors['authoritarian_tendency'] = await self._analyze_authoritarian_tendency(text)
        factors['democratic_tendency'] = await self._analyze_democratic_tendency(text)
        
        return factors
    
    async def _analyze_freedom_orientation(self, text: str) -> float:
        """ììœ  ì§€í–¥ì„± ë¶„ì„"""
        freedom_words = ['freedom', 'liberty', 'choice', 'autonomy', 'independence', 'self-directed']
        text_lower = text.lower()
        return min(1.0, sum(1 for word in freedom_words if word in text_lower) / len(freedom_words))
    
    async def _analyze_escape_tendency(self, text: str) -> float:
        """ë„í”¼ ì„±í–¥ ë¶„ì„"""
        escape_words = ['escape', 'avoid', 'hide', 'conform', 'follow', 'obey', 'submit']
        text_lower = text.lower()
        return min(1.0, sum(1 for word in escape_words if word in text_lower) / len(escape_words))
    
    async def _analyze_love_capacity(self, text: str) -> float:
        """ì‚¬ë‘ì˜ ëŠ¥ë ¥ ë¶„ì„"""
        love_words = ['love', 'care', 'compassion', 'empathy', 'understanding', 'nurture', 'support']
        text_lower = text.lower()
        return min(1.0, sum(1 for word in love_words if word in text_lower) / len(love_words))
    
    async def _analyze_destructive_tendency(self, text: str) -> float:
        """íŒŒê´´ì  ì„±í–¥ ë¶„ì„"""
        destructive_words = ['destroy', 'break', 'damage', 'hurt', 'harm', 'violent', 'aggressive']
        text_lower = text.lower()
        return min(1.0, sum(1 for word in destructive_words if word in text_lower) / len(destructive_words))
    
    async def _analyze_constructive_tendency(self, text: str) -> float:
        """ê±´ì„¤ì  ì„±í–¥ ë¶„ì„"""
        constructive_words = ['build', 'create', 'construct', 'develop', 'grow', 'nurture', 'improve']
        text_lower = text.lower()
        return min(1.0, sum(1 for word in constructive_words if word in text_lower) / len(constructive_words))
    
    async def _analyze_authoritarian_tendency(self, text: str) -> float:
        """ê¶Œìœ„ì£¼ì˜ ì„±í–¥ ë¶„ì„"""
        authoritarian_words = ['obey', 'submit', 'authority', 'control', 'dominate', 'command', 'rule']
        text_lower = text.lower()
        return min(1.0, sum(1 for word in authoritarian_words if word in text_lower) / len(authoritarian_words))
    
    async def _analyze_democratic_tendency(self, text: str) -> float:
        """ë¯¼ì£¼ì  ì„±í–¥ ë¶„ì„"""
        democratic_words = ['equal', 'fair', 'justice', 'participate', 'collaborate', 'consensus', 'dialogue']
        text_lower = text.lower()
        return min(1.0, sum(1 for word in democratic_words if word in text_lower) / len(democratic_words))
    
    async def _determine_overall_orientation(self, being_score: float, having_score: float) -> FrommOrientation:
        """ì „ì²´ ì§€í–¥ì„± ê²°ì •"""
        difference = abs(being_score - having_score)
        
        if difference < 0.2:  # ì°¨ì´ê°€ ì‘ìœ¼ë©´ í˜¼í•©
            return FrommOrientation.MIXED
        elif being_score > having_score:
            return FrommOrientation.BEING
        else:
            return FrommOrientation.HAVING
    
    async def _calculate_analysis_confidence(self, text: str, being_score: float, 
                                          having_score: float, authenticity: float, 
                                          alienation: float) -> float:
        """ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì‹ ë¢°ë„
        text_length_factor = min(1.0, len(text.split()) / 50)  # 50ë‹¨ì–´ ì´ìƒì´ë©´ ìµœëŒ€ ì‹ ë¢°ë„
        
        # ì ìˆ˜ë“¤ì˜ ì¼ê´€ì„± ê¸°ë°˜ ì‹ ë¢°ë„
        scores = [being_score, having_score, authenticity, 1.0 - alienation]
        consistency_factor = 1.0 - np.std(scores) / np.mean(scores) if np.mean(scores) > 0 else 0.5
        
        # ì¢…í•© ì‹ ë¢°ë„
        overall_confidence = (text_length_factor * 0.3 + consistency_factor * 0.7)
        return max(0.1, min(1.0, overall_confidence))
    


class FrommEnhancedBenthamCalculator:
    """
    ì—ë¦¬íˆ í”„ë¡¬ ì² í•™ì´ í†µí•©ëœ ë²¤ë‹´ ê³„ì‚°ê¸°
    
    ë²¤ë‹´ì˜ ê³µë¦¬ì£¼ì˜ ê³„ì‚°ì— í”„ë¡¬ì˜ ì¸ê°„ì£¼ì˜ì  ìœ¤ë¦¬í•™ì„ í†µí•©í•˜ì—¬
    ë” ê¹Šì´ ìˆëŠ” ì¸ê°„ ì¤‘ì‹¬ì  í–‰ë³µ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, base_calculator: 'AdvancedBenthamCalculator'):
        self.base_calculator = base_calculator
        self.fromm_analyzer = FrommEthicalAnalyzer()
        self.logger = logging.getLogger(__name__)
        
        # í”„ë¡¬ ìš”ì†Œì˜ ë²¤ë‹´ ê³„ì‚° í†µí•© ê°€ì¤‘ì¹˜
        self.fromm_integration_weights = {
            'being_orientation_bonus': 0.2,  # ì¡´ì¬ ì§€í–¥ì¼ ë•Œ ì¶”ê°€ ê°€ì¤‘ì¹˜
            'authenticity_multiplier': 0.15,  # ì§„ì •ì„± ë°°ìˆ˜
            'alienation_penalty': 0.1,  # ì†Œì™¸ í˜ë„í‹°
            'creative_potential_bonus': 0.1,  # ì°½ì¡°ì  ì ì¬ë ¥ ë³´ë„ˆìŠ¤
            'social_connectedness_bonus': 0.05  # ì‚¬íšŒì  ì—°ê²°ì„± ë³´ë„ˆìŠ¤
        }
    
    async def calculate_fromm_enhanced_pleasure(self, 
                                             situation: EthicalSituation,
                                             context: AdvancedCalculationContext = None) -> EnhancedHedonicResult:
        """
        í”„ë¡¬ ì² í•™ì´ í†µí•©ëœ ì¾Œë½ ê³„ì‚°
        
        Args:
            situation: ìœ¤ë¦¬ì  ìƒí™©
            context: ê³„ì‚° ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            í”„ë¡¬ ìš”ì†Œê°€ í†µí•©ëœ í—¤ë„ë‹‰ ê²°ê³¼
        """
        try:
            # 1. ê¸°ë³¸ ë²¤ë‹´ ê³„ì‚° ìˆ˜í–‰
            base_result = await self.base_calculator.calculate_enhanced_pleasure(situation, context)
            
            # 2. í”„ë¡¬ ì² í•™ ë¶„ì„ ìˆ˜í–‰
            fromm_analysis = await self.fromm_analyzer.analyze_fromm_orientation(
                situation.description, 
                context.metadata if context else {}
            )
            
            # 3. í”„ë¡¬ ìš”ì†Œë¥¼ ë²¤ë‹´ ê³„ì‚°ì— í†µí•©
            enhanced_result = await self._integrate_fromm_into_bentham(
                base_result, fromm_analysis, situation
            )
            
            # 4. í”„ë¡¬ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            enhanced_result.context_analysis['fromm_analysis'] = {
                'orientation': fromm_analysis.orientation.value,
                'being_score': fromm_analysis.being_score,
                'having_score': fromm_analysis.having_score,
                'authenticity_level': fromm_analysis.authenticity_level,
                'alienation_level': fromm_analysis.alienation_level,
                'character_traits': fromm_analysis.character_traits,
                'fromm_factors': fromm_analysis.fromm_factors,
                'analysis_confidence': fromm_analysis.confidence
            }
            
            return enhanced_result
            
        except Exception as e:
            self.logger.error(f"í”„ë¡¬ í†µí•© ë²¤ë‹´ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return await self.base_calculator.calculate_enhanced_pleasure(situation, context)
    
    async def _integrate_fromm_into_bentham(self, 
                                          base_result: EnhancedHedonicResult,
                                          fromm_analysis: FrommAnalysisResult,
                                          situation: EthicalSituation) -> EnhancedHedonicResult:
        """í”„ë¡¬ ìš”ì†Œë¥¼ ë²¤ë‹´ ê³„ì‚°ì— í†µí•©"""
        
        # ê¸°ë³¸ ê²°ê³¼ ë³µì‚¬
        enhanced_result = base_result
        
        # 1. ì¡´ì¬ ì§€í–¥ ë³´ë„ˆìŠ¤ ì ìš©
        being_bonus = self._calculate_being_orientation_bonus(fromm_analysis)
        enhanced_result.final_pleasure_score *= (1 + being_bonus)
        
        # 2. ì§„ì •ì„± ë°°ìˆ˜ ì ìš©
        authenticity_multiplier = self._calculate_authenticity_multiplier(fromm_analysis)
        enhanced_result.final_pleasure_score *= authenticity_multiplier
        
        # 3. ì†Œì™¸ í˜ë„í‹° ì ìš©
        alienation_penalty = self._calculate_alienation_penalty(fromm_analysis)
        enhanced_result.final_pleasure_score *= (1 - alienation_penalty)
        
        # 4. ì°½ì¡°ì  ì ì¬ë ¥ ë³´ë„ˆìŠ¤ ì ìš©
        creative_bonus = self._calculate_creative_potential_bonus(fromm_analysis)
        enhanced_result.final_pleasure_score *= (1 + creative_bonus)
        
        # 5. ì‚¬íšŒì  ì—°ê²°ì„± ë³´ë„ˆìŠ¤ ì ìš©
        social_bonus = self._calculate_social_connectedness_bonus(fromm_analysis)
        enhanced_result.final_pleasure_score *= (1 + social_bonus)
        
        # 6. í”„ë¡¬ ì² í•™ ê¸°ë°˜ ì¶”ê°€ ê°€ì¤‘ì¹˜ ë ˆì´ì–´ ìƒì„±
        fromm_layer = WeightLayerResult(
            layer_name="fromm_humanistic_ethics",
            weight_factor=self._calculate_overall_fromm_weight(fromm_analysis),
            contribution_score=self._calculate_fromm_contribution(fromm_analysis),
            confidence=fromm_analysis.confidence,
            metadata={
                'orientation': fromm_analysis.orientation.value,
                'being_bonus': being_bonus,
                'authenticity_multiplier': authenticity_multiplier,
                'alienation_penalty': alienation_penalty,
                'creative_bonus': creative_bonus,
                'social_bonus': social_bonus,
                'reasoning': self._generate_fromm_reasoning(fromm_analysis)
            }
        )
        
        # 7. ë ˆì´ì–´ ê¸°ì—¬ë„ì— í”„ë¡¬ ë ˆì´ì–´ ì¶”ê°€
        enhanced_result.layer_contributions.append(fromm_layer)
        
        # 8. ìµœì¢… ì ìˆ˜ ì¬ì •ê·œí™” (0-10 ë²”ìœ„ ìœ ì§€)
        enhanced_result.final_pleasure_score = max(0.0, min(10.0, enhanced_result.final_pleasure_score))
        
        return enhanced_result
    
    def _calculate_being_orientation_bonus(self, fromm_analysis: FrommAnalysisResult) -> float:
        """ì¡´ì¬ ì§€í–¥ ë³´ë„ˆìŠ¤ ê³„ì‚°"""
        if fromm_analysis.orientation == FrommOrientation.BEING:
            return fromm_analysis.being_score * self.fromm_integration_weights['being_orientation_bonus']
        return 0.0
    
    def _calculate_authenticity_multiplier(self, fromm_analysis: FrommAnalysisResult) -> float:
        """ì§„ì •ì„± ë°°ìˆ˜ ê³„ì‚°"""
        base_multiplier = 1.0
        authenticity_bonus = fromm_analysis.authenticity_level * self.fromm_integration_weights['authenticity_multiplier']
        return base_multiplier + authenticity_bonus
    
    def _calculate_alienation_penalty(self, fromm_analysis: FrommAnalysisResult) -> float:
        """ì†Œì™¸ í˜ë„í‹° ê³„ì‚°"""
        return fromm_analysis.alienation_level * self.fromm_integration_weights['alienation_penalty']
    
    def _calculate_creative_potential_bonus(self, fromm_analysis: FrommAnalysisResult) -> float:
        """ì°½ì¡°ì  ì ì¬ë ¥ ë³´ë„ˆìŠ¤ ê³„ì‚°"""
        return fromm_analysis.creative_potential * self.fromm_integration_weights['creative_potential_bonus']
    
    def _calculate_social_connectedness_bonus(self, fromm_analysis: FrommAnalysisResult) -> float:
        """ì‚¬íšŒì  ì—°ê²°ì„± ë³´ë„ˆìŠ¤ ê³„ì‚°"""
        return fromm_analysis.social_connectedness * self.fromm_integration_weights['social_connectedness_bonus']
    
    def _calculate_overall_fromm_weight(self, fromm_analysis: FrommAnalysisResult) -> float:
        """ì „ì²´ í”„ë¡¬ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        weights = [
            fromm_analysis.being_score,
            fromm_analysis.authenticity_level,
            1.0 - fromm_analysis.alienation_level,  # ì†Œì™¸ì˜ ì—­ìˆ˜
            fromm_analysis.creative_potential,
            fromm_analysis.social_connectedness,
            fromm_analysis.self_realization
        ]
        return np.mean(weights)
    
    def _calculate_fromm_contribution(self, fromm_analysis: FrommAnalysisResult) -> float:
        """í”„ë¡¬ ì² í•™ì˜ ê¸°ì—¬ë„ ê³„ì‚°"""
        # ì¡´ì¬ ì§€í–¥ì„±ì´ ë†’ê³  ì†Œì™¸ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ê¸°ì—¬ë„
        contribution = (
            fromm_analysis.being_score * 0.3 +
            fromm_analysis.authenticity_level * 0.25 +
            (1.0 - fromm_analysis.alienation_level) * 0.2 +
            fromm_analysis.creative_potential * 0.15 +
            fromm_analysis.social_connectedness * 0.1
        )
        return contribution
    
    def _generate_fromm_reasoning(self, fromm_analysis: FrommAnalysisResult) -> str:
        """í”„ë¡¬ ë¶„ì„ì— ê¸°í•œ ì¶”ë¡  ìƒì„±"""
        orientation = fromm_analysis.orientation.value
        being_score = fromm_analysis.being_score
        authenticity = fromm_analysis.authenticity_level
        alienation = fromm_analysis.alienation_level
        
        reasoning_parts = []
        
        if orientation == "being":
            reasoning_parts.append(f"ì¡´ì¬ ì§€í–¥ì  ì„±ê²© (ì ìˆ˜: {being_score:.2f})ìœ¼ë¡œ ì§„ì •í•œ ìê¸°ì‹¤í˜„ì— ê¸°ì—¬")
        elif orientation == "having":
            reasoning_parts.append(f"ì†Œìœ  ì§€í–¥ì  ì„±ê²©ìœ¼ë¡œ ë¬¼ì§ˆì  ë§Œì¡±ì— ì¹˜ì¤‘")
        else:
            reasoning_parts.append(f"ì¡´ì¬ì™€ ì†Œìœ ì˜ í˜¼í•©ì  ì§€í–¥")
        
        if authenticity > 0.7:
            reasoning_parts.append(f"ë†’ì€ ì§„ì •ì„± ({authenticity:.2f})ìœ¼ë¡œ ë‚´ì¬ì  ë§Œì¡± ì¦ì§„")
        elif authenticity < 0.3:
            reasoning_parts.append(f"ë‚®ì€ ì§„ì •ì„± ({authenticity:.2f})ìœ¼ë¡œ í‘œë©´ì  ë§Œì¡±ì— ì œí•œ")
        
        if alienation > 0.5:
            reasoning_parts.append(f"ì†Œì™¸ê° ({alienation:.2f})ìœ¼ë¡œ ì¸í•œ í–‰ë³µ ì €í•´")
        
        if fromm_analysis.creative_potential > 0.6:
            reasoning_parts.append(f"ë†’ì€ ì°½ì¡°ì  ì ì¬ë ¥ìœ¼ë¡œ ìê¸°ì‹¤í˜„ ê°€ëŠ¥ì„± ì¦ëŒ€")
        
        return "; ".join(reasoning_parts)


if __name__ == "__main__":
    test_advanced_bentham_calculator()