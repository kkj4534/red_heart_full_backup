🚀 Red Heart AI 통합 학습 시스템 시작
===========================================
[0;34m[INFO][0m 작업 디렉토리: /mnt/c/large_project/linux_red_heart
[0;34m[INFO][0m Red Heart AI 통합 환경 상태 확인 중...
[0;32m[SUCCESS][0m ✅ red_heart_env 가상환경 존재
[0;32m[SUCCESS][0m ✅ faiss-test conda 환경 존재
[0;32m[SUCCESS][0m ✅ FAISS 설치됨 및 작동 확인
✅ Red Heart AI 통합 환경 활성화 완료
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (함께 활성화됨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;32m[SUCCESS][0m ✅ 주요 패키지 (torch, transformers, numpy) 설치됨
[0;32m[SUCCESS][0m 🎉 모든 환경이 이미 준비되어 있습니다!
✅ Red Heart AI 통합 환경 활성화 완료
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (함께 활성화됨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;32m[SUCCESS][0m ✅ Red Heart AI 통합 환경 활성화 완료
[0;32m[SUCCESS][0m    - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
[0;32m[SUCCESS][0m    - conda: faiss-test 환경 준비됨
[0;32m[SUCCESS][0m    - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
[0;32m[SUCCESS][0m    - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;34m[INFO][0m 🔐 HuggingFace 오프라인 모드 활성화 (캐시된 모델만 사용)
[0;34m[INFO][0m Red Heart AI 통합 학습 시스템 시작
[0;34m[INFO][0m 환경 분리: conda(faiss) + venv(transformers,torch)
[0;34m[INFO][0m Red Heart AI 통합 학습 시스템 실행 시작...
[0;34m[INFO][0m 실행 모드: unified-test
[0;34m[INFO][0m 🧪 730M 최종 통합 시스템 학습 테스트 모드...
[0;34m[INFO][0m    - 60 에폭 학습 테스트 (--samples로 제한 가능)
[0;34m[INFO][0m    - LR 스윕, Sweet Spot, Parameter Crossover 포함
[0;34m[INFO][0m    - Advanced Training Techniques 활성화
[0;34m[INFO][0m 🔍 Hierarchical LR Sweep (5-5-5-5) 실행 모드
[0;34m[INFO][0m    - 25개 포인트로 최적 LR 탐색
[0;34m[INFO][0m    - 각 LR은 독립적으로 초기 가중치에서 시작
2025-08-21 18:15:02,042 - __main__ - INFO - ================================================================================
2025-08-21 18:15:02,042 - __main__ - INFO - 🚀 독립적인 Hierarchical Learning Rate Sweep 시작
2025-08-21 18:15:02,042 - __main__ - INFO - ================================================================================
2025-08-21 18:15:02,127 - __main__ - INFO - Device: cuda
2025-08-21 18:15:02,169 - __main__ - INFO - GPU: NVIDIA GeForce RTX 2070 SUPER
2025-08-21 18:15:02,170 - __main__ - INFO - GPU Memory: 8.6 GB
2025-08-21 18:15:02,170 - __main__ - INFO - 
📊 모델 설정:
2025-08-21 18:15:02,171 - __main__ - INFO -   - d_model: 896
2025-08-21 18:15:02,171 - __main__ - INFO -   - num_heads: 16
2025-08-21 18:15:02,171 - __main__ - INFO -   - num_layers: 6
2025-08-21 18:15:02,172 - __main__ - INFO -   - dropout: 0.1
2025-08-21 18:15:02,172 - __main__ - INFO - 
🔧 모델 생성 중...
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
2025-08-21 18:15:02,695 - unified_backbone - INFO - 백본 총 파라미터: 90,624,132 (90.62M)
2025-08-21 18:15:02,696 - unified_backbone - INFO - 학습 가능 파라미터: 90,624,132 (90.62M)
2025-08-21 18:15:02,903 - unified_heads - INFO - 감정 헤드 파라미터: 17,254,583 (17.25M)
2025-08-21 18:15:03,014 - unified_heads - INFO - 벤담 헤드 파라미터: 13,871,919 (13.87M)
2025-08-21 18:15:03,168 - unified_heads - INFO - 후회 헤드 파라미터: 19,897,161 (19.90M)
2025-08-21 18:15:03,263 - unified_heads - INFO - SURD 헤드 파라미터: 12,025,739 (12.03M)
2025-08-21 18:15:04,192 - analyzer_neural_modules - INFO - NeuralEmotionAnalyzer 초기화: 122,595,407 파라미터
2025-08-21 18:15:04,791 - analyzer_neural_modules - INFO - NeuralBenthamCalculator 초기화: 78,281,602 파라미터
2025-08-21 18:15:05,946 - analyzer_neural_modules - INFO - NeuralRegretAnalyzer 초기화: 153,872,666 파라미터
2025-08-21 18:15:06,051 - analyzer_neural_modules - INFO - NeuralSURDAnalyzer 초기화: 13,473,032 파라미터
2025-08-21 18:15:06,053 - analyzer_neural_modules - INFO - 전체 신경망 분석기 파라미터: 368,222,707 (368.2M)
2025-08-21 18:15:06,936 - emotion_dsp_simulator - INFO - EmotionDSPSimulator 초기화 완료 (~14M 파라미터)
2025-08-21 18:15:07,231 - __main__ - INFO -   - 총 파라미터: 539.9M
2025-08-21 18:15:07,231 - __main__ - INFO -   - 학습 가능 파라미터: 539.9M
2025-08-21 18:15:20,719 - __main__ - INFO -   - 초기 가중치 저장 완료
2025-08-21 18:15:20,719 - __main__ - INFO - 
📁 데이터 로더 생성 중...
2025-08-21 18:15:20,722 - __main__ - INFO - 🎯 임베딩 파일 발견: claude_api_preprocessing/claude_preprocessed_complete.embedded.json
2025-08-21 18:15:20,769 - __main__ - INFO -   - 전체 데이터: 1000개
2025-08-21 18:15:20,770 - __main__ - INFO -   - LR 스윕용 학습 데이터: 900개
2025-08-21 18:15:20,770 - __main__ - INFO -   - LR 스윕용 검증 데이터: 100개
2025-08-21 18:15:20,771 - __main__ - INFO - 📊 임베딩 상태:
2025-08-21 18:15:20,771 - __main__ - INFO -   - 전체 데이터: 900개
2025-08-21 18:15:20,771 - __main__ - INFO -   - 임베딩 있음: 2개 (0.2%)
2025-08-21 18:15:20,772 - __main__ - INFO -   - 임베딩 없음: 898개 (99.8%)
2025-08-21 18:15:20,772 - __main__ - WARNING - ⚠️ 898개 항목에 임베딩이 없습니다. 자동 생성됩니다.
2025-08-21 18:15:20,773 - __main__ - INFO - 📊 임베딩 상태:
2025-08-21 18:15:20,773 - __main__ - INFO -   - 전체 데이터: 100개
2025-08-21 18:15:20,773 - __main__ - INFO -   - 임베딩 있음: 0개 (0.0%)
2025-08-21 18:15:20,774 - __main__ - INFO -   - 임베딩 없음: 100개 (100.0%)
2025-08-21 18:15:20,774 - __main__ - WARNING - ⚠️ 100개 항목에 임베딩이 없습니다. 자동 생성됩니다.
2025-08-21 18:15:20,775 - __main__ - INFO -   - Train batches: 450
2025-08-21 18:15:20,775 - __main__ - INFO -   - Val batches: 50
2025-08-21 18:15:20,775 - __main__ - INFO - 
⚙️ Sweep 설정:
2025-08-21 18:15:20,776 - __main__ - INFO -   - 테스트 에폭: 3
2025-08-21 18:15:20,776 - __main__ - INFO -   - 테스트 스텝/에폭: 50
2025-08-21 18:15:20,777 - __main__ - INFO -   - 예상 총 포인트: 25개 (5-5-5-5 전략)
2025-08-21 18:15:20,777 - __main__ - INFO -   - 각 LR은 독립적으로 초기 가중치에서 시작
2025-08-21 18:15:20,778 - training.hierarchical_lr_sweep - INFO - ======================================================================
2025-08-21 18:15:20,778 - training.hierarchical_lr_sweep - INFO - 🎯 Hierarchical LR Sweep 초기화
2025-08-21 18:15:20,778 - training.hierarchical_lr_sweep - INFO -   - 전략: 5-5-5-5 (총 25개 포인트)
2025-08-21 18:15:20,779 - training.hierarchical_lr_sweep - INFO -   - 테스트 에폭: 3
2025-08-21 18:15:20,779 - training.hierarchical_lr_sweep - INFO -   - 테스트 스텝: 50/epoch
2025-08-21 18:15:20,780 - training.hierarchical_lr_sweep - INFO -   - 기존 테스트 LR: 0개
2025-08-21 18:15:20,780 - training.hierarchical_lr_sweep - INFO - ======================================================================
2025-08-21 18:15:20,780 - __main__ - INFO - 
================================================================================
2025-08-21 18:15:20,781 - __main__ - INFO - 📌 각 LR 테스트는 동일한 초기 가중치에서 독립적으로 시작됩니다
2025-08-21 18:15:20,781 - __main__ - INFO - ================================================================================
2025-08-21 18:15:20,781 - training.hierarchical_lr_sweep - INFO - 
🚀 Hierarchical LR Sweep 시작...
2025-08-21 18:15:20,782 - training.hierarchical_lr_sweep - INFO - 
📊 [Stage 0] 초기 탐색: [1e-05, 5.6e-05, 0.00032, 0.0018, 0.01]
2025-08-21 18:15:20,782 - training.hierarchical_lr_sweep - INFO - 
  📌 LR 1.0e-05 테스트 시작 (Stage 0)
2025-08-21 18:15:21,175 - unified_backbone - INFO - 백본 총 파라미터: 90,624,132 (90.62M)
2025-08-21 18:15:21,176 - unified_backbone - INFO - 학습 가능 파라미터: 90,624,132 (90.62M)
2025-08-21 18:15:21,245 - unified_heads - INFO - 감정 헤드 파라미터: 17,254,583 (17.25M)
2025-08-21 18:15:21,302 - unified_heads - INFO - 벤담 헤드 파라미터: 13,871,919 (13.87M)
2025-08-21 18:15:21,379 - unified_heads - INFO - 후회 헤드 파라미터: 19,897,161 (19.90M)
2025-08-21 18:15:21,427 - unified_heads - INFO - SURD 헤드 파라미터: 12,025,739 (12.03M)
2025-08-21 18:15:22,153 - analyzer_neural_modules - INFO - NeuralEmotionAnalyzer 초기화: 122,595,407 파라미터
2025-08-21 18:15:22,650 - analyzer_neural_modules - INFO - NeuralBenthamCalculator 초기화: 78,281,602 파라미터
2025-08-21 18:15:23,786 - analyzer_neural_modules - INFO - NeuralRegretAnalyzer 초기화: 153,872,666 파라미터
2025-08-21 18:15:23,865 - analyzer_neural_modules - INFO - NeuralSURDAnalyzer 초기화: 13,473,032 파라미터
2025-08-21 18:15:23,866 - analyzer_neural_modules - INFO - 전체 신경망 분석기 파라미터: 368,222,707 (368.2M)
2025-08-21 18:15:24,671 - emotion_dsp_simulator - INFO - EmotionDSPSimulator 초기화 완료 (~14M 파라미터)
2025-08-21 18:15:51,228 - sentence_transformer_singleton - INFO - 새 클라이언트 생성 시작: sentence-transformers/all-MiniLM-L6-v2_cuda
2025-08-21 18:15:51,228 - sentence_transformer_client - INFO - 현재 Python이 venv 환경: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
2025-08-21 18:15:51,229 - sentence_transformer_client - INFO - SentenceTransformer Client 초기화: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-08-21 18:15:51,229 - sentence_transformer_client - INFO - Python 실행파일: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
2025-08-21 18:15:51,229 - sentence_transformer_singleton - INFO - 서버 시작 및 모델 로딩: sentence-transformers/all-MiniLM-L6-v2 (device: cuda)
2025-08-21 18:15:51,230 - sentence_transformer_client - INFO - SentenceTransformer 서버 시작: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-08-21 18:15:51,230 - sentence_transformer_client - INFO - PYTHONPATH: /mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages:/mnt/c/large_project/linux_red_heart
2025-08-21 18:15:51,231 - sentence_transformer_client - INFO - VIRTUAL_ENV: /mnt/c/large_project/linux_red_heart/red_heart_env
2025-08-21 18:16:00,871 - sentence_transformer_client - INFO - 서버 연결 성공
2025-08-21 18:16:00,871 - sentence_transformer_client - INFO - 모델 로딩 요청: sentence-transformers/all-MiniLM-L6-v2 (device: cuda)
2025-08-21 18:17:25,790 - sentence_transformer_client - INFO - 모델 로딩 성공: sentence-transformers/all-MiniLM-L6-v2
2025-08-21 18:17:25,790 - sentence_transformer_singleton - INFO - 클라이언트 생성 및 모델 로딩 성공: sentence-transformers/all-MiniLM-L6-v2_cuda
/mnt/c/large_project/linux_red_heart/unified_heads.py:449: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.smooth_l1_loss(predictions, targets)
2025-08-21 18:17:35,470 - training.hierarchical_lr_sweep - INFO -     Epoch 1: loss=0.0936, grad_norm=3.8165
2025-08-21 18:19:44,253 - sentence_transformer_client - ERROR - 요청 전송 실패: 응답 타임아웃 (120.0초)
2025-08-21 18:19:44,255 - sentence_transformer_client - WARNING - 요청 실패 (시도 1/2): 응답 타임아웃 (120.0초)
2025-08-21 18:19:44,256 - sentence_transformer_client - INFO - 재연결 시도 중...
2025-08-21 18:19:45,261 - sentence_transformer_client - INFO - SentenceTransformer 서버 시작: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-08-21 18:19:45,262 - sentence_transformer_client - INFO - PYTHONPATH: /mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages:/mnt/c/large_project/linux_red_heart
2025-08-21 18:19:45,262 - sentence_transformer_client - INFO - VIRTUAL_ENV: /mnt/c/large_project/linux_red_heart/red_heart_env
2025-08-21 18:19:55,762 - sentence_transformer_client - INFO - 서버 연결 성공
2025-08-21 18:19:55,763 - sentence_transformer_client - ERROR - 텍스트 인코딩 실패: 모델이 로드되지 않음. 먼저 load action을 실행하세요.
2025-08-21 18:19:55,763 - __main__ - ERROR - ❌ 임베딩 생성 실패: 텍스트 인코딩 실패: 모델이 로드되지 않음. 먼저 load action을 실행하세요.
2025-08-21 18:19:55,764 - __main__ - ERROR - ❌ 스윕 실행 중 오류: 임베딩 생성 실패: 텍스트 인코딩 실패: 모델이 로드되지 않음. 먼저 load action을 실행하세요.
2025-08-21 18:19:55,781 - __main__ - ERROR - Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/training/run_hierarchical_lr_sweep.py", line 94, in __getitem__
    embedding = self.embedding_manager.encode(text[:512])
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/sentence_transformer_singleton.py", line 278, in encode
    raise RuntimeError(f"텍스트 인코딩 실패: {error_msg}")
RuntimeError: 텍스트 인코딩 실패: 모델이 로드되지 않음. 먼저 load action을 실행하세요.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/training/run_hierarchical_lr_sweep.py", line 304, in main
    results = sweep.run_hierarchical_sweep(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/training/hierarchical_lr_sweep.py", line 145, in run_hierarchical_sweep
    result = self._test_single_lr(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/training/hierarchical_lr_sweep.py", line 252, in _test_single_lr
    for step, batch in enumerate(train_loader):
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/mnt/c/large_project/linux_red_heart/training/run_hierarchical_lr_sweep.py", line 109, in __getitem__
    raise RuntimeError(f"임베딩 생성 실패: {e}")
RuntimeError: 임베딩 생성 실패: 텍스트 인코딩 실패: 모델이 로드되지 않음. 먼저 load action을 실행하세요.

2025-08-21 18:19:55,781 - __main__ - INFO - 
💾 학습 데이터셋 임베딩 저장 중...
2025-08-21 18:20:10,630 - __main__ - INFO - ✅ 임베딩이 저장되었습니다: claude_api_preprocessing/claude_preprocessed_complete.embedded.json
2025-08-21 18:20:10,630 - __main__ - INFO - 💾 검증 데이터셋 임베딩 저장 중...
2025-08-21 18:20:10,634 - __main__ - INFO - 
🧹 GPU 메모리 정리 완료
2025-08-21 18:20:10,738 - __main__ - INFO -   - 임시 초기 가중치 파일 삭제
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/training/run_hierarchical_lr_sweep.py", line 94, in __getitem__
    embedding = self.embedding_manager.encode(text[:512])
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/sentence_transformer_singleton.py", line 278, in encode
    raise RuntimeError(f"텍스트 인코딩 실패: {error_msg}")
RuntimeError: 텍스트 인코딩 실패: 모델이 로드되지 않음. 먼저 load action을 실행하세요.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/training/run_hierarchical_lr_sweep.py", line 390, in <module>
    results = main()
              ^^^^^^
  File "/mnt/c/large_project/linux_red_heart/training/run_hierarchical_lr_sweep.py", line 304, in main
    results = sweep.run_hierarchical_sweep(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/training/hierarchical_lr_sweep.py", line 145, in run_hierarchical_sweep
    result = self._test_single_lr(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/training/hierarchical_lr_sweep.py", line 252, in _test_single_lr
    for step, batch in enumerate(train_loader):
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/mnt/c/large_project/linux_red_heart/training/run_hierarchical_lr_sweep.py", line 109, in __getitem__
    raise RuntimeError(f"임베딩 생성 실패: {e}")
RuntimeError: 임베딩 생성 실패: 텍스트 인코딩 실패: 모델이 로드되지 않음. 먼저 load action을 실행하세요.
2025-08-21 18:20:11,266 - sentence_transformer_client - INFO - 서버 종료 중...
2025-08-21 18:20:11,593 - sentence_transformer_client - INFO - 서버 정상 종료
[0;34m[INFO][0m 학습 시스템 정리 중...
[0;34m[INFO][0m GPU 메모리 정리...
[0;32m[SUCCESS][0m 정리 완료
