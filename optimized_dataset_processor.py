"""
ê³ í’ˆì§ˆ ë°ì´í„° ìœ ì§€í•˜ë©´ì„œ ìµœì í™”ëœ LLM ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹œìŠ¤í…œ
High-Quality Data Processing with Performance Optimization
"""

import os
import json
import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, field
import re
from datetime import datetime
import uuid
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from llm_module.advanced_llm_engine import get_llm_engine, LLMRequest, TaskComplexity

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('OptimizedDatasetProcessor')

@dataclass
class BenthamFactors:
    """ë²¤ë‹´ ì¾Œë½ ê³„ì‚° 7ê°œ ë³€ìˆ˜"""
    intensity: float = 0.5
    duration: float = 0.5
    certainty: float = 0.5
    propinquity: float = 0.5
    fecundity: float = 0.5
    purity: float = 0.5
    extent: float = 0.5

@dataclass
class EnhancedScenario:
    """ê³ í’ˆì§ˆ ì²˜ë¦¬ëœ ì‹œë‚˜ë¦¬ì˜¤"""
    id: str
    title: str
    description: str
    source_type: str
    
    # ê³ í’ˆì§ˆ ì¶”ì¶œ ë°ì´í„°
    bentham_factors: BenthamFactors
    category: str = "general"
    stakeholders: List[str] = field(default_factory=list)
    ethical_themes: List[str] = field(default_factory=list)
    binary_label: Optional[str] = None
    complexity_score: float = 0.5
    controversy_score: float = 0.5
    
    # ë©”íƒ€ë°ì´í„°
    processing_timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    processing_time: float = 0.0
    quality_score: float = 1.0

class SmartDataParser:
    """ìŠ¤ë§ˆíŠ¸ ë°ì´í„° íŒŒì‹± - íŒŒì‹± ìµœì í™”"""
    
    def __init__(self):
        self.logger = logging.getLogger(f'{__name__}.SmartDataParser')
    
    def parse_ebs_literature_optimized(self, file_path: str, max_scenarios: int = None) -> List[Dict[str, Any]]:
        """EBS ë¬¸í•™ ë°ì´í„° ìµœì í™” íŒŒì‹±"""
        self.logger.info(f"EBS ë¬¸í•™ íŒŒì‹± ì‹œì‘: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        scenarios = []
        current_scenario = {}
        
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ìƒˆ ì‘í’ˆ ì‹œì‘ (ì²« ê¸€ìê°€ í•œê¸€ì´ê³  ê´„í˜¸ í¬í•¨)
            if re.match(r'^[ê°€-í£].+\([^)]+\)$', line):
                if current_scenario and current_scenario.get('description'):
                    scenarios.append(current_scenario)
                    if max_scenarios and len(scenarios) >= max_scenarios:
                        break
                
                current_scenario = {
                    'title': line,
                    'description': '',
                    'stakeholders': [],
                    'raw_text': line + '\n'
                }
            
            elif line.startswith('ìƒí™©ì„¤ëª…:'):
                current_scenario['description'] = line.replace('ìƒí™©ì„¤ëª…:', '').strip()
                current_scenario['raw_text'] += line + '\n'
            
            elif line.startswith('ì´í•´ê´€ê³„ì:'):
                stakeholders_text = line.replace('ì´í•´ê´€ê³„ì:', '').strip()
                current_scenario['stakeholders'] = [
                    s.strip().strip("'\"") for s in stakeholders_text.split(',')
                ]
                current_scenario['raw_text'] += line + '\n'
            
            elif current_scenario:
                current_scenario['raw_text'] += line + '\n'
        
        # ë§ˆì§€ë§‰ ì‹œë‚˜ë¦¬ì˜¤ ì¶”ê°€
        if current_scenario and current_scenario.get('description'):
            scenarios.append(current_scenario)
        
        self.logger.info(f"íŒŒì‹± ì™„ë£Œ: {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤")
        return scenarios

class HighQualityLLMProcessor:
    """ê³ í’ˆì§ˆ LLM ì²˜ë¦¬ - í’ˆì§ˆ ìš°ì„ """
    
    def __init__(self):
        self.llm_engine = None
        self.logger = logging.getLogger(f'{__name__}.HighQualityLLMProcessor')
        
        # í’ˆì§ˆ ê´€ë¦¬ ì„¤ì •
        self.quality_thresholds = {
            'min_response_length': 50,
            'required_json_fields': ['intensity', 'duration', 'certainty'],
            'max_retry_attempts': 2
        }
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìµœì í™”
        self.bentham_prompt_template = """
ë‹¤ìŒì€ ìœ¤ë¦¬ì  ìƒí™©ì…ë‹ˆë‹¤. ë²¤ë‹´ì˜ ì¾Œë½ ê³„ì‚°ë²• 7ê°œ ë³€ìˆ˜ë¥¼ ì •í™•íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.

ìƒí™©: {scenario_text}

ê° ë³€ìˆ˜ë¥¼ 0.0~1.0 ì‚¬ì´ ê°’ìœ¼ë¡œ í‰ê°€:
- intensity: ì¾Œë½/ê³ í†µì˜ ê°•ë„
- duration: ì˜í–¥ì˜ ì§€ì† ì‹œê°„  
- certainty: ê²°ê³¼ì˜ í™•ì‹¤ì„±
- propinquity: ì‹œê°„ì  ê·¼ì ‘ì„±
- fecundity: ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ ë‚³ì„ ê°€ëŠ¥ì„±
- purity: ë°˜ëŒ€ íš¨ê³¼ ì—†ì´ ìˆœìˆ˜í•œ ê²°ê³¼ì¼ ê°€ëŠ¥ì„±
- extent: ì˜í–¥ë°›ëŠ” ì‚¬ëŒì˜ ìˆ˜

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{"intensity": 0.0, "duration": 0.0, "certainty": 0.0, "propinquity": 0.0, "fecundity": 0.0, "purity": 0.0, "extent": 0.0}}
"""
    
    def initialize(self):
        """LLM ì—”ì§„ ì´ˆê¸°í™”"""
        try:
            self.llm_engine = get_llm_engine()
            self.logger.info("ê³ í’ˆì§ˆ LLM ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"LLM ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def extract_bentham_factors_hq(self, scenario_text: str) -> Tuple[BenthamFactors, float]:
        """ê³ í’ˆì§ˆ ë²¤ë‹´ ë³€ìˆ˜ ì¶”ì¶œ"""
        if not self.llm_engine:
            raise RuntimeError("LLM ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ìµœì í™” (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°)
        if len(scenario_text) > 1000:
            scenario_text = scenario_text[:1000] + "..."
        
        prompt = self.bentham_prompt_template.format(scenario_text=scenario_text)
        
        for attempt in range(self.quality_thresholds['max_retry_attempts'] + 1):
            try:
                start_time = time.time()
                
                request = LLMRequest(
                    prompt=prompt,
                    task_type="bentham_analysis",
                    complexity=TaskComplexity.MODERATE
                )
                
                response = self.llm_engine.generate_sync(request)
                processing_time = time.time() - start_time
                
                # í’ˆì§ˆ ê²€ì¦ ë° íŒŒì‹±
                factors, quality_score = self._parse_and_validate_bentham_response(
                    response.generated_text
                )
                
                if quality_score >= 0.8:  # ê³ í’ˆì§ˆ ê¸°ì¤€
                    self.logger.debug(f"ê³ í’ˆì§ˆ ë²¤ë‹´ ì¶”ì¶œ ì™„ë£Œ (í’ˆì§ˆì ìˆ˜: {quality_score:.2f})")
                    return factors, quality_score
                elif attempt < self.quality_thresholds['max_retry_attempts']:
                    self.logger.warning(f"í’ˆì§ˆ ë¯¸ë‹¬ (ì‹œë„ {attempt + 1}), ì¬ì‹œë„...")
                    continue
                else:
                    self.logger.warning(f"ìµœì¢… ì‹œë„ - ë‚®ì€ í’ˆì§ˆë¡œ ì§„í–‰ (í’ˆì§ˆì ìˆ˜: {quality_score:.2f})")
                    return factors, quality_score
                    
            except Exception as e:
                if attempt < self.quality_thresholds['max_retry_attempts']:
                    self.logger.warning(f"ë²¤ë‹´ ì¶”ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}, ì¬ì‹œë„...")
                    continue
                else:
                    self.logger.error(f"ë²¤ë‹´ ì¶”ì¶œ ìµœì¢… ì‹¤íŒ¨: {e}")
                    return BenthamFactors(), 0.0
        
        return BenthamFactors(), 0.0
    
    def _parse_and_validate_bentham_response(self, response_text: str) -> Tuple[BenthamFactors, float]:
        """ë²¤ë‹´ ì‘ë‹µ íŒŒì‹± ë° í’ˆì§ˆ ê²€ì¦"""
        quality_score = 0.0
        
        # ê¸°ë³¸ ì‘ë‹µ ê¸¸ì´ ê²€ì¦
        if len(response_text) < self.quality_thresholds['min_response_length']:
            return BenthamFactors(), 0.1
        
        # JSON ì¶”ì¶œ
        json_match = re.search(r'\{[^}]+\}', response_text)
        if not json_match:
            return BenthamFactors(), 0.2
        
        try:
            factors_dict = json.loads(json_match.group())
            quality_score += 0.3  # JSON íŒŒì‹± ì„±ê³µ
            
            # í•„ìˆ˜ í•„ë“œ ì¡´ì¬ ê²€ì¦
            required_fields = ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent']
            missing_fields = [field for field in required_fields if field not in factors_dict]
            
            if not missing_fields:
                quality_score += 0.3  # ëª¨ë“  í•„ë“œ ì¡´ì¬
            else:
                quality_score += 0.1  # ì¼ë¶€ í•„ë“œë§Œ ì¡´ì¬
            
            # ê°’ ë²”ìœ„ ê²€ì¦ (0.0~1.0)
            valid_values = 0
            for field in required_fields:
                value = factors_dict.get(field, 0.5)
                try:
                    float_value = float(value)
                    if 0.0 <= float_value <= 1.0:
                        valid_values += 1
                except (ValueError, TypeError):
                    pass
            
            quality_score += (valid_values / len(required_fields)) * 0.4  # ê°’ ìœ íš¨ì„±
            
            # BenthamFactors ê°ì²´ ìƒì„±
            factors = BenthamFactors(
                intensity=float(factors_dict.get('intensity', 0.5)),
                duration=float(factors_dict.get('duration', 0.5)),
                certainty=float(factors_dict.get('certainty', 0.5)),
                propinquity=float(factors_dict.get('propinquity', 0.5)),
                fecundity=float(factors_dict.get('fecundity', 0.5)),
                purity=float(factors_dict.get('purity', 0.5)),
                extent=float(factors_dict.get('extent', 0.5))
            )
            
            return factors, quality_score
            
        except json.JSONDecodeError:
            return BenthamFactors(), 0.2

class OptimizedDatasetProcessor:
    """ìµœì í™”ëœ ë°ì´í„°ì…‹ ì²˜ë¦¬ê¸° - í’ˆì§ˆê³¼ ì„±ëŠ¥ì˜ ê· í˜•"""
    
    def __init__(self, output_dir: str = "high_quality_training_data"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.parser = SmartDataParser()
        self.llm_processor = HighQualityLLMProcessor()
        self.logger = logging.getLogger(f'{__name__}.OptimizedDatasetProcessor')
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        self.max_concurrent_llm_calls = 1  # LLMì€ ìˆœì°¨ ì²˜ë¦¬ (ì•ˆì •ì„±)
        self.chunk_size = 10  # ì‘ì€ ì²­í¬ë¡œ ìì£¼ ì €ì¥
        self.enable_parallel_parsing = True  # íŒŒì‹±ì€ ë³‘ë ¬í™”
        
        # í’ˆì§ˆ í†µê³„
        self.quality_stats = {
            'total_processed': 0,
            'high_quality': 0,
            'medium_quality': 0,
            'low_quality': 0,
            'failed': 0,
            'average_quality': 0.0,
            'average_processing_time': 0.0
        }
    
    def initialize(self):
        """ì´ˆê¸°í™”"""
        self.llm_processor.initialize()
        self.logger.info("ìµœì í™”ëœ ë°ì´í„°ì…‹ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_single_scenario(self, raw_scenario: Dict[str, Any], source_type: str, index: int) -> EnhancedScenario:
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ê³ í’ˆì§ˆ ì²˜ë¦¬"""
        start_time = time.time()
        
        try:
            # í…ìŠ¤íŠ¸ ì¤€ë¹„
            main_text = raw_scenario.get('description', '') or raw_scenario.get('raw_text', '')
            if not main_text:
                raise ValueError("ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ê³ í’ˆì§ˆ ë²¤ë‹´ ë³€ìˆ˜ ì¶”ì¶œ
            bentham_factors, quality_score = self.llm_processor.extract_bentham_factors_hq(main_text)
            
            processing_time = time.time() - start_time
            
            # EnhancedScenario ìƒì„±
            scenario = EnhancedScenario(
                id=f"{source_type}_{index}_{uuid.uuid4().hex[:8]}",
                title=raw_scenario.get('title', f'{source_type} ì‹œë‚˜ë¦¬ì˜¤ {index+1}'),
                description=main_text[:2000],  # ê¸¸ì´ ì œí•œ
                source_type=source_type,
                bentham_factors=bentham_factors,
                stakeholders=raw_scenario.get('stakeholders', []),
                processing_time=processing_time,
                quality_score=quality_score
            )
            
            # í’ˆì§ˆ í†µê³„ ì—…ë°ì´íŠ¸
            self._update_quality_stats(quality_score, processing_time)
            
            return scenario
            
        except Exception as e:
            self.logger.error(f"ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨ ({source_type}_{index}): {e}")
            self.quality_stats['failed'] += 1
            
            # ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ ë°˜í™˜
            return EnhancedScenario(
                id=f"{source_type}_{index}_failed",
                title=raw_scenario.get('title', 'Failed Scenario'),
                description=raw_scenario.get('description', '')[:500],
                source_type=source_type,
                bentham_factors=BenthamFactors(),
                quality_score=0.0,
                processing_time=time.time() - start_time
            )
    
    def _update_quality_stats(self, quality_score: float, processing_time: float):
        """í’ˆì§ˆ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.quality_stats['total_processed'] += 1
        
        if quality_score >= 0.8:
            self.quality_stats['high_quality'] += 1
        elif quality_score >= 0.5:
            self.quality_stats['medium_quality'] += 1
        else:
            self.quality_stats['low_quality'] += 1
        
        # í‰ê·  ê³„ì‚°
        total = self.quality_stats['total_processed']
        self.quality_stats['average_quality'] = (
            (self.quality_stats['average_quality'] * (total - 1) + quality_score) / total
        )
        self.quality_stats['average_processing_time'] = (
            (self.quality_stats['average_processing_time'] * (total - 1) + processing_time) / total
        )
    
    def process_ebs_file(self, file_path: str, max_scenarios: int = 20) -> List[EnhancedScenario]:
        """EBS íŒŒì¼ ì²˜ë¦¬ - ì œí•œëœ ê°œìˆ˜ë¡œ ê³ í’ˆì§ˆ ì²˜ë¦¬"""
        self.logger.info(f"EBS íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path} (ìµœëŒ€ {max_scenarios}ê°œ)")
        
        # íŒŒì‹±
        raw_scenarios = self.parser.parse_ebs_literature_optimized(file_path, max_scenarios)
        self.logger.info(f"íŒŒì‹± ì™„ë£Œ: {len(raw_scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤")
        
        processed_scenarios = []
        
        # ìˆœì°¨ ì²˜ë¦¬ (LLM ì•ˆì •ì„± ìœ„í•´)
        for idx, raw_scenario in enumerate(raw_scenarios):
            if idx >= max_scenarios:
                break
                
            try:
                scenario = self.process_single_scenario(raw_scenario, "ebs_literature", idx)
                processed_scenarios.append(scenario)
                
                # ì§„í–‰ìƒí™© ë¡œê¹…
                self.logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {idx + 1}/{len(raw_scenarios)} "
                                f"(í’ˆì§ˆ: {scenario.quality_score:.2f}, "
                                f"ì‹œê°„: {scenario.processing_time:.1f}ì´ˆ)")
                
                # ì²­í¬ ë‹¨ìœ„ ì €ì¥
                if (idx + 1) % self.chunk_size == 0:
                    self._save_chunk(processed_scenarios[-self.chunk_size:], f"ebs_chunk_{idx//self.chunk_size}")
                    
            except Exception as e:
                self.logger.error(f"ì‹œë‚˜ë¦¬ì˜¤ {idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        return processed_scenarios
    
    def _save_chunk(self, scenarios: List[EnhancedScenario], chunk_name: str):
        """ì²­í¬ ì €ì¥"""
        chunk_file = self.output_dir / f"{chunk_name}.json"
        
        scenarios_dict = []
        for scenario in scenarios:
            scenario_dict = {
                'id': scenario.id,
                'title': scenario.title,
                'description': scenario.description,
                'source_type': scenario.source_type,
                'bentham_factors': {
                    'intensity': scenario.bentham_factors.intensity,
                    'duration': scenario.bentham_factors.duration,
                    'certainty': scenario.bentham_factors.certainty,
                    'propinquity': scenario.bentham_factors.propinquity,
                    'fecundity': scenario.bentham_factors.fecundity,
                    'purity': scenario.bentham_factors.purity,
                    'extent': scenario.bentham_factors.extent
                },
                'stakeholders': scenario.stakeholders,
                'quality_score': scenario.quality_score,
                'processing_time': scenario.processing_time,
                'processing_timestamp': scenario.processing_timestamp
            }
            scenarios_dict.append(scenario_dict)
        
        with open(chunk_file, 'w', encoding='utf-8') as f:
            f.write(json.dumps(scenarios_dict, ensure_ascii=False, indent=2))
        
        self.logger.info(f"ì²­í¬ ì €ì¥: {chunk_file} ({len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤)")
    
    def save_final_results(self, all_scenarios: List[EnhancedScenario]):
        """ìµœì¢… ê²°ê³¼ ë° í’ˆì§ˆ í†µê³„ ì €ì¥"""
        # ìµœì¢… ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼
        final_file = self.output_dir / "high_quality_scenarios.json"
        
        scenarios_dict = []
        for scenario in all_scenarios:
            scenario_dict = {
                'id': scenario.id,
                'title': scenario.title,
                'description': scenario.description,
                'source_type': scenario.source_type,
                'bentham_factors': {
                    'intensity': scenario.bentham_factors.intensity,
                    'duration': scenario.bentham_factors.duration,
                    'certainty': scenario.bentham_factors.certainty,
                    'propinquity': scenario.bentham_factors.propinquity,
                    'fecundity': scenario.bentham_factors.fecundity,
                    'purity': scenario.bentham_factors.purity,
                    'extent': scenario.bentham_factors.extent
                },
                'stakeholders': scenario.stakeholders,
                'quality_score': scenario.quality_score,
                'processing_time': scenario.processing_time,
                'processing_timestamp': scenario.processing_timestamp
            }
            scenarios_dict.append(scenario_dict)
        
        final_data = {
            'metadata': {
                'total_scenarios': len(all_scenarios),
                'quality_statistics': self.quality_stats,
                'processing_timestamp': datetime.now().isoformat()
            },
            'scenarios': scenarios_dict
        }
        
        with open(final_file, 'w', encoding='utf-8') as f:
            f.write(json.dumps(final_data, ensure_ascii=False, indent=2))
        
        # í’ˆì§ˆ í†µê³„ íŒŒì¼
        stats_file = self.output_dir / "quality_statistics.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write(json.dumps(self.quality_stats, ensure_ascii=False, indent=2))
        
        self.logger.info(f"ìµœì¢… ê²°ê³¼ ì €ì¥: {final_file}")
        self.logger.info(f"í’ˆì§ˆ í†µê³„ ì €ì¥: {stats_file}")
        
        # í’ˆì§ˆ ë¦¬í¬íŠ¸ ì¶œë ¥
        self._print_quality_report()
    
    def _print_quality_report(self):
        """í’ˆì§ˆ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        stats = self.quality_stats
        total = stats['total_processed']
        
        if total == 0:
            self.logger.warning("ì²˜ë¦¬ëœ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n{'='*60}")
        print(f"ğŸ† ê³ í’ˆì§ˆ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ ë¦¬í¬íŠ¸")
        print(f"{'='*60}")
        print(f"ğŸ“Š ì „ì²´ ì²˜ë¦¬: {total}ê°œ ì‹œë‚˜ë¦¬ì˜¤")
        print(f"âœ¨ ê³ í’ˆì§ˆ (â‰¥0.8): {stats['high_quality']}ê°œ ({stats['high_quality']/total*100:.1f}%)")
        print(f"ğŸ”¶ ì¤‘í’ˆì§ˆ (â‰¥0.5): {stats['medium_quality']}ê°œ ({stats['medium_quality']/total*100:.1f}%)")
        print(f"ğŸ”¸ ì €í’ˆì§ˆ (<0.5): {stats['low_quality']}ê°œ ({stats['low_quality']/total*100:.1f}%)")
        print(f"âŒ ì‹¤íŒ¨: {stats['failed']}ê°œ ({stats['failed']/total*100:.1f}%)")
        print(f"ğŸ“ˆ í‰ê·  í’ˆì§ˆ ì ìˆ˜: {stats['average_quality']:.3f}")
        print(f"â±ï¸ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {stats['average_processing_time']:.2f}ì´ˆ")
        print(f"{'='*60}\n")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    processor = OptimizedDatasetProcessor()
    
    try:
        print("ğŸš€ ê³ í’ˆì§ˆ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘...")
        processor.initialize()
        
        # EBS íŒŒì¼ í•˜ë‚˜ë§Œ ê³ í’ˆì§ˆë¡œ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸)
        scenarios = processor.process_ebs_file(
            'for_learn_dataset/ai_ebs/ebs_1.txt', 
            max_scenarios=10  # í…ŒìŠ¤íŠ¸ìš© 10ê°œë§Œ
        )
        
        processor.save_final_results(scenarios)
        
        print("âœ… ê³ í’ˆì§ˆ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    main()