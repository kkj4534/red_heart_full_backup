"""
Red Heart - ê³ ê¸‰ ìœ¤ë¦¬ì  ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ (Linux ì „ìš©)
Advanced Ethical Decision Support System for Linux

ëª¨ë“  ê³ ê¸‰ AI ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•œ ë©”ì¸ ì‹œìŠ¤í…œ
- ê³ ê¸‰ ê°ì • ë¶„ì„ (Advanced Emotion Analysis)
- ê³ ê¸‰ ë²¤ë‹´ ê³„ì‚°ê¸° (Advanced Bentham Calculator)  
- ê³ ê¸‰ ì˜ë¯¸ ë¶„ì„ (Advanced Semantic Analysis)
- ê³ ê¸‰ SURD ì‹œìŠ¤í…œ (Advanced SURD Analysis)
"""

import os
import sys
import logging
import time
import asyncio
import json
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, field
from pathlib import Path
import argparse

# ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import numpy as np
import torch
from concurrent.futures import ThreadPoolExecutor
import threading

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from config import ADVANCED_CONFIG, DEVICE, MODELS_DIR, LOGS_DIR
from data_models import (
    EmotionData, EthicalSituation, DecisionScenario,
    IntegratedAnalysisResult, SystemStatus
)
from advanced_emotion_analyzer import AdvancedEmotionAnalyzer
from advanced_bentham_calculator import AdvancedBenthamCalculator
from advanced_semantic_analyzer import AdvancedSemanticAnalyzer
from advanced_surd_analyzer import AdvancedSURDAnalyzer
from advanced_experience_database import AdvancedExperienceDatabase

# ìƒˆë¡œ ì¶”ê°€ëœ ê³ ê¸‰ ëª¨ë“ˆë“¤
from advanced_hierarchical_emotion_system import AdvancedHierarchicalEmotionSystem
from advanced_regret_learning_system import AdvancedRegretLearningSystem
from advanced_bayesian_inference_module import AdvancedBayesianInference
from advanced_llm_integration_layer import AdvancedLLMIntegrationLayer
from advanced_counterfactual_reasoning import AdvancedCounterfactualReasoning

# ëª¨ë“ˆ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„° ì„í¬íŠ¸
from module_bridge_coordinator import (
    ModuleBridgeCoordinator, ModuleType, 
    EmotionModuleAdapter, BenthamModuleAdapter,
    SemanticModuleAdapter, SURDModuleAdapter
)

# ë¡œê¹… ê¸°ë³¸ê°’ ì¶”ê°€ í•„í„°
class DefaultFilter(logging.Filter):
    """ë¡œê¹… ë ˆì½”ë“œì— ê¸°ë³¸ê°’ì„ ì¶”ê°€í•˜ëŠ” í•„í„°"""
    def filter(self, record):
        # ê¸°ë³¸ê°’ ì„¤ì •
        if not hasattr(record, 'phase'):
            record.phase = 'GENERAL'
        if not hasattr(record, 'regret'):
            record.regret = 0.0
        if not hasattr(record, 'component'):
            record.component = 'SYSTEM'
        if not hasattr(record, 'metric'):
            record.metric = 'N/A'
        if not hasattr(record, 'value'):
            record.value = 0.0
        return True

# ê³ ê¸‰ ë¡œê¹… ì„¤ì •
def setup_advanced_logging():
    """ê³ ê¸‰ ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì • - í•™ìŠµ ì§„í–‰ ìƒí™© ìƒì„¸ ì¶”ì """
    os.makedirs(LOGS_DIR, exist_ok=True)
    
    # ê¸°ë³¸ê°’ í•„í„°
    default_filter = DefaultFilter()
    
    # ë©”ì¸ ë¡œê·¸ í•¸ë“¤ëŸ¬
    main_formatter = logging.Formatter(
        '%(asctime)s | %(name)-30s | %(levelname)-8s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ë“¤
    handlers = []
    
    # 1. ë©”ì¸ ì‹œìŠ¤í…œ ë¡œê·¸
    main_handler = logging.FileHandler(
        os.path.join(LOGS_DIR, f'red_heart_main_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        encoding='utf-8'
    )
    main_handler.setFormatter(main_formatter)
    main_handler.setLevel(logging.INFO)
    main_handler.addFilter(default_filter)
    handlers.append(main_handler)
    
    # 2. í•™ìŠµ ì „ìš© ë¡œê·¸ (í›„íšŒ, ê°ì • í•™ìŠµ ë“±)
    learning_formatter = logging.Formatter(
        '%(asctime)s | %(levelname)-8s | PHASE:%(phase)s | REGRET:%(regret).3f | %(message)s',
        datefmt='%H:%M:%S'
    )
    learning_handler = logging.FileHandler(
        os.path.join(LOGS_DIR, f'learning_progress_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        encoding='utf-8'
    )
    learning_handler.setFormatter(learning_formatter)
    learning_handler.setLevel(logging.DEBUG)
    learning_handler.addFilter(default_filter)
    handlers.append(learning_handler)
    
    # 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¡œê·¸
    performance_handler = logging.FileHandler(
        os.path.join(LOGS_DIR, f'performance_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        encoding='utf-8'
    )
    performance_handler.setFormatter(logging.Formatter(
        '%(asctime)s | PERF | %(component)s | %(metric)s:%(value).3f | %(message)s'
    ))
    performance_handler.setLevel(logging.INFO)
    performance_handler.addFilter(default_filter)
    handlers.append(performance_handler)
    
    # 4. ì½˜ì†” í•¸ë“¤ëŸ¬ (ê°„ì†Œí™”ëœ ì¶œë ¥)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(message)s',
        datefmt='%H:%M:%S'
    ))
    console_handler.setLevel(logging.INFO)
    console_handler.addFilter(default_filter)
    handlers.append(console_handler)
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # ìƒˆ í•¸ë“¤ëŸ¬ ì¶”ê°€
    for handler in handlers:
        root_logger.addHandler(handler)
    
    return handlers

# í•™ìŠµ ì „ìš© ë¡œê±° ìƒì„± í•¨ìˆ˜ë“¤
def get_learning_logger(name: str):
    """í•™ìŠµ ì „ìš© ë¡œê±° ìƒì„±"""
    logger = logging.getLogger(f'Learning.{name}')
    return logger

def log_regret_progress(phase: str, regret_value: float, message: str, **kwargs):
    """í›„íšŒ í•™ìŠµ ì§„í–‰ ë¡œê¹…"""
    logger = get_learning_logger('Regret')
    extra = {'phase': phase, 'regret': regret_value, **kwargs}
    logger.info(message, extra=extra)

def log_performance_metric(module: str, metric: str, value: float, message: str = ""):
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…"""
    logger = logging.getLogger('Performance')
    extra = {'component': module, 'metric': metric, 'value': value}
    logger.info(message or f"{metric} measurement", extra=extra)

logger = logging.getLogger('RedHeart.Main')


@dataclass
class AnalysisRequest:
    """ë¶„ì„ ìš”ì²­"""
    text: str
    language: str = "ko"
    scenario_type: str = "general"
    include_emotion: bool = True
    include_bentham: bool = True
    include_semantic: bool = True
    include_surd: bool = True
    additional_context: Dict[str, Any] = field(default_factory=dict)


@dataclass 
class IntegratedResult:
    """í†µí•© ë¶„ì„ ê²°ê³¼"""
    request: AnalysisRequest
    emotion_analysis: Optional[Any] = None
    bentham_analysis: Optional[Any] = None
    semantic_analysis: Optional[Any] = None
    surd_analysis: Optional[Any] = None
    integrated_score: float = 0.0
    recommendation: str = ""
    confidence: float = 0.0
    processing_time: float = 0.0
    timestamp: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)


class RedHeartSystem:
    """Red Heart í†µí•© ì‹œìŠ¤í…œ - Module Bridge Coordinator í†µí•©"""
    
    def __init__(self):
        self.logger = logger
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.is_initialized = False
        self.initialization_lock = threading.Lock()
        
        # ê¸°ì¡´ ë¶„ì„ê¸°ë“¤
        self.emotion_analyzer = None
        self.bentham_calculator = None
        self.semantic_analyzer = None
        self.surd_analyzer = None
        
        # ê²½í—˜ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
        self.experience_database = None
        
        # ìƒˆë¡œ ì¶”ê°€ëœ ê³ ê¸‰ ì‹œìŠ¤í…œë“¤
        self.hierarchical_emotion_system = None
        self.regret_learning_system = None
        self.bayesian_inference = None
        self.llm_integration_layer = None
        self.counterfactual_reasoning = None
        
        # â­ í•µì‹¬: ëª¨ë“ˆ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„°
        self.module_coordinator = ModuleBridgeCoordinator()
        self.integrated_training_enabled = False
        
        # ìŠ¤ë ˆë“œ í’€
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        self.result_cache = {}
        self.cache_lock = threading.Lock()
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            'total_requests': 0,
            'successful_analyses': 0,
            'failed_analyses': 0,
            'average_processing_time': 0.0,
            'cache_hits': 0
        }
        
        self.logger.info("Red Heart ì‹œìŠ¤í…œ ìƒì„±ì ì™„ë£Œ - Module Bridge Coordinator í¬í•¨")
        
    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë¹„ë™ê¸°)"""
        with self.initialization_lock:
            if self.is_initialized:
                return
                
            self.logger.info("Red Heart ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
            start_time = time.time()
            
            try:
                # 0. ì˜ì¡´ì„± ì‚¬ì „ ê²€ì¦ (ì—„ê²©í•œ ëª¨ë“œ)
                self.logger.info("ì˜ì¡´ì„± ì‚¬ì „ ê²€ì¦ ì‹œì‘...")
                from dependency_validator import validate_dependencies
                if not validate_dependencies():
                    raise RuntimeError("ì˜ì¡´ì„± ê²€ì¦ ì‹¤íŒ¨ - ì‹œìŠ¤í…œì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.logger.info("âœ… ì˜ì¡´ì„± ì‚¬ì „ ê²€ì¦ ì™„ë£Œ")
                
                # 1. GPU/CUDA í™•ì¸
                self._check_system_requirements()
                
                # 2. ë³‘ë ¬ë¡œ ë¶„ì„ê¸°ë“¤ ì´ˆê¸°í™”
                init_tasks = [
                    self._init_emotion_analyzer(),
                    self._init_bentham_calculator(),
                    self._init_semantic_analyzer(),
                    self._init_surd_analyzer(),
                    self._init_experience_database(),
                    # ìƒˆë¡œ ì¶”ê°€ëœ ê³ ê¸‰ ì‹œìŠ¤í…œë“¤
                    self._init_hierarchical_emotion_system(),
                    self._init_regret_learning_system(),
                    self._init_bayesian_inference(),
                    self._init_llm_integration_layer(),
                    self._init_counterfactual_reasoning()
                ]
                
                # ì´ˆê¸°í™” íƒ€ì„ì•„ì›ƒ ì„¤ì • (60ì´ˆë¡œ ë‹¨ì¶•)
                timeout_seconds = 60
                self.logger.info(f"ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘ (íƒ€ì„ì•„ì›ƒ: {timeout_seconds}ì´ˆ)")
                
                try:
                    results = await asyncio.wait_for(
                        asyncio.gather(*init_tasks, return_exceptions=True),
                        timeout=timeout_seconds
                    )
                except asyncio.TimeoutError:
                    error_msg = f"ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”ê°€ {timeout_seconds}ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                    self.logger.error(error_msg)
                    raise RuntimeError(error_msg)
                
                # 3. ì´ˆê¸°í™” ê²°ê³¼ í™•ì¸
                self._validate_initialization_results(results)
                
                # 4. â­ ëª¨ë“ˆ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„°ì— ëª¨ë“ˆ ë“±ë¡
                await self._register_modules_to_coordinator()
                
                # 5. ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
                await self._run_integration_test()
                
                init_time = time.time() - start_time
                self.is_initialized = True
                
                self.logger.info(f"Red Heart ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ ({init_time:.2f}ì´ˆ)")
                
            except Exception as e:
                self.logger.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                raise
                
    def _check_system_requirements(self):
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
        self.logger.info("ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘...")
        
        # GPU í™•ì¸
        if ADVANCED_CONFIG['enable_gpu']:
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                gpu_name = torch.cuda.get_device_name(0)
                self.logger.info(f"GPU ì‚¬ìš© ê°€ëŠ¥: {gpu_count}ê°œ, ë©”ì¸ GPU: {gpu_name}")
            else:
                self.logger.warning("GPUê°€ ìš”ì²­ë˜ì—ˆì§€ë§Œ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                
        # ë©”ëª¨ë¦¬ í™•ì¸
        if torch.cuda.is_available():
            memory_allocated = torch.cuda.memory_allocated(0) / 1024**3
            memory_cached = torch.cuda.memory_reserved(0) / 1024**3
            self.logger.info(f"GPU ë©”ëª¨ë¦¬: í• ë‹¹ë¨ {memory_allocated:.2f}GB, ìºì‹œë¨ {memory_cached:.2f}GB")
            
        # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
        models_dir = Path(MODELS_DIR)
        if models_dir.exists():
            total_size = sum(f.stat().st_size for f in models_dir.rglob('*') if f.is_file())
            self.logger.info(f"ëª¨ë¸ ë””ë ‰í† ë¦¬ í¬ê¸°: {total_size / 1024**3:.2f}GB")
            
    async def _init_emotion_analyzer(self):
        """ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        try:
            from config import register_system_module
            
            self.logger.info("ê³ ê¸‰ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
            self.emotion_analyzer = AdvancedEmotionAnalyzer()
            
            # ì „ì—­ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
            register_system_module('emotion_analyzer', self.emotion_analyzer, 'emotion')
            
            self.logger.info("ê³ ê¸‰ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
            
    async def _init_bentham_calculator(self):
        """ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™”"""
        try:
            from config import register_system_module
            
            self.logger.info("ê³ ê¸‰ ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì¤‘...")
            self.bentham_calculator = AdvancedBenthamCalculator()
            
            # ì „ì—­ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
            register_system_module('bentham_calculator', self.bentham_calculator, 'bentham')
            
            self.logger.info("ê³ ê¸‰ ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
            
    async def _init_semantic_analyzer(self):
        """ì˜ë¯¸ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        try:
            from config import register_system_module
            
            self.logger.info("ê³ ê¸‰ ì˜ë¯¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
            self.semantic_analyzer = AdvancedSemanticAnalyzer()
            
            # ì „ì—­ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
            register_system_module('semantic_analyzer', self.semantic_analyzer, 'semantic')
            
            self.logger.info("ê³ ê¸‰ ì˜ë¯¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"ì˜ë¯¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
            
    async def _init_surd_analyzer(self):
        """SURD ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        try:
            self.logger.info("ê³ ê¸‰ SURD ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
            self.surd_analyzer = AdvancedSURDAnalyzer()
            self.logger.info("ê³ ê¸‰ SURD ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"SURD ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_experience_database(self):
        """ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
            self.experience_database = AdvancedExperienceDatabase()
            log_performance_metric("ExperienceDB", "initialization", 1.0, "ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            self.logger.info("ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_hierarchical_emotion_system(self):
        """ê³„ì¸µì  ê°ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ê³„ì¸µì  ê°ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            self.hierarchical_emotion_system = AdvancedHierarchicalEmotionSystem()
            log_performance_metric("HierarchicalEmotion", "initialization", 1.0, "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            self.logger.info("ê³„ì¸µì  ê°ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"ê³„ì¸µì  ê°ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_regret_learning_system(self):
        """í›„íšŒ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            from config import register_system_module
            
            self.logger.info("í›„íšŒ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            self.regret_learning_system = AdvancedRegretLearningSystem()
            
            # ì „ì—­ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
            register_system_module('regret_analyzer', self.regret_learning_system, 'regret')
            
            log_regret_progress("INIT", 0.0, "í›„íšŒ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            self.logger.info("í›„íšŒ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"í›„íšŒ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_bayesian_inference(self):
        """ë² ì´ì§€ì•ˆ ì¶”ë¡  ëª¨ë“ˆ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ë² ì´ì§€ì•ˆ ì¶”ë¡  ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")
            self.bayesian_inference = AdvancedBayesianInference()
            log_performance_metric("BayesianInference", "initialization", 1.0, "ì¶”ë¡  ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
            self.logger.info("ë² ì´ì§€ì•ˆ ì¶”ë¡  ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"ë² ì´ì§€ì•ˆ ì¶”ë¡  ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_llm_integration_layer(self):
        """LLM í†µí•© ë ˆì´ì–´ ì´ˆê¸°í™”"""
        try:
            self.logger.info("LLM í†µí•© ë ˆì´ì–´ ì´ˆê¸°í™” ì¤‘...")
            self.llm_integration_layer = AdvancedLLMIntegrationLayer()
            log_performance_metric("LLMIntegration", "initialization", 1.0, "LLM ë ˆì´ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
            self.logger.info("LLM í†µí•© ë ˆì´ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"LLM í†µí•© ë ˆì´ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _init_counterfactual_reasoning(self):
        """ë°˜ì‚¬ì‹¤ì  ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            self.logger.info("ë°˜ì‚¬ì‹¤ì  ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            self.counterfactual_reasoning = AdvancedCounterfactualReasoning()
            log_performance_metric("CounterfactualReasoning", "initialization", 1.0, "ë°˜ì‚¬ì‹¤ì  ì¶”ë¡  ì´ˆê¸°í™” ì™„ë£Œ")
            self.logger.info("ë°˜ì‚¬ì‹¤ì  ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"ë°˜ì‚¬ì‹¤ì  ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def _register_modules_to_coordinator(self):
        """ëª¨ë“ˆ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„°ì— ëª¨ë“ˆë“¤ ë“±ë¡"""
        self.logger.info("ëª¨ë“ˆ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„°ì— ëª¨ë“ˆ ë“±ë¡ ì¤‘...")
        
        registration_count = 0
        
        # ê¸°ë³¸ 4ê°œ ëª¨ë“ˆ ë“±ë¡
        if self.emotion_analyzer:
            self.module_coordinator.register_module(ModuleType.EMOTION, self.emotion_analyzer)
            registration_count += 1
            self.logger.info("ê°ì • ë¶„ì„ê¸° ë“±ë¡ ì™„ë£Œ")
            
        if self.bentham_calculator:
            self.module_coordinator.register_module(ModuleType.BENTHAM, self.bentham_calculator)
            registration_count += 1
            self.logger.info("ë²¤ë‹´ ê³„ì‚°ê¸° ë“±ë¡ ì™„ë£Œ")
            
        if self.semantic_analyzer:
            self.module_coordinator.register_module(ModuleType.SEMANTIC, self.semantic_analyzer)
            registration_count += 1
            self.logger.info("ì˜ë¯¸ ë¶„ì„ê¸° ë“±ë¡ ì™„ë£Œ")
            
        if self.surd_analyzer:
            self.module_coordinator.register_module(ModuleType.SURD, self.surd_analyzer)
            registration_count += 1
            self.logger.info("SURD ë¶„ì„ê¸° ë“±ë¡ ì™„ë£Œ")
            
        # âœ… ëª¨ë“  ì£¼ìš” HeadAdapterë“¤ì´ êµ¬í˜„ ë° ë“±ë¡ ì™„ë£Œ
        # - EmotionEmpathyHeadAdapter (140M)
        # - BenthamFrommHeadAdapter (120M)  
        # - SemanticSURDHeadAdapter (80M)
        # - RegretLearningHeadAdapter (120M)
        # - MetaIntegrationHeadAdapter (40M)
        
        self.logger.info(f"ì´ {registration_count}ê°œ ëª¨ë“ˆì´ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„°ì— ë“±ë¡ë¨")
        
        if registration_count >= 2:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ ëª¨ë“ˆì´ ë“±ë¡ë˜ì–´ì•¼ í†µí•© í•™ìŠµ ì˜ë¯¸ê°€ ìˆìŒ
            self.integrated_training_enabled = True
            self.logger.info("í†µí•© í•™ìŠµ ëª¨ë“œ ì¤€ë¹„ ì™„ë£Œ")
        else:
            self.logger.warning("í†µí•© í•™ìŠµì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œ ì´ìƒì˜ ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤")
            
    def _validate_initialization_results(self, results: List[Union[bool, Exception]]):
        """ì´ˆê¸°í™” ê²°ê³¼ ê²€ì¦"""
        component_names = [
            "ê°ì • ë¶„ì„ê¸°", "ë²¤ë‹´ ê³„ì‚°ê¸°", "ì˜ë¯¸ ë¶„ì„ê¸°", "SURD ë¶„ì„ê¸°", "ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤",
            "ê³„ì¸µì  ê°ì • ì‹œìŠ¤í…œ", "í›„íšŒ í•™ìŠµ ì‹œìŠ¤í…œ", "ë² ì´ì§€ì•ˆ ì¶”ë¡ ", "LLM í†µí•© ë ˆì´ì–´", "ë°˜ì‚¬ì‹¤ì  ì¶”ë¡ "
        ]
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.error(f"{component_names[i]} ì´ˆê¸°í™” ì¤‘ ì˜ˆì™¸ ë°œìƒ: {result}")
            elif result is False:
                self.logger.error(f"{component_names[i]} ì´ˆê¸°í™” ì‹¤íŒ¨")
            else:
                self.logger.info(f"{component_names[i]} ì´ˆê¸°í™” ì„±ê³µ")
                
        # ì—„ê²©í•œ ì´ˆê¸°í™” ëª¨ë“œ: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì„±ê³µí•´ì•¼ í•¨
        successful_components = sum(1 for r in results if r is True)
        failed_components = len(results) - successful_components
        
        if failed_components > 0:
            failed_names = [component_names[i] for i, r in enumerate(results) if r is not True]
            error_msg = f"ì´ˆê¸°í™” ì‹¤íŒ¨ ì»´í¬ë„ŒíŠ¸ ({failed_components}ê°œ): {', '.join(failed_names)}"
            self.logger.error(error_msg)
            self.logger.error("ì—„ê²©í•œ ëª¨ë“œ: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒ ì´ˆê¸°í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            raise RuntimeError(f"ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨ - {error_msg}")
        
        self.logger.info(f"âœ… ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì„±ê³µ ({successful_components}/{len(results)})")
        self.logger.info("ì‹œìŠ¤í…œì´ ì™„ì „í•œ ê¸°ëŠ¥ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
    async def _run_integration_test(self):
        """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("í†µí•© í…ŒìŠ¤íŠ¸ ì„ì‹œ ë¹„í™œì„±í™”ë¨ - ì´ˆê¸°í™”ë§Œ í…ŒìŠ¤íŠ¸")
        return  # í†µí•© í…ŒìŠ¤íŠ¸ ì„ì‹œ ë¹„í™œì„±í™”
        
        test_request = AnalysisRequest(
            text="ì´ê²ƒì€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ë¬¸ì¥ì…ë‹ˆë‹¤.",
            language="ko",
            scenario_type="test"
        )
        
        try:
            result = await self.analyze_async(test_request)
            if result:
                self.logger.info("í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            else:
                self.logger.warning("í†µí•© í…ŒìŠ¤íŠ¸ì—ì„œ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤.")
        except Exception as e:
            self.logger.error(f"í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            # í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ëŠ” ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë¥¼ ë§‰ì§€ ì•ŠìŒ
    
    async def analyze_with_bridge_coordinator(self, request: AnalysisRequest) -> Dict[str, Any]:
        """â­ ìƒˆë¡œìš´ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„°ë¥¼ í†µí•œ í†µí•© ë¶„ì„"""
        if not self.is_initialized:
            await self.initialize()
            
        if not self.integrated_training_enabled:
            self.logger.warning("í†µí•© í•™ìŠµì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ë°©ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return await self.analyze_async(request)
            
        start_time = time.time()
        self.performance_stats['total_requests'] += 1
        
        try:
            # í™œì„±í™”ëœ ëª¨ë“ˆ ê²°ì •
            enabled_modules = []
            if request.include_emotion and ModuleType.EMOTION in self.module_coordinator.adapters:
                enabled_modules.append(ModuleType.EMOTION)
            if request.include_bentham and ModuleType.BENTHAM in self.module_coordinator.adapters:
                enabled_modules.append(ModuleType.BENTHAM)
            if request.include_semantic and ModuleType.SEMANTIC in self.module_coordinator.adapters:
                enabled_modules.append(ModuleType.SEMANTIC)
            if request.include_surd and ModuleType.SURD in self.module_coordinator.adapters:
                enabled_modules.append(ModuleType.SURD)
                
            if not enabled_modules:
                raise ValueError("í™œì„±í™”ëœ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤")
                
            # ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„°ë¥¼ í†µí•œ í†µí•© ë¶„ì„ ì‹¤í–‰
            bridge_results = await self.module_coordinator.integrated_analysis(
                input_text=request.text,
                enable_modules=enabled_modules
            )
            
            processing_time = time.time() - start_time
            
            # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            self.performance_stats['successful_analyses'] += 1
            alpha = 0.1
            self.performance_stats['average_processing_time'] = (
                alpha * processing_time + 
                (1 - alpha) * self.performance_stats['average_processing_time']
            )
            
            # ê²°ê³¼ ì •ë¦¬ ë° ì„¤ëª… ê°€ëŠ¥ì„± ì •ë³´ ì¶”ê°€
            integrated_result = {
                'request': request,
                'bridge_results': bridge_results,
                'processing_time': processing_time,
                'timestamp': time.time(),
                'enabled_modules': [m.value for m in enabled_modules],
                'xai_explanation': self._generate_xai_explanation(bridge_results),
                'performance_report': self.module_coordinator.get_performance_report(),
                'integration_quality': self._assess_integration_quality(bridge_results)
            }
            
            self.logger.info(f"ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„° ë¶„ì„ ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
            return integrated_result
            
        except Exception as e:
            self.performance_stats['failed_analyses'] += 1
            self.logger.error(f"ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            raise
    
    def _generate_xai_explanation(self, bridge_results: Dict[str, Any]) -> Dict[str, Any]:
        """XAI ì„¤ëª… ìƒì„±"""
        explanation = {
            'module_contributions': {},
            'decision_factors': {},
            'confidence_breakdown': {},
            'processing_flow': []
        }
        
        for module_name, result in bridge_results.items():
            if result:
                explanation['module_contributions'][module_name] = {
                    'confidence': getattr(result, 'confidence', 0.0),
                    'processing_time': getattr(result, 'processing_time', 0.0),
                    'explanation': getattr(result, 'explanation', {})
                }
                
                explanation['processing_flow'].append({
                    'module': module_name,
                    'status': 'success',
                    'time': getattr(result, 'processing_time', 0.0)
                })
            else:
                explanation['processing_flow'].append({
                    'module': module_name,
                    'status': 'failed',
                    'time': 0.0
                })
                
        return explanation
    
    def _assess_integration_quality(self, bridge_results: Dict[str, Any]) -> Dict[str, Any]:
        """í†µí•© í’ˆì§ˆ í‰ê°€"""
        successful_modules = sum(1 for result in bridge_results.values() if result is not None)
        total_modules = len(bridge_results)
        
        avg_confidence = 0.0
        if successful_modules > 0:
            confidences = [
                getattr(result, 'confidence', 0.0) 
                for result in bridge_results.values() 
                if result is not None
            ]
            avg_confidence = np.mean(confidences) if confidences else 0.0
            
        return {
            'success_rate': successful_modules / max(total_modules, 1),
            'average_confidence': avg_confidence,
            'module_harmony': self._calculate_module_harmony(bridge_results),
            'recommendation': 'excellent' if avg_confidence > 0.8 else 'good' if avg_confidence > 0.6 else 'needs_improvement'
        }
    
    def _calculate_module_harmony(self, bridge_results: Dict[str, Any]) -> float:
        """ëª¨ë“ˆ ê°„ ì¡°í™”ë„ ê³„ì‚°"""
        # ê°„ë‹¨í•œ ì¡°í™”ë„ ê³„ì‚° - ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê³„ì‚° í•„ìš”
        confidences = [
            getattr(result, 'confidence', 0.0) 
            for result in bridge_results.values() 
            if result is not None
        ]
        
        if len(confidences) < 2:
            return 1.0
            
        # ì‹ ë¢°ë„ì˜ í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ëª¨ë“ˆë“¤ì´ ì¡°í™”ë¡­ê²Œ ì‘ë™
        std_dev = np.std(confidences)
        harmony = max(0.0, 1.0 - std_dev)
        return harmony
            
    async def analyze_async(self, request: AnalysisRequest) -> IntegratedResult:
        """ë¹„ë™ê¸° ë¶„ì„ ì‹¤í–‰"""
        if not self.is_initialized:
            await self.initialize()
            
        start_time = time.time()
        self.performance_stats['total_requests'] += 1
        
        # ìºì‹œ í™•ì¸
        cache_key = self._generate_cache_key(request)
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            self.performance_stats['cache_hits'] += 1
            self.logger.debug("ìºì‹œëœ ê²°ê³¼ ë°˜í™˜")
            return cached_result
            
        try:
            # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
            analysis_tasks = []
            
            if request.include_emotion and self.emotion_analyzer:
                analysis_tasks.append(self._analyze_emotion_async(request))
            if request.include_bentham and self.bentham_calculator:
                analysis_tasks.append(self._analyze_bentham_async(request))
            if request.include_semantic and self.semantic_analyzer:
                analysis_tasks.append(self._analyze_semantic_async(request))
            if request.include_surd and self.surd_analyzer:
                analysis_tasks.append(self._analyze_surd_async(request))
                
            # ëª¨ë“  ë¶„ì„ ì™„ë£Œ ëŒ€ê¸°
            analysis_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            
            # ê²°ê³¼ í†µí•©
            integrated_result = self._integrate_results(request, analysis_results, start_time)
            
            # ìºì‹œ ì €ì¥
            self._cache_result(cache_key, integrated_result)
            
            self.performance_stats['successful_analyses'] += 1
            self._update_performance_stats(time.time() - start_time)
            
            return integrated_result
            
        except Exception as e:
            self.logger.error(f"ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            self.performance_stats['failed_analyses'] += 1
            
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return IntegratedResult(
                request=request,
                recommendation="ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                confidence=0.0,
                processing_time=time.time() - start_time,
                timestamp=time.time(),
                metadata={'error': str(e)}
            )
            
    async def _analyze_emotion_async(self, request: AnalysisRequest):
        """ë¹„ë™ê¸° ê°ì • ë¶„ì„"""
        try:
            result = self.emotion_analyzer.analyze_text_advanced(
                text=request.text,
                language=request.language,
                context=request.additional_context
            )
            return ('emotion', result)
        except Exception as e:
            self.logger.error(f"ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            return ('emotion', None)
            
    async def _analyze_bentham_async(self, request: AnalysisRequest):
        """ë¹„ë™ê¸° ë²¤ë‹´ ë¶„ì„ - ê²½í—˜ ë©”ëª¨ë¦¬ í†µí•©"""
        try:
            # ê°ì • ë°ì´í„° ì¤€ë¹„
            emotion_data = self._extract_emotion_data_from_text(request.text)
            
            # ë²¤ë‹´ ê³„ì‚° ë°ì´í„° ì¤€ë¹„
            bentham_data = {
                'input_values': {
                    'intensity': 0.7,
                    'duration': 0.6,
                    'certainty': 0.8,
                    'propinquity': 0.9,
                    'fecundity': 0.5,
                    'purity': 0.7,
                    'extent': 0.8
                },
                'emotion_data': emotion_data,
                'text_description': request.text,
                'language': request.language,
                **request.additional_context
            }
            
            # â­ ê²½í—˜ ë©”ëª¨ë¦¬ í†µí•© ë²¤ë‹´ ê³„ì‚° ì‚¬ìš©
            if self.experience_database:
                result = await self.bentham_calculator.calculate_with_experience_integration(
                    bentham_data, self.experience_database
                )
            else:
                # fallback to regular calculation
                result = self.bentham_calculator.calculate_with_advanced_layers(bentham_data)
                
            return ('bentham', result)
        except Exception as e:
            self.logger.error(f"ë²¤ë‹´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return ('bentham', None)
            
    async def _analyze_semantic_async(self, request: AnalysisRequest):
        """ë¹„ë™ê¸° ì˜ë¯¸ ë¶„ì„"""
        try:
            result = self.semantic_analyzer.analyze_text_advanced(
                text=request.text,
                language=request.language,
                analysis_depth="full"
            )
            return ('semantic', result)
        except Exception as e:
            self.logger.error(f"ì˜ë¯¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return ('semantic', None)
            
    async def _analyze_surd_async(self, request: AnalysisRequest):
        """ë¹„ë™ê¸° SURD ë¶„ì„"""
        try:
            # SURD ë¶„ì„ì„ ìœ„í•œ ë³€ìˆ˜ ì¤€ë¹„
            variables = self._extract_variables_from_text(request.text, request.additional_context)
            
            result = self.surd_analyzer.analyze_advanced(
                variables=variables,
                target_variable='decision_outcome',
                additional_context=request.additional_context
            )
            return ('surd', result)
        except Exception as e:
            self.logger.error(f"SURD ë¶„ì„ ì‹¤íŒ¨: {e}")
            return ('surd', None)
            
    def _extract_emotion_data_from_text(self, text: str) -> EmotionData:
        """í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ë°ì´í„° ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ ê°ì • ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¶„ì„ í•„ìš”)
        return EmotionData(
            valence=0.1,  # ê°ì •ì˜ ê¸ì •/ë¶€ì •ì„±
            arousal=0.5,  # ê°ì •ì˜ í™œì„±í™” ì •ë„
            dominance=0.6,  # ê°ì •ì˜ í†µì œê°
            confidence=0.7
        )
        
    def _extract_variables_from_text(self, text: str, context: Dict[str, Any]) -> Dict[str, float]:
        """í…ìŠ¤íŠ¸ì™€ ì»¨í…ìŠ¤íŠ¸ì—ì„œ SURD ë³€ìˆ˜ ì¶”ì¶œ"""
        # ê¸°ë³¸ ë³€ìˆ˜ë“¤
        variables = {
            'emotion_intensity': 0.7,
            'ethical_weight': 0.8,
            'social_impact': 0.6,
            'time_pressure': 0.4,
            'uncertainty': 0.5,
            'decision_outcome': 0.65
        }
        
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì¶”ê°€ ë³€ìˆ˜ ì¶”ì¶œ
        if context:
            for key, value in context.items():
                if isinstance(value, (int, float)) and 0 <= value <= 1:
                    variables[key] = float(value)
                    
        return variables
        
    def _integrate_results(self, request: AnalysisRequest, analysis_results: List, start_time: float) -> IntegratedResult:
        """ë¶„ì„ ê²°ê³¼ë“¤ì„ í†µí•©"""
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        results = {}
        for result in analysis_results:
            if isinstance(result, tuple) and len(result) == 2:
                analysis_type, analysis_result = result
                results[analysis_type] = analysis_result
            elif isinstance(result, Exception):
                self.logger.error(f"ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {result}")
                
        # í†µí•© ì ìˆ˜ ê³„ì‚°
        integrated_score = self._calculate_integrated_score(results)
        
        # ì¶”ì²œ ìƒì„±
        recommendation = self._generate_recommendation(results, integrated_score)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_overall_confidence(results)
        
        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            'analyzed_components': list(results.keys()),
            'system_version': '2.0.0-linux',
            'gpu_used': ADVANCED_CONFIG['enable_gpu'] and torch.cuda.is_available(),
            'language': request.language,
            'scenario_type': request.scenario_type
        }
        
        return IntegratedResult(
            request=request,
            emotion_analysis=results.get('emotion'),
            bentham_analysis=results.get('bentham'),
            semantic_analysis=results.get('semantic'),
            surd_analysis=results.get('surd'),
            integrated_score=integrated_score,
            recommendation=recommendation,
            confidence=confidence,
            processing_time=time.time() - start_time,
            timestamp=time.time(),
            metadata=metadata
        )
        
    def _calculate_integrated_score(self, results: Dict[str, Any]) -> float:
        """í†µí•© ì ìˆ˜ ê³„ì‚°"""
        scores = []
        weights = {
            'emotion': 0.25,
            'bentham': 0.35,
            'semantic': 0.20,
            'surd': 0.20
        }
        
        total_weight = 0.0
        weighted_sum = 0.0
        
        for component, weight in weights.items():
            if component in results and results[component]:
                score = self._extract_score_from_result(component, results[component])
                if score is not None:
                    weighted_sum += score * weight
                    total_weight += weight
                    
        if total_weight > 0:
            return weighted_sum / total_weight
        else:
            return 0.5  # ê¸°ë³¸ê°’
            
    def _extract_score_from_result(self, component: str, result: Any) -> Optional[float]:
        """ì»´í¬ë„ŒíŠ¸ë³„ ê²°ê³¼ì—ì„œ ì ìˆ˜ ì¶”ì¶œ"""
        try:
            if component == 'emotion':
                if hasattr(result, 'overall_emotion_score'):
                    return result.overall_emotion_score
                elif hasattr(result, 'confidence_score'):
                    return result.confidence_score
                    
            elif component == 'bentham':
                if hasattr(result, 'final_score'):
                    return abs(result.final_score)  # ì ˆëŒ“ê°’ ì‚¬ìš©
                    
            elif component == 'semantic':
                if hasattr(result, 'confidence_score'):
                    return result.confidence_score
                    
            elif component == 'surd':
                if hasattr(result, 'confidence_score'):
                    return getattr(result, 'confidence_score', 0.5)
                elif hasattr(result, 'information_decomposition'):
                    # SURD ê²°ê³¼ì—ì„œ ì „ì²´ ì •ë³´ëŸ‰ ê¸°ë°˜ ì ìˆ˜
                    decomp = result.information_decomposition
                    if decomp and 'all_variables' in decomp:
                        total_info = decomp['all_variables'].total_information
                        return min(total_info, 1.0)
                        
        except Exception as e:
            self.logger.error(f"{component} ì ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
        return None
        
    def _generate_recommendation(self, results: Dict[str, Any], integrated_score: float) -> str:
        """í†µí•© ì¶”ì²œ ìƒì„±"""
        recommendations = []
        
        # ê°ì • ë¶„ì„ ê¸°ë°˜ ì¶”ì²œ
        if 'emotion' in results and results['emotion']:
            emotion_result = results['emotion']
            if hasattr(emotion_result, 'dominant_emotion'):
                recommendations.append(f"ì£¼ìš” ê°ì • '{emotion_result.dominant_emotion}'ì„ ê³ ë ¤í•˜ì—¬")
                
        # ë²¤ë‹´ ë¶„ì„ ê¸°ë°˜ ì¶”ì²œ
        if 'bentham' in results and results['bentham']:
            bentham_result = results['bentham']
            if hasattr(bentham_result, 'final_score'):
                if bentham_result.final_score > 0.6:
                    recommendations.append("ë†’ì€ ì¾Œë½ ì ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸ì •ì  ê²°ì •ì„")
                elif bentham_result.final_score < 0.4:
                    recommendations.append("ë‚®ì€ ì¾Œë½ ì ìˆ˜ë¥¼ ê³ ë ¤í•˜ì—¬ ì‹ ì¤‘í•œ ê²€í† ë¥¼")
                    
        # ì˜ë¯¸ ë¶„ì„ ê¸°ë°˜ ì¶”ì²œ
        if 'semantic' in results and results['semantic']:
            semantic_result = results['semantic']
            if hasattr(semantic_result, 'ethical_analysis'):
                ethical = semantic_result.ethical_analysis
                if ethical and 'ethical_categories' in ethical:
                    recommendations.append("ìœ¤ë¦¬ì  ê°€ì¹˜ë¥¼ ìš°ì„  ê³ ë ¤í•˜ì—¬")
                    
        # SURD ë¶„ì„ ê¸°ë°˜ ì¶”ì²œ
        if 'surd' in results and results['surd']:
            surd_result = results['surd']
            if hasattr(surd_result, 'information_decomposition'):
                recommendations.append("ì¸ê³¼ê´€ê³„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ")
                
        # í†µí•© ì ìˆ˜ ê¸°ë°˜ ìµœì¢… ì¶”ì²œ
        if integrated_score > 0.7:
            action = "ì ê·¹ì ìœ¼ë¡œ ì¶”ì§„í•˜ëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤."
        elif integrated_score > 0.5:
            action = "ì‹ ì¤‘í•˜ê²Œ ê³ ë ¤í•´ ë³¼ ë§Œí•©ë‹ˆë‹¤."
        else:
            action = "ì¬ê²€í† ê°€ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤."
            
        if recommendations:
            return " ".join(recommendations) + " " + action
        else:
            return f"ì „ì²´ ë¶„ì„ ì ìˆ˜({integrated_score:.2f})ë¥¼ ë°”íƒ•ìœ¼ë¡œ " + action
            
    def _calculate_overall_confidence(self, results: Dict[str, Any]) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidences = []
        
        for component, result in results.items():
            if result and hasattr(result, 'confidence_score'):
                confidences.append(result.confidence_score)
            elif result:
                confidences.append(0.7)  # ê¸°ë³¸ ì‹ ë¢°ë„
                
        if confidences:
            return float(np.mean(confidences))
        else:
            return 0.5
            
    def _generate_cache_key(self, request: AnalysisRequest) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        import hashlib
        
        key_data = f"{request.text}_{request.language}_{request.scenario_type}"
        key_data += f"_{request.include_emotion}_{request.include_bentham}"
        key_data += f"_{request.include_semantic}_{request.include_surd}"
        
        return hashlib.md5(key_data.encode()).hexdigest()
        
    def _get_cached_result(self, cache_key: str) -> Optional[IntegratedResult]:
        """ìºì‹œëœ ê²°ê³¼ ì¡°íšŒ"""
        with self.cache_lock:
            return self.result_cache.get(cache_key)
            
    def _cache_result(self, cache_key: str, result: IntegratedResult):
        """ê²°ê³¼ ìºì‹±"""
        with self.cache_lock:
            if len(self.result_cache) >= 100:  # ìºì‹œ í¬ê¸° ì œí•œ
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                oldest_key = next(iter(self.result_cache))
                del self.result_cache[oldest_key]
                
            self.result_cache[cache_key] = result
            
    def _update_performance_stats(self, processing_time: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        total_requests = self.performance_stats['total_requests']
        current_avg = self.performance_stats['average_processing_time']
        
        # ì´ë™ í‰ê·  ê³„ì‚°
        new_avg = ((current_avg * (total_requests - 1)) + processing_time) / total_requests
        self.performance_stats['average_processing_time'] = new_avg
        
    async def run_production_loop(self):
        """ìš´ìš© ëª¨ë“œ ë©”ì¸ ë£¨í”„ - ì—°ì† ì²˜ë¦¬"""
        self.logger.info("ìš´ìš© ëª¨ë“œ ì‹œì‘ - ì…ë ¥ ëŒ€ê¸° ì¤‘...")
        
        try:
            while True:
                # í‘œì¤€ ì…ë ¥ì—ì„œ í…ìŠ¤íŠ¸ ì½ê¸°
                print("\ní…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: 'quit' ë˜ëŠ” Ctrl+C):")
                text = input("> ")
                
                if text.lower() in ['quit', 'exit', 'q']:
                    print("ìš´ìš© ëª¨ë“œ ì¢…ë£Œ")
                    break
                
                if not text.strip():
                    continue
                
                # ë¶„ì„ ìš”ì²­ ìƒì„±
                request = AnalysisRequest(
                    text=text,
                    include_emotion=True,
                    include_bentham=True,
                    include_semantic=True,
                    include_surd=True,
                    enable_all_modules=True
                )
                
                # ë¶„ì„ ì‹¤í–‰
                result = await self.analyze_async(request)
                
                # ê²°ê³¼ ì¶œë ¥
                print("\n" + "=" * 60)
                print("ğŸ“Š ë¶„ì„ ê²°ê³¼:")
                print_analysis_result(result)
                print("=" * 60)
                
        except KeyboardInterrupt:
            print("\n\nìš´ìš© ëª¨ë“œ ì¤‘ë‹¨ë¨")
        except Exception as e:
            self.logger.error(f"ìš´ìš© ë£¨í”„ ì˜¤ë¥˜: {e}")
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    async def run_advanced_analysis(self, text: str):
        """ê³ ê¸‰ ë¶„ì„ ëª¨ë“œ - ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™”"""
        self.logger.info("ê³ ê¸‰ ë¶„ì„ ëª¨ë“œ ì‹œì‘")
        
        # ëª¨ë“  ê³ ê¸‰ ëª¨ë“ˆ í™œì„±í™”
        if hasattr(self, 'enable_advanced_features'):
            self.enable_advanced_features = True
        
        # ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„° ë¶„ì„
        if self.module_coordinator:
            print("\nğŸ”— Module Bridge Coordinator ë¶„ì„ ì¤‘...")
            request = AnalysisRequest(
                text=text,
                include_emotion=True,
                include_bentham=True,
                include_semantic=True,
                include_surd=True,
                include_bridge_analysis=True
            )
            
            bridge_result = await self.analyze_with_bridge_coordinator(request)
            
            # XAI ì„¤ëª… ì¶œë ¥
            if 'xai_explanation' in bridge_result:
                print("\nğŸ” XAI ì„¤ëª…:")
                for key, value in bridge_result['xai_explanation'].items():
                    print(f"   {key}: {value}")
            
            # í†µí•© í’ˆì§ˆ í‰ê°€ ì¶œë ¥
            if 'integration_quality' in bridge_result:
                quality = bridge_result['integration_quality']
                print(f"\nâœ¨ í†µí•© í’ˆì§ˆ: {quality.get('status', 'N/A')}")
                print(f"   ì „ì²´ ì¡°í™”ë„: {quality.get('overall_harmony', 0):.2f}")
        
        # ê³„ì¸µì  ê°ì • ë¶„ì„
        if self.hierarchical_emotion_system:
            print("\nğŸ­ ê³„ì¸µì  ê°ì • ë¶„ì„ ì¤‘...")
            emotion_result = await self.hierarchical_emotion_system.process_literary_emotion_sequence(
                [{'text': text, 'context': 'advanced_analysis'}]
            )
            print(f"   ê°ì • ë°œë‹¬ ê¶¤ì : {emotion_result.get('emotion_trajectory', [])}")
        
        # ë² ì´ì§€ì•ˆ ì¶”ë¡ 
        if self.bayesian_inference:
            print("\nğŸ§  ë² ì´ì§€ì•ˆ ì¶”ë¡  ì¤‘...")
            # ë² ì´ì§€ì•ˆ ë¶„ì„ ì‹¤í–‰
        
        # ë°˜ì‚¬ì‹¤ì  ì¶”ë¡ 
        if self.counterfactual_reasoning:
            print("\nğŸ”® ë°˜ì‚¬ì‹¤ì  ì¶”ë¡  ì¤‘...")
            # ë°˜ì‚¬ì‹¤ì  ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        
        print("\nê³ ê¸‰ ë¶„ì„ ì™„ë£Œ!")
    
    async def run_system_test(self):
        """ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ëª¨ë“œ"""
        self.logger.info("ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        test_results = {
            'modules': {},
            'integration': {},
            'performance': {}
        }
        
        # 1. ëª¨ë“ˆë³„ í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        test_text = "ìœ¤ë¦¬ì  ë”œë ˆë§ˆì— ì§ë©´í•œ ìƒí™©ì—ì„œ ì˜¬ë°”ë¥¸ ì„ íƒì€ ë¬´ì—‡ì¼ê¹Œ?"
        
        # ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸
        if self.emotion_analyzer:
            try:
                emotion_result = self.emotion_analyzer.analyze_text_advanced(test_text)
                test_results['modules']['emotion'] = 'PASS'
                print("   âœ… ê°ì • ë¶„ì„ ëª¨ë“ˆ: ì •ìƒ")
            except Exception as e:
                test_results['modules']['emotion'] = f'FAIL: {e}'
                print(f"   âŒ ê°ì • ë¶„ì„ ëª¨ë“ˆ: ì‹¤íŒ¨ - {e}")
        
        # ë²¤ë‹´ ê³„ì‚°ê¸° í…ŒìŠ¤íŠ¸
        if self.bentham_calculator:
            try:
                bentham_data = {'text_description': test_text}
                bentham_result = await self.bentham_calculator.calculate_hedonic_value(bentham_data)
                test_results['modules']['bentham'] = 'PASS'
                print("   âœ… ë²¤ë‹´ ê³„ì‚°ê¸°: ì •ìƒ")
            except Exception as e:
                test_results['modules']['bentham'] = f'FAIL: {e}'
                print(f"   âŒ ë²¤ë‹´ ê³„ì‚°ê¸°: ì‹¤íŒ¨ - {e}")
        
        # 2. í†µí•© í…ŒìŠ¤íŠ¸
        print("\nğŸ”— í†µí•© í…ŒìŠ¤íŠ¸ ì¤‘...")
        try:
            request = AnalysisRequest(text=test_text)
            result = await self.analyze_async(request)
            test_results['integration']['basic'] = 'PASS'
            print("   âœ… ê¸°ë³¸ í†µí•©: ì •ìƒ")
        except Exception as e:
            test_results['integration']['basic'] = f'FAIL: {e}'
            print(f"   âŒ ê¸°ë³¸ í†µí•©: ì‹¤íŒ¨ - {e}")
        
        # 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        print("\nâš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
        import time
        
        start = time.time()
        for _ in range(3):
            await self.analyze_async(AnalysisRequest(text=test_text))
        elapsed = time.time() - start
        avg_time = elapsed / 3
        
        test_results['performance']['avg_response_time'] = avg_time
        print(f"   í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
        print(f"   ëª¨ë“ˆ í…ŒìŠ¤íŠ¸: {sum(1 for v in test_results['modules'].values() if v == 'PASS')}/{len(test_results['modules'])} í†µê³¼")
        print(f"   í†µí•© í…ŒìŠ¤íŠ¸: {'í†µê³¼' if test_results['integration'].get('basic') == 'PASS' else 'ì‹¤íŒ¨'}")
        print(f"   ì„±ëŠ¥: {'ì–‘í˜¸' if avg_time < 2.0 else 'ê°œì„  í•„ìš”'}")
        print("=" * 60)
        
        return test_results
    
    def get_system_status(self) -> SystemStatus:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        return SystemStatus(
            is_initialized=self.is_initialized,
            is_running=True,
            current_phase="running" if self.is_initialized else "initializing",
            active_modules=[
                name for name, analyzer in {
                    'emotion': self.emotion_analyzer,
                    'bentham': self.bentham_calculator,
                    'semantic': self.semantic_analyzer,
                    'surd': self.surd_analyzer,
                    'experience_database': self.experience_database
                }.items() if analyzer is not None
            ],
            performance_stats=self.performance_stats.copy(),
            gpu_available=torch.cuda.is_available(),
            device=str(DEVICE)
        )
        
    def clear_cache(self):
        """ìºì‹œ í´ë¦¬ì–´"""
        with self.cache_lock:
            self.result_cache.clear()
            
        # ê° ë¶„ì„ê¸°ì˜ ìºì‹œë„ í´ë¦¬ì–´
        if self.emotion_analyzer:
            self.emotion_analyzer.clear_cache()
        if self.bentham_calculator:
            self.bentham_calculator.clear_cache()
        if self.semantic_analyzer:
            self.semantic_analyzer.clear_cache()
        if self.surd_analyzer:
            self.surd_analyzer.clear_cache()
        if self.experience_database:
            # ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìºì‹œë¥¼ í´ë¦¬ì–´í•˜ì§€ ì•ŠìŒ (ë°ì´í„° ì†ì‹¤ ìœ„í—˜)
            pass
            
        self.logger.info("ëª¨ë“  ìºì‹œê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # â­ í†µí•© í•™ìŠµ ê´€ë ¨ ë©”ì†Œë“œë“¤
    def enable_integrated_training(self):
        """í†µí•© í•™ìŠµ ëª¨ë“œ í™œì„±í™”"""
        if self.integrated_training_enabled:
            self.logger.info("í†µí•© í•™ìŠµ ëª¨ë“œê°€ ì´ë¯¸ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return
            
        self.module_coordinator.enable_integrated_training()
        self.integrated_training_enabled = True
        self.logger.info("â­ í†µí•© í•™ìŠµ ëª¨ë“œ í™œì„±í™” ì™„ë£Œ")
        
    def disable_integrated_training(self):
        """í†µí•© í•™ìŠµ ëª¨ë“œ ë¹„í™œì„±í™”"""
        self.integrated_training_enabled = False
        self.logger.info("í†µí•© í•™ìŠµ ëª¨ë“œ ë¹„í™œì„±í™”")
        
    async def optimize_module_performance(self, sample_texts: List[str]) -> Dict[str, Any]:
        """ëª¨ë“ˆ ì„±ëŠ¥ ìµœì í™”"""
        if not self.integrated_training_enabled:
            raise ValueError("í†µí•© í•™ìŠµ ëª¨ë“œê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        optimization_report = await self.module_coordinator.optimize_data_flow(sample_texts)
        self.logger.info("ëª¨ë“ˆ ì„±ëŠ¥ ìµœì í™” ì™„ë£Œ")
        return optimization_report
        
    def get_integration_status(self) -> Dict[str, Any]:
        """í†µí•© ìƒíƒœ ì¡°íšŒ"""
        return {
            'integrated_training_enabled': self.integrated_training_enabled,
            'registered_modules': len(self.module_coordinator.adapters),
            'module_list': [module.value for module in self.module_coordinator.adapters.keys()],
            'performance_report': self.module_coordinator.get_performance_report() if self.module_coordinator.adapters else {},
            'system_harmony': self._assess_system_harmony()
        }
    
    def _assess_system_harmony(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì¡°í™”ë„ í‰ê°€"""
        if not self.module_coordinator.adapters:
            return {'harmony_score': 0.0, 'status': 'no_modules'}
            
        # ê° ëª¨ë“ˆì˜ ì„±ëŠ¥ í†µê³„ ìˆ˜ì§‘
        module_stats = []
        for module_type, adapter in self.module_coordinator.adapters.items():
            stats = adapter.performance_stats
            if stats['total_calls'] > 0:
                success_rate = stats['successful_calls'] / stats['total_calls']
                module_stats.append({
                    'module': module_type.value,
                    'success_rate': success_rate,
                    'avg_time': stats['average_time'],
                    'confidence': stats['last_confidence']
                })
                
        if not module_stats:
            return {'harmony_score': 0.0, 'status': 'no_data'}
            
        # ì¡°í™”ë„ ê³„ì‚°
        success_rates = [s['success_rate'] for s in module_stats]
        avg_times = [s['avg_time'] for s in module_stats]
        confidences = [s['confidence'] for s in module_stats]
        
        # í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ëª¨ë“ˆë“¤ì´ ê· ë“±í•˜ê²Œ ì„±ëŠ¥ì„ ë°œíœ˜
        success_harmony = 1.0 - np.std(success_rates) if success_rates else 0.0
        time_harmony = 1.0 - (np.std(avg_times) / max(np.mean(avg_times), 1.0)) if avg_times else 0.0
        confidence_harmony = 1.0 - np.std(confidences) if confidences else 0.0
        
        overall_harmony = (success_harmony + time_harmony + confidence_harmony) / 3.0
        
        return {
            'harmony_score': overall_harmony,
            'success_harmony': success_harmony,
            'time_harmony': time_harmony, 
            'confidence_harmony': confidence_harmony,
            'module_details': module_stats,
            'status': 'excellent' if overall_harmony > 0.8 else 'good' if overall_harmony > 0.6 else 'needs_improvement'
        }


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    setup_advanced_logging()
    
    parser = argparse.ArgumentParser(description='Red Heart ìœ¤ë¦¬ì  ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ')
    parser.add_argument('--mode', type=str, default='demo', 
                       choices=['production', 'advanced', 'demo', 'test'],
                       help='ì‹¤í–‰ ëª¨ë“œ (production/advanced/demo/test)')
    parser.add_argument('--text', type=str, help='ë¶„ì„í•  í…ìŠ¤íŠ¸')
    parser.add_argument('--language', type=str, default='ko', help='ì–¸ì–´ ì„¤ì •')
    parser.add_argument('--scenario', type=str, default='general', help='ì‹œë‚˜ë¦¬ì˜¤ íƒ€ì…')
    parser.add_argument('--demo', action='store_true', help='ë°ëª¨ ëª¨ë“œ ì‹¤í–‰ (ë ˆê±°ì‹œ)')
    
    # ê³ ê¸‰ ì˜µì…˜ë“¤
    parser.add_argument('--enable-xai', action='store_true', help='XAI í”¼ë“œë°± í†µí•© í™œì„±í™”')
    parser.add_argument('--enable-temporal', action='store_true', help='ì‹œê³„ì—´ ë¶„ì„ í™œì„±í™”')
    parser.add_argument('--enable-bayesian', action='store_true', help='ë² ì´ì§€ì•ˆ ì¶”ë¡  í™œì„±í™”')
    parser.add_argument('--oss-integration', action='store_true', help='OSS 20B ëª¨ë¸ í†µí•©')
    parser.add_argument('--enable-all', action='store_true', help='ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ í™œì„±í™”')
    
    args = parser.parse_args()
    
    # Red Heart ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = RedHeartSystem()
    
    # ëª¨ë“œë³„ ì‹œìŠ¤í…œ ì„¤ì •
    if args.mode == 'production' or args.mode == 'advanced':
        print("ğŸš€ Red Heart AI - Production Mode")
        print("   ëª¨ë“  ê³ ê¸‰ ë¶„ì„ ëª¨ë“ˆ í™œì„±í™”")
        if args.enable_all or args.mode == 'advanced':
            system.enable_advanced_features = True
            system.enable_xai = True
            system.enable_temporal = True
            system.enable_bayesian = True
        else:
            system.enable_xai = args.enable_xai
            system.enable_temporal = args.enable_temporal
            system.enable_bayesian = args.enable_bayesian
        
        if args.oss_integration:
            print("   OSS 20B ëª¨ë¸ í†µí•© ëª¨ë“œ")
            system.oss_integration = True
    else:
        print("ğŸ”´â¤ï¸ Red Heart ê³ ê¸‰ ìœ¤ë¦¬ì  ì˜ì‚¬ê²°ì • ì§€ì› ì‹œìŠ¤í…œ (Linux)")
    
    print("=" * 60)
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        await system.initialize()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
        status = system.get_system_status()
        print(f"\nâœ… ì‹œìŠ¤í…œ ìƒíƒœ:")
        print(f"   ì´ˆê¸°í™”: {'ì™„ë£Œ' if status.is_initialized else 'ì‹¤íŒ¨'}")
        print(f"   ë””ë°”ì´ìŠ¤: {status.device}")
        print(f"   GPU ì‚¬ìš© ê°€ëŠ¥: {'ì˜ˆ' if status.gpu_available else 'ì•„ë‹ˆì˜¤'}")
        print(f"   í™œì„± ëª¨ë“ˆ: {', '.join(status.active_modules) if status.active_modules else 'ì—†ìŒ'}")
        print(f"   í˜„ì¬ ë‹¨ê³„: {status.current_phase}")
        print(f"   ì‹¤í–‰ ëª¨ë“œ: {args.mode.upper()}")
        
        # ëª¨ë“œë³„ ì‹¤í–‰
        if args.mode == 'production':
            # ìš´ìš© ëª¨ë“œ - ì‹¤ì œ ë¶„ì„ ì‘ì—…
            if not args.text:
                print("\nìš´ìš© ëª¨ë“œ: í…ìŠ¤íŠ¸ ì…ë ¥ ëŒ€ê¸° ì¤‘...")
                # ì…ë ¥ ëŒ€ê¸° ë£¨í”„ ë˜ëŠ” íŒŒì¼/ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
                await system.run_production_loop()
            else:
                request = AnalysisRequest(
                    text=args.text,
                    language=args.language,
                    scenario_type=args.scenario,
                    enable_all_modules=True
                )
                result = await system.analyze_async(request)
                print_analysis_result(result)
                
        elif args.mode == 'advanced':
            # ê³ ê¸‰ ëª¨ë“œ - ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™”
            print("\nê³ ê¸‰ ëª¨ë“œ: ëª¨ë“  ë¶„ì„ ëª¨ë“ˆ í™œì„±í™”")
            await system.run_advanced_analysis(args.text or "ê³ ê¸‰ ë¶„ì„ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸")
            
        elif args.mode == 'test':
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
            print("\ní…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì‹œìŠ¤í…œ ê²€ì¦ ì¤‘...")
            await system.run_system_test()
            
        elif args.demo or not args.text:
            # ë°ëª¨ ëª¨ë“œ
            await run_demo(system)
        else:
            # ë‹¨ì¼ ë¶„ì„
            request = AnalysisRequest(
                text=args.text,
                language=args.language,
                scenario_type=args.scenario
            )
            
            result = await system.analyze_async(request)
            print_analysis_result(result)
            
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ì˜¤ë¥˜: {e}")
        
    finally:
        # ì •ë¦¬
        if hasattr(system, 'thread_pool'):
            system.thread_pool.shutdown(wait=True)


async def run_demo(system: RedHeartSystem):
    """ë°ëª¨ ì‹¤í–‰"""
    print("\nğŸ® ë°ëª¨ ëª¨ë“œ")
    print("-" * 40)
    
    demo_scenarios = [
        {
            'text': "ì´ ê²°ì •ì€ ë§ì€ ì‚¬ëŒë“¤ì˜ ìƒëª…ê³¼ ì•ˆì „ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ë©°, ìš°ë¦¬ëŠ” ì •ì˜ë¡­ê³  ê³µì •í•œ ì„ íƒì„ í•´ì•¼ í•©ë‹ˆë‹¤.",
            'language': 'ko',
            'scenario_type': 'ethical_dilemma',
            'description': 'ìœ¤ë¦¬ì  ë”œë ˆë§ˆ ìƒí™©'
        },
        {
            'text': "ìƒˆë¡œìš´ ê¸°ìˆ  ë„ì…ìœ¼ë¡œ íš¨ìœ¨ì„±ì€ ë†’ì•„ì§€ì§€ë§Œ ì¼ë¶€ ì§ì›ë“¤ì´ ì¼ìë¦¬ë¥¼ ìƒì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            'language': 'ko', 
            'scenario_type': 'technology_ethics',
            'description': 'ê¸°ìˆ  ìœ¤ë¦¬ ìƒí™©'
        },
        {
            'text': "ê°œì¸ì •ë³´ ë³´í˜¸ì™€ ê³µìµì„ ìœ„í•œ ì •ë³´ ê³µê°œ ì‚¬ì´ì—ì„œ ê· í˜•ì ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.",
            'language': 'ko',
            'scenario_type': 'privacy_vs_public',
            'description': 'í”„ë¼ì´ë²„ì‹œ vs ê³µìµ'
        }
    ]
    
    for i, scenario in enumerate(demo_scenarios, 1):
        print(f"\nğŸ“ ì‹œë‚˜ë¦¬ì˜¤ {i}: {scenario['description']}")
        print(f"   í…ìŠ¤íŠ¸: {scenario['text']}")
        
        request = AnalysisRequest(
            text=scenario['text'],
            language=scenario['language'],
            scenario_type=scenario['scenario_type']
        )
        
        print("   ë¶„ì„ ì¤‘...")
        start_time = time.time()
        result = await system.analyze_async(request)
        analysis_time = time.time() - start_time
        
        print(f"   â±ï¸ ë¶„ì„ ì‹œê°„: {analysis_time:.2f}ì´ˆ")
        print(f"   ğŸ¯ í†µí•© ì ìˆ˜: {result.integrated_score:.3f}")
        print(f"   ğŸ”® ì‹ ë¢°ë„: {result.confidence:.3f}")
        print(f"   ğŸ’¡ ì¶”ì²œ: {result.recommendation}")
        
        # ì»´í¬ë„ŒíŠ¸ë³„ ê°„ë‹¨í•œ ê²°ê³¼
        if result.emotion_analysis:
            print(f"   ğŸ˜Š ê°ì • ë¶„ì„: ì™„ë£Œ")
        if result.bentham_analysis:
            print(f"   âš–ï¸ ë²¤ë‹´ ë¶„ì„: ì™„ë£Œ (ì ìˆ˜: {result.bentham_analysis.final_score:.3f})")
        if result.semantic_analysis:
            print(f"   ğŸ§  ì˜ë¯¸ ë¶„ì„: ì™„ë£Œ")
        if result.surd_analysis:
            print(f"   ğŸ”— SURD ë¶„ì„: ì™„ë£Œ")
            
        if i < len(demo_scenarios):
            print("   " + "-" * 30)
            
    # ì‹œìŠ¤í…œ í†µê³„
    status = system.get_system_status()
    print(f"\nğŸ“Š ì‹œìŠ¤í…œ í†µê³„:")
    print(f"   ì´ ìš”ì²­ ìˆ˜: {status.performance_stats['total_requests']}")
    print(f"   ì„±ê³µ ë¶„ì„: {status.performance_stats['successful_analyses']}")
    print(f"   ì‹¤íŒ¨ ë¶„ì„: {status.performance_stats['failed_analyses']}")
    print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {status.performance_stats['average_processing_time']:.3f}ì´ˆ")
    print(f"   ìºì‹œ íˆíŠ¸: {status.performance_stats['cache_hits']}")
    print(f"   ìºì‹œ í¬ê¸°: {status.cache_size}")


def print_analysis_result(result: IntegratedResult):
    """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
    print(f"\nğŸ“‹ ë¶„ì„ ê²°ê³¼")
    print("=" * 40)
    print(f"í…ìŠ¤íŠ¸: {result.request.text}")
    print(f"ì–¸ì–´: {result.request.language}")
    print(f"ì‹œë‚˜ë¦¬ì˜¤: {result.request.scenario_type}")
    print(f"ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
    print(f"\nğŸ¯ í†µí•© ì ìˆ˜: {result.integrated_score:.3f}")
    print(f"ğŸ”® ì‹ ë¢°ë„: {result.confidence:.3f}")
    print(f"ğŸ’¡ ì¶”ì²œì‚¬í•­: {result.recommendation}")
    
    print(f"\nğŸ“Š ì»´í¬ë„ŒíŠ¸ë³„ ê²°ê³¼:")
    
    if result.emotion_analysis:
        print(f"  ğŸ˜Š ê°ì • ë¶„ì„: âœ…")
        if hasattr(result.emotion_analysis, 'dominant_emotion'):
            print(f"     ì£¼ìš” ê°ì •: {result.emotion_analysis.dominant_emotion}")
    else:
        print(f"  ğŸ˜Š ê°ì • ë¶„ì„: âŒ")
        
    if result.bentham_analysis:
        print(f"  âš–ï¸ ë²¤ë‹´ ë¶„ì„: âœ…")
        print(f"     ìµœì¢… ì ìˆ˜: {result.bentham_analysis.final_score:.3f}")
        print(f"     ì‹ ë¢°ë„: {result.bentham_analysis.confidence_score:.3f}")
    else:
        print(f"  âš–ï¸ ë²¤ë‹´ ë¶„ì„: âŒ")
        
    if result.semantic_analysis:
        print(f"  ğŸ§  ì˜ë¯¸ ë¶„ì„: âœ…")
        print(f"     ì‹ ë¢°ë„: {result.semantic_analysis.confidence_score:.3f}")
    else:
        print(f"  ğŸ§  ì˜ë¯¸ ë¶„ì„: âŒ")
        
    if result.surd_analysis:
        print(f"  ğŸ”— SURD ë¶„ì„: âœ…")
        if hasattr(result.surd_analysis, 'processing_time'):
            print(f"     ì²˜ë¦¬ ì‹œê°„: {result.surd_analysis.processing_time:.3f}ì´ˆ")
    else:
        print(f"  ğŸ”— SURD ë¶„ì„: âŒ")
        
    print(f"\nğŸ”§ ì‹œìŠ¤í…œ ì •ë³´:")
    for key, value in result.metadata.items():
        print(f"  {key}: {value}")


if __name__ == "__main__":
    asyncio.run(main())