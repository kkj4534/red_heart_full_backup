"""
ëª¨ë“ˆë³„ ì²´í¬í¬ì¸íŠ¸ ì „ëµ êµ¬í˜„
ì—°ë™ ê·¸ë£¹ì€ í•¨ê»˜, ë…ë¦½ ëª¨ë“ˆì€ ê°œë³„ ì €ì¥
"""

import torch
import os
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class ModularCheckpointStrategy:
    """
    ì—°ë™ ê·¸ë£¹ì€ í•¨ê»˜, ë…ë¦½ ëª¨ë“ˆì€ ê°œë³„ ì €ì¥í•˜ëŠ” ì²´í¬í¬ì¸íŠ¸ ì „ëµ
    
    ì—°ë™ ê·¸ë£¹:
    1. Backbone-Heads: ë°±ë³¸ê³¼ í—¤ë“œë“¤ì´ ê¸´ë°€í•˜ê²Œ ì—°ê²°
    2. Phase0-1: ê°ì • íˆ¬ì˜ê³¼ ê³µê° í•™ìŠµì´ ìˆœì°¨ì  ì˜ì¡´
    3. DSP-Kalman: DSP ì¶œë ¥ì„ ì¹¼ë§Œ í•„í„°ê°€ í•„ìˆ˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
    
    ë…ë¦½ ëª¨ë“ˆ:
    - Neural Analyzers: ê°ê° ë…ë¦½ì ìœ¼ë¡œ ì‘ë™
    - Advanced Analyzers: ë„ë©”ì¸ë³„ íŠ¹í™” ì²˜ë¦¬
    - Phase2: ê³µë™ì²´ ìˆ˜ì¤€ ë…ë¦½ ì²˜ë¦¬
    """
    
    def __init__(self, checkpoint_dir: str = "checkpoints"):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(exist_ok=True)
        
        # ì—°ë™ ê·¸ë£¹ ì •ì˜
        self.coupled_groups = {
            'backbone_heads': {
                'modules': ['backbone', 'emotion_head', 'bentham_head', 'regret_head', 'surd_head'],
                'description': 'Backboneê³¼ ëª¨ë“  í—¤ë“œ (ë°ì´í„° íë¦„ ê³µìœ )',
                'params': '278M'
            },
            'phase_0_1': {
                'modules': ['phase0_calibrator', 'phase1_empathy'],
                'description': 'Phase0 íˆ¬ì˜ â†’ Phase1 ê³µê° (ìˆœì°¨ ì˜ì¡´)',
                'params': '2.23M'
            },
            'dsp_kalman': {
                'modules': ['emotion_dsp', 'kalman_filter'],
                'description': 'DSP ì‹œë®¬ë ˆì´í„° â†’ ì¹¼ë§Œ í•„í„° (í•„ìˆ˜ ì…ë ¥)',
                'params': '14M'
            }
        }
        
        # ë…ë¦½ ëª¨ë“ˆ ì •ì˜
        self.independent_modules = {
            # Neural Analyzers
            'neural_emotion': {'description': 'ì‹ ê²½ë§ ê°ì • ë¶„ì„ê¸°', 'params': '55M'},
            'neural_bentham': {'description': 'ì‹ ê²½ë§ ë²¤ë‹´ ê³„ì‚°ê¸°', 'params': '62M'},
            'neural_regret': {'description': 'ì‹ ê²½ë§ í›„íšŒ ë¶„ì„ê¸°', 'params': '68M'},
            'neural_surd': {'description': 'ì‹ ê²½ë§ SURD ë¶„ì„ê¸°', 'params': '47M'},
            
            # Advanced Analyzers
            'advanced_emotion': {'description': 'ê³ ê¸‰ ê°ì • ë¶„ì„ê¸°', 'params': '48M'},
            'advanced_regret': {'description': 'ê³ ê¸‰ í›„íšŒ ë¶„ì„ê¸°', 'params': '50M'},
            'advanced_surd': {'description': 'ê³ ê¸‰ SURD ë¶„ì„ê¸°', 'params': '25M'},
            'advanced_bentham': {'description': 'ê³ ê¸‰ ë²¤ë‹´ ê³„ì‚°ê¸°', 'params': '2.5M'},
            
            # Phase2
            'phase2_community': {'description': 'ê³µë™ì²´ í™•ì¥ ëª¨ë“ˆ', 'params': '2.5M'}
        }
        
        # ìµœì  ì„±ëŠ¥ ì¶”ì 
        self.best_metrics = {}
        self.load_best_metrics()
        
        logger.info("âœ… ëª¨ë“ˆë³„ ì²´í¬í¬ì¸íŠ¸ ì „ëµ ì´ˆê¸°í™”")
        logger.info(f"  - ì—°ë™ ê·¸ë£¹: {len(self.coupled_groups)}ê°œ")
        logger.info(f"  - ë…ë¦½ ëª¨ë“ˆ: {len(self.independent_modules)}ê°œ")
    
    def load_best_metrics(self):
        """ì €ì¥ëœ ìµœì  ë©”íŠ¸ë¦­ ë¡œë“œ"""
        metrics_file = self.checkpoint_dir / "best_metrics.json"
        if metrics_file.exists():
            with open(metrics_file, 'r') as f:
                self.best_metrics = json.load(f)
    
    def save_best_metrics(self):
        """ìµœì  ë©”íŠ¸ë¦­ ì €ì¥"""
        metrics_file = self.checkpoint_dir / "best_metrics.json"
        with open(metrics_file, 'w') as f:
            json.dump(self.best_metrics, f, indent=2)
    
    def is_best_performance(self, module_name: str, current_metric: float) -> bool:
        """í˜„ì¬ ì„±ëŠ¥ì´ ìµœê³ ì¸ì§€ í™•ì¸"""
        if module_name not in self.best_metrics:
            return True
        return current_metric < self.best_metrics[module_name]
    
    def save_checkpoint(self, 
                       epoch: int,
                       model: Any,
                       metrics: Dict[str, float],
                       optimizer: Optional[Any] = None,
                       scheduler: Optional[Any] = None):
        """
        ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        
        Args:
            epoch: í˜„ì¬ ì—í­
            model: ì „ì²´ ëª¨ë¸ ê°ì²´
            metrics: ê° ëª¨ë“ˆë³„ ë©”íŠ¸ë¦­
            optimizer: ì˜µí‹°ë§ˆì´ì € (ì„ íƒ)
            scheduler: ìŠ¤ì¼€ì¤„ëŸ¬ (ì„ íƒ)
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ì—°ë™ ê·¸ë£¹ ì €ì¥ (ê°™ì€ ì—í­)
        for group_name, group_info in self.coupled_groups.items():
            group_dir = self.checkpoint_dir / group_name
            group_dir.mkdir(exist_ok=True)
            
            group_checkpoint = {
                'epoch': epoch,
                'timestamp': timestamp,
                'modules': {},
                'metrics': {}
            }
            
            # ê° ëª¨ë“ˆì˜ state_dict ìˆ˜ì§‘
            for module_name in group_info['modules']:
                module_state = self._get_module_state(model, module_name)
                if module_state is not None:
                    group_checkpoint['modules'][module_name] = module_state
                    if module_name in metrics:
                        group_checkpoint['metrics'][module_name] = metrics[module_name]
            
            # ê·¸ë£¹ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint_path = group_dir / f"epoch_{epoch:04d}.pt"
            torch.save(group_checkpoint, checkpoint_path)
            logger.info(f"  ğŸ’¾ {group_name} ê·¸ë£¹ ì €ì¥: {checkpoint_path}")
        
        # 2. ë…ë¦½ ëª¨ë“ˆ ì €ì¥ (ìµœì  ì„±ëŠ¥ ì‹œì ë§Œ)
        for module_name, module_info in self.independent_modules.items():
            if module_name in metrics:
                current_metric = metrics[module_name]
                
                if self.is_best_performance(module_name, current_metric):
                    module_dir = self.checkpoint_dir / module_name
                    module_dir.mkdir(exist_ok=True)
                    
                    module_state = self._get_module_state(model, module_name)
                    if module_state is not None:
                        checkpoint = {
                            'epoch': epoch,
                            'timestamp': timestamp,
                            'state_dict': module_state,
                            'metric': current_metric,
                            'description': module_info['description'],
                            'params': module_info['params']
                        }
                        
                        checkpoint_path = module_dir / "best.pt"
                        torch.save(checkpoint, checkpoint_path)
                        
                        # ìµœì  ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                        self.best_metrics[module_name] = current_metric
                        
                        logger.info(f"  ğŸ† {module_name} ìµœì  ëª¨ë¸ ì €ì¥ (metric: {current_metric:.4f})")
        
        # 3. ì˜µí‹°ë§ˆì´ì €/ìŠ¤ì¼€ì¤„ëŸ¬ ì €ì¥ (ì„ íƒ)
        if optimizer is not None:
            optimizer_path = self.checkpoint_dir / f"optimizer_epoch_{epoch:04d}.pt"
            torch.save(optimizer.state_dict(), optimizer_path)
        
        if scheduler is not None:
            scheduler_path = self.checkpoint_dir / f"scheduler_epoch_{epoch:04d}.pt"
            torch.save(scheduler.state_dict(), scheduler_path)
        
        # ìµœì  ë©”íŠ¸ë¦­ ì €ì¥
        self.save_best_metrics()
    
    def _get_module_state(self, model: Any, module_name: str) -> Optional[Dict]:
        """ëª¨ë“ˆì˜ state_dict ì¶”ì¶œ"""
        # ë°±ë³¸
        if module_name == 'backbone' and hasattr(model, 'backbone'):
            return model.backbone.state_dict() if model.backbone else None
        
        # í—¤ë“œ
        if '_head' in module_name:
            head_key = module_name.replace('_head', '')
            if hasattr(model, 'heads') and head_key in model.heads:
                return model.heads[head_key].state_dict()
        
        # ë¶„ì„ê¸°
        if 'neural_' in module_name or 'advanced_' in module_name:
            if hasattr(model, 'analyzers') and module_name in model.analyzers:
                analyzer = model.analyzers[module_name]
                
                # Advanced AnalyzerëŠ” ë‚´ë¶€ ëª¨ë“ˆë“¤ ìˆ˜ì§‘
                if 'advanced_' in module_name:
                    state_dict = {}
                    for attr_name in dir(analyzer):
                        if not attr_name.startswith('_'):
                            attr = getattr(analyzer, attr_name, None)
                            if attr is not None and isinstance(attr, torch.nn.Module):
                                state_dict[attr_name] = attr.state_dict()
                    return state_dict if state_dict else None
                else:
                    # Neural AnalyzerëŠ” ì§ì ‘ state_dict
                    return analyzer.state_dict() if hasattr(analyzer, 'state_dict') else None
        
        # Phase ëª¨ë“ˆ
        if 'phase' in module_name:
            # Phase ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ (êµ¬í˜„ í•„ìš”)
            pass
        
        # DSP/Kalman
        if module_name == 'emotion_dsp':
            if hasattr(model, 'dsp_simulator'):
                return model.dsp_simulator.state_dict()
        elif module_name == 'kalman_filter':
            if hasattr(model, 'kalman_filter'):
                return model.kalman_filter.state_dict()
        
        return None
    
    def load_checkpoint(self, 
                       model: Any,
                       checkpoint_type: str = 'best',
                       epoch: Optional[int] = None,
                       modules_to_load: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        
        Args:
            model: ëª¨ë¸ ê°ì²´
            checkpoint_type: 'best' ë˜ëŠ” 'epoch'
            epoch: íŠ¹ì • ì—í­ (checkpoint_type='epoch'ì¼ ë•Œ)
            modules_to_load: ë¡œë“œí•  ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´)
            
        Returns:
            ë¡œë“œëœ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        loaded_info = {}
        
        if checkpoint_type == 'best':
            # ìµœì  ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            for module_name in modules_to_load or list(self.independent_modules.keys()):
                module_path = self.checkpoint_dir / module_name / "best.pt"
                if module_path.exists():
                    checkpoint = torch.load(module_path)
                    self._load_module_state(model, module_name, checkpoint['state_dict'])
                    loaded_info[module_name] = {
                        'epoch': checkpoint['epoch'],
                        'metric': checkpoint['metric']
                    }
                    logger.info(f"  âœ… {module_name} ìµœì  ëª¨ë¸ ë¡œë“œ (epoch {checkpoint['epoch']})")
        
        elif checkpoint_type == 'epoch' and epoch is not None:
            # íŠ¹ì • ì—í­ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            for group_name, group_info in self.coupled_groups.items():
                group_path = self.checkpoint_dir / group_name / f"epoch_{epoch:04d}.pt"
                if group_path.exists():
                    checkpoint = torch.load(group_path)
                    for module_name, state_dict in checkpoint['modules'].items():
                        if modules_to_load is None or module_name in modules_to_load:
                            self._load_module_state(model, module_name, state_dict)
                            loaded_info[module_name] = {'epoch': epoch}
                    logger.info(f"  âœ… {group_name} ê·¸ë£¹ ë¡œë“œ (epoch {epoch})")
        
        return loaded_info
    
    def _load_module_state(self, model: Any, module_name: str, state_dict: Dict):
        """ëª¨ë“ˆì— state_dict ë¡œë“œ"""
        # ë°±ë³¸
        if module_name == 'backbone' and hasattr(model, 'backbone'):
            if model.backbone:
                model.backbone.load_state_dict(state_dict)
        
        # í—¤ë“œ
        elif '_head' in module_name:
            head_key = module_name.replace('_head', '')
            if hasattr(model, 'heads') and head_key in model.heads:
                model.heads[head_key].load_state_dict(state_dict)
        
        # ë¶„ì„ê¸°
        elif 'neural_' in module_name or 'advanced_' in module_name:
            if hasattr(model, 'analyzers') and module_name in model.analyzers:
                analyzer = model.analyzers[module_name]
                
                # Advanced AnalyzerëŠ” ë‚´ë¶€ ëª¨ë“ˆë³„ë¡œ ë¡œë“œ
                if 'advanced_' in module_name and isinstance(state_dict, dict):
                    for attr_name, attr_state in state_dict.items():
                        if hasattr(analyzer, attr_name):
                            attr = getattr(analyzer, attr_name)
                            if isinstance(attr, torch.nn.Module):
                                attr.load_state_dict(attr_state)
                else:
                    # Neural AnalyzerëŠ” ì§ì ‘ ë¡œë“œ
                    if hasattr(analyzer, 'load_state_dict'):
                        analyzer.load_state_dict(state_dict)
    
    def find_optimal_combination(self) -> Dict[str, int]:
        """
        ìµœì  ì—í­ ì¡°í•© ì°¾ê¸°
        
        Returns:
            ê° ëª¨ë“ˆë³„ ìµœì  ì—í­
        """
        optimal = {}
        
        # ì—°ë™ ê·¸ë£¹ì€ ìµœì‹  ì—í­ ì‚¬ìš©
        for group_name in self.coupled_groups:
            group_dir = self.checkpoint_dir / group_name
            if group_dir.exists():
                checkpoints = sorted(group_dir.glob("epoch_*.pt"))
                if checkpoints:
                    latest = checkpoints[-1]
                    epoch = int(latest.stem.split('_')[1])
                    for module in self.coupled_groups[group_name]['modules']:
                        optimal[module] = epoch
        
        # ë…ë¦½ ëª¨ë“ˆì€ ìµœì  ì„±ëŠ¥ ì—í­ ì‚¬ìš©
        for module_name in self.independent_modules:
            best_path = self.checkpoint_dir / module_name / "best.pt"
            if best_path.exists():
                checkpoint = torch.load(best_path)
                optimal[module_name] = checkpoint['epoch']
        
        return optimal
    
    def get_summary(self) -> str:
        """ì²´í¬í¬ì¸íŠ¸ ì „ëµ ìš”ì•½"""
        summary = []
        summary.append("=" * 60)
        summary.append("ğŸ“Š ëª¨ë“ˆë³„ ì²´í¬í¬ì¸íŠ¸ ì „ëµ ìš”ì•½")
        summary.append("=" * 60)
        
        summary.append("\nğŸ”— ì—°ë™ ê·¸ë£¹ (í•¨ê»˜ ì €ì¥/ë¡œë“œ):")
        for group_name, group_info in self.coupled_groups.items():
            summary.append(f"  â€¢ {group_name}: {group_info['description']}")
            summary.append(f"    - ëª¨ë“ˆ: {', '.join(group_info['modules'])}")
            summary.append(f"    - íŒŒë¼ë¯¸í„°: {group_info['params']}")
        
        summary.append("\nğŸ¯ ë…ë¦½ ëª¨ë“ˆ (ê°œë³„ ìµœì í™”):")
        for module_name, module_info in self.independent_modules.items():
            best_metric = self.best_metrics.get(module_name, 'N/A')
            summary.append(f"  â€¢ {module_name}: {module_info['description']}")
            summary.append(f"    - íŒŒë¼ë¯¸í„°: {module_info['params']}")
            summary.append(f"    - ìµœì  ë©”íŠ¸ë¦­: {best_metric}")
        
        summary.append("\n" + "=" * 60)
        return "\n".join(summary)