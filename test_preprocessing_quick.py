#!/usr/bin/env python3
"""ë¹ ë¥¸ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ - 1ê°œ ìƒ˜í”Œë§Œ"""

import json
from data_preprocessing_pipeline_v3 import HelpingAIPreprocessor

def test_single_sample():
    """ë‹¨ì¼ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸"""
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_data = [{
        'text': "I am feeling very happy today. The sun is shining bright.",
        'source': 'test',
        'metadata': {'ethical_dilemma': 'none'}
    }]
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥
    with open('test_sample.json', 'w') as f:
        json.dump(test_data, f)
    
    # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    print("ğŸ”„ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”...")
    preprocessor = HelpingAIPreprocessor()
    
    # ë‹¨ì¼ ìƒ˜í”Œ ì²˜ë¦¬
    print("ğŸ“ ë‹¨ì¼ ìƒ˜í”Œ ì²˜ë¦¬ ì‹œì‘...")
    preprocessor.process_dataset(
        input_file="test_sample.json",
        output_file="test_output.json",
        limit=1
    )
    
    # ê²°ê³¼ í™•ì¸
    with open('test_output.json', 'r') as f:
        result = json.load(f)
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ì²˜ë¦¬ëœ ìƒ˜í”Œ ìˆ˜: {len(result)}")
    
    if result:
        sample = result[0]
        print("\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"  - ê°ì • ë²¡í„°: {sample.get('emotion_vector', [])[:3]}...")
        print(f"  - í›„íšŒ ì§€ìˆ˜: {sample.get('regret_factor', 0):.3f}")
        print(f"  - ë²¤ë‹´ ì ìˆ˜ í‚¤: {list(sample.get('bentham_scores', {}).keys())}")
        print(f"  - SURD ë©”íŠ¸ë¦­ í‚¤: {list(sample.get('surd_metrics', {}).keys())}")
        print(f"  - ì„ë² ë”© ì°¨ì›: {len(sample.get('context_embedding', []))}")

if __name__ == "__main__":
    test_single_sample()