#!/usr/bin/env python3
"""
Dynamic GPU Memory Manager for Red Heart AI System
ë™ì  GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ì - ëª¨ë¸ë³„ ë§ì¶¤í˜• ë©”ëª¨ë¦¬ í• ë‹¹

Features:
- ëª¨ë¸ë³„ ê°œë³„ ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëµ
- klue/bert-base ë“± ì˜¤ë²„í—¤ë“œ ìœ„í—˜ ëª¨ë¸ ì•ˆì •ì„± ë³´ì¥
- ë©”ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ë™ì  ìµœì í™”
- ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë° ì¡°ì •
"""

import torch
import gc
import time
import logging
from typing import Dict, Optional, Tuple, List
from dataclasses import dataclass
from contextlib import contextmanager
import threading
from enum import Enum

class ModelRiskLevel(Enum):
    """ëª¨ë¸ ì˜¤ë²„í—¤ë“œ ìœ„í—˜ë„ ë¶„ë¥˜"""
    LOW = "low"           # ì•ˆì „í•œ ëª¨ë¸ë“¤
    MEDIUM = "medium"     # ì¤‘ê°„ ìœ„í—˜ë„
    HIGH = "high"         # klue/bert-base ë“± ì˜¤ë²„í—¤ë“œ ìœ„í—˜ ëª¨ë¸

@dataclass
class GPUMemoryProfile:
    """GPU ë©”ëª¨ë¦¬ í”„ë¡œí•„"""
    model_name: str
    risk_level: ModelRiskLevel
    base_allocation: float      # ê¸°ë³¸ í• ë‹¹ëŸ‰ (ë¹„ìœ¨)
    max_allocation: float       # ìµœëŒ€ í• ë‹¹ëŸ‰ (ë¹„ìœ¨)
    min_allocation: float       # ìµœì†Œ í• ë‹¹ëŸ‰ (ë¹„ìœ¨)
    priority: int              # ìš°ì„ ìˆœìœ„ (1=ìµœê³ )
    stable_mode: bool          # ì•ˆì • ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€

class DynamicGPUManager:
    """ë™ì  GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.logger = logging.getLogger(__name__)
        
        # GPU ì´ ë©”ëª¨ë¦¬ ì •ë³´
        if torch.cuda.is_available():
            self.total_memory = torch.cuda.get_device_properties(0).total_memory
            self.total_memory_gb = self.total_memory / (1024**3)
        else:
            self.total_memory = 0
            self.total_memory_gb = 0
        
        # ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ í”„ë¡œí•„ ì„¤ì •
        self.memory_profiles = self._initialize_memory_profiles()
        
        # í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ì¶”ì 
        self.loaded_models: Dict[str, torch.nn.Module] = {}
        self.model_memory_usage: Dict[str, float] = {}
        
        # ë™ì  í• ë‹¹ì„ ìœ„í•œ ë©”ëª¨ë¦¬ í’€
        self.reserved_memory = 0.1  # 10% ì‹œìŠ¤í…œ ì˜ˆì•½
        self.available_memory_ratio = 1.0 - self.reserved_memory
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self.lock = threading.Lock()
        
        self.logger.info(f"Dynamic GPU Manager initialized - Total GPU Memory: {self.total_memory_gb:.1f}GB")
    
    def _initialize_memory_profiles(self) -> Dict[str, GPUMemoryProfile]:
        """ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ í”„ë¡œí•„ ì´ˆê¸°í™”"""
        profiles = {
            # ì˜¤ë²„í—¤ë“œ ìœ„í—˜ ëª¨ë¸ë“¤ - ì•ˆì •ì„± ìš°ì„ 
            'klue/bert-base': GPUMemoryProfile(
                model_name='klue/bert-base',
                risk_level=ModelRiskLevel.HIGH,
                base_allocation=0.15,      # 15% ê³ ì • (í˜„ì¬ ì„¤ì • ìœ ì§€)
                max_allocation=0.20,       # ìµœëŒ€ 20%
                min_allocation=0.10,       # ìµœì†Œ 10%
                priority=1,                # ìµœê³  ìš°ì„ ìˆœìœ„
                stable_mode=True           # ì•ˆì • ëª¨ë“œ í™œì„±í™”
            ),
            'beomi/KcELECTRA-base-v2022': GPUMemoryProfile(
                model_name='beomi/KcELECTRA-base-v2022',
                risk_level=ModelRiskLevel.HIGH,
                base_allocation=0.15,
                max_allocation=0.20,
                min_allocation=0.10,
                priority=2,
                stable_mode=True
            ),
            
            # ì¤‘ê°„ ìœ„í—˜ë„ ëª¨ë¸ë“¤
            'j-hartmann/emotion-english-distilroberta-base': GPUMemoryProfile(
                model_name='j-hartmann/emotion-english-distilroberta-base',
                risk_level=ModelRiskLevel.MEDIUM,
                base_allocation=0.25,
                max_allocation=0.35,
                min_allocation=0.15,
                priority=3,
                stable_mode=False
            ),
            
            # ì•ˆì „í•œ ëª¨ë¸ë“¤ - ë™ì  ìµœì í™” ì ìš©
            'main_learning_pipeline': GPUMemoryProfile(
                model_name='main_learning_pipeline',
                risk_level=ModelRiskLevel.LOW,
                base_allocation=0.40,      # 40% ê¸°ë³¸ í• ë‹¹
                max_allocation=0.70,       # ìµœëŒ€ 70% ê¹Œì§€ í™•ì¥ ê°€ëŠ¥
                min_allocation=0.20,       # ìµœì†Œ 20% ë³´ì¥
                priority=4,
                stable_mode=False          # ë™ì  ìµœì í™” í™œì„±í™”
            ),
            'neural_networks': GPUMemoryProfile(
                model_name='neural_networks',
                risk_level=ModelRiskLevel.LOW,
                base_allocation=0.30,
                max_allocation=0.60,
                min_allocation=0.15,
                priority=5,
                stable_mode=False
            ),
            
            # ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë“ˆë“¤
            'legal_expert_system': GPUMemoryProfile(
                model_name='legal_expert_system',
                risk_level=ModelRiskLevel.LOW,
                base_allocation=0.10,      # 10% ê¸°ë³¸ í• ë‹¹ (ë‚´ì¥ ëª¨ë¸ ê¸°ë°˜)
                max_allocation=0.15,       # ìµœëŒ€ 15%
                min_allocation=0.05,       # ìµœì†Œ 5%
                priority=6,
                stable_mode=False          # ë™ì  ìµœì í™” í™œì„±í™”
            ),
            'three_view_scenario_system': GPUMemoryProfile(
                model_name='three_view_scenario_system',
                risk_level=ModelRiskLevel.LOW,
                base_allocation=0.15,      # 15% ê¸°ë³¸ í• ë‹¹ (ì‹ ê²½ë§ ê¸°ë°˜)
                max_allocation=0.25,       # ìµœëŒ€ 25%
                min_allocation=0.08,       # ìµœì†Œ 8%
                priority=7,
                stable_mode=False          # ë™ì  ìµœì í™” í™œì„±í™”
            ),
            'phase_controller_hook': GPUMemoryProfile(
                model_name='phase_controller_hook',
                risk_level=ModelRiskLevel.LOW,
                base_allocation=0.05,      # 5% ê¸°ë³¸ í• ë‹¹ (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§)
                max_allocation=0.10,       # ìµœëŒ€ 10%
                min_allocation=0.02,       # ìµœì†Œ 2%
                priority=8,
                stable_mode=False          # ë™ì  ìµœì í™” í™œì„±í™”
            )
        }
        return profiles
    
    @contextmanager
    def allocate_memory(self, model_name: str, dynamic_boost: bool = False):
        """
        ëª¨ë¸ë³„ ë©”ëª¨ë¦¬ í• ë‹¹ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
        
        Args:
            model_name: ëª¨ë¸ ì´ë¦„
            dynamic_boost: ë™ì  ë¶€ìŠ¤íŠ¸ í™œì„±í™” ì—¬ë¶€
        """
        profile = self.memory_profiles.get(model_name)
        if not profile:
            # ì•Œë ¤ì§€ì§€ ì•Šì€ ëª¨ë¸ì€ ì¤‘ê°„ ìœ„í—˜ë„ë¡œ ì²˜ë¦¬
            profile = GPUMemoryProfile(
                model_name=model_name,
                risk_level=ModelRiskLevel.MEDIUM,
                base_allocation=0.25,
                max_allocation=0.35,
                min_allocation=0.15,
                priority=10,
                stable_mode=True
            )
        
        with self.lock:
            try:
                # ë©”ëª¨ë¦¬ í• ë‹¹
                allocated_memory = self._allocate_model_memory(profile, dynamic_boost)
                self.model_memory_usage[model_name] = allocated_memory
                
                self.logger.info(f"ğŸ”§ {model_name} ë©”ëª¨ë¦¬ í• ë‹¹: {allocated_memory:.1%} ({allocated_memory * self.total_memory_gb:.1f}GB)")
                
                yield allocated_memory
                
            finally:
                # ë©”ëª¨ë¦¬ í•´ì œ
                self._release_model_memory(model_name)
                self.logger.info(f"ğŸ—‘ï¸ {model_name} ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ")
    
    def _allocate_model_memory(self, profile: GPUMemoryProfile, dynamic_boost: bool) -> float:
        """ì‹¤ì œ ë©”ëª¨ë¦¬ í• ë‹¹ ë¡œì§"""
        if not torch.cuda.is_available():
            return 0.0
        
        # í˜„ì¬ ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
        current_allocated = torch.cuda.memory_allocated() / self.total_memory
        current_reserved = torch.cuda.memory_reserved() / self.total_memory
        available_ratio = self.available_memory_ratio - current_reserved
        
        # í• ë‹¹ëŸ‰ ê²°ì • - ë¦¬ë¯¸íŠ¸ ì ‘ê·¼ ë¬¸ì œ í•´ê²°
        if profile.stable_mode:
            # ì•ˆì • ëª¨ë“œ: ê³ ì • í• ë‹¹
            target_allocation = profile.base_allocation
            self.logger.info(f"ğŸ”’ {profile.model_name}: ì•ˆì • ëª¨ë“œ - ê³ ì • í• ë‹¹ {target_allocation:.1%}")
        else:
            # ë™ì  ëª¨ë“œ: ìƒí™©ì— ë”°ë¼ ì¡°ì • (ë” ë³´ìˆ˜ì  ì ‘ê·¼)
            if dynamic_boost and available_ratio > 0.6:  # 0.5 â†’ 0.6ìœ¼ë¡œ ìƒí–¥
                # ì—¬ìœ  ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë©´ í™•ì¥ í• ë‹¹ (ë” ë³´ìˆ˜ì )
                target_allocation = min(profile.max_allocation, available_ratio * 0.7)  # 0.8 â†’ 0.7ë¡œ ê°ì†Œ
                self.logger.info(f"âš¡ {profile.model_name}: ë™ì  ë¶€ìŠ¤íŠ¸ - í™•ì¥ í• ë‹¹ {target_allocation:.1%}")
            elif available_ratio > 0.3:  # ìµœì†Œ ì—¬ìœ ë¶„ ì²´í¬ ì¶”ê°€
                # ê¸°ë³¸ í• ë‹¹ (ë” ë³´ìˆ˜ì )
                target_allocation = min(profile.base_allocation, available_ratio * 0.5)  # 0.6 â†’ 0.5ë¡œ ê°ì†Œ
                self.logger.info(f"ğŸ”§ {profile.model_name}: ê¸°ë³¸ í• ë‹¹ {target_allocation:.1%}")
            else:
                # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ìµœì†Œ í• ë‹¹
                target_allocation = min(profile.min_allocation, available_ratio * 0.8)
                self.logger.warning(f"âš ï¸ {profile.model_name}: ë©”ëª¨ë¦¬ ë¶€ì¡± - ìµœì†Œ í• ë‹¹ {target_allocation:.1%}")
        
        # ìµœì†Œ/ìµœëŒ€ ì œí•œ ì ìš©
        target_allocation = max(profile.min_allocation, target_allocation)
        target_allocation = min(profile.max_allocation, target_allocation)
        
        # PyTorch ë©”ëª¨ë¦¬ ì„¤ì •
        try:
            if target_allocation > 0:
                # ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
                torch.cuda.empty_cache()
                gc.collect()
                
                # ë©”ëª¨ë¦¬ í• ë‹¹ëŸ‰ ì„¤ì • (ì‹¤ì œ í• ë‹¹ì€ ëª¨ë¸ ë¡œë”© ì‹œ)
                self.logger.info(f"ğŸ¯ ìµœì¢… í• ë‹¹: {target_allocation:.1%} ({target_allocation * self.total_memory_gb:.1f}GB)")
                
        except Exception as e:
            self.logger.warning(f"ë©”ëª¨ë¦¬ í• ë‹¹ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì•ˆì „í•œ ê¸°ë³¸ê°’ìœ¼ë¡œ fallback
            target_allocation = profile.min_allocation
        
        return target_allocation
    
    def _release_model_memory(self, model_name: str):
        """ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ"""
        if model_name in self.model_memory_usage:
            del self.model_memory_usage[model_name]
        
        if model_name in self.loaded_models:
            del self.loaded_models[model_name]
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
    
    def get_memory_status(self) -> Dict[str, float]:
        """í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ ë°˜í™˜"""
        if not torch.cuda.is_available():
            return {"error": "CUDA not available"}
        
        allocated_bytes = torch.cuda.memory_allocated()
        reserved_bytes = torch.cuda.memory_reserved()
        total_bytes = self.total_memory
        
        return {
            "total_gb": total_bytes / (1024**3),
            "allocated_gb": allocated_bytes / (1024**3),
            "reserved_gb": reserved_bytes / (1024**3),
            "available_gb": (total_bytes - reserved_bytes) / (1024**3),
            "utilization_percent": (allocated_bytes / total_bytes) * 100,
            "active_models": list(self.model_memory_usage.keys()),
            "model_allocations": self.model_memory_usage.copy()
        }
    
    def optimize_for_learning(self) -> bool:
        """í•™ìŠµ ìµœì í™” ëª¨ë“œ í™œì„±í™”"""
        try:
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
            
            # í•™ìŠµ ì „ìš© ë©”ëª¨ë¦¬ í’€ ì„¤ì •
            memory_status = self.get_memory_status()
            available_memory = memory_status.get("available_gb", 0)
            
            if available_memory > 4.0:  # 4GB ì´ìƒ ì—¬ìœ 
                self.logger.info(f"ğŸš€ í•™ìŠµ ìµœì í™” ëª¨ë“œ í™œì„±í™” - ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬: {available_memory:.1f}GB")
                return True
            else:
                self.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ í•™ìŠµ ìµœì í™” ì œí•œ - ì‚¬ìš© ê°€ëŠ¥: {available_memory:.1f}GB")
                return False
                
        except Exception as e:
            self.logger.error(f"í•™ìŠµ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def emergency_cleanup(self):
        """ë¹„ìƒ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        self.logger.warning("ğŸš¨ ë¹„ìƒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰")
        
        # ëª¨ë“  ëª¨ë¸ í•´ì œ
        for model_name in list(self.loaded_models.keys()):
            self._release_model_memory(model_name)
        
        # ê°•ì œ ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        gc.collect()
        self.logger.info("âœ… ë¹„ìƒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

# ì „ì—­ GPU ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
_gpu_manager = None

def get_gpu_manager() -> DynamicGPUManager:
    """ì „ì—­ GPU ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _gpu_manager
    if _gpu_manager is None:
        _gpu_manager = DynamicGPUManager()
    return _gpu_manager

# í¸ì˜ í•¨ìˆ˜ë“¤
def allocate_gpu_memory(model_name: str, dynamic_boost: bool = False):
    """GPU ë©”ëª¨ë¦¬ í• ë‹¹ (ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €)"""
    return get_gpu_manager().allocate_memory(model_name, dynamic_boost)

def get_gpu_status() -> Dict[str, float]:
    """í˜„ì¬ GPU ìƒíƒœ ì¡°íšŒ"""
    return get_gpu_manager().get_memory_status()

def optimize_gpu_for_learning() -> bool:
    """í•™ìŠµìš© GPU ìµœì í™”"""
    return get_gpu_manager().optimize_for_learning()

def emergency_gpu_cleanup():
    """ë¹„ìƒ GPU ë©”ëª¨ë¦¬ ì •ë¦¬"""
    get_gpu_manager().emergency_cleanup()