ğŸš€ Red Heart AI í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘
===========================================
[0;34m[INFO][0m ì‘ì—… ë””ë ‰í† ë¦¬: /mnt/c/large_project/linux_red_heart
[0;34m[INFO][0m Red Heart AI í†µí•© í™˜ê²½ ìƒíƒœ í™•ì¸ ì¤‘...
[0;32m[SUCCESS][0m âœ… red_heart_env ê°€ìƒí™˜ê²½ ì¡´ì¬
[0;32m[SUCCESS][0m âœ… faiss-test conda í™˜ê²½ ì¡´ì¬
[0;32m[SUCCESS][0m âœ… FAISS ì„¤ì¹˜ë¨ ë° ì‘ë™ í™•ì¸
âœ… Red Heart AI í†µí•© í™˜ê²½ í™œì„±í™” ì™„ë£Œ
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (í•¨ê»˜ í™œì„±í™”ë¨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - í™˜ê²½ ë¶„ë¦¬: faissâ†’conda subprocess, ë‚˜ë¨¸ì§€â†’venv
[0;32m[SUCCESS][0m âœ… ì£¼ìš” íŒ¨í‚¤ì§€ (torch, transformers, numpy) ì„¤ì¹˜ë¨
[0;32m[SUCCESS][0m ğŸ‰ ëª¨ë“  í™˜ê²½ì´ ì´ë¯¸ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!
âœ… Red Heart AI í†µí•© í™˜ê²½ í™œì„±í™” ì™„ë£Œ
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (í•¨ê»˜ í™œì„±í™”ë¨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - í™˜ê²½ ë¶„ë¦¬: faissâ†’conda subprocess, ë‚˜ë¨¸ì§€â†’venv
[0;32m[SUCCESS][0m âœ… Red Heart AI í†µí•© í™˜ê²½ í™œì„±í™” ì™„ë£Œ
[0;32m[SUCCESS][0m    - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
[0;32m[SUCCESS][0m    - conda: faiss-test í™˜ê²½ ì¤€ë¹„ë¨
[0;32m[SUCCESS][0m    - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
[0;32m[SUCCESS][0m    - í™˜ê²½ ë¶„ë¦¬: faissâ†’conda subprocess, ë‚˜ë¨¸ì§€â†’venv
[0;34m[INFO][0m Red Heart AI í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘
[0;34m[INFO][0m í™˜ê²½ ë¶„ë¦¬: conda(faiss) + venv(transformers,torch)
[0;34m[INFO][0m Red Heart AI í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹œì‘...
[0;34m[INFO][0m ì‹¤í–‰ ëª¨ë“œ: unified-test
[0;34m[INFO][0m ğŸ§ª 800M í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ëª¨ë“œ...
ğŸ” [ì´ˆê¸°í™” ì‹œì‘ ì „] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 0.000GB (0.0%)
   ğŸ“¦ ì˜ˆì•½ë¨: 0.000GB
   ğŸ’š ì—¬ìœ : 8.000GB
   ğŸ”„ config.py ì¸¡ì •: 0.0%
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
   ğŸ§  GPU í…ì„œ: 0ê°œ, 0.000GB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.000GB
ğŸ” fast_init_mode = False
ğŸŒ ì „ì—­ ëª¨ë“ˆ ìˆœì°¨ ì´ˆê¸°í™” ì‹œì‘ - MasterMemoryOrchestrator ê´€ë¦¬
Device set to use cuda:0
Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.
Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cuda:0
Device set to use cuda:0
Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.
Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cuda:0
Device set to use cuda:0
Device set to use cuda:0
ì–¸ë¡œë“œ ìš”ì²­ëœ ëª¨ë¸ì´ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì—†ìŒ: semantic_analyzer
HierarchicalPatternStructure: PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì—†ìŒ (ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ êµ¬ì¡°)
HierarchicalPatternStructure: PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì—†ìŒ (ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ êµ¬ì¡°)
   âš ï¸ DSM ë“±ë¡ ìŠ¤í‚µ: neural_components (nn.Module ì¶”ì¶œ ì‹¤íŒ¨)
âš ï¸ í´ë˜ìŠ¤ 'AdvancedSurdAnalyzer' ëŒ€ì‹  'AdvancedSURDAnalyzer' ì‚¬ìš© (ìœ ì‚¬ë„ ê¸°ë°˜)
   âš ï¸ DSM ë“±ë¡ ìŠ¤í‚µ: surd_analyzer (nn.Module ì¶”ì¶œ ì‹¤íŒ¨)
âš ï¸ í´ë˜ìŠ¤ 'AdvancedBayesianInferenceModule' ëŒ€ì‹  'AdvancedBayesianInference' ì‚¬ìš© (ìœ ì‚¬ë„ ê¸°ë°˜)
   âš ï¸ DSM ë“±ë¡ ìŠ¤í‚µ: bayesian_engine (nn.Module ì¶”ì¶œ ì‹¤íŒ¨)
   âš ï¸ DSM ë“±ë¡ ìŠ¤í‚µ: llm_engine (nn.Module ì¶”ì¶œ ì‹¤íŒ¨)
   âš ï¸ DSM ë“±ë¡ ìŠ¤í‚µ: experience_database (nn.Module ì¶”ì¶œ ì‹¤íŒ¨)
   âš ï¸ DSM ë“±ë¡ ìŠ¤í‚µ: hierarchical_emotion (nn.Module ì¶”ì¶œ ì‹¤íŒ¨)
   âš ï¸ DSM ë“±ë¡ ìŠ¤í‚µ: usage_pattern_analyzer (nn.Module ì¶”ì¶œ ì‹¤íŒ¨)
âš ï¸ meta_integration ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedMetaIntegrationSystem), ìŠ¤í‚µ
âš ï¸ GPU ì‚¬ìš©ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤ (47.5%) - ë” ì ê·¹ì  ë¡œë”© í•„ìš”
âœ… ì „ì—­ ëª¨ë“ˆ ìˆœì°¨ ì´ˆê¸°í™” ì™„ë£Œ
ğŸ” [ì „ì—­ ëª¨ë“ˆ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 3.780GB (47.3%)
   ğŸ“¦ ì˜ˆì•½ë¨: 3.875GB
   ğŸ’š ì—¬ìœ : 4.220GB
   ğŸ”„ config.py ì¸¡ì •: 47.3%
   ğŸ§  GPU í…ì„œ: 1767ê°œ, 3.750GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50265, 1024] (torch.float32) - 196.3MB
      2. [54343, 768] (torch.float32) - 159.2MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [50265, 768] (torch.float32) - 147.3MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.095GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 3.807GB (at ì „ì—­ ëª¨ë“ˆ ì´ˆê¸°í™” í›„)
ğŸ” [ë°±ë³¸ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 5.501GB (68.8%)
   ğŸ“¦ ì˜ˆì•½ë¨: 5.629GB
   ğŸ’š ì—¬ìœ : 2.499GB
   ğŸ”„ config.py ì¸¡ì •: 68.8%
   ğŸ§  GPU í…ì„œ: 2011ê°œ, 5.435GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.128GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 5.501GB (at ë°±ë³¸ ì´ˆê¸°í™” í›„)
ğŸ” [ìŠ¤ì™‘ ë§¤ë‹ˆì € ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 5.501GB (68.8%)
   ğŸ“¦ ì˜ˆì•½ë¨: 5.629GB
   ğŸ’š ì—¬ìœ : 2.499GB
   ğŸ”„ config.py ì¸¡ì •: 68.8%
   ğŸ§  GPU í…ì„œ: 2011ê°œ, 5.435GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.128GB
ğŸ“‹ í—¤ë“œ ì„ ë“±ë¡ ë³´ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨
ğŸ” [í—¤ë“œ í˜¸í™˜ì„± ë§¤ë‹ˆì € ìƒì„± í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 5.501GB (68.8%)
   ğŸ“¦ ì˜ˆì•½ë¨: 5.629GB
   ğŸ’š ì—¬ìœ : 2.499GB
   ğŸ”„ config.py ì¸¡ì •: 68.8%
   ğŸ§  GPU í…ì„œ: 2011ê°œ, 5.435GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.128GB
ğŸ“‹ í—¤ë“œ ì„ ë“±ë¡ ë³´ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨
ğŸš¨ í—¤ë“œ ì´ˆê¸°í™” ì‹œì‘ - ë©”ëª¨ë¦¬ í­ë°œ ì˜ì‹¬ êµ¬ê°„!
ğŸ” head_compatibility_manager = <class 'head_compatibility_interface.HeadCompatibilityManager'>
ğŸ” head_compatibility_manager.initialized = False
ğŸ” initialize_all_heads() í˜¸ì¶œ ì§ì „...
âš ï¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì£¼ì˜: 69.7% (85% ì´ˆê³¼)
ğŸ“Š ì¶”ê°€ í™œìš© ê°€ëŠ¥: í˜„ì¬ 72.4% (ëª©í‘œ 82%)
ğŸ” initialize_all_heads() í˜¸ì¶œ ì™„ë£Œ!
ğŸš¨ í—¤ë“œ ì´ˆê¸°í™” ì™„ë£Œ - ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì¤‘...
ğŸ” [ëª¨ë“  í—¤ë“œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 5.794GB (72.4%)
   ğŸ“¦ ì˜ˆì•½ë¨: 5.941GB
   ğŸ’š ì—¬ìœ : 2.205GB
   ğŸ”„ config.py ì¸¡ì •: 72.4%
   ğŸ§  GPU í…ì„œ: 2056ê°œ, 5.727GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.147GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 5.794GB (at ëª¨ë“  í—¤ë“œ ì´ˆê¸°í™” í›„)
ğŸ” [ì‹œë„ˆì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 5.794GB (72.4%)
   ğŸ“¦ ì˜ˆì•½ë¨: 5.941GB
   ğŸ’š ì—¬ìœ : 2.205GB
   ğŸ”„ config.py ì¸¡ì •: 72.4%
   ğŸ§  GPU í…ì„œ: 2056ê°œ, 5.727GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.147GB
ğŸ” [í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 7.516GB (94.0%)
   ğŸ“¦ ì˜ˆì•½ë¨: 7.697GB
   ğŸ’š ì—¬ìœ : 0.484GB
   ğŸ”„ config.py ì¸¡ì •: 94.0%
   ğŸ§  GPU í…ì„œ: 2300ê°œ, 7.412GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50265, 1024] (torch.float32) - 196.3MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.181GB
   âš ï¸ WARNING: ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (94.0%)
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 7.516GB (at í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„)
ğŸ” [íŒ¨í„´ ë¶„ì„ê¸° ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 7.516GB (94.0%)
   ğŸ“¦ ì˜ˆì•½ë¨: 7.697GB
   ğŸ’š ì—¬ìœ : 0.484GB
   ğŸ”„ config.py ì¸¡ì •: 94.0%
   ğŸ§  GPU í…ì„œ: 2300ê°œ, 7.412GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50265, 1024] (torch.float32) - 196.3MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.181GB
   âš ï¸ WARNING: ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (94.0%)
ğŸ“‹ í—¤ë“œ ì„ ë“±ë¡ ë³´ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨
[DSM] ë“±ë¡ë˜ì§€ ì•Šì€ í—¤ë“œ ìš”ì²­: emotion_empathy_head
[DSM] í˜„ì¬ keys(models): []
í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ë“±ë¡ë˜ì§€ ì•Šì€ í—¤ë“œ: emotion_empathy_head
ğŸ˜¨ ìƒì„¸ ì—ëŸ¬ ìŠ¤íƒ:
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 1611, in train_unified_system
    await self._load_active_heads(active_heads)
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 1687, in _load_active_heads
    await self.swap_manager.load_head_to_gpu(head_type.value)
  File "/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py", line 554, in load_head_to_gpu
    raise ValueError(f"ë“±ë¡ë˜ì§€ ì•Šì€ í—¤ë“œ: {head_name}")
ValueError: ë“±ë¡ë˜ì§€ ì•Šì€ í—¤ë“œ: emotion_empathy_head

ğŸ” ì—ëŸ¬ íƒ€ì…: ValueError
ğŸ“ ì—íŸ¼í¬: 1/1, ë°°ì¹˜: 0
Python í†µí•© í•™ìŠµ ì˜¤ë¥˜: ë“±ë¡ë˜ì§€ ì•Šì€ í—¤ë“œ: emotion_empathy_head
ğŸ˜¨ ìƒì„¸ ì—ëŸ¬ ìŠ¤íƒ:
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 1773, in _run_python_training
    await self.learning_system.train_unified_system(
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 1611, in train_unified_system
    await self._load_active_heads(active_heads)
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 1687, in _load_active_heads
    await self.swap_manager.load_head_to_gpu(head_type.value)
  File "/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py", line 554, in load_head_to_gpu
    raise ValueError(f"ë“±ë¡ë˜ì§€ ì•Šì€ í—¤ë“œ: {head_name}")
ValueError: ë“±ë¡ë˜ì§€ ì•Šì€ í—¤ë“œ: emotion_empathy_head

ğŸ” ì—ëŸ¬ íƒ€ì…: ValueError
ğŸ“ num_epochs: 1, num_batches: 1
ğŸ” [ì´ˆê¸°í™” ì‹œì‘ ì „] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 7.516GB (94.0%)
   ğŸ“¦ ì˜ˆì•½ë¨: 7.697GB
   ğŸ’š ì—¬ìœ : 0.484GB
   ğŸ”„ config.py ì¸¡ì •: 94.0%
   ğŸ§  GPU í…ì„œ: 2300ê°œ, 7.412GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50265, 1024] (torch.float32) - 196.3MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.181GB
   âš ï¸ WARNING: ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (94.0%)
ğŸ” fast_init_mode = False
ğŸŒ ì „ì—­ ëª¨ë“ˆ ìˆœì°¨ ì´ˆê¸°í™” ì‹œì‘ - MasterMemoryOrchestrator ê´€ë¦¬
[GPU BLOCKING] âŒ transformers.models.auto.tokenization_auto_opus-mt-ko-en í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
âš ï¸ ë©”ëª¨ë¦¬ í™•ë³´ ì‹¤íŒ¨í–ˆì§€ë§Œ ì„ íƒ ëª¨ë“ˆì´ë¯€ë¡œ ê³„ì† ì§„í–‰: transformers.models.auto.tokenization_auto_opus-mt-ko-en
[GPU BLOCKING] âŒ translator_opus-mt-ko-en í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
âš ï¸ ë©”ëª¨ë¦¬ í™•ë³´ ì‹¤íŒ¨í–ˆì§€ë§Œ ì„ íƒ ëª¨ë“ˆì´ë¯€ë¡œ ê³„ì† ì§„í–‰: translator_opus-mt-ko-en
âš ï¸ translator ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: LocalTranslator), ìŠ¤í‚µ
[ì–¸ë¡œë“œ ë¶ˆê°€] ë” ì´ìƒ ì–¸ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤
[DSM] GPU ì‚¬ìš©ë¥  94.0%ë¡œ ëª©í‘œ 85.0% ë‹¬ì„± ì‹¤íŒ¨
ìŠ¤ì™‘ ê³µê°„ ë¶€ì¡±: temp_model_1754754909 (í•„ìš”: 1000MB, í™•ë³´: FalseMB)
[GPU BLOCKING] âŒ transformers.pipelines.base_emotion-english-distilroberta-base í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
âš ï¸ ë©”ëª¨ë¦¬ í™•ë³´ ì‹¤íŒ¨í–ˆì§€ë§Œ ì„ íƒ ëª¨ë“ˆì´ë¯€ë¡œ ê³„ì† ì§„í–‰: transformers.pipelines.base_emotion-english-distilroberta-base
[GPU BLOCKING] âŒ transformers.pipelines_emotion-english-distilroberta-base í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
âš ï¸ ë©”ëª¨ë¦¬ í™•ë³´ ì‹¤íŒ¨í–ˆì§€ë§Œ ì„ íƒ ëª¨ë“ˆì´ë¯€ë¡œ ê³„ì† ì§„í–‰: transformers.pipelines_emotion-english-distilroberta-base
Device set to use cpu
Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.
[GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
[GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì¤‘ ì˜¤ë¥˜: [GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
ë‹¤êµ­ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: [GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì¤‘ ì˜¤ë¥˜: [GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: [GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì¤‘ ì˜¤ë¥˜: [GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
AdvancedEmotionAnalyzer ì´ˆê¸°í™” ì‹¤íŒ¨: [GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì¤‘ ì˜¤ë¥˜: [GPU BLOCKING] âŒ emotion_analyzer_emotion-english-distilroberta-base í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ (30.0ì´ˆ)
âš ï¸ ëŒ€í˜• ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨í–ˆì§€ë§Œ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ë¡œ ê³„ì† ì§„í–‰
run_learning.sh: line 240: 26676 Killed                  python unified_system_main.py --mode test "$@"
[1;33m[WARNING][0m í•™ìŠµ ì¤‘ë‹¨ë¨
[0;34m[INFO][0m í•™ìŠµ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...
[0;34m[INFO][0m GPU ë©”ëª¨ë¦¬ ì •ë¦¬...
[0;32m[SUCCESS][0m ì •ë¦¬ ì™„ë£Œ
[0;34m[INFO][0m í•™ìŠµ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...
[0;34m[INFO][0m GPU ë©”ëª¨ë¦¬ ì •ë¦¬...
[0;32m[SUCCESS][0m ì •ë¦¬ ì™„ë£Œ
