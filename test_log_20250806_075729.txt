🚀 Red Heart AI 통합 학습 시스템 시작
===========================================
[0;34m[INFO][0m 작업 디렉토리: /mnt/c/large_project/linux_red_heart
[0;34m[INFO][0m Red Heart AI 통합 환경 상태 확인 중...
[0;32m[SUCCESS][0m ✅ red_heart_env 가상환경 존재
[0;32m[SUCCESS][0m ✅ faiss-test conda 환경 존재
[0;32m[SUCCESS][0m ✅ FAISS 설치됨 및 작동 확인
✅ Red Heart AI 통합 환경 활성화 완료
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (함께 활성화됨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;32m[SUCCESS][0m ✅ 주요 패키지 (torch, transformers, numpy) 설치됨
[0;32m[SUCCESS][0m 🎉 모든 환경이 이미 준비되어 있습니다!
✅ Red Heart AI 통합 환경 활성화 완료
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (함께 활성화됨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;32m[SUCCESS][0m ✅ Red Heart AI 통합 환경 활성화 완료
[0;32m[SUCCESS][0m    - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
[0;32m[SUCCESS][0m    - conda: faiss-test 환경 준비됨
[0;32m[SUCCESS][0m    - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
[0;32m[SUCCESS][0m    - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;34m[INFO][0m Red Heart AI 통합 학습 시스템 시작
[0;34m[INFO][0m 환경 분리: conda(faiss) + venv(transformers,torch)
[0;34m[INFO][0m Red Heart AI 통합 학습 시스템 실행 시작...
[0;34m[INFO][0m 실행 모드: unified-test
[0;34m[INFO][0m 🧪 800M 통합 시스템 테스트 모드...
🔍 [초기화 시작 전] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 0.000GB (0.0%)
   📦 예약됨: 0.000GB
   💚 여유: 8.000GB
   🔄 config.py 측정: 0.0%
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
   🧠 GPU 텐서: 0개, 0.000GB
   🗂️ 캐시된 메모리: 0.000GB
🔍 fast_init_mode = False
🌐 전역 모듈 순차 초기화 시작 - MasterMemoryOrchestrator 관리
Device set to use cuda:0
Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.
Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cuda:0
Device set to use cuda:0
Device set to use cuda:0
언로드 요청된 모델이 레지스트리에 없음: semantic_analyzer
⚠️ 클래스 'AdvancedSurdAnalyzer' 대신 'AdvancedSURDAnalyzer' 사용 (유사도 기반)
⚠️ 클래스 'AdvancedBayesianInferenceModule' 대신 'AdvancedBayesianInference' 사용 (유사도 기반)
⚠️ meta_integration 이미 등록됨 (동일 타입: AdvancedMetaIntegrationSystem), 스킵
⚠️ GPU 사용률이 낮습니다 (51.2%) - 더 적극적 로딩 필요
✅ 전역 모듈 순차 초기화 완료
🔍 [전역 모듈 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 4.094GB (51.2%)
   📦 예약됨: 4.191GB
   💚 여유: 3.906GB
   🔄 config.py 측정: 51.2%
   🧠 GPU 텐서: 2072개, 4.064GB
   📋 큰 텐서 TOP 5:
      1. [50265, 1024] (torch.float32) - 196.3MB
      2. [54343, 768] (torch.float32) - 159.2MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [50265, 768] (torch.float32) - 147.3MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.097GB
   🔝 새로운 Peak 메모리: 4.098GB (at 전역 모듈 초기화 후)
🔍 [백본 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.815GB (72.7%)
   📦 예약됨: 5.945GB
   💚 여유: 2.184GB
   🔄 config.py 측정: 72.7%
   🧠 GPU 텐서: 2316개, 5.749GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.130GB
   🔝 새로운 Peak 메모리: 5.815GB (at 백본 초기화 후)
🔍 [스왑 매니저 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.815GB (72.7%)
   📦 예약됨: 5.945GB
   💚 여유: 2.184GB
   🔄 config.py 측정: 72.7%
   🧠 GPU 텐서: 2316개, 5.749GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.130GB
🔍 [헤드 호환성 매니저 생성 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.815GB (72.7%)
   📦 예약됨: 5.945GB
   💚 여유: 2.184GB
   🔄 config.py 측정: 72.7%
   🧠 GPU 텐서: 2316개, 5.749GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.130GB
🚨 헤드 초기화 시작 - 메모리 폭발 의심 구간!
🔍 head_compatibility_manager = <class 'head_compatibility_interface.HeadCompatibilityManager'>
🔍 head_compatibility_manager.initialized = False
🔍 initialize_all_heads() 호출 직전...
📊 추가 활용 가능: 현재 76.4% (목표 82%)
🔍 initialize_all_heads() 호출 완료!
🚨 헤드 초기화 완료 - 메모리 상태 확인 중...
🔍 [모든 헤드 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 6.109GB (76.4%)
   📦 예약됨: 6.258GB
   💚 여유: 1.891GB
   🔄 config.py 측정: 76.4%
   🧠 GPU 텐서: 2361개, 6.041GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.149GB
   🔝 새로운 Peak 메모리: 6.109GB (at 모든 헤드 초기화 후)
🚨 긴급 GPU 메모리 정리 시작
🚨 초기 GPU 메모리: 76.4% 사용 중
🔍 실제 GPU 상주 모델 전면 스캔 시작...
🔍 PyTorch 실제 메모리: 할당=6.11GB, 예약=6.26GB
🗑️ 총 350개 모델 중 CRITICAL 외 모든 모델 언로드 시작
🧹 최종 전면 메모리 정리 시작...
모델 가비지 컬렉션 감지: discovered_ModuleDict_12MB_140491584829920 - 레지스트리 정리
모델 가비지 컬렉션 감지: discovered_MetaIntegrationNetwork_23MB_140491573570080 - 레지스트리 정리
🧹 가비지 컬렉션 1회: 979개 객체 정리
🧹 가비지 컬렉션 2회: 0개 객체 정리
🧹 가비지 컬렉션 3회: 0개 객체 정리
🚀 CUDA 캐시 완전 정리 완료
✅ 긴급 정리 완료:
   📊 메모리 사용률: 76.4% → 76.1% (+0.3%)
   🗑️ 언로드된 모델: 0개
   💾 해제된 메모리: 0MB
🔍 [자동 메모리 정리 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 6.085GB (76.1%)
   📦 예약됨: 6.258GB
   💚 여유: 1.915GB
   🔄 config.py 측정: 76.1%
   🧠 GPU 텐서: 2312개, 6.018GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.173GB
🔍 [시너지 시스템 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 6.085GB (76.1%)
   📦 예약됨: 6.258GB
   💚 여유: 1.915GB
   🔄 config.py 측정: 76.1%
   🧠 GPU 텐서: 2312개, 6.018GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.173GB
🔍 [학습 시스템 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 7.807GB (97.6%)
   📦 예약됨: 7.992GB
   💚 여유: 0.193GB
   🔄 config.py 측정: 97.6%
   🧠 GPU 텐서: 2556개, 7.703GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50265, 1024] (torch.float32) - 196.3MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   🗂️ 캐시된 메모리: 0.186GB
   ⚠️ WARNING: 높은 메모리 사용률 (97.6%)
   🔝 새로운 Peak 메모리: 7.807GB (at 학습 시스템 초기화 후)
🔍 [패턴 분석기 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 7.807GB (97.6%)
   📦 예약됨: 7.992GB
   💚 여유: 0.193GB
   🔄 config.py 측정: 97.6%
   🧠 GPU 텐서: 2556개, 7.703GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50265, 1024] (torch.float32) - 196.3MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   🗂️ 캐시된 메모리: 0.186GB
   ⚠️ WARNING: 높은 메모리 사용률 (97.6%)
Python 통합 학습 오류: 'UnifiedLearningSystem' object has no attribute '_optimizers_initialized'
😨 상세 에러 스택:
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 1492, in _run_python_training
    await self.learning_system.train_unified_system(
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 1425, in train_unified_system
    if not self._optimizers_initialized:
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'UnifiedLearningSystem' object has no attribute '_optimizers_initialized'

🔍 에러 타입: AttributeError
📍 num_epochs: 1, num_batches: 1
🔍 [초기화 시작 전] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 7.807GB (97.6%)
   📦 예약됨: 7.992GB
   💚 여유: 0.193GB
   🔄 config.py 측정: 97.6%
   🧠 GPU 텐서: 2556개, 7.703GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50265, 1024] (torch.float32) - 196.3MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   🗂️ 캐시된 메모리: 0.186GB
   ⚠️ WARNING: 높은 메모리 사용률 (97.6%)
🔍 fast_init_mode = False
🌐 전역 모듈 순차 초기화 시작 - MasterMemoryOrchestrator 관리
⚠️ GPU 메모리 부족 - 정리 시작 (사용률: 97.6%, 여유: 7.5625MB)
🚨 긴급 GPU 메모리 정리 시작
🚨 초기 GPU 메모리: 97.6% 사용 중
🔍 실제 GPU 상주 모델 전면 스캔 시작...
🔍 PyTorch 실제 메모리: 할당=7.81GB, 예약=7.99GB
🗑️ 총 435개 모델 중 CRITICAL 외 모든 모델 언로드 시작
🧹 최종 전면 메모리 정리 시작...
🧹 가비지 컬렉션 1회: 378개 객체 정리
🧹 가비지 컬렉션 2회: 0개 객체 정리
🧹 가비지 컬렉션 3회: 0개 객체 정리
🚀 CUDA 캐시 완전 정리 완료
✅ 긴급 정리 완료:
   📊 메모리 사용률: 97.6% → 97.6% (+0.0%)
   🗑️ 언로드된 모델: 0개
   💾 해제된 메모리: 0MB
⚠️ 메모리 사용률이 여전히 높음 - 추가 조치 필요
❌ GPU 메모리 공간 확보 실패 - 필요: 400MB, 여유: 7.5625MB
[GPU BLOCKING] ❌ transformers.models.auto.tokenization_auto_opus-mt-ko-en 할당 중 오류: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)
⚠️ 메모리 확보 실패했지만 선택 모듈이므로 계속 진행: transformers.models.auto.tokenization_auto_opus-mt-ko-en
[GPU BLOCKING] ❌ translator_opus-mt-ko-en 할당 중 오류: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)
⚠️ 메모리 확보 실패했지만 선택 모듈이므로 계속 진행: translator_opus-mt-ko-en
[경고] 여전히 공간 부족: 7.5625MB < 900MB
긴급 메모리 정리 시작!
긴급 정리 완료: 0개 모델 언로드
스왑 공간 부족: temp_model_1754435119 (필요: 900MB, 확보: FalseMB)
비동기 실행 타임아웃
❌ 모듈 translator 로딩 실패: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)
🚨 translator 로딩 실패 상세 스택:
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 1406, in run_training_pipeline
    raise Exception("Python 통합 학습 시스템 실행 실패")
Exception: Python 통합 학습 시스템 실행 실패

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 1058, in _load_single_module
    await self.memory_manager.request_gpu(
  File "/mnt/c/large_project/linux_red_heart/workflow_aware_memory_manager.py", line 471, in request_gpu
    from dynamic_swap_manager import get_swap_manager
ImportError: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)

   ❌ translator 초기화 실패: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)
❌ 전역 모듈 초기화 실패: 필수 모듈 translator 초기화 실패: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)
❌ 스택 트레이스:
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 1406, in run_training_pipeline
    raise Exception("Python 통합 학습 시스템 실행 실패")
Exception: Python 통합 학습 시스템 실행 실패

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 824, in _initialize_global_modules_sequential
    module_instance = await asyncio.wait_for(
                      ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/tasks.py", line 520, in wait_for
    return await fut
           ^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 1058, in _load_single_module
    await self.memory_manager.request_gpu(
  File "/mnt/c/large_project/linux_red_heart/workflow_aware_memory_manager.py", line 471, in request_gpu
    from dynamic_swap_manager import get_swap_manager
ImportError: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 1263, in _initialize_core_components
    await self._initialize_global_modules_sequential()
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 873, in _initialize_global_modules_sequential
    raise RuntimeError(f"필수 모듈 {spec['name']} 초기화 실패: {e}")
RuntimeError: 필수 모듈 translator 초기화 실패: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)

자동 복구 실패: 전역 모듈 초기화 실패 - 시스템 중단: 필수 모듈 translator 초기화 실패: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)
============================================================
🚀 Red Heart AI 통합 시스템 (800M 파라미터)
============================================================
모드: test
시작 시간: 2025-08-06 07:58:22
------------------------------------------------------------
🔧 klue/bert-base 모델: 안정성 보장을 위한 15.0% 할당
📋 Transformer 모델: 최적화된 배치 처리 방식 활성화
[08:05:18] ✅ 시스템 초기화 완료
[08:05:18] 🧪 테스트 모드 시작...

============================================================
🚨 필수 모듈 translator 로딩 실패!
============================================================
에러: cannot import name 'get_swap_manager' from 'dynamic_swap_manager' (/mnt/c/large_project/linux_red_heart/dynamic_swap_manager.py)
모듈 경로: local_translator.LocalTranslator
============================================================

[08:05:24] ❌ 테스트 모드 실패
스왑 대기 타임아웃: temp_model_1754435119 (최대 대기 시간 30.0초 초과)
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/llama_cpp/lib/libggml-base.so(+0x16ceb)[0x7fc6e3962ceb]
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/llama_cpp/lib/libggml-base.so(ggml_print_backtrace+0x21f)[0x7fc6e396314f]
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/llama_cpp/lib/libggml-base.so(+0x2846f)[0x7fc6e397446f]
/lib/x86_64-linux-gnu/libstdc++.so.6(+0xbb0da)[0x7fc782abb0da]
/lib/x86_64-linux-gnu/libstdc++.so.6(_ZSt10unexpectedv+0x0)[0x7fc782aa5a55]
/lib/x86_64-linux-gnu/libstdc++.so.6(+0xa592a)[0x7fc782aa592a]
/lib/x86_64-linux-gnu/libgcc_s.so.1(+0x22ce5)[0x7fc7f87bdce5]
/lib/x86_64-linux-gnu/libgcc_s.so.1(_Unwind_ForcedUnwind+0x130)[0x7fc7f87be3c0]
/lib/x86_64-linux-gnu/libc.so.6(+0xa57a4)[0x7fc7f8ea57a4]
/lib/x86_64-linux-gnu/libc.so.6(pthread_exit+0x42)[0x7fc7f8e9dd22]
python(PyThread_create_key+0x0)[0x4bb41d]
python[0x4a4ecf]
python(PyEval_RestoreThread+0x1e)[0x5fbdfe]
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/lib/libtorch_python.so(+0x58fde5)[0x7fc7cd928de5]
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/lib/libtorch_python.so(+0x5dad87)[0x7fc7cd973d87]
python[0x5513f8]
python(PyObject_Vectorcall+0x35)[0x549985]
python(_PyEval_EvalFrameDefault+0xadf)[0x5d6b2f]
python[0x54cacd]
python(_PyEval_EvalFrameDefault+0x4cc6)[0x5dad16]
python[0x66bca9]
/usr/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so(+0x9d44)[0x7fc7f87dfd44]
/usr/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so(+0x9b5b)[0x7fc7f87dfb5b]
python(_PyObject_MakeTpCall+0x75)[0x548f85]
python[0x6a4abc]
python[0x581bcd]
python(_PyEval_EvalFrameDefault+0x4cc6)[0x5dad16]
python[0x54cb32]
python(_PyEval_EvalFrameDefault+0x4cc6)[0x5dad16]
python[0x54cb32]
python[0x6f80dc]
python[0x6b931c]
/lib/x86_64-linux-gnu/libc.so.6(+0x9caa4)[0x7fc7f8e9caa4]
/lib/x86_64-linux-gnu/libc.so.6(+0x129c3c)[0x7fc7f8f29c3c]
terminate called without an active exception
run_learning.sh: line 240: 149017 Aborted                 (core dumped) python unified_system_main.py --mode test "$@"
[0;34m[INFO][0m 학습 시스템 정리 중...
[0;34m[INFO][0m GPU 메모리 정리...
[0;32m[SUCCESS][0m 정리 완료
