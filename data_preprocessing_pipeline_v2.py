#!/usr/bin/env python3
"""
Red Heart AI ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ v2
- sentence-transformersë¥¼ í†µí•œ ì‹¤ì œ ì„ë² ë”© ìƒì„±
- LLM ê¸°ë°˜ ì™„ì „í•œ ë©”íŠ¸ë¦­ ìƒì„± (ë”ë¯¸ ë°ì´í„° ì œê±°)
- parsed_raw_datasets.json í™œìš©
- í”„ë¡œì íŠ¸ ê·œì¹™ ì¤€ìˆ˜: fallback/simplification ì—†ìŒ
"""

import os
import json
import torch
import numpy as np
import logging
import gc
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
from datetime import datetime
from sentence_transformers import SentenceTransformer

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from llm_module.advanced_llm_engine import (
    LLMRequest, LLMResponse, 
    TaskComplexity,
    AdvancedLLMEngine
)
from config import ADVANCED_CONFIG, get_device

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('RedHeart.DataPreprocessingV2')

@dataclass
class EnrichedDataPoint:
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° í¬ì¸íŠ¸"""
    text: str
    original_label: str
    
    # LLMì´ ìƒì„±í•œ enriched ë°ì´í„°
    emotion_vector: List[float]      # 7ì°¨ì› ê°ì • ë²¡í„°
    regret_factor: float            # í›„íšŒ ì§€ìˆ˜
    bentham_scores: Dict[str, float]  # ë²¤ë‹´ ì¾Œë½ ê³„ì‚°
    surd_metrics: Dict[str, float]    # SURD ë¶„ì„
    context_embedding: List[float]     # 768ì°¨ì› ë¬¸ë§¥ ì„ë² ë”©
    
    # ë©”íƒ€ë°ì´í„°
    processing_time: float
    llm_confidence: float
    timestamp: str
    source: str  # ë°ì´í„° ì¶œì²˜

class ImprovedDataPreprocessor:
    """ê°œì„ ëœ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ - í”„ë¡œì íŠ¸ ê·œì¹™ ì™„ì „ ì¤€ìˆ˜"""
    
    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        ì´ˆê¸°í™”
        Args:
            model_name: sentence-transformers ëª¨ë¸ëª…
        """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"ë””ë°”ì´ìŠ¤: {self.device}")
        
        # Sentence Transformer ë¡œë“œ
        logger.info(f"Loading sentence transformer: {model_name}")
        self.sentence_model = SentenceTransformer(model_name, device=self.device)
        
        # LLM ì—”ì§„ ì´ˆê¸°í™”
        self.llm_engine = None
        self.is_llm_initialized = False
        
        logger.info("âœ… ê°œì„ ëœ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def initialize_llm(self):
        """LLM ì´ˆê¸°í™”"""
        if self.is_llm_initialized:
            logger.info("LLMì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŒ")
            return
        
        logger.info("ğŸ”„ LLM ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        
        self.llm_engine = AdvancedLLMEngine()
        self.is_llm_initialized = True
        
        logger.info("âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ")
    
    def generate_context_embedding(self, text: str) -> List[float]:
        """
        Sentence-Transformersë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ ì„ë² ë”© ìƒì„±
        
        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸
            
        Returns:
            768ì°¨ì› ì„ë² ë”© ë²¡í„°
        """
        with torch.no_grad():
            embedding = self.sentence_model.encode(text, convert_to_tensor=False)
        return embedding.tolist()
    
    def analyze_emotions_with_llm(self, text: str) -> Dict[str, Any]:
        """
        LLMì„ í†µí•œ ê°ì • ë¶„ì„
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼
        """
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ì„¸ìš”. ê° ê°ì •ì„ 0-1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.
ëª¨ë“  ê°ì •ì˜ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: {text[:500]}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{
    "joy": 0.x,
    "sadness": 0.x,
    "anger": 0.x,
    "fear": 0.x,
    "surprise": 0.x,
    "disgust": 0.x,
    "trust": 0.x
}}"""
        
        request = LLMRequest(
            prompt=prompt,
            task_type="emotion_analysis",
            complexity=TaskComplexity.MODERATE
        )
        response = self.llm_engine.generate_sync(request)
        
        # JSON íŒŒì‹±
        import re
        json_match = re.search(r'\{[^}]+\}', response.generated_text)
        if not json_match:
            raise ValueError("LLMì´ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ì•ŠìŒ")
        
        emotion_dict = json.loads(json_match.group())
        emotion_vector = [
            emotion_dict.get('joy', 0.0),
            emotion_dict.get('sadness', 0.0),
            emotion_dict.get('anger', 0.0),
            emotion_dict.get('fear', 0.0),
            emotion_dict.get('surprise', 0.0),
            emotion_dict.get('disgust', 0.0),
            emotion_dict.get('trust', 0.0)
        ]
        
        # ì •ê·œí™”
        total = sum(emotion_vector)
        if total > 0:
            emotion_vector = [e/total for e in emotion_vector]
        else:
            raise ValueError("ê°ì • ë²¡í„° í•©ì´ 0")
        
        return {"vector": emotion_vector, "confidence": response.confidence}
    
    def calculate_bentham_scores(self, text: str, emotion_vector: List[float]) -> Dict[str, float]:
        """
        LLMì„ í†µí•œ ë²¤ë‹´ ì¾Œë½ ê³„ì‚°
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            emotion_vector: ê°ì • ë²¡í„°
            
        Returns:
            ë²¤ë‹´ ì ìˆ˜
        """
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë²¤ë‹´ì˜ ì¾Œë½ ê³„ì‚°ë²•ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: {text[:500]}
í˜„ì¬ ê°ì • ìƒíƒœ: {emotion_vector}

ë‹¤ìŒ 4ê°€ì§€ ì°¨ì›ì„ 0-1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”:
1. intensity (ê°•ë„): í–‰ë³µ/ì¾Œë½ì˜ ê°•ë„
2. duration (ì§€ì†ì„±): íš¨ê³¼ì˜ ì§€ì† ì‹œê°„
3. certainty (í™•ì‹¤ì„±): ë°œìƒ ê°€ëŠ¥ì„±
4. propinquity (ê·¼ì ‘ì„±): ì‹œê°„ì /ê³µê°„ì  ê·¼ì ‘ì„±

í˜•ì‹:
{{
    "intensity": 0.x,
    "duration": 0.x,
    "certainty": 0.x,
    "propinquity": 0.x
}}"""
        
        request = LLMRequest(
            prompt=prompt,
            task_type="bentham_analysis",
            complexity=TaskComplexity.COMPLEX
        )
        response = self.llm_engine.generate_sync(request)
        
        # JSON íŒŒì‹±
        import re
        json_match = re.search(r'\{[^}]+\}', response.generated_text)
        if not json_match:
            raise ValueError("LLMì´ ìœ íš¨í•œ ë²¤ë‹´ ì ìˆ˜ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ")
        
        scores = json.loads(json_match.group())
        return {
            'intensity': float(scores['intensity']),
            'duration': float(scores['duration']),
            'certainty': float(scores['certainty']),
            'propinquity': float(scores['propinquity'])
        }
    
    def calculate_regret_factor(self, text: str) -> float:
        """
        LLMì„ í†µí•œ í›„íšŒ ì§€ìˆ˜ ê³„ì‚°
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            í›„íšŒ ì§€ìˆ˜ (0-1)
        """
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í›„íšŒì˜ ì •ë„ë¥¼ 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.
0ì€ í›„íšŒ ì—†ìŒ, 1ì€ ê·¹ë„ì˜ í›„íšŒë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

í…ìŠ¤íŠ¸: {text[:500]}

ìˆ«ìë§Œ ë‹µí•˜ì„¸ìš” (ì˜ˆ: 0.7)"""
        
        request = LLMRequest(
            prompt=prompt,
            task_type="regret_analysis",
            complexity=TaskComplexity.SIMPLE
        )
        response = self.llm_engine.generate_sync(request)
        
        # ìˆ«ì ì¶”ì¶œ
        import re
        numbers = re.findall(r'0\.\d+|1\.0|0|1', response.generated_text)
        if not numbers:
            raise ValueError("LLMì´ ìœ íš¨í•œ í›„íšŒ ì§€ìˆ˜ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ")
        
        return float(numbers[0])
    
    def calculate_surd_metrics(self, text: str, metadata: Dict[str, Any]) -> Dict[str, float]:
        """
        LLMì„ í†µí•œ SURD (ì¶©ë¶„ì„±, ì´í•´ê°€ëŠ¥ì„±, ë³µì›ë ¥, ê²°ì •ì„±) ë©”íŠ¸ë¦­ ê³„ì‚°
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            metadata: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            
        Returns:
            SURD ë©”íŠ¸ë¦­
        """
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
        ethical_dilemma = metadata.get('ethical_dilemma', '')
        stakeholders = metadata.get('stakeholders', '')
        
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ SURD í”„ë ˆì„ì›Œí¬ë¡œ ë¶„ì„í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: {text[:500]}
{f"ìœ¤ë¦¬ì  ë”œë ˆë§ˆ: {ethical_dilemma[:200]}" if ethical_dilemma else ""}
{f"ì´í•´ê´€ê³„ì: {stakeholders[:100]}" if stakeholders else ""}

ë‹¤ìŒ 4ê°€ì§€ ì°¨ì›ì„ 0-1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”:

1. Sufficiency (ì¶©ë¶„ì„±): ìœ¤ë¦¬ì  íŒë‹¨ì„ ìœ„í•œ ì •ë³´ì˜ ì¶©ë¶„ì„±
   - ìƒí™©ì´ ì–¼ë§ˆë‚˜ ì™„ì „í•˜ê²Œ ì„¤ëª…ë˜ì—ˆëŠ”ê°€?
   - ëª¨ë“  ê´€ë ¨ ì¸¡ë©´ì´ ê³ ë ¤ë˜ì—ˆëŠ”ê°€?

2. Understandability (ì´í•´ê°€ëŠ¥ì„±): ìƒí™©ì˜ ëª…í™•ì„±ê³¼ ì´í•´ ìš©ì´ì„±
   - ë”œë ˆë§ˆê°€ ì–¼ë§ˆë‚˜ ëª…í™•í•˜ê²Œ í‘œí˜„ë˜ì—ˆëŠ”ê°€?
   - ì´í•´ê´€ê³„ìë“¤ì˜ ì…ì¥ì´ ë¶„ëª…í•œê°€?

3. Resilience (ë³µì›ë ¥): ê²°ì •ì˜ ê²¬ê³ ì„±ê³¼ ì ì‘ë ¥
   - ê²°ì •ì´ ë³€í™”í•˜ëŠ” ìƒí™©ì—ì„œë„ ìœ íš¨í•œê°€?
   - ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ì— ëŒ€ì‘í•  ìˆ˜ ìˆëŠ”ê°€?

4. Decisiveness (ê²°ì •ì„±): ëª…í™•í•œ ì„ íƒê³¼ í–‰ë™ ê°€ëŠ¥ì„±
   - êµ¬ì²´ì ì¸ í–‰ë™ ë°©í–¥ì´ ì œì‹œë˜ëŠ”ê°€?
   - ê²°ì •ì´ ì‹¤í–‰ ê°€ëŠ¥í•œê°€?

í˜•ì‹:
{{
    "sufficiency": 0.x,
    "understandability": 0.x,
    "resilience": 0.x,
    "decisiveness": 0.x
}}"""
        
        request = LLMRequest(
            prompt=prompt,
            task_type="surd_analysis",
            complexity=TaskComplexity.COMPLEX
        )
        response = self.llm_engine.generate_sync(request)
        
        # JSON íŒŒì‹±
        import re
        json_match = re.search(r'\{[^}]+\}', response.generated_text)
        if not json_match:
            raise ValueError("LLMì´ ìœ íš¨í•œ SURD ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•˜ì§€ ì•ŠìŒ")
        
        metrics = json.loads(json_match.group())
        return {
            'sufficiency': float(metrics['sufficiency']),
            'understandability': float(metrics['understandability']),
            'resilience': float(metrics['resilience']),
            'decisiveness': float(metrics['decisiveness'])
        }
    
    def process_single_item(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ë°ì´í„° ì•„ì´í…œ ì²˜ë¦¬ - ì˜ˆì™¸ ì²˜ë¦¬ ì—†ìŒ (í”„ë¡œì íŠ¸ ê·œì¹™)
        
        Args:
            item: ì›ë³¸ ë°ì´í„° ì•„ì´í…œ
            
        Returns:
            ì „ì²˜ë¦¬ëœ ë°ì´í„°
        """
        text = item.get('text', '')
        if not text:
            raise ValueError("í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ")
        
        start_time = time.time()
        
        # 1. Sentence-Transformerë¡œ ì‹¤ì œ ì„ë² ë”© ìƒì„±
        context_embedding = self.generate_context_embedding(text)
        
        # 2. LLMìœ¼ë¡œ ê°ì • ë¶„ì„
        emotion_result = self.analyze_emotions_with_llm(text)
        emotion_vector = emotion_result['vector']
        
        # 3. í›„íšŒ ì§€ìˆ˜ ê³„ì‚°
        regret_factor = self.calculate_regret_factor(text)
        
        # 4. ë²¤ë‹´ ì ìˆ˜ ê³„ì‚° (LLM)
        bentham_scores = self.calculate_bentham_scores(text, emotion_vector)
        
        # 5. SURD ë©”íŠ¸ë¦­ ê³„ì‚° (LLM, ë©”íƒ€ë°ì´í„° í™œìš©)
        surd_metrics = self.calculate_surd_metrics(text, item.get('metadata', {}))
        
        processing_time = time.time() - start_time
        
        return {
            'text': text,
            'source': item.get('source', 'unknown'),
            'emotion_vector': emotion_vector,
            'regret_factor': regret_factor,
            'bentham_scores': bentham_scores,
            'surd_metrics': surd_metrics,
            'context_embedding': context_embedding,
            'processing_time': processing_time,
            'llm_confidence': emotion_result.get('confidence', 0.5),
            'timestamp': datetime.now().isoformat(),
            'metadata': item.get('metadata', {})
        }
    
    def process_dataset(self, input_file: str = "parsed_raw_datasets.json",
                        output_file: str = "preprocessed_dataset_v3.json",
                        limit: Optional[int] = None):
        """
        ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬
        
        Args:
            input_file: ì…ë ¥ íŒŒì¼ ê²½ë¡œ
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            limit: ì²˜ë¦¬í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
        """
        logger.info(f"ğŸ“š ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹œì‘: {input_file}")
        
        # ë°ì´í„° ë¡œë“œ
        with open(input_file, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        if limit:
            raw_data = raw_data[:limit]
        
        logger.info(f"ì´ {len(raw_data)}ê°œ ìƒ˜í”Œ ì²˜ë¦¬ ì˜ˆì •")
        
        # LLM ì´ˆê¸°í™”
        self.initialize_llm()
        
        # ì²˜ë¦¬
        processed_data = []
        failed_count = 0
        
        for i, item in enumerate(raw_data):
            if i % 10 == 0:
                logger.info(f"ì§„í–‰ë¥ : {i}/{len(raw_data)} ({i*100/len(raw_data):.1f}%)")
            
            try:
                result = self.process_single_item(item)
                processed_data.append(result)
            except Exception as e:
                logger.error(f"ìƒ˜í”Œ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                failed_count += 1
                # í”„ë¡œì íŠ¸ ê·œì¹™: fallback ì—†ìŒ, ì‹¤íŒ¨ëŠ” ì‹¤íŒ¨
                raise
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬
            if i % 50 == 0:
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        
        # ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(processed_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {len(processed_data)}ê°œ ìƒ˜í”Œ ì €ì¥ â†’ {output_file}")
        
        # í†µê³„ ì¶œë ¥
        self.print_statistics(processed_data)
    
    def print_statistics(self, data: List[Dict]):
        """ë°ì´í„° í†µê³„ ì¶œë ¥"""
        if not data:
            return
        
        print("\nğŸ“Š ë°ì´í„°ì…‹ í†µê³„:")
        print(f"  - ì´ ìƒ˜í”Œ ìˆ˜: {len(data)}")
        
        # ì†ŒìŠ¤ë³„ ë¶„í¬
        sources = {}
        for item in data:
            src = item.get('source', 'unknown')
            sources[src] = sources.get(src, 0) + 1
        
        print("\n  ì†ŒìŠ¤ë³„ ë¶„í¬:")
        for src, count in sources.items():
            print(f"    - {src}: {count}ê°œ")
        
        # í‰ê·  ì§€í‘œ
        avg_regret = sum(item['regret_factor'] for item in data) / len(data)
        print(f"\n  í‰ê·  í›„íšŒ ì§€ìˆ˜: {avg_regret:.3f}")
        
        # ì„ë² ë”© ì°¨ì›
        if data[0].get('context_embedding'):
            print(f"  ì„ë² ë”© ì°¨ì›: {len(data[0]['context_embedding'])}")
        
        # SURD ë©”íŠ¸ë¦­ í‰ê· 
        avg_surd = {
            'sufficiency': sum(item['surd_metrics']['sufficiency'] for item in data) / len(data),
            'understandability': sum(item['surd_metrics']['understandability'] for item in data) / len(data),
            'resilience': sum(item['surd_metrics']['resilience'] for item in data) / len(data),
            'decisiveness': sum(item['surd_metrics']['decisiveness'] for item in data) / len(data)
        }
        print("\n  í‰ê·  SURD ë©”íŠ¸ë¦­:")
        for key, value in avg_surd.items():
            print(f"    - {key}: {value:.3f}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    preprocessor = ImprovedDataPreprocessor(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì²˜ìŒ 10ê°œë§Œ)
    preprocessor.process_dataset(
        input_file="parsed_raw_datasets.json",
        output_file="preprocessed_dataset_v3.json",
        limit=10  # í…ŒìŠ¤íŠ¸ìš©
    )

if __name__ == "__main__":
    main()