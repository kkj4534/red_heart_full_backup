"""
ìœ¤ë¦¬ ì •ì±… ìë™ ì¡°ì •ê¸° (Ethics Policy Auto-Updater)
Ethics Policy Auto-Updater Module

ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ë¥¼ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  ì¡°ì •í•˜ì—¬
ê°œì¸í™”ëœ ìœ¤ë¦¬ ì •ì±…ê³¼ ë¬¸í™”ì  ë§¥ë½ì„ ë°˜ì˜í•œ ì ì‘ì  ìœ¤ë¦¬ íŒë‹¨ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.

í•µì‹¬ ê¸°ëŠ¥:
1. ê²½í—˜ ê¸°ë°˜ ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ìë™ ì¡°ì •
2. ê°œì¸-ê³µë™ì²´ ê· í˜• ê³„ìˆ˜ ë„ì…
3. ë¬¸í™”ì  ë§¥ë½ ê³ ë ¤ ë‹¤ì°¨ì› ìœ¤ë¦¬ ê³„ì‚°
4. ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ì •ì±… ê°œì„ 
"""

import numpy as np
import torch
import logging
import json
import time
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from pathlib import Path
from collections import defaultdict, deque
import sqlite3

try:
    from config import ADVANCED_CONFIG, DEVICE, DATA_DIR
    import os
    # pathlib ëŒ€ì‹  os.path ì‚¬ìš© (WSL í˜¸í™˜ì„±)
    EXPERIENCE_DB_DIR = os.path.join(DATA_DIR, "experience_db")
except ImportError:
    # config.pyì— ë¬¸ì œê°€ ìˆì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
    ADVANCED_CONFIG = {'enable_gpu': False}
    DEVICE = 'cpu'
    from pathlib import Path
    EXPERIENCE_DB_DIR = Path("data/experience_db")
    print("âš ï¸  config.py ì„í¬íŠ¸ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
from data_models import EmotionData

logger = logging.getLogger('EthicsPolicyUpdater')

@dataclass
class EthicsPolicy:
    """ìœ¤ë¦¬ ì •ì±… ë°ì´í„° í´ë˜ìŠ¤"""
    policy_id: str
    user_id: str = "default"
    
    # ê¸°ë³¸ ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ (ë„ë• ê¸°ë°˜ ì´ë¡ )
    care_harm: float = 0.8
    fairness_cheating: float = 0.7
    loyalty_betrayal: float = 0.6
    authority_subversion: float = 0.5
    sanctity_degradation: float = 0.6
    
    # ê°œì¸-ê³µë™ì²´ ê· í˜• ê³„ìˆ˜
    individual_weight: float = 0.4
    community_weight: float = 0.6
    
    # ë¬¸í™”ì  ë§¥ë½ ê°€ì¤‘ì¹˜
    cultural_context: Dict[str, float] = field(default_factory=lambda: {
        'hierarchy_respect': 0.7,  # ìœ„ê³„ ì¡´ì¤‘
        'group_harmony': 0.8,     # ì§‘ë‹¨ ì¡°í™”
        'face_saving': 0.6,       # ì²´ë©´ ì¤‘ì‹œ
        'long_term_thinking': 0.9 # ì¥ê¸°ì  ì‚¬ê³ 
    })
    
    # ì •ì±… ë©”íƒ€ë°ì´í„°
    creation_time: float = field(default_factory=time.time)
    last_updated: float = field(default_factory=time.time)
    update_count: int = 0
    confidence_score: float = 0.5
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
        return {
            'policy_id': self.policy_id,
            'user_id': self.user_id,
            'care_harm': self.care_harm,
            'fairness_cheating': self.fairness_cheating,
            'loyalty_betrayal': self.loyalty_betrayal,
            'authority_subversion': self.authority_subversion,
            'sanctity_degradation': self.sanctity_degradation,
            'individual_weight': self.individual_weight,
            'community_weight': self.community_weight,
            'cultural_context': self.cultural_context,
            'creation_time': self.creation_time,
            'last_updated': self.last_updated,
            'update_count': self.update_count,
            'confidence_score': self.confidence_score
        }

@dataclass
class EthicsExperience:
    """ìœ¤ë¦¬ì  ê²½í—˜ ë°ì´í„°"""
    experience_id: str
    scenario: str
    decision_made: str
    outcome_rating: float  # -1.0 ~ 1.0 (ë§¤ìš° ë‚˜ì¨ ~ ë§¤ìš° ì¢‹ìŒ)
    
    # ë§¥ë½ ì •ë³´
    emotion_state: EmotionData
    stakeholders: List[str]
    cultural_context: str
    decision_urgency: float
    
    # ê²°ê³¼ ì •ë³´
    actual_regret: float
    user_satisfaction: float
    moral_correctness: float  # ì™¸ë¶€ í‰ê°€ì ë˜ëŠ” ì „ë¬¸ê°€ í‰ê°€
    
    # ë©”íƒ€ë°ì´í„°
    timestamp: float = field(default_factory=time.time)
    feedback_quality: float = 0.8  # í”¼ë“œë°± í’ˆì§ˆ ì ìˆ˜
    decision: Optional[str] = None  # í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­

@dataclass
class PolicyUpdateResult:
    """ì •ì±… ì—…ë°ì´íŠ¸ ê²°ê³¼"""
    old_policy: EthicsPolicy
    new_policy: EthicsPolicy
    update_magnitude: float
    convergence_achieved: bool
    improvement_areas: List[str]
    confidence_change: float
    reasoning_trace: List[str] = field(default_factory=list)

class EthicsPolicyUpdater:
    """ìœ¤ë¦¬ ì •ì±… ìë™ ì¡°ì •ê¸°"""
    
    def __init__(self, db_path: Optional[str] = None):
        self.logger = logger
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        self.db_path = db_path or str(EXPERIENCE_DB_DIR / "ethics_policy.db")
        self._init_database()
        
        # í•™ìŠµ ì„¤ì •
        self.learning_config = {
            'learning_rate': 0.01,
            'momentum': 0.9,
            'decay_rate': 0.99,
            'min_experiences_for_update': 5,
            'convergence_threshold': 0.001,
            'max_update_magnitude': 0.1,
            'experience_weight_decay': 0.95,  # ì˜¤ë˜ëœ ê²½í—˜ì˜ ê°€ì¤‘ì¹˜ ê°ì†Œ
            'cultural_adaptation_rate': 0.05
        }
        
        # ë©”ëª¨ë¦¬ ë²„í¼
        self.experience_buffer = deque(maxlen=1000)
        self.recent_updates = deque(maxlen=50)
        
        # í†µê³„ ì¶”ì 
        self.update_statistics = {
            'total_updates': 0,
            'successful_updates': 0,
            'average_improvement': 0.0,
            'convergence_rate': 0.0
        }
        
        # ë‹¤ì°¨ì› ìœ¤ë¦¬ ê³„ì‚°ê¸°
        self.multi_ethics_calculator = MultiEthicsCalculator()
        
        self.logger.info("ìœ¤ë¦¬ ì •ì±… ìë™ ì¡°ì •ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            # ì •ì±… í…Œì´ë¸”
            conn.execute('''
                CREATE TABLE IF NOT EXISTS ethics_policies (
                    policy_id TEXT PRIMARY KEY,
                    user_id TEXT,
                    policy_data TEXT,
                    creation_time REAL,
                    last_updated REAL,
                    update_count INTEGER,
                    confidence_score REAL
                )
            ''')
            
            # ê²½í—˜ í…Œì´ë¸”
            conn.execute('''
                CREATE TABLE IF NOT EXISTS ethics_experiences (
                    experience_id TEXT PRIMARY KEY,
                    user_id TEXT,
                    scenario TEXT,
                    decision_made TEXT,
                    outcome_rating REAL,
                    actual_regret REAL,
                    user_satisfaction REAL,
                    moral_correctness REAL,
                    experience_data TEXT,
                    timestamp REAL,
                    feedback_quality REAL
                )
            ''')
            
            # ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
            conn.execute('''
                CREATE TABLE IF NOT EXISTS policy_updates (
                    update_id TEXT PRIMARY KEY,
                    policy_id TEXT,
                    old_policy_data TEXT,
                    new_policy_data TEXT,
                    update_magnitude REAL,
                    improvement_score REAL,
                    timestamp REAL
                )
            ''')
            
            conn.commit()
    
    def add_experience(self, experience: EthicsExperience):
        """ìƒˆë¡œìš´ ìœ¤ë¦¬ì  ê²½í—˜ ì¶”ê°€"""
        
        # ë©”ëª¨ë¦¬ ë²„í¼ì— ì¶”ê°€
        self.experience_buffer.append(experience)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO ethics_experiences 
                (experience_id, user_id, scenario, decision_made, outcome_rating,
                 actual_regret, user_satisfaction, moral_correctness, 
                 experience_data, timestamp, feedback_quality)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                experience.experience_id,
                "default",  # ì‚¬ìš©ì ID
                experience.scenario,
                experience.decision_made,
                experience.outcome_rating,
                experience.actual_regret,
                experience.user_satisfaction,
                experience.moral_correctness,
                json.dumps(experience.__dict__, default=str),
                experience.timestamp,
                experience.feedback_quality
            ))
            conn.commit()
        
        self.logger.info(f"ìƒˆë¡œìš´ ìœ¤ë¦¬ì  ê²½í—˜ ì¶”ê°€: {experience.experience_id}")
    
    def get_policy(self, user_id: str = "default") -> EthicsPolicy:
        """ì‚¬ìš©ìë³„ ìœ¤ë¦¬ ì •ì±… ì¡°íšŒ"""
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT policy_data FROM ethics_policies 
                WHERE user_id = ? 
                ORDER BY last_updated DESC LIMIT 1
            ''', (user_id,))
            
            row = cursor.fetchone()
            
            if row:
                policy_data = json.loads(row[0])
                policy = EthicsPolicy(**policy_data)
                return policy
            else:
                # ê¸°ë³¸ ì •ì±… ìƒì„±
                default_policy = EthicsPolicy(
                    policy_id=f"default_{user_id}_{int(time.time())}",
                    user_id=user_id
                )
                self.save_policy(default_policy)
                return default_policy
    
    def save_policy(self, policy: EthicsPolicy):
        """ì •ì±… ì €ì¥"""
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO ethics_policies 
                (policy_id, user_id, policy_data, creation_time, 
                 last_updated, update_count, confidence_score)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                policy.policy_id,
                policy.user_id,
                json.dumps(policy.to_dict()),
                policy.creation_time,
                policy.last_updated,
                policy.update_count,
                policy.confidence_score
            ))
            conn.commit()
    
    def update_policy_from_experiences(
        self, 
        user_id: str = "default",
        min_experiences: Optional[int] = None
    ) -> PolicyUpdateResult:
        """ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì •ì±… ì—…ë°ì´íŠ¸"""
        
        # ê¸°ì¡´ ì •ì±… ë¡œë“œ
        old_policy = self.get_policy(user_id)
        
        # ìµœê·¼ ê²½í—˜ë“¤ ìˆ˜ì§‘
        experiences = self._get_recent_experiences(
            user_id, 
            min_experiences or self.learning_config['min_experiences_for_update']
        )
        
        if len(experiences) < (min_experiences or self.learning_config['min_experiences_for_update']):
            self.logger.warning(f"ê²½í—˜ ë°ì´í„° ë¶€ì¡±: {len(experiences)}ê°œ (ìµœì†Œ {min_experiences}ê°œ í•„ìš”)")
            return self._create_no_update_result(old_policy, "insufficient_data")
        
        reasoning_trace = [f"ì •ì±… ì—…ë°ì´íŠ¸ ì‹œì‘: {len(experiences)}ê°œ ê²½í—˜ ë¶„ì„"]
        
        # 1ë‹¨ê³„: ê²½í—˜ ë¶„ì„ ë° ê°€ì¤‘ì¹˜ ê³„ì‚°
        experience_weights = self._calculate_experience_weights(experiences)
        reasoning_trace.append(f"ê²½í—˜ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ: í‰ê·  í’ˆì§ˆ {np.mean(experience_weights):.3f}")
        
        # 2ë‹¨ê³„: ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ì¡°ì •
        new_ethics_weights = self._update_ethics_weights(
            old_policy, experiences, experience_weights, reasoning_trace
        )
        
        # 3ë‹¨ê³„: ê°œì¸-ê³µë™ì²´ ê· í˜• ì¡°ì •
        new_balance = self._update_individual_community_balance(
            old_policy, experiences, experience_weights, reasoning_trace
        )
        
        # 4ë‹¨ê³„: ë¬¸í™”ì  ë§¥ë½ ì¡°ì •
        new_cultural_context = self._update_cultural_context(
            old_policy, experiences, experience_weights, reasoning_trace
        )
        
        # 5ë‹¨ê³„: ìƒˆë¡œìš´ ì •ì±… ìƒì„±
        new_policy = EthicsPolicy(
            policy_id=f"{user_id}_{int(time.time())}",
            user_id=user_id,
            care_harm=new_ethics_weights['care_harm'],
            fairness_cheating=new_ethics_weights['fairness_cheating'],
            loyalty_betrayal=new_ethics_weights['loyalty_betrayal'],
            authority_subversion=new_ethics_weights['authority_subversion'],
            sanctity_degradation=new_ethics_weights['sanctity_degradation'],
            individual_weight=new_balance['individual'],
            community_weight=new_balance['community'],
            cultural_context=new_cultural_context,
            last_updated=time.time(),
            update_count=old_policy.update_count + 1
        )
        
        # 6ë‹¨ê³„: ì—…ë°ì´íŠ¸ í¬ê¸° ë° ìˆ˜ë ´ ì²´í¬
        update_magnitude = self._calculate_update_magnitude(old_policy, new_policy)
        convergence_achieved = update_magnitude < self.learning_config['convergence_threshold']
        
        # 7ë‹¨ê³„: ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
        new_policy.confidence_score = self._update_confidence_score(
            old_policy, experiences, update_magnitude
        )
        
        # 8ë‹¨ê³„: ê°œì„  ì˜ì—­ ì‹ë³„
        improvement_areas = self._identify_improvement_areas(
            old_policy, new_policy, experiences
        )
        
        reasoning_trace.append(
            f"ì •ì±… ì—…ë°ì´íŠ¸ ì™„ë£Œ: í¬ê¸° {update_magnitude:.4f}, "
            f"ìˆ˜ë ´ {'ë‹¬ì„±' if convergence_achieved else 'ë¯¸ë‹¬ì„±'}"
        )
        
        # ì •ì±… ì €ì¥
        self.save_policy(new_policy)
        
        # ì—…ë°ì´íŠ¸ ê²°ê³¼ ìƒì„±
        result = PolicyUpdateResult(
            old_policy=old_policy,
            new_policy=new_policy,
            update_magnitude=update_magnitude,
            convergence_achieved=convergence_achieved,
            improvement_areas=improvement_areas,
            confidence_change=new_policy.confidence_score - old_policy.confidence_score,
            reasoning_trace=reasoning_trace
        )
        
        # ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬ ì €ì¥
        self._save_update_history(result)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self._update_statistics(result)
        
        return result
    
    def _get_recent_experiences(self, user_id: str, min_count: int) -> List[EthicsExperience]:
        """ìµœê·¼ ê²½í—˜ ë°ì´í„° ì¡°íšŒ"""
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT experience_data FROM ethics_experiences 
                WHERE user_id = ? 
                ORDER BY timestamp DESC 
                LIMIT ?
            ''', (user_id, min_count * 2))  # ì—¬ìœ ë¡­ê²Œ ê°€ì ¸ì˜¤ê¸°
            
            experiences = []
            for row in cursor.fetchall():
                try:
                    exp_data = json.loads(row[0])
                    # EmotionData ë³µì›
                    if 'emotion_state' in exp_data and isinstance(exp_data['emotion_state'], dict):
                        emotion_dict = exp_data['emotion_state']
                        # ê°„ë‹¨í•œ EmotionData ë³µì› (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• í•„ìš”)
                        exp_data['emotion_state'] = EmotionData(
                            valence=emotion_dict.get('valence', 0.0),
                            arousal=emotion_dict.get('arousal', 0.0),
                            dominance=emotion_dict.get('dominance', 0.0),
                            confidence=emotion_dict.get('confidence', 0.5)
                        )
                    
                    experience = EthicsExperience(**exp_data)
                    experiences.append(experience)
                except Exception as e:
                    self.logger.warning(f"ê²½í—˜ ë°ì´í„° ë³µì› ì‹¤íŒ¨: {e}")
                    continue
            
            return experiences[:min_count * 3]  # ìµœëŒ€ 3ë°°ê¹Œì§€
    
    def _calculate_experience_weights(self, experiences: List[EthicsExperience]) -> np.ndarray:
        """ê²½í—˜ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        
        weights = []
        current_time = time.time()
        
        for exp in experiences:
            # ì‹œê°„ ê°€ì¤‘ì¹˜ (ìµœê·¼ì¼ìˆ˜ë¡ ë†’ìŒ)
            time_weight = np.exp(-(current_time - exp.timestamp) / (86400 * 30))  # 30ì¼ ê¸°ì¤€
            
            # í”¼ë“œë°± í’ˆì§ˆ ê°€ì¤‘ì¹˜
            quality_weight = exp.feedback_quality
            
            # ê²°ê³¼ ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ (ë§Œì¡±ë„ì™€ ë„ë•ì  ì •í™•ì„± ê¸°ë°˜)
            result_weight = (exp.user_satisfaction + exp.moral_correctness) / 2.0
            
            # ì „ì²´ ê°€ì¤‘ì¹˜
            total_weight = time_weight * quality_weight * result_weight
            weights.append(total_weight)
        
        # ì •ê·œí™”
        weights = np.array(weights)
        if np.sum(weights) > 0:
            weights = weights / np.sum(weights)
        else:
            weights = np.ones(len(weights)) / len(weights)
        
        return weights
    
    def _update_ethics_weights(
        self, 
        old_policy: EthicsPolicy,
        experiences: List[EthicsExperience],
        weights: np.ndarray,
        reasoning_trace: List[str]
    ) -> Dict[str, float]:
        """ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        
        # í˜„ì¬ ê°€ì¤‘ì¹˜
        current_weights = {
            'care_harm': old_policy.care_harm,
            'fairness_cheating': old_policy.fairness_cheating,
            'loyalty_betrayal': old_policy.loyalty_betrayal,
            'authority_subversion': old_policy.authority_subversion,
            'sanctity_degradation': old_policy.sanctity_degradation
        }
        
        # ê²½í—˜ ê¸°ë°˜ ì¡°ì • ê³„ì‚°
        adjustments = defaultdict(float)
        
        for i, exp in enumerate(experiences):
            exp_weight = weights[i]
            
            # ê²°ê³¼ í‰ê°€ (-1: ë§¤ìš° ë‚˜ì¨, 1: ë§¤ìš° ì¢‹ìŒ)
            outcome_score = exp.outcome_rating
            
            # ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ê¸°ë°˜ ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ì¡°ì •
            scenario_ethics = self._analyze_scenario_ethics(exp.scenario)
            
            for ethics_type, relevance in scenario_ethics.items():
                if ethics_type in current_weights:
                    # ê²°ê³¼ê°€ ì¢‹ì•˜ë‹¤ë©´ í•´ë‹¹ ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ì¦ê°€, ë‚˜ë¹´ë‹¤ë©´ ê°ì†Œ
                    adjustment = outcome_score * relevance * exp_weight * self.learning_config['learning_rate']
                    adjustments[ethics_type] += adjustment
        
        # ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ ê³„ì‚°
        new_weights = {}
        total_adjustment = 0.0
        
        for ethics_type, current_weight in current_weights.items():
            adjustment = adjustments[ethics_type]
            new_weight = current_weight + adjustment
            
            # ë²”ìœ„ ì œí•œ (0.1 ~ 0.9)
            new_weight = np.clip(new_weight, 0.1, 0.9)
            new_weights[ethics_type] = new_weight
            total_adjustment += abs(adjustment)
        
        reasoning_trace.append(
            f"ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ì¡°ì •: ì´ ë³€í™”ëŸ‰ {total_adjustment:.4f}"
        )
        
        return new_weights
    
    def _analyze_scenario_ethics(self, scenario: str) -> Dict[str, float]:
        """ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìœ¤ë¦¬ ê´€ë ¨ì„± ë¶„ì„"""
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨í•œ ë¶„ì„ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP í•„ìš”)
        ethics_keywords = {
            'care_harm': ['ì•ˆì „', 'ìœ„í—˜', 'í•´ë¡œìš´', 'ë³´í˜¸', 'ëŒë´„', 'í”¼í•´', 'ìƒì²˜'],
            'fairness_cheating': ['ê³µì •', 'ë¶ˆê³µì •', 'ì°¨ë³„', 'í‰ë“±', 'ê³µí‰', 'ë¶€ë‹¹'],
            'loyalty_betrayal': ['ë°°ì‹ ', 'ì¶©ì„±', 'ì‹ ë¢°', 'ë°°ë°˜', 'ì•½ì†', 'ì˜ë¦¬'],
            'authority_subversion': ['ê¶Œìœ„', 'ê·œì¹™', 'ë²•', 'ì§ˆì„œ', 'ë³µì¢…', 'ë°˜í•­'],
            'sanctity_degradation': ['ì‹ ì„±', 'ìˆœìˆ˜', 'ë”ëŸ¬ìš´', 'ê¹¨ë—', 'ì¡´ì—„', 'ëª¨ë…']
        }
        
        scenario_lower = scenario.lower()
        relevance_scores = {}
        
        for ethics_type, keywords in ethics_keywords.items():
            score = 0.0
            for keyword in keywords:
                if keyword in scenario_lower:
                    score += 1.0
            
            # ì •ê·œí™” (0-1 ë²”ìœ„)
            relevance_scores[ethics_type] = min(score / len(keywords), 1.0)
        
        return relevance_scores
    
    def _update_individual_community_balance(
        self,
        old_policy: EthicsPolicy,
        experiences: List[EthicsExperience],
        weights: np.ndarray,
        reasoning_trace: List[str]
    ) -> Dict[str, float]:
        """ê°œì¸-ê³µë™ì²´ ê· í˜• ì¡°ì •"""
        
        current_individual = old_policy.individual_weight
        current_community = old_policy.community_weight
        
        # ê²½í—˜ ê¸°ë°˜ ê· í˜• ì¡°ì •
        balance_adjustments = []
        
        for i, exp in enumerate(experiences):
            exp_weight = weights[i]
            
            # ì´í•´ê´€ê³„ì ìˆ˜ì— ë”°ë¥¸ ê³µë™ì²´ ì¤‘ìš”ë„
            stakeholder_count = len(exp.stakeholders) if exp.stakeholders else 1
            community_importance = min(stakeholder_count / 10.0, 1.0)
            
            # ê²°ê³¼ ê¸°ë°˜ ì¡°ì •
            if exp.outcome_rating > 0.5:  # ì¢‹ì€ ê²°ê³¼
                if community_importance > 0.7:
                    # ê³µë™ì²´ ì¤‘ì‹¬ ê²°ì •ì´ ì„±ê³µì ì´ì—ˆìŒ
                    balance_adjustments.append(('community', exp_weight * 0.1))
                else:
                    # ê°œì¸ ì¤‘ì‹¬ ê²°ì •ì´ ì„±ê³µì ì´ì—ˆìŒ
                    balance_adjustments.append(('individual', exp_weight * 0.1))
            elif exp.outcome_rating < -0.5:  # ë‚˜ìœ ê²°ê³¼
                if community_importance > 0.7:
                    # ê³µë™ì²´ ì¤‘ì‹¬ ê²°ì •ì´ ì‹¤íŒ¨í–ˆìŒ
                    balance_adjustments.append(('individual', exp_weight * 0.05))
                else:
                    # ê°œì¸ ì¤‘ì‹¬ ê²°ì •ì´ ì‹¤íŒ¨í–ˆìŒ
                    balance_adjustments.append(('community', exp_weight * 0.05))
        
        # ì¡°ì • ì ìš©
        individual_adjustment = sum(adj for direction, adj in balance_adjustments if direction == 'individual')
        community_adjustment = sum(adj for direction, adj in balance_adjustments if direction == 'community')
        
        new_individual = current_individual + individual_adjustment - community_adjustment
        new_community = current_community + community_adjustment - individual_adjustment
        
        # ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)
        total = new_individual + new_community
        if total > 0:
            new_individual /= total
            new_community /= total
        else:
            new_individual, new_community = 0.4, 0.6  # ê¸°ë³¸ê°’
        
        reasoning_trace.append(
            f"ê°œì¸-ê³µë™ì²´ ê· í˜• ì¡°ì •: {current_individual:.3f}->{new_individual:.3f}, "
            f"{current_community:.3f}->{new_community:.3f}"
        )
        
        return {
            'individual': new_individual,
            'community': new_community
        }
    
    def _update_cultural_context(
        self,
        old_policy: EthicsPolicy,
        experiences: List[EthicsExperience],
        weights: np.ndarray,
        reasoning_trace: List[str]
    ) -> Dict[str, float]:
        """ë¬¸í™”ì  ë§¥ë½ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        
        current_context = old_policy.cultural_context.copy()
        
        # ê²½í—˜ì—ì„œ ë¬¸í™”ì  ë§¥ë½ ë¶„ì„
        cultural_factors = {
            'hierarchy_respect': 0.0,
            'group_harmony': 0.0,
            'face_saving': 0.0,
            'long_term_thinking': 0.0
        }
        
        for i, exp in enumerate(experiences):
            exp_weight = weights[i]
            
            # ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ë¬¸í™”ì  ìš”ì†Œ ì¶”ì¶œ
            scenario_lower = exp.scenario.lower()
            
            # ìœ„ê³„ ì¡´ì¤‘
            if any(word in scenario_lower for word in ['ìƒì‚¬', 'ì„ ë°°', 'ê¶Œìœ„', 'ì§€ìœ„']):
                if exp.outcome_rating > 0:
                    cultural_factors['hierarchy_respect'] += exp_weight * 0.1
                else:
                    cultural_factors['hierarchy_respect'] -= exp_weight * 0.05
            
            # ì§‘ë‹¨ ì¡°í™”
            if any(word in scenario_lower for word in ['íŒ€', 'ì¡°ì§', 'ë‹¨ì²´', 'í˜‘ë ¥']):
                if exp.outcome_rating > 0:
                    cultural_factors['group_harmony'] += exp_weight * 0.1
                else:
                    cultural_factors['group_harmony'] -= exp_weight * 0.05
            
            # ì²´ë©´ ì¤‘ì‹œ
            if any(word in scenario_lower for word in ['ì²´ë©´', 'ëª…ì˜ˆ', 'í‰íŒ', 'ì´ë¯¸ì§€']):
                if exp.outcome_rating > 0:
                    cultural_factors['face_saving'] += exp_weight * 0.1
                else:
                    cultural_factors['face_saving'] -= exp_weight * 0.05
            
            # ì¥ê¸°ì  ì‚¬ê³ 
            if any(word in scenario_lower for word in ['ë¯¸ë˜', 'ì¥ê¸°', 'ì§€ì†', 'ì„¸ëŒ€']):
                if exp.outcome_rating > 0:
                    cultural_factors['long_term_thinking'] += exp_weight * 0.1
                else:
                    cultural_factors['long_term_thinking'] -= exp_weight * 0.05
        
        # ë¬¸í™”ì  ë§¥ë½ ì—…ë°ì´íŠ¸
        new_context = {}
        for factor, adjustment in cultural_factors.items():
            current_value = current_context.get(factor, 0.7)
            new_value = current_value + adjustment * self.learning_config['cultural_adaptation_rate']
            new_context[factor] = np.clip(new_value, 0.1, 1.0)
        
        reasoning_trace.append(f"ë¬¸í™”ì  ë§¥ë½ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        return new_context
    
    def _calculate_update_magnitude(self, old_policy: EthicsPolicy, new_policy: EthicsPolicy) -> float:
        """ì •ì±… ì—…ë°ì´íŠ¸ í¬ê¸° ê³„ì‚°"""
        
        # ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ë³€í™”
        ethics_changes = [
            abs(new_policy.care_harm - old_policy.care_harm),
            abs(new_policy.fairness_cheating - old_policy.fairness_cheating),
            abs(new_policy.loyalty_betrayal - old_policy.loyalty_betrayal),
            abs(new_policy.authority_subversion - old_policy.authority_subversion),
            abs(new_policy.sanctity_degradation - old_policy.sanctity_degradation)
        ]
        
        # ê· í˜• ë³€í™”
        balance_changes = [
            abs(new_policy.individual_weight - old_policy.individual_weight),
            abs(new_policy.community_weight - old_policy.community_weight)
        ]
        
        # ë¬¸í™”ì  ë§¥ë½ ë³€í™”
        cultural_changes = []
        for key in old_policy.cultural_context:
            old_val = old_policy.cultural_context.get(key, 0.7)
            new_val = new_policy.cultural_context.get(key, 0.7)
            cultural_changes.append(abs(new_val - old_val))
        
        # ì „ì²´ ë³€í™”ëŸ‰ (ê°€ì¤‘ í‰ê· )
        total_change = (
            np.mean(ethics_changes) * 0.5 +
            np.mean(balance_changes) * 0.3 +
            np.mean(cultural_changes) * 0.2
        )
        
        return total_change
    
    def _update_confidence_score(
        self,
        old_policy: EthicsPolicy,
        experiences: List[EthicsExperience],
        update_magnitude: float
    ) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ì—…ë°ì´íŠ¸"""
        
        # ê²½í—˜ í’ˆì§ˆ ê¸°ë°˜ ì‹ ë¢°ë„
        experience_quality = np.mean([exp.feedback_quality for exp in experiences])
        
        # ê²°ê³¼ ì¼ê´€ì„± ê¸°ë°˜ ì‹ ë¢°ë„
        outcome_variance = np.var([exp.outcome_rating for exp in experiences])
        consistency_score = max(0.0, 1.0 - outcome_variance)
        
        # ì—…ë°ì´íŠ¸ í¬ê¸° ê¸°ë°˜ ì•ˆì •ì„±
        stability_score = max(0.0, 1.0 - update_magnitude * 10)
        
        # ê²½í—˜ ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„
        sample_score = min(len(experiences) / 20.0, 1.0)
        
        # ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
        new_confidence = (
            old_policy.confidence_score * 0.3 +
            experience_quality * 0.25 +
            consistency_score * 0.25 +
            stability_score * 0.1 +
            sample_score * 0.1
        )
        
        return np.clip(new_confidence, 0.1, 1.0)
    
    def _identify_improvement_areas(
        self,
        old_policy: EthicsPolicy,
        new_policy: EthicsPolicy,
        experiences: List[EthicsExperience]
    ) -> List[str]:
        """ê°œì„  ì˜ì—­ ì‹ë³„"""
        
        areas = []
        
        # ë‚®ì€ ë§Œì¡±ë„ ê²½í—˜ ë¶„ì„
        low_satisfaction_exps = [exp for exp in experiences if exp.user_satisfaction < 0.3]
        if len(low_satisfaction_exps) > len(experiences) * 0.3:
            areas.append("ì‚¬ìš©ì ë§Œì¡±ë„ ê°œì„  í•„ìš”")
        
        # ë†’ì€ í›„íšŒ ê²½í—˜ ë¶„ì„
        high_regret_exps = [exp for exp in experiences if exp.actual_regret > 0.7]
        if len(high_regret_exps) > len(experiences) * 0.2:
            areas.append("í›„íšŒ ìµœì†Œí™” ì „ëµ í•„ìš”")
        
        # ë„ë•ì  ì •í™•ì„± ë¶„ì„
        low_moral_exps = [exp for exp in experiences if exp.moral_correctness < 0.4]
        if len(low_moral_exps) > len(experiences) * 0.2:
            areas.append("ë„ë•ì  íŒë‹¨ ì •í™•ì„± í–¥ìƒ í•„ìš”")
        
        # ì‹ ë¢°ë„ ë¶„ì„
        if new_policy.confidence_score < 0.6:
            areas.append("ì •ì±… ì‹ ë¢°ë„ í–¥ìƒ í•„ìš”")
        
        return areas
    
    def _create_no_update_result(self, policy: EthicsPolicy, reason: str) -> PolicyUpdateResult:
        """ì—…ë°ì´íŠ¸ ì—†ëŠ” ê²°ê³¼ ìƒì„±"""
        return PolicyUpdateResult(
            old_policy=policy,
            new_policy=policy,
            update_magnitude=0.0,
            convergence_achieved=True,
            improvement_areas=[],
            confidence_change=0.0,
            reasoning_trace=[f"ì—…ë°ì´íŠ¸ ë¯¸ì‹¤í–‰: {reason}"]
        )
    
    def _save_update_history(self, result: PolicyUpdateResult):
        """ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬ ì €ì¥"""
        
        update_id = f"update_{int(time.time())}"
        improvement_score = 1.0 if len(result.improvement_areas) == 0 else 0.5
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT INTO policy_updates 
                (update_id, policy_id, old_policy_data, new_policy_data,
                 update_magnitude, improvement_score, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                update_id,
                result.new_policy.policy_id,
                json.dumps(result.old_policy.to_dict()),
                json.dumps(result.new_policy.to_dict()),
                result.update_magnitude,
                improvement_score,
                time.time()
            ))
            conn.commit()
    
    def _update_statistics(self, result: PolicyUpdateResult):
        """í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.update_statistics['total_updates'] += 1
        
        if len(result.improvement_areas) == 0:
            self.update_statistics['successful_updates'] += 1
        
        # í‰ê·  ê°œì„ ë„ ì—…ë°ì´íŠ¸
        improvement = 1.0 if len(result.improvement_areas) == 0 else 0.0
        total = self.update_statistics['total_updates']
        current_avg = self.update_statistics['average_improvement']
        new_avg = (current_avg * (total - 1) + improvement) / total
        self.update_statistics['average_improvement'] = new_avg
        
        # ìˆ˜ë ´ë¥  ì—…ë°ì´íŠ¸
        convergence = 1.0 if result.convergence_achieved else 0.0
        current_conv = self.update_statistics['convergence_rate']
        new_conv = (current_conv * (total - 1) + convergence) / total
        self.update_statistics['convergence_rate'] = new_conv
    
    def get_analytics(self, user_id: str = "default") -> Dict[str, Any]:
        """ë¶„ì„ ì •ë³´ ë°˜í™˜ (í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­)"""
        return self.get_policy_analytics(user_id)
    
    def get_policy_analytics(self, user_id: str = "default") -> Dict[str, Any]:
        """ì •ì±… ë¶„ì„ ì •ë³´ ë°˜í™˜"""
        
        policy = self.get_policy(user_id)
        
        # ìµœê·¼ ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT update_magnitude, improvement_score, timestamp 
                FROM policy_updates 
                WHERE policy_id LIKE ? 
                ORDER BY timestamp DESC 
                LIMIT 10
            ''', (f"{user_id}%",))
            
            recent_updates = cursor.fetchall()
        
        return {
            'current_policy': policy.to_dict(),
            'update_statistics': self.update_statistics,
            'recent_updates': [
                {
                    'magnitude': row[0],
                    'improvement': row[1],
                    'timestamp': row[2]
                } for row in recent_updates
            ],
            'experience_buffer_size': len(self.experience_buffer)
        }


class MultiEthicsCalculator:
    """ë‹¤ì°¨ì› ìœ¤ë¦¬ ê³„ì‚°ê¸° (ê³µë¦¬ì£¼ì˜ + ë•ìœ¤ë¦¬ + ì˜ë¬´ë¡ )"""
    
    def __init__(self):
        self.ethics_weights = {
            'utilitarian': 0.4,    # ê³µë¦¬ì£¼ì˜ (ê¸°ì¡´ ë²¤ë‹´ ê³„ì‚°)
            'virtue_ethics': 0.3,  # ë• ìœ¤ë¦¬í•™
            'deontological': 0.3   # ì˜ë¬´ë¡ ì  ìœ¤ë¦¬í•™
        }
    
    def calculate_multi_dimensional_ethics(
        self,
        scenario: str,
        stakeholders: List[str],
        consequences: Dict[str, float],
        moral_rules: List[str],
        virtues_involved: List[str]
    ) -> Dict[str, float]:
        """ë‹¤ì°¨ì› ìœ¤ë¦¬ ì ìˆ˜ ê³„ì‚°"""
        
        # 1. ê³µë¦¬ì£¼ì˜ì  ê³„ì‚° (ê²°ê³¼ ê¸°ë°˜)
        utilitarian_score = self._calculate_utilitarian_score(consequences, stakeholders)
        
        # 2. ë• ìœ¤ë¦¬í•™ì  ê³„ì‚° (ì„±í’ˆ ê¸°ë°˜)
        virtue_score = self._calculate_virtue_score(virtues_involved, scenario)
        
        # 3. ì˜ë¬´ë¡ ì  ê³„ì‚° (ê·œì¹™ ê¸°ë°˜)
        deontological_score = self._calculate_deontological_score(moral_rules, scenario)
        
        # 4. í†µí•© ì ìˆ˜ ê³„ì‚°
        integrated_score = (
            utilitarian_score * self.ethics_weights['utilitarian'] +
            virtue_score * self.ethics_weights['virtue_ethics'] +
            deontological_score * self.ethics_weights['deontological']
        )
        
        return {
            'utilitarian': utilitarian_score,
            'virtue_ethics': virtue_score,
            'deontological': deontological_score,
            'integrated': integrated_score
        }
    
    def _calculate_utilitarian_score(self, consequences: Dict[str, float], stakeholders: List[str]) -> float:
        """ê³µë¦¬ì£¼ì˜ì  ì ìˆ˜ ê³„ì‚°"""
        if not consequences:
            return 0.5
        
        # ê²°ê³¼ì˜ ì „ì²´ íš¨ìš© ê³„ì‚°
        total_utility = sum(consequences.values())
        stakeholder_count = len(stakeholders) if stakeholders else 1
        
        # í‰ê·  íš¨ìš©ìœ¼ë¡œ ì •ê·œí™”
        average_utility = total_utility / max(stakeholder_count, 1)
        
        # 0-1 ë²”ìœ„ë¡œ ë³€í™˜
        return np.clip((average_utility + 1) / 2, 0.0, 1.0)
    
    def _calculate_virtue_score(self, virtues: List[str], scenario: str) -> float:
        """ë• ìœ¤ë¦¬í•™ì  ì ìˆ˜ ê³„ì‚°"""
        if not virtues:
            return 0.5
        
        # ë•ëª©ë³„ ì ìˆ˜ ë§¤í•‘
        virtue_scores = {
            'courage': 0.8,      # ìš©ê¸°
            'justice': 0.9,      # ì •ì˜
            'temperance': 0.7,   # ì ˆì œ
            'wisdom': 0.8,       # ì§€í˜œ
            'compassion': 0.9,   # ì—°ë¯¼
            'honesty': 0.8,      # ì •ì§
            'integrity': 0.9,    # ì„±ì‹¤ì„±
            'humility': 0.7      # ê²¸ì†
        }
        
        # ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìš”êµ¬ë˜ëŠ” ë•ëª©ë“¤ì˜ í‰ê·  ì ìˆ˜
        relevant_scores = [virtue_scores.get(virtue.lower(), 0.5) for virtue in virtues]
        
        return np.mean(relevant_scores) if relevant_scores else 0.5
    
    def _calculate_deontological_score(self, moral_rules: List[str], scenario: str) -> float:
        """ì˜ë¬´ë¡ ì  ì ìˆ˜ ê³„ì‚°"""
        if not moral_rules:
            return 0.5
        
        # ë„ë• ê·œì¹™ë³„ ì¤€ìˆ˜ ì ìˆ˜
        rule_compliance = {
            'no_harm': 0.9,           # í•´ë¥¼ ë¼ì¹˜ì§€ ë§ë¼
            'truth_telling': 0.8,     # ì§„ì‹¤ì„ ë§í•˜ë¼
            'promise_keeping': 0.8,   # ì•½ì†ì„ ì§€ì¼œë¼
            'respect_autonomy': 0.9,  # ììœ¨ì„±ì„ ì¡´ì¤‘í•˜ë¼
            'fairness': 0.9,          # ê³µì •í•˜ê²Œ ëŒ€í•˜ë¼
            'respect_dignity': 1.0    # ì¸ê°„ ì¡´ì—„ì„±ì„ ì¡´ì¤‘í•˜ë¼
        }
        
        # ê´€ë ¨ ê·œì¹™ë“¤ì˜ í‰ê·  ì¤€ìˆ˜ ì ìˆ˜
        relevant_scores = [rule_compliance.get(rule.lower(), 0.5) for rule in moral_rules]
        
        return np.mean(relevant_scores) if relevant_scores else 0.5


# í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ í•¨ìˆ˜
def test_ethics_policy_updater():
    """ìœ¤ë¦¬ ì •ì±… ìë™ ì¡°ì •ê¸° í…ŒìŠ¤íŠ¸"""
    print("ğŸ”§ ìœ¤ë¦¬ ì •ì±… ìë™ ì¡°ì •ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ì¡°ì •ê¸° ì´ˆê¸°í™”
    updater = EthicsPolicyUpdater()
    
    # í…ŒìŠ¤íŠ¸ ê²½í—˜ ë°ì´í„° ìƒì„±
    test_experiences = [
        EthicsExperience(
            experience_id="exp_1",
            scenario="íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ë™ë£Œê°€ ê¸°ì—¬í•˜ì§€ ì•Šì•˜ì§€ë§Œ ê³µì •í•œ í‰ê°€ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.",
            decision_made="ë™ë£Œì—ê²Œ ì§ì ‘ ì´ì•¼ê¸°í•˜ê³  ìƒí™©ì„ ê°œì„ í•˜ë ¤ ë…¸ë ¥í–ˆìŠµë‹ˆë‹¤.",
            outcome_rating=0.7,
            emotion_state=EmotionData(valence=0.2, arousal=0.6, dominance=0.5, confidence=0.8),
            stakeholders=["ë™ë£Œ", "íŒ€ì›ë“¤", "í”„ë¡œì íŠ¸ ì„±ê³¼"],
            cultural_context="ì§ì¥",
            decision_urgency=0.6,
            actual_regret=0.3,
            user_satisfaction=0.8,
            moral_correctness=0.9
        ),
        EthicsExperience(
            experience_id="exp_2",
            scenario="ìƒì‚¬ê°€ ë¶€ë‹¹í•œ ìš”êµ¬ë¥¼ í–ˆì§€ë§Œ ê±°ë¶€í•˜ê¸° ì–´ë ¤ìš´ ìƒí™©ì´ì—ˆìŠµë‹ˆë‹¤.",
            decision_made="ì •ì¤‘í•˜ê²Œ ëŒ€ì•ˆì„ ì œì‹œí•˜ë©° ê±°ë¶€í–ˆìŠµë‹ˆë‹¤.",
            outcome_rating=0.4,
            emotion_state=EmotionData(valence=-0.3, arousal=0.8, dominance=0.3, confidence=0.7),
            stakeholders=["ìƒì‚¬", "ìì‹ ", "ì¡°ì§"],
            cultural_context="ìœ„ê³„ì§ˆì„œ",
            decision_urgency=0.8,
            actual_regret=0.5,
            user_satisfaction=0.6,
            moral_correctness=0.8
        )
    ]
    
    # ê²½í—˜ ì¶”ê°€
    for exp in test_experiences:
        updater.add_experience(exp)
    
    # ì´ˆê¸° ì •ì±… í™•ì¸
    initial_policy = updater.get_policy()
    print(f"ì´ˆê¸° ì •ì±… ì‹ ë¢°ë„: {initial_policy.confidence_score:.3f}")
    
    # ì •ì±… ì—…ë°ì´íŠ¸ ì‹¤í–‰
    update_result = updater.update_policy_from_experiences(min_experiences=2)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ì •ì±… ì—…ë°ì´íŠ¸ ê²°ê³¼:")
    print(f"- ì—…ë°ì´íŠ¸ í¬ê¸°: {update_result.update_magnitude:.4f}")
    print(f"- ìˆ˜ë ´ ë‹¬ì„±: {'ì˜ˆ' if update_result.convergence_achieved else 'ì•„ë‹ˆì˜¤'}")
    print(f"- ì‹ ë¢°ë„ ë³€í™”: {update_result.confidence_change:.3f}")
    print(f"- ê°œì„  ì˜ì—­: {', '.join(update_result.improvement_areas)}")
    
    print(f"\nâš–ï¸ ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ë³€í™”:")
    old_policy = update_result.old_policy
    new_policy = update_result.new_policy
    
    ethics_types = ['care_harm', 'fairness_cheating', 'loyalty_betrayal', 
                   'authority_subversion', 'sanctity_degradation']
    
    for ethics_type in ethics_types:
        old_val = getattr(old_policy, ethics_type)
        new_val = getattr(new_policy, ethics_type)
        change = new_val - old_val
        print(f"- {ethics_type}: {old_val:.3f} â†’ {new_val:.3f} ({change:+.3f})")
    
    print(f"\nğŸ›ï¸ ê°œì¸-ê³µë™ì²´ ê· í˜• ë³€í™”:")
    print(f"- ê°œì¸: {old_policy.individual_weight:.3f} â†’ {new_policy.individual_weight:.3f}")
    print(f"- ê³µë™ì²´: {old_policy.community_weight:.3f} â†’ {new_policy.community_weight:.3f}")
    
    print(f"\nğŸŒ ë¬¸í™”ì  ë§¥ë½ ë³€í™”:")
    for key in old_policy.cultural_context:
        old_val = old_policy.cultural_context[key]
        new_val = new_policy.cultural_context[key]
        change = new_val - old_val
        print(f"- {key}: {old_val:.3f} â†’ {new_val:.3f} ({change:+.3f})")
    
    # ë¶„ì„ ì •ë³´
    analytics = updater.get_policy_analytics()
    print(f"\nğŸ“ˆ ì •ì±… ë¶„ì„:")
    print(f"- ì´ ì—…ë°ì´íŠ¸: {analytics['update_statistics']['total_updates']}")
    print(f"- ì„±ê³µë¥ : {analytics['update_statistics']['average_improvement']:.3f}")
    print(f"- ìˆ˜ë ´ë¥ : {analytics['update_statistics']['convergence_rate']:.3f}")
    
    return updater, update_result


if __name__ == "__main__":
    test_ethics_policy_updater()
