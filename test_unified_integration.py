#!/usr/bin/env python3
"""
Red Heart AI í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ë° í†µí•© í…ŒìŠ¤íŠ¸
"""

import asyncio
import torch
import time
import argparse
import json
from pathlib import Path
from typing import Dict, List, Any
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s'
)
logger = logging.getLogger('TestUnifiedIntegration')

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
import sys
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from main_unified import UnifiedInferenceSystem, InferenceConfig, MemoryMode


class UnifiedSystemTester:
    """í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤í„°"""
    
    def __init__(self, memory_mode: str = "normal", verbose: bool = False):
        self.memory_mode = MemoryMode[memory_mode.upper()]
        self.verbose = verbose
        self.results = {
            'passed': 0,
            'failed': 0,
            'skipped': 0,
            'tests': []
        }
        self.system = None
        
    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        
        config = InferenceConfig(
            memory_mode=self.memory_mode,
            auto_memory_mode=False,
            debug=self.verbose
        )
        
        self.system = UnifiedInferenceSystem(config)
        await self.system.initialize()
        
        logger.info(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë“œ: {self.memory_mode.value})")
    
    async def test_basic_inference(self):
        """ê¸°ë³¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
        test_name = "ê¸°ë³¸ ì¶”ë¡ "
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {test_name}")
        
        try:
            text = "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ì„œ ê¸°ë¶„ì´ ì¢‹ìŠµë‹ˆë‹¤."
            result = await self.system.analyze(text)
            
            # ê²°ê³¼ ê²€ì¦
            assert 'emotion' in result, "ê°ì • ë¶„ì„ ê²°ê³¼ ì—†ìŒ"
            assert 'bentham' in result, "ë²¤ë‹´ ê³„ì‚° ê²°ê³¼ ì—†ìŒ"
            assert 'processing_time' in result, "ì²˜ë¦¬ ì‹œê°„ ì—†ìŒ"
            
            if self.verbose:
                logger.info(f"   ê°ì •: {result.get('emotion', {})}")
                logger.info(f"   ë²¤ë‹´: {result.get('bentham', {})}")
                logger.info(f"   ì²˜ë¦¬ ì‹œê°„: {result.get('processing_time', 0):.2f}ì´ˆ")
            
            self.results['passed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'passed',
                'time': result.get('processing_time', 0)
            })
            logger.info(f"   âœ… {test_name} í†µê³¼")
            
        except Exception as e:
            self.results['failed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'failed',
                'error': str(e)
            })
            logger.error(f"   âŒ {test_name} ì‹¤íŒ¨: {e}")
    
    async def test_pipeline_connection(self):
        """íŒŒì´í”„ë¼ì¸ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        test_name = "íŒŒì´í”„ë¼ì¸ ì—°ê²°"
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {test_name}")
        
        try:
            text = "ì¤‘ìš”í•œ ê²°ì •ì„ ì•ë‘ê³  ê³ ë¯¼ì´ ë§ìŠµë‹ˆë‹¤."
            result = await self.system.analyze(text)
            
            # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ê²€ì¦
            checks = []
            
            # 1. ê°ì • â†’ ë²¤ë‹´ ì—°ê²°
            if 'emotion' in result and 'bentham' in result:
                bentham = result['bentham']
                if isinstance(bentham, dict) and 'intensity' in bentham:
                    checks.append("ê°ì •â†’ë²¤ë‹´")
            
            # 2. ë°˜ì‚¬ì‹¤ ì¶”ë¡ 
            if 'counterfactuals' in result:
                checks.append("ë°˜ì‚¬ì‹¤ì¶”ë¡ ")
            
            # 3. í›„íšŒ ê³„ì‚°
            if 'regret' in result:
                checks.append("í›„íšŒê³„ì‚°")
            
            # 4. ì‹œê³„ì—´ ì „íŒŒ
            if self.memory_mode.value in ['normal', 'heavy', 'ultra', 'extreme']:
                if 'temporal_impact' in result:
                    checks.append("ì‹œê³„ì—´ì „íŒŒ")
            
            # 5. ë©”íƒ€ í†µí•©
            if self.memory_mode.value == 'extreme':
                if 'meta_integrated' in result:
                    checks.append("ë©”íƒ€í†µí•©")
            
            if self.verbose:
                logger.info(f"   ì—°ê²°ëœ ë‹¨ê³„: {' â†’ '.join(checks)}")
            
            assert len(checks) >= 3, f"íŒŒì´í”„ë¼ì¸ ì—°ê²° ë¶€ì¡± ({len(checks)}/5)"
            
            self.results['passed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'passed',
                'pipeline': checks
            })
            logger.info(f"   âœ… {test_name} í†µê³¼ ({len(checks)}ë‹¨ê³„ ì—°ê²°)")
            
        except Exception as e:
            self.results['failed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'failed',
                'error': str(e)
            })
            logger.error(f"   âŒ {test_name} ì‹¤íŒ¨: {e}")
    
    async def test_memory_mode_modules(self):
        """ë©”ëª¨ë¦¬ ëª¨ë“œë³„ ëª¨ë“ˆ í™œì„±í™” í…ŒìŠ¤íŠ¸"""
        test_name = f"ë©”ëª¨ë¦¬ ëª¨ë“œ ëª¨ë“ˆ ({self.memory_mode.value})"
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {test_name}")
        
        try:
            # ëª¨ë“œë³„ ì˜ˆìƒ ëª¨ë“ˆ
            expected_modules = {
                MemoryMode.MINIMAL: [],
                MemoryMode.LIGHT: [],
                MemoryMode.NORMAL: ['dsp_simulator', 'kalman_filter'],
                MemoryMode.HEAVY: ['dsp_simulator', 'kalman_filter', 'neural_analyzers'],
                MemoryMode.ULTRA: ['dsp_simulator', 'kalman_filter', 'neural_analyzers', 'advanced_wrappers'],
                MemoryMode.EXTREME: ['dsp_simulator', 'kalman_filter', 'neural_analyzers', 
                                    'advanced_wrappers', 'meta_integration', 'counterfactual_reasoning']
            }
            
            expected = expected_modules[self.memory_mode]
            actual = []
            
            if self.system.dsp_simulator is not None:
                actual.append('dsp_simulator')
            if self.system.kalman_filter is not None:
                actual.append('kalman_filter')
            if self.system.neural_analyzers is not None:
                actual.append('neural_analyzers')
            if self.system.advanced_wrappers is not None:
                actual.append('advanced_wrappers')
            if self.system.meta_integration is not None:
                actual.append('meta_integration')
            if self.system.counterfactual_reasoning is not None:
                actual.append('counterfactual_reasoning')
            
            if self.verbose:
                logger.info(f"   ì˜ˆìƒ ëª¨ë“ˆ: {expected}")
                logger.info(f"   ì‹¤ì œ ëª¨ë“ˆ: {actual}")
            
            # ì˜ˆìƒ ëª¨ë“ˆì´ ëª¨ë‘ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
            for module in expected:
                assert module in actual, f"{module} ëª¨ë“ˆì´ ë¡œë“œë˜ì§€ ì•ŠìŒ"
            
            self.results['passed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'passed',
                'modules': actual
            })
            logger.info(f"   âœ… {test_name} í†µê³¼ ({len(actual)}ê°œ ëª¨ë“ˆ)")
            
        except Exception as e:
            self.results['failed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'failed',
                'error': str(e)
            })
            logger.error(f"   âŒ {test_name} ì‹¤íŒ¨: {e}")
    
    async def test_emotion_to_bentham(self):
        """ê°ì •â†’ë²¤ë‹´ ë³€í™˜ í…ŒìŠ¤íŠ¸"""
        test_name = "ê°ì •â†’ë²¤ë‹´ ë³€í™˜"
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {test_name}")
        
        try:
            # í…ŒìŠ¤íŠ¸ ê°ì • ë°ì´í„°
            emotion_data = {
                'scores': [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2],
                'hierarchy': {'community': True, 'other': True, 'self': True}
            }
            
            # ë³€í™˜ ì‹¤í–‰
            bentham_params = self.system.emotion_to_bentham_converter(emotion_data)
            
            # ê²°ê³¼ ê²€ì¦
            required_keys = ['intensity', 'duration', 'certainty', 
                           'propinquity', 'fecundity', 'purity', 'extent']
            
            for key in required_keys:
                assert key in bentham_params, f"ë²¤ë‹´ íŒŒë¼ë¯¸í„° '{key}' ì—†ìŒ"
                assert 0 <= bentham_params[key] <= 2, f"ë²¤ë‹´ íŒŒë¼ë¯¸í„° '{key}' ë²”ìœ„ ì´ˆê³¼"
            
            # ê³„ì¸µì  ê°€ì¤‘ì¹˜ ì ìš© í™•ì¸
            assert bentham_params['extent'] > 0.2, "ê³„ì¸µì  ê°€ì¤‘ì¹˜ ë¯¸ì ìš©"
            
            if self.verbose:
                logger.info(f"   ë³€í™˜ ê²°ê³¼: {bentham_params}")
            
            self.results['passed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'passed',
                'bentham': bentham_params
            })
            logger.info(f"   âœ… {test_name} í†µê³¼")
            
        except Exception as e:
            self.results['failed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'failed',
                'error': str(e)
            })
            logger.error(f"   âŒ {test_name} ì‹¤íŒ¨: {e}")
    
    async def test_batch_processing(self):
        """ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        test_name = "ë°°ì¹˜ ì²˜ë¦¬"
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {test_name}")
        
        try:
            texts = [
                "ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤.",
                "ë‘ ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤.",
                "ì„¸ ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤."
            ]
            
            start_time = time.time()
            results = []
            
            for text in texts:
                result = await self.system.analyze(text)
                results.append(result)
            
            total_time = time.time() - start_time
            avg_time = total_time / len(texts)
            
            # ëª¨ë“  ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            assert len(results) == len(texts), "ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ìˆ˜ ë¶ˆì¼ì¹˜"
            
            for i, result in enumerate(results):
                assert 'error' not in result, f"ë°°ì¹˜ {i+1} ì²˜ë¦¬ ì˜¤ë¥˜"
            
            if self.verbose:
                logger.info(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
                logger.info(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            
            self.results['passed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'passed',
                'batch_size': len(texts),
                'avg_time': avg_time
            })
            logger.info(f"   âœ… {test_name} í†µê³¼ (í‰ê·  {avg_time:.2f}ì´ˆ)")
            
        except Exception as e:
            self.results['failed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'failed',
                'error': str(e)
            })
            logger.error(f"   âŒ {test_name} ì‹¤íŒ¨: {e}")
    
    async def test_cache_functionality(self):
        """ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_name = "ìºì‹œ ê¸°ëŠ¥"
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {test_name}")
        
        try:
            text = "ìºì‹œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë¬¸ì¥ì…ë‹ˆë‹¤."
            
            # ì²« ë²ˆì§¸ ë¶„ì„
            result1 = await self.system.analyze(text)
            time1 = result1.get('processing_time', 0)
            
            # ë‘ ë²ˆì§¸ ë¶„ì„ (ìºì‹œ íˆíŠ¸ ì˜ˆìƒ)
            result2 = await self.system.analyze(text)
            time2 = result2.get('processing_time', 0)
            
            # ìºì‹œê°€ ì‘ë™í•˜ë©´ ë‘ ë²ˆì§¸ê°€ ë” ë¹¨ë¼ì•¼ í•¨
            assert time2 <= time1, "ìºì‹œ ì„±ëŠ¥ ê°œì„  ì—†ìŒ"
            
            if self.verbose:
                logger.info(f"   ì²« ë²ˆì§¸ ì²˜ë¦¬: {time1:.3f}ì´ˆ")
                logger.info(f"   ë‘ ë²ˆì§¸ ì²˜ë¦¬: {time2:.3f}ì´ˆ")
                logger.info(f"   ì„±ëŠ¥ ê°œì„ : {((time1-time2)/time1*100):.1f}%")
            
            self.results['passed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'passed',
                'improvement': f"{((time1-time2)/time1*100):.1f}%"
            })
            logger.info(f"   âœ… {test_name} í†µê³¼")
            
        except Exception as e:
            self.results['failed'] += 1
            self.results['tests'].append({
                'name': test_name,
                'status': 'failed',
                'error': str(e)
            })
            logger.error(f"   âŒ {test_name} ì‹¤íŒ¨: {e}")
    
    async def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("="*60)
        logger.info(f"ğŸš€ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ (ë©”ëª¨ë¦¬ ëª¨ë“œ: {self.memory_mode.value})")
        logger.info("="*60)
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        await self.initialize()
        
        # í…ŒìŠ¤íŠ¸ ëª©ë¡
        tests = [
            self.test_basic_inference,
            self.test_pipeline_connection,
            self.test_memory_mode_modules,
            self.test_emotion_to_bentham,
            self.test_batch_processing,
            self.test_cache_functionality
        ]
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for test in tests:
            await test()
            await asyncio.sleep(0.5)  # í…ŒìŠ¤íŠ¸ ê°„ ì§§ì€ ëŒ€ê¸°
        
        # ê²°ê³¼ ì¶œë ¥
        self.print_summary()
        
        # JSON ê²°ê³¼ ì €ì¥
        self.save_results()
        
        return self.results['failed'] == 0
    
    def print_summary(self):
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ ì¶œë ¥"""
        logger.info("="*60)
        logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        logger.info("="*60)
        
        total = self.results['passed'] + self.results['failed'] + self.results['skipped']
        
        logger.info(f"ì´ í…ŒìŠ¤íŠ¸: {total}")
        logger.info(f"âœ… ì„±ê³µ: {self.results['passed']}")
        logger.info(f"âŒ ì‹¤íŒ¨: {self.results['failed']}")
        logger.info(f"â­ï¸ ê±´ë„ˆëœ€: {self.results['skipped']}")
        
        if total > 0:
            success_rate = (self.results['passed'] / total) * 100
            logger.info(f"ì„±ê³µë¥ : {success_rate:.1f}%")
            
            if success_rate == 100:
                logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
            elif success_rate >= 80:
                logger.info("ğŸ‘ ëŒ€ë¶€ë¶„ì˜ í…ŒìŠ¤íŠ¸ í†µê³¼")
            else:
                logger.warning("âš ï¸ ê°œì„  í•„ìš”")
    
    def save_results(self):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        results_file = f"test_results_{self.memory_mode.value}_{int(time.time())}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥: {results_file}")


async def main():
    parser = argparse.ArgumentParser(description='Red Heart AI í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--memory-mode', default='normal',
                       choices=['minimal', 'light', 'normal', 'heavy', 'ultra', 'extreme'],
                       help='ë©”ëª¨ë¦¬ ëª¨ë“œ')
    parser.add_argument('--verbose', action='store_true',
                       help='ìƒì„¸ ì¶œë ¥')
    
    args = parser.parse_args()
    
    # í…ŒìŠ¤í„° ìƒì„± ë° ì‹¤í–‰
    tester = UnifiedSystemTester(
        memory_mode=args.memory_mode,
        verbose=args.verbose
    )
    
    success = await tester.run_all_tests()
    
    # ì¢…ë£Œ ì½”ë“œ ë°˜í™˜
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    asyncio.run(main())