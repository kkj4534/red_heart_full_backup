ğŸš€ Red Heart AI í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘
===========================================
[0;34m[INFO][0m ì‘ì—… ë””ë ‰í† ë¦¬: /mnt/c/large_project/linux_red_heart
[0;34m[INFO][0m Red Heart AI í†µí•© í™˜ê²½ ìƒíƒœ í™•ì¸ ì¤‘...
[0;32m[SUCCESS][0m âœ… red_heart_env ê°€ìƒí™˜ê²½ ì¡´ì¬
[0;32m[SUCCESS][0m âœ… faiss-test conda í™˜ê²½ ì¡´ì¬
[0;32m[SUCCESS][0m âœ… FAISS ì„¤ì¹˜ë¨ ë° ì‘ë™ í™•ì¸
âœ… Red Heart AI í†µí•© í™˜ê²½ í™œì„±í™” ì™„ë£Œ
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (í•¨ê»˜ í™œì„±í™”ë¨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - í™˜ê²½ ë¶„ë¦¬: faissâ†’conda subprocess, ë‚˜ë¨¸ì§€â†’venv
[0;32m[SUCCESS][0m âœ… ì£¼ìš” íŒ¨í‚¤ì§€ (torch, transformers, numpy) ì„¤ì¹˜ë¨
[0;32m[SUCCESS][0m ğŸ‰ ëª¨ë“  í™˜ê²½ì´ ì´ë¯¸ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!
âœ… Red Heart AI í†µí•© í™˜ê²½ í™œì„±í™” ì™„ë£Œ
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (í•¨ê»˜ í™œì„±í™”ë¨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - í™˜ê²½ ë¶„ë¦¬: faissâ†’conda subprocess, ë‚˜ë¨¸ì§€â†’venv
[0;32m[SUCCESS][0m âœ… Red Heart AI í†µí•© í™˜ê²½ í™œì„±í™” ì™„ë£Œ
[0;32m[SUCCESS][0m    - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
[0;32m[SUCCESS][0m    - conda: faiss-test í™˜ê²½ ì¤€ë¹„ë¨
[0;32m[SUCCESS][0m    - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
[0;32m[SUCCESS][0m    - í™˜ê²½ ë¶„ë¦¬: faissâ†’conda subprocess, ë‚˜ë¨¸ì§€â†’venv
[0;34m[INFO][0m Red Heart AI í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘
[0;34m[INFO][0m í™˜ê²½ ë¶„ë¦¬: conda(faiss) + venv(transformers,torch)
[0;34m[INFO][0m Red Heart AI í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹œì‘...
[0;34m[INFO][0m ì‹¤í–‰ ëª¨ë“œ: unified-test
[0;34m[INFO][0m ğŸ§ª 800M í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ëª¨ë“œ...
ğŸ” [ì´ˆê¸°í™” ì‹œì‘ ì „] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 0.000GB (0.0%)
   ğŸ“¦ ì˜ˆì•½ë¨: 0.000GB
   ğŸ’š ì—¬ìœ : 8.000GB
   ğŸ”„ config.py ì¸¡ì •: 0.0%
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
   ğŸ§  GPU í…ì„œ: 0ê°œ, 0.000GB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.000GB
ğŸ” fast_init_mode = False
ğŸŒ ì „ì—­ ëª¨ë“ˆ ìˆœì°¨ ì´ˆê¸°í™” ì‹œì‘ - MasterMemoryOrchestrator ê´€ë¦¬
Device set to use cuda:0
Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.
Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cuda:0
Device set to use cpu
Device set to use cpu
HierarchicalPatternStructure: PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì—†ìŒ (ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ êµ¬ì¡°)
HierarchicalPatternStructure: PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì—†ìŒ (ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ êµ¬ì¡°)
   âš ï¸ neural_components nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ í´ë˜ìŠ¤ 'AdvancedSurdAnalyzer' ëŒ€ì‹  'AdvancedSURDAnalyzer' ì‚¬ìš© (ìœ ì‚¬ë„ ê¸°ë°˜)
   âš ï¸ surd_analyzer nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ í´ë˜ìŠ¤ 'AdvancedBayesianInferenceModule' ëŒ€ì‹  'AdvancedBayesianInference' ì‚¬ìš© (ìœ ì‚¬ë„ ê¸°ë°˜)
   âš ï¸ bayesian_engine nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ llm_engine nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ experience_database nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ hierarchical_emotion nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ usage_pattern_analyzer nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ meta_integration ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedMetaIntegrationSystem), ìŠ¤í‚µ
âš ï¸ GPU ì‚¬ìš©ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤ (20.3%) - ë” ì ê·¹ì  ë¡œë”© í•„ìš”
âœ… ì „ì—­ ëª¨ë“ˆ ìˆœì°¨ ì´ˆê¸°í™” ì™„ë£Œ
ğŸ” [ì „ì—­ ëª¨ë“ˆ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 1.598GB (20.0%)
   ğŸ“¦ ì˜ˆì•½ë¨: 1.686GB
   ğŸ’š ì—¬ìœ : 6.402GB
   ğŸ”„ config.py ì¸¡ì •: 20.0%
   ğŸ§  GPU í…ì„œ: 1095ê°œ, 1.590GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [54343, 768] (torch.float32) - 159.2MB
      2. [50265, 768] (torch.float32) - 147.3MB
      3. [65001, 512] (torch.float32) - 127.0MB
      4. [30522, 768] (torch.float32) - 89.4MB
      5. [3072, 768] (torch.float32) - 9.0MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.088GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 1.914GB (at ì „ì—­ ëª¨ë“ˆ ì´ˆê¸°í™” í›„)
ğŸ” [ë°±ë³¸ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 3.319GB (41.5%)
   ğŸ“¦ ì˜ˆì•½ë¨: 3.441GB
   ğŸ’š ì—¬ìœ : 4.681GB
   ğŸ”„ config.py ì¸¡ì •: 41.5%
   ğŸ§  GPU í…ì„œ: 1339ê°œ, 3.275GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [54343, 768] (torch.float32) - 159.2MB
      3. [50265, 768] (torch.float32) - 147.3MB
      4. [65001, 512] (torch.float32) - 127.0MB
      5. [30522, 768] (torch.float32) - 89.4MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.122GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 3.319GB (at ë°±ë³¸ ì´ˆê¸°í™” í›„)
[O] set_swap_manager OK: self_id=126886791937152 global_id=126886791937152
âœ… ë°±ë³¸ DSM ë“±ë¡ ì™„ë£Œ (CRITICAL ìš°ì„ ìˆœìœ„)
ğŸ” [ìŠ¤ì™‘ ë§¤ë‹ˆì € ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 3.319GB (41.5%)
   ğŸ“¦ ì˜ˆì•½ë¨: 3.441GB
   ğŸ’š ì—¬ìœ : 4.681GB
   ğŸ”„ config.py ì¸¡ì •: 41.5%
   ğŸ§  GPU í…ì„œ: 1339ê°œ, 3.275GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [54343, 768] (torch.float32) - 159.2MB
      3. [50265, 768] (torch.float32) - 147.3MB
      4. [65001, 512] (torch.float32) - 127.0MB
      5. [30522, 768] (torch.float32) - 89.4MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.122GB
[DSM@ìŠ¤ì™‘ë§¤ë‹ˆì €ì´ˆê¸°í™”í›„] models=['unified_backbone']
[DSM@ìŠ¤ì™‘ë§¤ë‹ˆì €ì´ˆê¸°í™”í›„] gpu_resident=['unified_backbone'] sizes={'unified_backbone': '1725.4MB'}
[DSM@ìŠ¤ì™‘ë§¤ë‹ˆì €ì´ˆê¸°í™”í›„] priorities={'unified_backbone': 'critical'}
ğŸ“‹ í—¤ë“œ ì„ ë“±ë¡ ë³´ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨
ğŸ“‹ swap_manager ìƒíƒœ: <class 'dynamic_swap_manager.RedHeartDynamicSwapManager'>
ğŸ“Š DSM ë“±ë¡ëœ í‚¤(ì„ ë“±ë¡ ì „): ['unified_backbone']
ğŸ” [í—¤ë“œ í˜¸í™˜ì„± ë§¤ë‹ˆì € ìƒì„± í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 3.319GB (41.5%)
   ğŸ“¦ ì˜ˆì•½ë¨: 3.441GB
   ğŸ’š ì—¬ìœ : 4.681GB
   ğŸ”„ config.py ì¸¡ì •: 41.5%
   ğŸ§  GPU í…ì„œ: 1339ê°œ, 3.275GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [54343, 768] (torch.float32) - 159.2MB
      3. [50265, 768] (torch.float32) - 147.3MB
      4. [65001, 512] (torch.float32) - 127.0MB
      5. [30522, 768] (torch.float32) - 89.4MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.122GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 3.319GB (at í—¤ë“œ í˜¸í™˜ì„± ë§¤ë‹ˆì € ìƒì„± í›„)
ğŸ“‹ í—¤ë“œ ì„ ë“±ë¡ ë³´ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨
ğŸ“‹ swap_manager ìƒíƒœ: <class 'dynamic_swap_manager.RedHeartDynamicSwapManager'>
ğŸ“Š DSM ë“±ë¡ëœ í‚¤(ì„ ë“±ë¡ ì „): ['emotion_empathy_head', 'unified_backbone']
ğŸš¨ í—¤ë“œ ì´ˆê¸°í™” ì‹œì‘ - ë©”ëª¨ë¦¬ í­ë°œ ì˜ì‹¬ êµ¬ê°„!
ğŸ” head_compatibility_manager = <class 'head_compatibility_interface.HeadCompatibilityManager'>
ğŸ” head_compatibility_manager.initialized = False
ğŸ” initialize_all_heads() í˜¸ì¶œ ì§ì „...
ğŸ“Š ë©”ëª¨ë¦¬ ê³¼ì†Œ í™œìš©: 42.4% (GPU ë¦¬ì†ŒìŠ¤ ë‚­ë¹„)
ğŸ“Š ì¶”ê°€ í™œìš© ê°€ëŠ¥: í˜„ì¬ 45.2% (ëª©í‘œ 82%)
ğŸ” initialize_all_heads() í˜¸ì¶œ ì™„ë£Œ!
ğŸš¨ í—¤ë“œ ì´ˆê¸°í™” ì™„ë£Œ - ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì¤‘...
ğŸ” [ëª¨ë“  í—¤ë“œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 3.612GB (45.2%)
   ğŸ“¦ ì˜ˆì•½ë¨: 3.740GB
   ğŸ’š ì—¬ìœ : 4.387GB
   ğŸ”„ config.py ì¸¡ì •: 45.2%
   ğŸ§  GPU í…ì„œ: 1384ê°œ, 3.568GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [54343, 768] (torch.float32) - 159.2MB
      3. [50265, 768] (torch.float32) - 147.3MB
      4. [65001, 512] (torch.float32) - 127.0MB
      5. [30522, 768] (torch.float32) - 89.4MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.128GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 3.612GB (at ëª¨ë“  í—¤ë“œ ì´ˆê¸°í™” í›„)
[DSM@í—¤ë“œì´ˆê¸°í™”í›„] models=['unified_backbone', 'emotion_empathy_head', 'meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head']
[DSM@í—¤ë“œì´ˆê¸°í™”í›„] gpu_resident=['unified_backbone', 'meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head', 'emotion_empathy_head'] sizes={'unified_backbone': '1725.4MB', 'meta_integration_head': '23.6MB', 'semantic_surd_head': '417.6MB', 'bentham_fromm_head': '0.0MB', 'regret_learning_head': '4.8MB', 'emotion_empathy_head': '31.1MB'}
[DSM@í—¤ë“œì´ˆê¸°í™”í›„] priorities={'unified_backbone': 'critical', 'meta_integration_head': 'low', 'semantic_surd_head': 'medium', 'bentham_fromm_head': 'high', 'regret_learning_head': 'medium', 'emotion_empathy_head': 'high'}
ğŸ” [ì‹œë„ˆì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 3.612GB (45.2%)
   ğŸ“¦ ì˜ˆì•½ë¨: 3.740GB
   ğŸ’š ì—¬ìœ : 4.387GB
   ğŸ”„ config.py ì¸¡ì •: 45.2%
   ğŸ§  GPU í…ì„œ: 1384ê°œ, 3.568GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [54343, 768] (torch.float32) - 159.2MB
      3. [50265, 768] (torch.float32) - 147.3MB
      4. [65001, 512] (torch.float32) - 127.0MB
      5. [30522, 768] (torch.float32) - 89.4MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.128GB
[ULS] DSM id=126886791937152
ğŸ” [í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 5.334GB (66.7%)
   ğŸ“¦ ì˜ˆì•½ë¨: 5.496GB
   ğŸ’š ì—¬ìœ : 2.666GB
   ğŸ”„ config.py ì¸¡ì •: 66.7%
   ğŸ§  GPU í…ì„œ: 1628ê°œ, 5.253GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [50265, 768] (torch.float32) - 147.3MB
      5. [65001, 512] (torch.float32) - 127.0MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.163GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 5.334GB (at í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„)
[DSM@í•™ìŠµì‹œìŠ¤í…œì´ˆê¸°í™”í›„] models=['unified_backbone', 'emotion_empathy_head', 'meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head']
[DSM@í•™ìŠµì‹œìŠ¤í…œì´ˆê¸°í™”í›„] gpu_resident=['unified_backbone', 'meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head', 'emotion_empathy_head'] sizes={'unified_backbone': '1725.4MB', 'meta_integration_head': '23.6MB', 'semantic_surd_head': '417.6MB', 'bentham_fromm_head': '0.0MB', 'regret_learning_head': '4.8MB', 'emotion_empathy_head': '31.1MB'}
[DSM@í•™ìŠµì‹œìŠ¤í…œì´ˆê¸°í™”í›„] priorities={'unified_backbone': 'critical', 'meta_integration_head': 'low', 'semantic_surd_head': 'medium', 'bentham_fromm_head': 'high', 'regret_learning_head': 'medium', 'emotion_empathy_head': 'high'}
ğŸ” [íŒ¨í„´ ë¶„ì„ê¸° ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 5.334GB (66.7%)
   ğŸ“¦ ì˜ˆì•½ë¨: 5.496GB
   ğŸ’š ì—¬ìœ : 2.666GB
   ğŸ”„ config.py ì¸¡ì •: 66.7%
   ğŸ§  GPU í…ì„œ: 1628ê°œ, 5.253GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [50265, 768] (torch.float32) - 147.3MB
      5. [65001, 512] (torch.float32) - 127.0MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.163GB
ğŸ“‹ í—¤ë“œ ì„ ë“±ë¡ ë³´ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨
ğŸ“‹ swap_manager ìƒíƒœ: <class 'dynamic_swap_manager.RedHeartDynamicSwapManager'>
ğŸ“Š DSM ë“±ë¡ëœ í‚¤(ì„ ë“±ë¡ ì „): ['bentham_fromm_head', 'emotion_empathy_head', 'meta_integration_head', 'regret_learning_head', 'semantic_surd_head', 'unified_backbone']
emotion_empathy_head forward ì‹¤íŒ¨: 'dict' object has no attribute 'shape'
ì…ë ¥ shape: torch.Size([4, 768])
í—¤ë“œ emotion_empathy_head - gradient ëŠê¹€ ê°ì§€, ì¬ê³„ì‚° ì‹œë„...
emotion_empathy_head forward ì‹¤íŒ¨: 'dict' object has no attribute 'shape'
ì…ë ¥ shape: torch.Size([4, 768])
emotion_empathy_head loss ê³„ì‚° ì‹¤íŒ¨: The size of tensor a (10) must match the size of tensor b (1280) at non-singleton dimension 1, fallback MSE ì‚¬ìš©
í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: The size of tensor a (1280) must match the size of tensor b (10) at non-singleton dimension 1
ğŸ˜¨ ìƒì„¸ ì—ëŸ¬ ìŠ¤íƒ:
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/fix_nan_loss.py", line 125, in _calculate_safe_loss
    loss = F.kl_div(F.log_softmax(output, dim=-1), target_probs, reduction='batchmean')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/nn/functional.py", line 3381, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The size of tensor a (10) must match the size of tensor b (1280) at non-singleton dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 1729, in train_unified_system
    step_metrics = await self.trainer.train_step(batch_data, active_heads)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 597, in train_step
    losses = self._calculate_losses(outputs, batch_data, active_heads)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 680, in _calculate_losses
    losses = self._stable_loss_calculator.calculate_stable_losses(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/fix_nan_loss.py", line 52, in calculate_stable_losses
    loss = self._calculate_safe_loss(head_output, target, head_type, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/fix_nan_loss.py", line 147, in _calculate_safe_loss
    loss = F.mse_loss(output, target)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/nn/functional.py", line 3791, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/functional.py", line 76, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The size of tensor a (1280) must match the size of tensor b (10) at non-singleton dimension 1

ğŸ” ì—ëŸ¬ íƒ€ì…: RuntimeError
ğŸ“ ì—íŸ¼í¬: 1/1, ë°°ì¹˜: 0
Python í†µí•© í•™ìŠµ ì˜¤ë¥˜: The size of tensor a (1280) must match the size of tensor b (10) at non-singleton dimension 1
ğŸ˜¨ ìƒì„¸ ì—ëŸ¬ ìŠ¤íƒ:
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/fix_nan_loss.py", line 125, in _calculate_safe_loss
    loss = F.kl_div(F.log_softmax(output, dim=-1), target_probs, reduction='batchmean')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/nn/functional.py", line 3381, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The size of tensor a (10) must match the size of tensor b (1280) at non-singleton dimension 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/unified_system_orchestrator.py", line 2030, in _run_python_training
    await self.learning_system.train_unified_system(
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 1729, in train_unified_system
    step_metrics = await self.trainer.train_step(batch_data, active_heads)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 597, in train_step
    losses = self._calculate_losses(outputs, batch_data, active_heads)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/unified_learning_system.py", line 680, in _calculate_losses
    losses = self._stable_loss_calculator.calculate_stable_losses(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/fix_nan_loss.py", line 52, in calculate_stable_losses
    loss = self._calculate_safe_loss(head_output, target, head_type, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/fix_nan_loss.py", line 147, in _calculate_safe_loss
    loss = F.mse_loss(output, target)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/nn/functional.py", line 3791, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/functional.py", line 76, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: The size of tensor a (1280) must match the size of tensor b (10) at non-singleton dimension 1

ğŸ” ì—ëŸ¬ íƒ€ì…: RuntimeError
ğŸ“ num_epochs: 1, num_batches: 1
ğŸ” [ì´ˆê¸°í™” ì‹œì‘ ì „] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 5.350GB (66.9%)
   ğŸ“¦ ì˜ˆì•½ë¨: 6.295GB
   ğŸ’š ì—¬ìœ : 2.650GB
   ğŸ”„ config.py ì¸¡ì •: 66.9%
   ğŸ§  GPU í…ì„œ: 1636ê°œ, 5.256GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [50265, 768] (torch.float32) - 147.3MB
      5. [65001, 512] (torch.float32) - 127.0MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.945GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 6.084GB (at ì´ˆê¸°í™” ì‹œì‘ ì „)
ğŸ” fast_init_mode = False
ğŸŒ ì „ì—­ ëª¨ë“ˆ ìˆœì°¨ ì´ˆê¸°í™” ì‹œì‘ - MasterMemoryOrchestrator ê´€ë¦¬
âš ï¸ translator ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: LocalTranslator), ìŠ¤í‚µ
   âš ï¸ translator DSM ë“±ë¡ ì¤‘ ê²½ê³ : name 'SwapPriority' is not defined
Device set to use cuda:0
Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.
Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cuda:0
âš ï¸ emotion_analyzer ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedEmotionAnalyzer), ìŠ¤í‚µ
   âš ï¸ emotion_analyzer DSM ë“±ë¡ ì¤‘ ê²½ê³ : name 'SwapPriority' is not defined
GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ìœ„í—˜ ìˆ˜ì¤€: 81.0%
ê¸´ê¸‰ GPU ë©”ëª¨ë¦¬ ìµœì í™” ì‹œì‘
ê¸´ê¸‰ GPU ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ
âš ï¸ bentham_calculator ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedBenthamCalculator), ìŠ¤í‚µ
   âš ï¸ bentham_calculator DSM ë“±ë¡ ì¤‘ ê²½ê³ : name 'SwapPriority' is not defined
Device set to use cpu
Device set to use cpu
âš ï¸ semantic_analyzer ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedMultiLevelSemanticAnalyzer), ìŠ¤í‚µ
   âš ï¸ semantic_analyzer DSM ë“±ë¡ ì¤‘ ê²½ê³ : name 'SwapPriority' is not defined
âš ï¸ regret_analyzer ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedRegretAnalyzer), ìŠ¤í‚µ
   âš ï¸ regret_analyzer DSM ë“±ë¡ ì¤‘ ê²½ê³ : name 'SwapPriority' is not defined
âš ï¸ neural_components ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: HierarchicalPatternStructure), ìŠ¤í‚µ
HierarchicalPatternStructure: PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì—†ìŒ (ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ êµ¬ì¡°)
   âš ï¸ neural_components nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
HierarchicalPatternStructure: PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì—†ìŒ (ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ êµ¬ì¡°)
HierarchicalPatternStructure: PyTorch ë„¤íŠ¸ì›Œí¬ê°€ ì—†ìŒ (ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ êµ¬ì¡°)
   âš ï¸ neural_components nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ meta_integration ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedMetaIntegrationSystem), ìŠ¤í‚µ
   âš ï¸ meta_integration DSM ë“±ë¡ ì¤‘ ê²½ê³ : name 'SwapPriority' is not defined
âš ï¸ í´ë˜ìŠ¤ 'AdvancedSurdAnalyzer' ëŒ€ì‹  'AdvancedSURDAnalyzer' ì‚¬ìš© (ìœ ì‚¬ë„ ê¸°ë°˜)
[ì–¸ë¡œë“œ ë¶ˆê°€] ë” ì´ìƒ ì–¸ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤
[DSM] GPU ì‚¬ìš©ë¥  86.2%ë¡œ ëª©í‘œ 85.0% ë‹¬ì„± ì‹¤íŒ¨
ìŠ¤ì™‘ ê³µê°„ ë¶€ì¡±: temp_model_1754865710 (í•„ìš”: 1000MB, í™•ë³´: FalseMB)
âš ï¸ surd_analyzer ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedSURDAnalyzer), ìŠ¤í‚µ
   âš ï¸ surd_analyzer nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ surd_analyzer nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ í´ë˜ìŠ¤ 'AdvancedBayesianInferenceModule' ëŒ€ì‹  'AdvancedBayesianInference' ì‚¬ìš© (ìœ ì‚¬ë„ ê¸°ë°˜)
âš ï¸ bayesian_engine ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedBayesianInference), ìŠ¤í‚µ
   âš ï¸ bayesian_engine nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ bayesian_engine nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ llm_engine ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedLLMEngine), ìŠ¤í‚µ
   âš ï¸ llm_engine nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ llm_engine nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
[ì–¸ë¡œë“œ ë¶ˆê°€] ë” ì´ìƒ ì–¸ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤
[DSM] GPU ì‚¬ìš©ë¥  86.2%ë¡œ ëª©í‘œ 85.0% ë‹¬ì„± ì‹¤íŒ¨
ìŠ¤ì™‘ ê³µê°„ ë¶€ì¡±: temp_model_1754865710 (í•„ìš”: 1000MB, í™•ë³´: FalseMB)
âš ï¸ experience_database ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedExperienceDatabase), ìŠ¤í‚µ
   âš ï¸ experience_database nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ experience_database nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ hierarchical_emotion ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedHierarchicalEmotionSystem), ìŠ¤í‚µ
   âš ï¸ hierarchical_emotion nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ hierarchical_emotion nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ usage_pattern_analyzer ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedUsagePatternAnalyzer), ìŠ¤í‚µ
   âš ï¸ usage_pattern_analyzer nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
   âš ï¸ usage_pattern_analyzer nn.Module ì¶”ì¶œ ì‹¤íŒ¨ - DSM ë“±ë¡ ìŠ¤í‚µ
âš ï¸ meta_integration ì´ë¯¸ ë“±ë¡ë¨ (ë™ì¼ íƒ€ì…: AdvancedMetaIntegrationSystem), ìŠ¤í‚µ
âœ… ì „ì—­ ëª¨ë“ˆ ìˆœì°¨ ì´ˆê¸°í™” ì™„ë£Œ
ğŸ” [ì „ì—­ ëª¨ë“ˆ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 6.899GB (86.2%)
   ğŸ“¦ ì˜ˆì•½ë¨: 7.164GB
   ğŸ’š ì—¬ìœ : 1.101GB
   ğŸ”„ config.py ì¸¡ì •: 86.2%
   ğŸ§  GPU í…ì„œ: 2624ê°œ, 6.803GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.266GB
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 7.259GB (at ì „ì—­ ëª¨ë“ˆ ì´ˆê¸°í™” í›„)
ğŸ” [ë°±ë³¸ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 6.899GB (86.2%)
   ğŸ“¦ ì˜ˆì•½ë¨: 7.164GB
   ğŸ’š ì—¬ìœ : 1.101GB
   ğŸ”„ config.py ì¸¡ì •: 86.2%
   ğŸ§  GPU í…ì„œ: 2624ê°œ, 6.803GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.266GB
[O] set_swap_manager OK: self_id=126886786946432 global_id=126886786946432
âœ… ë°±ë³¸ DSM ë“±ë¡ ì™„ë£Œ (CRITICAL ìš°ì„ ìˆœìœ„)
ğŸ” [ìŠ¤ì™‘ ë§¤ë‹ˆì € ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 6.899GB (86.2%)
   ğŸ“¦ ì˜ˆì•½ë¨: 7.164GB
   ğŸ’š ì—¬ìœ : 1.101GB
   ğŸ”„ config.py ì¸¡ì •: 86.2%
   ğŸ§  GPU í…ì„œ: 2624ê°œ, 6.803GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.266GB
[DSM@ìŠ¤ì™‘ë§¤ë‹ˆì €ì´ˆê¸°í™”í›„] models=['unified_backbone']
[DSM@ìŠ¤ì™‘ë§¤ë‹ˆì €ì´ˆê¸°í™”í›„] gpu_resident=[] sizes={}
[DSM@ìŠ¤ì™‘ë§¤ë‹ˆì €ì´ˆê¸°í™”í›„] priorities={}
ğŸ“‹ í—¤ë“œ ì„ ë“±ë¡ ë³´ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨
ğŸ“‹ swap_manager ìƒíƒœ: <class 'dynamic_swap_manager.RedHeartDynamicSwapManager'>
ğŸ“Š DSM ë“±ë¡ëœ í‚¤(ì„ ë“±ë¡ ì „): ['unified_backbone']
[ì–¸ë¡œë“œ ë¶ˆê°€] ë” ì´ìƒ ì–¸ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤
[DSM] GPU ì‚¬ìš©ë¥  86.2%ë¡œ ëª©í‘œ 85.0% ë‹¬ì„± ì‹¤íŒ¨
ìŠ¤ì™‘ ê³µê°„ ë¶€ì¡±: temp_model_1754865716 (í•„ìš”: 500.024641418457MB, í™•ë³´: FalseMB)
[DSM] emotion_empathy_head GPU ë¡œë”© ì‹¤íŒ¨: device=cpu (NO FALLBACK)
í—¤ë“œ GPU ë¡œë”© ì‹¤íŒ¨: emotion_empathy_head, ì˜¤ë¥˜: [DSM] emotion_empathy_head GPU ë¡œë”© ì‹¤íŒ¨: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (NO FALLBACK)
[ì–¸ë¡œë“œ ë¶ˆê°€] ë” ì´ìƒ ì–¸ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤
[DSM] GPU ì‚¬ìš©ë¥  86.2%ë¡œ ëª©í‘œ 85.0% ë‹¬ì„± ì‹¤íŒ¨
ìŠ¤ì™‘ ê³µê°„ ë¶€ì¡±: temp_model_1754865781 (í•„ìš”: 500.02669486999514MB, í™•ë³´: FalseMB)
[ì–¸ë¡œë“œ ë¶ˆê°€] ë” ì´ìƒ ì–¸ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤
[DSM] GPU ì‚¬ìš©ë¥  86.2%ë¡œ ëª©í‘œ 85.0% ë‹¬ì„± ì‹¤íŒ¨
ìŠ¤ì™‘ ê³µê°„ ë¶€ì¡±: temp_model_1754865781 (í•„ìš”: 500.02669486999514MB, í™•ë³´: FalseMB)
[ì–¸ë¡œë“œ ë¶ˆê°€] ë” ì´ìƒ ì–¸ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤
[DSM] GPU ì‚¬ìš©ë¥  86.2%ë¡œ ëª©í‘œ 85.0% ë‹¬ì„± ì‹¤íŒ¨
ìŠ¤ì™‘ ê³µê°„ ë¶€ì¡±: temp_model_1754865782 (í•„ìš”: 500.02669486999514MB, í™•ë³´: FalseMB)
âš ï¸ warm load/unload ì‹¤íŒ¨: [DSM] emotion_empathy_head GPU ë¡œë”© ì‹¤íŒ¨: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (NO FALLBACK)
ğŸ” [í—¤ë“œ í˜¸í™˜ì„± ë§¤ë‹ˆì € ìƒì„± í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 6.899GB (86.2%)
   ğŸ“¦ ì˜ˆì•½ë¨: 7.139GB
   ğŸ’š ì—¬ìœ : 1.101GB
   ğŸ”„ config.py ì¸¡ì •: 86.2%
   ğŸ§  GPU í…ì„œ: 2624ê°œ, 6.803GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.240GB
ğŸ“‹ í—¤ë“œ ì„ ë“±ë¡ ë³´ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨
ğŸ“‹ swap_manager ìƒíƒœ: <class 'dynamic_swap_manager.RedHeartDynamicSwapManager'>
ğŸ“Š DSM ë“±ë¡ëœ í‚¤(ì„ ë“±ë¡ ì „): ['emotion_empathy_head', 'unified_backbone']
ğŸš¨ í—¤ë“œ ì´ˆê¸°í™” ì‹œì‘ - ë©”ëª¨ë¦¬ í­ë°œ ì˜ì‹¬ êµ¬ê°„!
ğŸ” head_compatibility_manager = <class 'head_compatibility_interface.HeadCompatibilityManager'>
ğŸ” head_compatibility_manager.initialized = False
ğŸ” initialize_all_heads() í˜¸ì¶œ ì§ì „...
ğŸ” initialize_all_heads() í˜¸ì¶œ ì™„ë£Œ!
ğŸš¨ í—¤ë“œ ì´ˆê¸°í™” ì™„ë£Œ - ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸ ì¤‘...
ğŸ” [ëª¨ë“  í—¤ë“œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 6.899GB (86.2%)
   ğŸ“¦ ì˜ˆì•½ë¨: 7.139GB
   ğŸ’š ì—¬ìœ : 1.101GB
   ğŸ”„ config.py ì¸¡ì •: 86.2%
   ğŸ§  GPU í…ì„œ: 2624ê°œ, 6.803GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.240GB
[DSM@í—¤ë“œì´ˆê¸°í™”í›„] models=['unified_backbone', 'emotion_empathy_head', 'meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head']
[DSM@í—¤ë“œì´ˆê¸°í™”í›„] gpu_resident=['meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head', 'emotion_empathy_head'] sizes={'meta_integration_head': '23.6MB', 'semantic_surd_head': '417.6MB', 'bentham_fromm_head': '0.0MB', 'regret_learning_head': '4.8MB', 'emotion_empathy_head': '31.1MB'}
[DSM@í—¤ë“œì´ˆê¸°í™”í›„] priorities={'meta_integration_head': 'low', 'semantic_surd_head': 'medium', 'bentham_fromm_head': 'high', 'regret_learning_head': 'medium', 'emotion_empathy_head': 'high'}
ğŸš¨ GPU ì‚¬ìš©ë¥  86.2% - DSM ê¸´ê¸‰ ì •ë¦¬ ìˆ˜í–‰ (target=85%)
[DSM@ê¸´ê¸‰ì •ë¦¬ì „] models=['unified_backbone', 'emotion_empathy_head', 'meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head']
[DSM@ê¸´ê¸‰ì •ë¦¬ì „] gpu_resident=['meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head', 'emotion_empathy_head'] sizes={'meta_integration_head': '23.6MB', 'semantic_surd_head': '417.6MB', 'bentham_fromm_head': '0.0MB', 'regret_learning_head': '4.8MB', 'emotion_empathy_head': '31.1MB'}
[DSM@ê¸´ê¸‰ì •ë¦¬ì „] priorities={'meta_integration_head': 'low', 'semantic_surd_head': 'medium', 'bentham_fromm_head': 'high', 'regret_learning_head': 'medium', 'emotion_empathy_head': 'high'}
ğŸ” [ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 6.466GB (80.8%)
   ğŸ“¦ ì˜ˆì•½ë¨: 6.719GB
   ğŸ’š ì—¬ìœ : 1.534GB
   ğŸ”„ config.py ì¸¡ì •: 80.8%
   ğŸ§  GPU í…ì„œ: 2366ê°œ, 6.372GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.253GB
[DSM@ê¸´ê¸‰ì •ë¦¬í›„] models=['unified_backbone', 'emotion_empathy_head', 'meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head']
[DSM@ê¸´ê¸‰ì •ë¦¬í›„] gpu_resident=['regret_learning_head', 'emotion_empathy_head'] sizes={'regret_learning_head': '4.8MB', 'emotion_empathy_head': '31.1MB'}
[DSM@ê¸´ê¸‰ì •ë¦¬í›„] priorities={'regret_learning_head': 'medium', 'emotion_empathy_head': 'high'}
ğŸ” [ì‹œë„ˆì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 6.466GB (80.8%)
   ğŸ“¦ ì˜ˆì•½ë¨: 6.719GB
   ğŸ’š ì—¬ìœ : 1.534GB
   ğŸ”„ config.py ì¸¡ì •: 80.8%
   ğŸ§  GPU í…ì„œ: 2366ê°œ, 6.372GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.253GB
[ULS] DSM id=126886786946432
ğŸ” [í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 8.188GB (102.4%)
   ğŸ“¦ ì˜ˆì•½ë¨: 8.434GB
   ğŸ’š ì—¬ìœ : -0.189GB
   ğŸ”„ config.py ì¸¡ì •: 102.4%
   ğŸ§  GPU í…ì„œ: 2610ê°œ, 8.057GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50000, 1280] (torch.float32) - 244.1MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.245GB
   ğŸš¨ğŸš¨ğŸš¨ CRITICAL: ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš° (102.4%)
   ğŸ” ìƒˆë¡œìš´ Peak ë©”ëª¨ë¦¬: 8.188GB (at í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í›„)
[DSM@í•™ìŠµì‹œìŠ¤í…œì´ˆê¸°í™”í›„] models=['unified_backbone', 'emotion_empathy_head', 'meta_integration_head', 'semantic_surd_head', 'bentham_fromm_head', 'regret_learning_head']
[DSM@í•™ìŠµì‹œìŠ¤í…œì´ˆê¸°í™”í›„] gpu_resident=['regret_learning_head', 'emotion_empathy_head'] sizes={'regret_learning_head': '4.8MB', 'emotion_empathy_head': '31.1MB'}
[DSM@í•™ìŠµì‹œìŠ¤í…œì´ˆê¸°í™”í›„] priorities={'regret_learning_head': 'medium', 'emotion_empathy_head': 'high'}
ğŸ” [íŒ¨í„´ ë¶„ì„ê¸° ì´ˆê¸°í™” í›„] GPU ë©”ëª¨ë¦¬ ìƒíƒœ:
   ğŸ’¾ ì´ ë©”ëª¨ë¦¬: 8.00GB
   ğŸ“Š í• ë‹¹ë¨: 8.188GB (102.4%)
   ğŸ“¦ ì˜ˆì•½ë¨: 8.434GB
   ğŸ’š ì—¬ìœ : -0.189GB
   ğŸ”„ config.py ì¸¡ì •: 102.4%
   ğŸ§  GPU í…ì„œ: 2610ê°œ, 8.057GB
   ğŸ“‹ í° í…ì„œ TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50000, 1280] (torch.float32) - 244.1MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   ğŸ—‚ï¸ ìºì‹œëœ ë©”ëª¨ë¦¬: 0.245GB
   ğŸš¨ğŸš¨ğŸš¨ CRITICAL: ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš° (102.4%)
============================================================
ğŸš€ Red Heart AI í†µí•© ì‹œìŠ¤í…œ (800M íŒŒë¼ë¯¸í„°)
============================================================
ëª¨ë“œ: test
ì‹œì‘ ì‹œê°„: 2025-08-11 07:31:00
------------------------------------------------------------
ğŸ”§ klue/bert-base ëª¨ë¸: ì•ˆì •ì„± ë³´ì¥ì„ ìœ„í•œ 15.0% í• ë‹¹
ğŸ“‹ Transformer ëª¨ë¸: ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ ë°©ì‹ í™œì„±í™”
[07:39:42] âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ
[07:39:42] ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹œì‘...
ğŸ” ë°±ë³¸ Gradient ì¶”ì  ì‹œì‘
   ë°±ë³¸ training ëª¨ë“œ: True
   input_ids.requires_grad: False
   input_ids.shape: torch.Size([4, 128])
   token_embedding í›„: False
   ğŸ”§ gradient íë¦„ ê°•ì œ í™œì„±í™”: True
   token_embedding íŒŒë¼ë¯¸í„° requires_grad: True
   ğŸ”§ pooled_output gradient íë¦„ ê°•ì œ í™œì„±í™”: True
   unified_representation_network í›„: False
   ğŸ”§ unified_features gradient íë¦„ ê°•ì œ í™œì„±í™”: True
   memory_bank.requires_grad: True
   unified_representation_network íŒŒë¼ë¯¸í„° requires_grad: True
   memory_expanded.requires_grad: True
   unified_expanded.requires_grad: True
   [cross_modal_fusion ì‹¤í–‰ ì „]
     query.requires_grad: True
     key.requires_grad: True
     value.requires_grad: True
     cross_modal_fusion íŒŒë¼ë¯¸í„° requires_grad: True
   cross_modal_fusion í›„: False
   cross_modal_output.grad_fn: None
   ğŸ”§ cross_modal_output gradient íë¦„ ê°•ì œ í™œì„±í™”: True
ğŸ¯ ìµœì¢… cross_modal_features.requires_grad: True
   output_projection í›„: False
   ğŸ”§ final_output gradient íë¦„ ê°•ì œ í™œì„±í™”: True
âœ… ë°±ë³¸ ì¶œë ¥ gradient ì—°ê²° í™•ì¸: requires_grad=True
ğŸ‰ ìµœì¢… ë°±ë³¸ ì¶œë ¥ ì„±ê³µ: shared_embedding.requires_grad=True
ğŸ”§ klue/bert-base ëª¨ë¸: ì•ˆì •ì„± ë³´ì¥ì„ ìœ„í•œ 15.0% í• ë‹¹
ğŸ“‹ Transformer ëª¨ë¸: ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ ë°©ì‹ í™œì„±í™”
[07:43:47] âŒ í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤íŒ¨
[0;34m[INFO][0m í•™ìŠµ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...
[0;34m[INFO][0m GPU ë©”ëª¨ë¦¬ ì •ë¦¬...
[0;32m[SUCCESS][0m ì •ë¦¬ ì™„ë£Œ
