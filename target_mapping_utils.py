#!/usr/bin/env python3
"""
Red Heart AI íƒ€ê¹ƒ ë§¤í•‘ ìœ í‹¸ë¦¬í‹°
- ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ í•™ìŠµìš© íƒ€ê¹ƒìœ¼ë¡œ ë³€í™˜
- í”„ë¡œì íŠ¸ ê·œì¹™: NO FALLBACK, ë”ë¯¸ ë°ì´í„° ì—†ìŒ
"""

import torch
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
import logging

logger = logging.getLogger('RedHeart.TargetMapping')

class TargetMapper:
    """ì „ì²˜ë¦¬ ë°ì´í„°ë¥¼ í•™ìŠµ íƒ€ê¹ƒìœ¼ë¡œ ë§¤í•‘"""
    
    # Sentence-Transformers ì¸ì½”ë” ìºì‹± (í´ë˜ìŠ¤ ë³€ìˆ˜)
    _sentence_encoder = None
    _encoder_device = None
    
    @classmethod
    def _get_sentence_encoder(cls):
        """
        Sentence-Transformers ì¸ì½”ë” ì´ˆê¸°í™” ë° ë°˜í™˜
        ìºì‹±ëœ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        """
        if cls._sentence_encoder is None:
            try:
                from sentence_transformers import SentenceTransformer
                logger.info("ğŸ”„ Sentence-Transformers ì¸ì½”ë” ì´ˆê¸°í™” ì¤‘...")
                
                # ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš© (384ì°¨ì› ì¶œë ¥)
                # all-MiniLM-L6-v2: 80MB, ë¹ ë¥´ê³  íš¨ìœ¨ì 
                cls._sentence_encoder = SentenceTransformer('all-MiniLM-L6-v2')
                
                # ë””ë°”ì´ìŠ¤ ì„¤ì •
                cls._encoder_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                cls._sentence_encoder = cls._sentence_encoder.to(cls._encoder_device)
                
                logger.info(f"âœ… Sentence-Transformers ì¸ì½”ë” ì¤€ë¹„ ì™„ë£Œ (device: {cls._encoder_device})")
            except ImportError as e:
                raise RuntimeError(f"sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”: {e}")
            except Exception as e:
                raise RuntimeError(f"Sentence-Transformers ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        return cls._sentence_encoder
    
    @classmethod
    def extract_context_embedding(cls, batch: List[Dict], backbone_model=None) -> torch.Tensor:
        """
        ì»¨í…ìŠ¤íŠ¸ ì„ë² ë”© ì¶”ì¶œ (í˜¸í™˜ì„± ëª¨ë“œ í¬í•¨)
        Args:
            batch: ë°°ì¹˜ ë°ì´í„° (ë¦¬ìŠ¤íŠ¸ of dict)
            backbone_model: í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•  ë°±ë³¸ ëª¨ë¸ (ì„ íƒ)
        Returns:
            (batch_size, 768) í…ì„œ
        """
        if not batch:
            raise ValueError("ë°°ì¹˜ê°€ ë¹„ì–´ìˆìŒ")
        
        embeddings = []
        
        for item in batch:
            # context_embeddingì´ ìˆìœ¼ë©´ ì§ì ‘ ì‚¬ìš©
            if 'context_embedding' in item:
                emb = item['context_embedding']
                if isinstance(emb, list):
                    emb = torch.tensor(emb, dtype=torch.float32)
                elif isinstance(emb, np.ndarray):
                    emb = torch.from_numpy(emb).float()
                elif isinstance(emb, torch.Tensor):
                    emb = emb.float()
                else:
                    raise TypeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„ë² ë”© íƒ€ì…: {type(emb)}")
                embeddings.append(emb)
            
            # textë§Œ ìˆëŠ” ê²½ìš° (Sentence-Transformers ì‚¬ìš©)
            elif 'text' in item:
                text = item['text']
                
                # Sentence-Transformersë¡œ ì‹¤ì‹œê°„ ì„ë² ë”© ìƒì„±
                try:
                    encoder = cls._get_sentence_encoder()
                    with torch.no_grad():
                        # í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (384ì°¨ì›)
                        emb = encoder.encode(text, convert_to_tensor=True)
                        
                        # 768ì°¨ì›ìœ¼ë¡œ íˆ¬ì˜ (ë°±ë³¸ê³¼ í˜¸í™˜)
                        if emb.shape[-1] == 384:
                            # ê°„ë‹¨í•œ ì„ í˜• íˆ¬ì˜ìœ¼ë¡œ 768ì°¨ì› í™•ì¥
                            # í•„ìš”ì‹œ í•™ìŠµ ê°€ëŠ¥í•œ íˆ¬ì˜ ë ˆì´ì–´ ì¶”ê°€ ê°€ëŠ¥
                            if not hasattr(cls, '_projection_layer'):
                                cls._projection_layer = torch.nn.Linear(384, 768)
                                cls._projection_layer = cls._projection_layer.to(cls._encoder_device)
                                cls._projection_layer.eval()  # í•™ìŠµ ë¹„í™œì„±í™”
                                logger.debug("íˆ¬ì˜ ë ˆì´ì–´ ìƒì„±: 384 -> 768")
                            
                            emb = cls._projection_layer(emb)
                        
                        # float32ë¡œ ë³€í™˜ ë° CPUë¡œ ì´ë™ (ë‚˜ì¤‘ì— í†µí•©)
                        emb = emb.to(torch.float32).cpu()
                        
                except Exception as e:
                    # NO FALLBACK ì›ì¹™ - ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
                    raise RuntimeError(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                
                embeddings.append(emb)
            else:
                raise KeyError(f"ìƒ˜í”Œì— context_embedding ë˜ëŠ” text ì—†ìŒ: {item.get('id', 'unknown')}")
        
        # ìŠ¤íƒí•˜ì—¬ ë°°ì¹˜ í…ì„œ ìƒì„±
        return torch.stack(embeddings)
    
    @staticmethod
    def extract_emotion_target(batch: List[Dict]) -> torch.Tensor:
        """
        ê°ì • íƒ€ê¹ƒ ì¶”ì¶œ (7ì°¨ì› ë²¡í„°)
        Args:
            batch: ë°°ì¹˜ ë°ì´í„°
        Returns:
            (batch_size, 7) í…ì„œ
        """
        if not batch:
            raise ValueError("ë°°ì¹˜ê°€ ë¹„ì–´ìˆìŒ")
        
        emotion_vectors = []
        for item in batch:
            # emotion_vector ë˜ëŠ” emotions í‚¤ í™•ì¸ (í˜¸í™˜ì„±)
            if 'emotion_vector' in item:
                vec = item['emotion_vector']
            elif 'emotions' in item:
                vec = item['emotions']
            else:
                raise KeyError(f"emotion_vector ë˜ëŠ” emotions ì—†ìŒ")
            
            if isinstance(vec, list) and len(vec) == 7:
                vec = torch.tensor(vec, dtype=torch.float32)
            else:
                raise ValueError(f"ê°ì • ë²¡í„° ì°¨ì› ì˜¤ë¥˜: {len(vec) if isinstance(vec, list) else 'not list'}")
            
            emotion_vectors.append(vec)
        
        return torch.stack(emotion_vectors)
    
    @staticmethod
    def extract_emotion_labels(batch: List[Dict]) -> torch.Tensor:
        """
        ê°ì • ë¼ë²¨ ì¶”ì¶œ (ì¹´í…Œê³ ë¦¬ ì¸ë±ìŠ¤)
        Args:
            batch: ë°°ì¹˜ ë°ì´í„°
        Returns:
            (batch_size,) ì •ìˆ˜ í…ì„œ
        """
        emotion_vectors = TargetMapper.extract_emotion_target(batch)
        # ê°€ì¥ ë†’ì€ ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ë¼ë²¨ë¡œ ì‚¬ìš©
        return torch.argmax(emotion_vectors, dim=1)
    
    @staticmethod
    def extract_regret_target(batch: List[Dict]) -> torch.Tensor:
        """
        í›„íšŒ ì§€ìˆ˜ íƒ€ê¹ƒ ì¶”ì¶œ
        Args:
            batch: ë°°ì¹˜ ë°ì´í„°
        Returns:
            (batch_size, 1) í…ì„œ
        """
        if not batch:
            raise ValueError("ë°°ì¹˜ê°€ ë¹„ì–´ìˆìŒ")
        
        regret_scores = []
        for item in batch:
            if 'regret_factor' not in item:
                raise KeyError("regret_factor ì—†ìŒ")
            
            score = item['regret_factor']
            if isinstance(score, (int, float)):
                score = torch.tensor([score], dtype=torch.float32)
            else:
                raise TypeError(f"í›„íšŒ ì§€ìˆ˜ íƒ€ì… ì˜¤ë¥˜: {type(score)}")
            
            regret_scores.append(score)
        
        return torch.stack(regret_scores)
    
    @staticmethod
    def extract_bentham_target(batch: List[Dict]) -> torch.Tensor:
        """
        ë²¤ë‹´ ì ìˆ˜ íƒ€ê¹ƒ ì¶”ì¶œ (10ì°¨ì›)
        Args:
            batch: ë°°ì¹˜ ë°ì´í„°
        Returns:
            (batch_size, 10) í…ì„œ
        """
        if not batch:
            raise ValueError("ë°°ì¹˜ê°€ ë¹„ì–´ìˆìŒ")
        
        # ë²¤ë‹´ í‚¤ ìˆœì„œ ê³ ì • (ì¤‘ìš”!)
        bentham_keys = [
            'intensity', 'duration', 'certainty', 'propinquity',
            'purity', 'extent', 'fecundity', 'remoteness', 
            'succession', 'utility'
        ]
        
        bentham_vectors = []
        for item in batch:
            if 'bentham_scores' not in item:
                raise KeyError("bentham_scores ì—†ìŒ")
            
            scores = item['bentham_scores']
            if not isinstance(scores, dict):
                raise TypeError(f"bentham_scoresê°€ dictê°€ ì•„ë‹˜: {type(scores)}")
            
            # ê³ ì •ëœ ìˆœì„œë¡œ ë²¡í„° ìƒì„± (ì—†ëŠ” í‚¤ëŠ” 0.5ë¡œ ê¸°ë³¸ê°’)
            vec = []
            for key in bentham_keys:
                if key in scores:
                    vec.append(float(scores[key]))
                else:
                    # ê¸°ë³¸ê°’ 0.5 (ì¤‘ê°„ê°’)
                    vec.append(0.5)
            
            bentham_vectors.append(torch.tensor(vec, dtype=torch.float32))
        
        return torch.stack(bentham_vectors)
    
    @staticmethod
    def extract_surd_target(batch: List[Dict], normalize: bool = True) -> torch.Tensor:
        """
        SURD ë©”íŠ¸ë¦­ íƒ€ê¹ƒ ì¶”ì¶œ (4ì°¨ì›)
        Args:
            batch: ë°°ì¹˜ ë°ì´í„°
            normalize: Trueë©´ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”
        Returns:
            (batch_size, 4) í…ì„œ
        """
        if not batch:
            raise ValueError("ë°°ì¹˜ê°€ ë¹„ì–´ìˆìŒ")
        
        # SURD í‚¤ ìˆœì„œ ê³ ì • (í˜¸í™˜ì„± ë§¤í•‘ í¬í•¨)
        surd_keys = ['sufficiency', 'understandability', 'resilience', 'decisiveness']
        # ì‹¤ì œ ë°ì´í„° í‚¤ -> ì •ì‹ í‚¤ ë§¤í•‘
        key_mapping = {
            'selection': 'sufficiency',
            'uncertainty': 'understandability', 
            'risk': 'resilience',
            'decision': 'decisiveness'
        }
        
        surd_vectors = []
        for item in batch:
            if 'surd_metrics' not in item:
                raise KeyError("surd_metrics ì—†ìŒ")
            
            metrics = item['surd_metrics']
            if not isinstance(metrics, dict):
                raise TypeError(f"surd_metricsê°€ dictê°€ ì•„ë‹˜: {type(metrics)}")
            
            # ê³ ì •ëœ ìˆœì„œë¡œ ë²¡í„° ìƒì„±
            vec = []
            for key in surd_keys:
                value = None
                # ì •ì‹ í‚¤ë¡œ ë¨¼ì € í™•ì¸
                if key in metrics:
                    value = float(metrics[key])
                else:
                    # ë§¤í•‘ëœ í‚¤ í™•ì¸
                    for old_key, new_key in key_mapping.items():
                        if new_key == key and old_key in metrics:
                            value = float(metrics[old_key])
                            break
                
                if value is None:
                    raise KeyError(f"surd_metricsì— {key} ë˜ëŠ” ë§¤í•‘ëœ í‚¤ ì—†ìŒ")
                vec.append(value)
            
            vec_tensor = torch.tensor(vec, dtype=torch.float32)
            
            # ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)
            if normalize:
                vec_sum = vec_tensor.sum()
                if vec_sum > 0:
                    vec_tensor = vec_tensor / vec_sum
                else:
                    # ëª¨ë‘ 0ì¸ ê²½ìš° ê· ë“± ë¶„í¬
                    vec_tensor = torch.ones(4) / 4
            
            surd_vectors.append(vec_tensor)
        
        return torch.stack(surd_vectors)
    
    @staticmethod
    def validate_batch(batch: List[Dict]) -> bool:
        """
        ë°°ì¹˜ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        Args:
            batch: ë°°ì¹˜ ë°ì´í„°
        Returns:
            ìœ íš¨í•˜ë©´ True
        """
        if not batch:
            logger.error("ë¹ˆ ë°°ì¹˜")
            return False
        
        required_keys = [
            'context_embedding',
            'emotion_vector', 
            'regret_factor',
            'bentham_scores',
            'surd_metrics'
        ]
        
        for i, item in enumerate(batch):
            if not isinstance(item, dict):
                logger.error(f"ìƒ˜í”Œ {i}ì´ dictê°€ ì•„ë‹˜: {type(item)}")
                return False
            
            for key in required_keys:
                if key not in item:
                    logger.error(f"ìƒ˜í”Œ {i}ì— {key} ì—†ìŒ")
                    return False
        
        return True
    
    @staticmethod
    def prepare_training_batch(batch: List[Dict], device: torch.device) -> Dict[str, torch.Tensor]:
        """
        í•™ìŠµìš© ë°°ì¹˜ ì¤€ë¹„ (ëª¨ë“  íƒ€ê¹ƒ í¬í•¨)
        Args:
            batch: ë°°ì¹˜ ë°ì´í„°
            device: ë””ë°”ì´ìŠ¤ (cuda/cpu)
        Returns:
            í•™ìŠµìš© í…ì„œ ë”•ì…”ë„ˆë¦¬
        """
        if not TargetMapper.validate_batch(batch):
            raise ValueError("ë°°ì¹˜ ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨")
        
        # ëª¨ë“  íƒ€ê¹ƒ ì¶”ì¶œ ë° ë””ë°”ì´ìŠ¤ ì´ë™
        training_batch = {
            'input': TargetMapper.extract_context_embedding(batch).to(device),
            'emotion_target': TargetMapper.extract_emotion_target(batch).to(device),
            'emotion_labels': TargetMapper.extract_emotion_labels(batch).to(device),
            'regret_target': TargetMapper.extract_regret_target(batch).to(device),
            'bentham_target': TargetMapper.extract_bentham_target(batch).to(device),
            'surd_target': TargetMapper.extract_surd_target(batch, normalize=True).to(device)
        }
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ì„ íƒì )
        if 'source' in batch[0]:
            training_batch['sources'] = [item.get('source', 'unknown') for item in batch]
        
        return training_batch


def test_mapper():
    """ë§¤í¼ í…ŒìŠ¤íŠ¸"""
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_batch = [
        {
            'context_embedding': [0.1] * 768,
            'emotion_vector': [0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.16],
            'regret_factor': 0.5,
            'bentham_scores': {
                'intensity': 0.6, 'duration': 0.5, 'certainty': 0.7, 'propinquity': 0.4,
                'purity': 0.8, 'extent': 0.5, 'fecundity': 0.6, 'remoteness': 0.3,
                'succession': 0.4, 'utility': 0.55
            },
            'surd_metrics': {
                'sufficiency': 0.7, 'understandability': 0.8, 
                'resilience': 0.6, 'decisiveness': 0.9
            },
            'source': 'test'
        }
    ] * 4  # ë°°ì¹˜ í¬ê¸° 4
    
    device = torch.device('cpu')
    
    try:
        # ë°°ì¹˜ ì¤€ë¹„
        training_batch = TargetMapper.prepare_training_batch(test_batch, device)
        
        print("âœ… ë§¤í¼ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"  - Input shape: {training_batch['input'].shape}")
        print(f"  - Emotion target shape: {training_batch['emotion_target'].shape}")
        print(f"  - Emotion labels shape: {training_batch['emotion_labels'].shape}")
        print(f"  - Regret target shape: {training_batch['regret_target'].shape}")
        print(f"  - Bentham target shape: {training_batch['bentham_target'].shape}")
        print(f"  - SURD target shape: {training_batch['surd_target'].shape}")
        
        # SURD ì •ê·œí™” í™•ì¸
        surd_sums = training_batch['surd_target'].sum(dim=1)
        print(f"  - SURD í•© ê²€ì¦: {surd_sums} (ëª¨ë‘ 1ì´ì–´ì•¼ í•¨)")
        
    except Exception as e:
        print(f"âŒ ë§¤í¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    test_mapper()