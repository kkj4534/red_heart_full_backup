# Red Heart AI ì°¨ì› ë¶ˆì¼ì¹˜ ë¶„ì„ ë³´ê³ ì„œ

## í˜„ì¬ ì°¨ì› êµ¬ì¡° ë¶„ì„

### ë°±ë³¸ (Unified Backbone) - 300M íŒŒë¼ë¯¸í„°
- **d_model**: 1280 (core dimension)
- **num_heads**: 20
- **num_layers**: 18
- **feedforward_dim**: 5120

### HeadAdapter ì°¨ì› ë³€í™˜ í˜„í™©

#### 1. EmotionEmpathyHeadAdapter (140M)
- **input_adapter**: 1280 â†’ 1024 âœ…
- **output_adapter**: 1024 â†’ 1280 âœ…
- **ìƒíƒœ**: ì°¨ì› ë³€í™˜ ì¼ê´€ì„± ìœ ì§€

#### 2. BenthamFrommHeadAdapter (120M)
- **input_adapter**: 1280 â†’ 768 âœ…
- **output_adapter**: 768 â†’ 1280 âœ…
- **ìƒíƒœ**: ì°¨ì› ë³€í™˜ ì¼ê´€ì„± ìœ ì§€

#### 3. SemanticSURDHeadAdapter (80M)
- **input_adapter**: 1280 â†’ 512 âœ…
- **output_adapter**: 512 â†’ 1280 âœ…
- **ìƒíƒœ**: ì°¨ì› ë³€í™˜ ì¼ê´€ì„± ìœ ì§€

#### 4. RegretLearningHeadAdapter (120M) âš ï¸ ë¬¸ì œ ë°œê²¬
- **input_adapter**: 1280 â†’ 768
- **output_adapter**: 64 â†’ 1280 âŒ
- **ë¬¸ì œ**: input_adapter ì¶œë ¥(768)ê³¼ output_adapter ì…ë ¥(64) ë¶ˆì¼ì¹˜
- **ì‹¤ì œ regret_network ì¶œë ¥ ì°¨ì›**: configì—ì„œ hidden_layers ë§ˆì§€ë§‰ì´ 64

#### 5. MetaIntegrationHeadAdapter (40M)
- **ì°¨ì› ë³€í™˜**: ì•„ì§ í™•ì¸ í•„ìš”

## ì‹ë³„ëœ ë¬¸ì œì 

### 1. ì°¨ì› ë¶ˆì¼ì¹˜ (RegretLearningHeadAdapter)
```python
# head_compatibility_interface.py:1156-1161
self.input_adapter = self._create_input_adapter(
    input_dim=self.backbone_config['d_model'],  # 1280
    output_dim=768  # 768ë¡œ ë³€í™˜
)

self.output_adapter = self._create_output_adapter(
    input_dim=64,   # âŒ 768ì—ì„œ 64ë¡œ ì–´ë–»ê²Œ ë³€í™˜?
    output_dim=self.backbone_config['d_model']  # 1280
)
```

### 2. ë¹„íš¨ìœ¨ì ì¸ ë‹¤ë‹¨ê³„ ë³€í™˜
ëª¨ë“  HeadAdapterì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ ë°˜ë³µ:
- Backbone(1280) â†’ Headì…ë ¥ì°¨ì› â†’ Headì²˜ë¦¬ â†’ Headì¶œë ¥ì°¨ì› â†’ Backbone(1280)
- ì •ë³´ ì†ì‹¤ ê°€ëŠ¥ì„± ë° ê³„ì‚° ì˜¤ë²„í—¤ë“œ

### 3. ë¶ˆì¼ì¹˜í•œ internal dimension ì‚¬ìš©
- Emotion: 1024
- Bentham: 768  
- Semantic: 512
- Regret: 768â†’64 (ë¶ˆì¼ì¹˜)

## í•´ê²° ë°©ì•ˆ

### 1. ì¦‰ì‹œ ìˆ˜ì •: RegretLearningHeadAdapter ì°¨ì› ë¶ˆì¼ì¹˜
```python
# ìˆ˜ì • ì „:
self.output_adapter = self._create_output_adapter(
    input_dim=64,  # âŒ ì˜ëª»ëœ ì°¨ì›
    output_dim=self.backbone_config['d_model']
)

# ìˆ˜ì • í›„:
self.output_adapter = self._create_output_adapter(
    input_dim=768,  # âœ… input_adapter ì¶œë ¥ê³¼ ì¼ì¹˜
    output_dim=self.backbone_config['d_model']
)
```

### 2. í†µì¼ëœ ì°¨ì› ë³€í™˜ ì „ëµ
- **í‘œì¤€ internal dimension**: 1024ë¡œ í†µì¼ (ê°€ì¥ í° ì°¨ì› ê¸°ì¤€)
- **ì ì§„ì  ì°¨ì› ê°ì†Œ**: 1280 â†’ 1024 â†’ ì‹¤ì œ head ìš”êµ¬ ì°¨ì›
- **residual connection**: ì°¨ì› ë³€í™˜ ì‹œ ì •ë³´ ì†ì‹¤ ìµœì†Œí™”

### 3. ìµœì í™”ëœ ë³€í™˜ êµ¬ì¡°
```python
class OptimizedDimensionAdapter:
    def __init__(self, backbone_dim=1280, target_dim=None):
        self.standard_dim = 1024  # í‘œì¤€ internal dimension
        
        # 1280 â†’ 1024 (í‘œì¤€í™”)
        self.standardizer = nn.Linear(backbone_dim, self.standard_dim)
        
        # 1024 â†’ target_dim (headë³„ ë§ì¶¤)
        if target_dim and target_dim != self.standard_dim:
            self.head_adapter = nn.Linear(self.standard_dim, target_dim)
        
        # target_dim â†’ 1024 â†’ 1280 (ì—­ë³€í™˜)
        if target_dim and target_dim != self.standard_dim:
            self.head_reverse = nn.Linear(target_dim, self.standard_dim)
        self.backbone_restore = nn.Linear(self.standard_dim, backbone_dim)
```

## âœ… í•´ê²° ì™„ë£Œ ì‚¬í•­

### 1. ì°¨ì› ë¶ˆì¼ì¹˜ ë¬¸ì œ ìˆ˜ì • ì™„ë£Œ
- **RegretLearningHeadAdapter**: output_adapter ì…ë ¥ ì°¨ì›ì„ 64ì—ì„œ 768ë¡œ ìˆ˜ì • âœ…
- **MetaIntegrationHeadAdapter**: ì°¨ì› ë³€í™˜ êµ¬ì¡° í™•ì¸ ì™„ë£Œ âœ…

### 2. ìµœì í™”ëœ ì°¨ì› ë³€í™˜ ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ âœ…
```python
# ìƒˆë¡œìš´ OptimizedDimensionAdapter ì‹œìŠ¤í…œ
class OptimizedDimensionAdapter:
    - í‘œì¤€ internal dimension (1024) ê¸°ë°˜
    - Residual connectionìœ¼ë¡œ ì •ë³´ ì†ì‹¤ ìµœì†Œí™”  
    - ì ì§„ì  ì°¨ì› ë³€í™˜ìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ
    - ê° í—¤ë“œë³„ ë§ì¶¤í˜• ì°¨ì› ì§€ì›
```

### 3. ëª¨ë“  HeadAdapterì— ìµœì í™”ëœ ì–´ëŒ‘í„° ì ìš© ì™„ë£Œ âœ…
- **EmotionEmpathyHeadAdapter**: 1280 â†” 1024 (2.6M params)
- **BenthamFrommHeadAdapter**: 1280 â†” 768 (4.2M params)  
- **SemanticSURDHeadAdapter**: 1280 â†” 512 (3.7M params)
- **RegretLearningHeadAdapter**: 1280 â†” 768 (4.2M params)
- **MetaIntegrationHeadAdapter**: 1280 â†” 256 (3.2M params)

### 4. ê²€ì¦ í…ŒìŠ¤íŠ¸ ê²°ê³¼ âœ…
```
ğŸ§ª ìµœì í™”ëœ ì°¨ì› ë³€í™˜ ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸: ëª¨ë“  ì–´ëŒ‘í„° í†µê³¼ (5/5)
   - ì°¨ì› ì¼ê´€ì„± ê²€ì¦: âœ… í†µê³¼
   - Forward/Backward pass: âœ… í†µê³¼
   - Residual connection: âœ… í†µê³¼

ğŸŒŠ Gradient Flow ê²€ì¦: 100% íŒŒë¼ë¯¸í„°ì—ì„œ gradient ì „íŒŒ í™•ì¸ âœ…
```

## ìµœì¢… ê°œì„  ì‚¬í•­

### ê¸°ì¡´ ë¬¸ì œì 
1. âŒ ê° HeadAdapterë§ˆë‹¤ ì„œë¡œ ë‹¤ë¥¸ ë¹„íš¨ìœ¨ì  ì°¨ì› ë³€í™˜
2. âŒ RegretLearningHeadAdapter ì°¨ì› ë¶ˆì¼ì¹˜ (768 â†’ 64)
3. âŒ ë‹¤ë‹¨ê³„ ë³€í™˜ìœ¼ë¡œ ì¸í•œ ì •ë³´ ì†ì‹¤ ê°€ëŠ¥ì„±
4. âŒ ì¤‘ë³µ ì½”ë“œ ë° ë¹„ì¼ê´€ëœ êµ¬í˜„

### í•´ê²°ëœ ê²°ê³¼
1. âœ… í†µì¼ëœ OptimizedDimensionAdapter ì‹œìŠ¤í…œ
2. âœ… ëª¨ë“  ì°¨ì› ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°
3. âœ… Residual connectionìœ¼ë¡œ ì •ë³´ ì†ì‹¤ ìµœì†Œí™”
4. âœ… ì¼ê´€ëœ encode/decode ì¸í„°í˜ì´ìŠ¤

### ì„±ëŠ¥ ê°œì„ 
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ë¶ˆí•„ìš”í•œ ì¤‘ê°„ ë³€í™˜ ë‹¨ê³„ ì œê±°
- **ê³„ì‚° íš¨ìœ¨ì„±**: ìµœì í™”ëœ sequential layer êµ¬ì¡°
- **í•™ìŠµ ì•ˆì •ì„±**: LayerNorm, GELU, Dropout ì ìš©
- **ì •ë³´ ë³´ì¡´**: Residual connectionìœ¼ë¡œ ì •ë³´ ì†ì‹¤ ë°©ì§€

## ì¶”ê°€ ê¶Œì¥ ì‚¬í•­

### ë‹¨ê¸° ê°œì„  (ì„ íƒì‚¬í•­)
1. ë™ì  ë°°ì¹˜ í¬ê¸°ì— ëŒ€í•œ ì„±ëŠ¥ ìµœì í™”
2. í˜¼í•© ì •ë°€ë„(mixed precision) ì§€ì› ì¶”ê°€
3. ì–´ëŒ‘í„°ë³„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

### ì¥ê¸° ìµœì í™” (ì„ íƒì‚¬í•­)
1. ì–´ëŒ‘í„° ì••ì¶• ê¸°ë²• ì ìš©
2. ë™ì  ì°¨ì› ì¡°ì • ì‹œìŠ¤í…œ
3. ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹