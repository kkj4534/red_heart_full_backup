# Red Heart AI 고급 학습 전략 및 실행 가이드

## 📌 Executive Summary

10,000개 데이터셋으로 730M 파라미터 모델을 로컬 GPU(8GB VRAM)에서 학습하는 고급 전략. 
의도적 과적합 후 크로스오버를 통한 일반화 성능 향상을 목표로 함.

**핵심 전략:**
- **Phase 1**: LR Sweep (5 candidates × 5 epochs) 
- **Phase 2**: 본 학습 (60 epochs, 2 epoch마다 체크포인트)
- **Phase 3**: Sweet Spot 분석 (모듈별 최적 에폭 탐지)
- **Phase 4**: 파라미터 크로스오버 (최적 조합 생성)
- **예상 시간**: 170-200시간 (7-8일)
- **예상 성능**: 단일 모델 75-80% → 크로스오버 85-90%

---

## 1. 모듈 의존성 구조 및 그룹화

### 1.1 연동 모듈 그룹 (같은 에폭 체크포인트 필수)

#### 그룹 A: Backbone-Heads 상호 의존성
```python
DEPENDENCY_GROUP_A = {
    'backbone': 'RedHeartUnifiedBackbone',  # 90.6M
    'heads': {
        'emotion': 'EmotionHead',  # 17.3M  
        'bentham': 'BenthamHead',  # 13.9M
        'regret': 'RegretHead',    # 19.9M
        'surd': 'SURDHead'         # 12.0M
    }
}
# 총 153.7M - 백본이 헤드에 태스크별 특징 직접 전달
```

**의존성 이유:**
- 백본의 `task_projections`가 각 헤드별로 최적화됨
- 헤드 손실이 백본 파라미터에 직접 역전파
- 추론 시 백본 출력이 헤드 입력으로 직결

#### 그룹 B: Neural Analyzers 상호 참조
```python
DEPENDENCY_GROUP_B = {
    'neural_emotion': 'NeuralEmotionAnalyzer',  # 122.6M
    'neural_bentham': 'NeuralBenthamCalculator', # 78.3M
    'neural_regret': 'NeuralRegretAnalyzer',    # 153.9M
    'neural_surd': 'NeuralSURDAnalyzer'         # 13.5M
}
# 총 368.3M - 서로 간 attention 메커니즘 공유 가능
```

#### 그룹 C: DSP-Kalman 융합 의존성
```python
DEPENDENCY_GROUP_C = {
    'dsp': 'EmotionDSPSimulator',    # 2.3M
    'kalman': 'DynamicKalmanFilter'  # 0.7K
}
# 총 2.3M - Kalman이 DSP 출력을 필수 입력으로 요구
```

### 1.2 독립 모듈 (개별 최적 에폭 가능)

```python
INDEPENDENT_MODULES = {
    'advanced_emotion': 'AdvancedEmotionAnalyzer',  # 63.0M
    'advanced_regret': 'AdvancedRegretAnalyzer',   # 44.2M  
    'advanced_bentham': 'AdvancedBenthamCalculator', # 2.5M
    'advanced_surd': 'AdvancedSURDAnalyzer',       # 실제 미구현
    'phase0': 'Phase0EmotionCalibrator',           # 2.0M
    'phase1': 'Phase1EmpathyLearner',              # 0.2M
    'phase2': 'Phase2CommunityNetwork'             # 미구현
}
```

---

## 2. Phase 1: Learning Rate Sweep 전략

### 2.1 실행 설정
```python
# lr_sweep_config.py
LR_CANDIDATES = [1e-5, 5e-5, 1e-4, 2e-4, 5e-4]
SWEEP_CONFIG = {
    'epochs': 5,
    'batch_size': 4,
    'gradient_accumulation_steps': 16,  # Effective batch: 64
    'mixed_precision': True,
    'gradient_checkpointing': False,  # 730M은 불필요
    'save_metrics': True,
    'metrics_dir': 'C:/large_project/linux_red_heart/docs/data/lr_sweep/'
}
```

### 2.2 데이터 수집 및 저장
```python
class LRSweepLogger:
    def __init__(self, lr, output_dir):
        self.lr = lr
        self.metrics = {
            'lr': lr,
            'epochs': [],
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'gradient_norm': [],
            'learning_curve': [],
            'gpu_memory': [],
            'time_per_epoch': []
        }
        
    def log_epoch(self, epoch, metrics):
        """에폭별 메트릭 기록"""
        self.metrics['epochs'].append(epoch)
        self.metrics['train_loss'].append(metrics['train_loss'])
        self.metrics['val_loss'].append(metrics['val_loss'])
        self.metrics['gradient_norm'].append(metrics['grad_norm'])
        self.metrics['gpu_memory'].append(torch.cuda.max_memory_allocated() / 1e9)
        
    def save(self):
        """JSON 및 CSV 형식으로 저장 (논문용)"""
        # 메인 위치
        with open(f'{self.output_dir}/lr_{self.lr}_metrics.json', 'w') as f:
            json.dump(self.metrics, f, indent=2)
            
        # 백업 위치
        backup_path = 'C:/large_project/linux_red_heart/docs/data/lr_sweep/'
        os.makedirs(backup_path, exist_ok=True)
        shutil.copy2(
            f'{self.output_dir}/lr_{self.lr}_metrics.json',
            f'{backup_path}/lr_{self.lr}_backup.json'
        )
        
        # CSV 변환 (논문 그래프용)
        pd.DataFrame(self.metrics).to_csv(
            f'{backup_path}/lr_{self.lr}_table.csv',
            index=False
        )
```

### 2.3 최적 LR 자동 선택
```python
def select_best_lr(sweep_results_dir):
    """검증 손실 기준 최적 LR 선택"""
    best_lr = None
    best_val_loss = float('inf')
    
    for lr in LR_CANDIDATES:
        metrics_file = f'{sweep_results_dir}/lr_{lr}_metrics.json'
        with open(metrics_file, 'r') as f:
            metrics = json.load(f)
            
        # 마지막 3 에폭의 평균 검증 손실
        avg_val_loss = np.mean(metrics['val_loss'][-3:])
        
        # 과적합 지표 확인 (train vs val gap)
        overfit_score = metrics['train_loss'][-1] - metrics['val_loss'][-1]
        
        # 종합 점수 (낮을수록 좋음)
        score = avg_val_loss + 0.1 * abs(overfit_score)
        
        if score < best_val_loss:
            best_val_loss = score
            best_lr = lr
            
    logger.info(f"최적 LR 선택: {best_lr} (score: {best_val_loss:.4f})")
    return best_lr
```

---

## 3. Phase 2: 본 학습 (60 Epochs)

### 3.1 학습 설정
```python
# main_training_config.py
MAIN_CONFIG = {
    'epochs': 60,
    'batch_size': 4,
    'gradient_accumulation_steps': 16,  # Effective: 64
    'learning_rate': None,  # LR Sweep에서 자동 결정
    'scheduler': 'cosine_annealing_with_restarts',
    'warmup_ratio': 0.1,
    'weight_decay': 0.01,
    'mixed_precision': True,
    'save_every_n_epochs': 2,  # 30개 체크포인트 생성
    'early_stopping': False,  # 의도적 비활성화 (과적합 유도)
    'dropout': 0.1,  # 낮게 설정 (과적합 유도)
}
```

### 3.2 체크포인트 저장 전략
```python
class ModularCheckpointManager:
    def __init__(self, base_dir='checkpoints'):
        self.base_dir = base_dir
        self.backup_dir = 'C:/large_project/linux_red_heart/docs/data/checkpoints/'
        os.makedirs(self.base_dir, exist_ok=True)
        os.makedirs(self.backup_dir, exist_ok=True)
        
    def save_checkpoint(self, epoch, model, optimizer, metrics):
        """모듈별 개별 저장 + 메트릭 기록"""
        checkpoint = {
            'epoch': epoch,
            'timestamp': datetime.now().isoformat(),
            'metrics': metrics,
            'model_state': {},
            'optimizer_state': optimizer.state_dict()
        }
        
        # 1. 연동 그룹별 저장
        checkpoint['model_state']['group_a'] = {
            'backbone': model.backbone.state_dict(),
            'heads': {
                name: head.state_dict() 
                for name, head in model.heads.items()
            }
        }
        
        checkpoint['model_state']['group_b'] = {
            name: analyzer.state_dict()
            for name, analyzer in model.analyzers.items()
            if 'neural_' in name
        }
        
        checkpoint['model_state']['group_c'] = {
            'dsp': model.analyzers.get('dsp', {}).state_dict() if 'dsp' in model.analyzers else {},
            'kalman': model.analyzers.get('kalman', {}).state_dict() if 'kalman' in model.analyzers else {}
        }
        
        # 2. 독립 모듈 저장
        checkpoint['model_state']['independent'] = {
            name: module.state_dict()
            for name, module in model.analyzers.items()
            if 'advanced_' in name
        }
        
        # 3. 메트릭 상세 기록 (논문용)
        checkpoint['detailed_metrics'] = {
            'train_loss': metrics['train_loss'],
            'val_loss': metrics['val_loss'],
            'train_acc': metrics.get('train_acc', 0),
            'val_acc': metrics.get('val_acc', 0),
            'per_module_loss': self._calculate_per_module_loss(model),
            'gradient_statistics': self._get_gradient_stats(model),
            'activation_statistics': self._get_activation_stats(model),
            'weight_statistics': self._get_weight_stats(model),
            'gpu_memory': torch.cuda.max_memory_allocated() / 1e9,
            'learning_rate': optimizer.param_groups[0]['lr']
        }
        
        # 4. 저장 (메인 + 백업)
        checkpoint_path = f'{self.base_dir}/epoch_{epoch:03d}.pt'
        torch.save(checkpoint, checkpoint_path)
        
        # 백업 (압축)
        backup_path = f'{self.backup_dir}/epoch_{epoch:03d}_backup.pt.gz'
        with gzip.open(backup_path, 'wb') as f:
            torch.save(checkpoint, f)
            
        # 5. 메트릭만 별도 JSON 저장 (빠른 분석용)
        metrics_path = f'{self.backup_dir}/metrics_epoch_{epoch:03d}.json'
        with open(metrics_path, 'w') as f:
            json.dump(checkpoint['detailed_metrics'], f, indent=2)
            
        logger.info(f"✅ Epoch {epoch} 체크포인트 저장 완료")
        
    def _calculate_per_module_loss(self, model):
        """모듈별 손실 계산"""
        losses = {}
        # 각 모듈별로 더미 입력으로 손실 계산
        with torch.no_grad():
            dummy_input = torch.randn(2, 768).to(model.device)
            dummy_target = torch.randint(0, 7, (2,)).to(model.device)
            
            for name, module in model.analyzers.items():
                try:
                    output = module(dummy_input)
                    if isinstance(output, dict):
                        output = output.get('logits', output.get('scores', None))
                    if output is not None:
                        loss = F.cross_entropy(output, dummy_target)
                        losses[name] = loss.item()
                except:
                    losses[name] = -1
        return losses
        
    def _get_gradient_stats(self, model):
        """그래디언트 통계"""
        stats = {}
        for name, param in model.named_parameters():
            if param.grad is not None:
                grad = param.grad.data
                stats[name] = {
                    'mean': grad.mean().item(),
                    'std': grad.std().item(),
                    'max': grad.max().item(),
                    'min': grad.min().item(),
                    'norm': grad.norm().item()
                }
        return stats
        
    def _get_activation_stats(self, model):
        """활성화 통계 (hook 사용)"""
        # 구현 생략 - 필요시 추가
        return {}
        
    def _get_weight_stats(self, model):
        """가중치 통계"""
        stats = {}
        for name, param in model.named_parameters():
            stats[name] = {
                'mean': param.data.mean().item(),
                'std': param.data.std().item(),
                'norm': param.data.norm().item(),
                'sparsity': (param.data.abs() < 1e-6).float().mean().item()
            }
        return stats
```

### 3.3 DSM 메모리 관리 전략
```python
class AdaptiveDSMScheduler:
    """GPU 메모리 70-90% 유지하며 동적 스왑"""
    
    def __init__(self, target_memory_usage=0.85, max_memory_gb=8.0):
        self.target_usage = target_memory_usage
        self.max_memory = max_memory_gb * 1e9
        self.swap_history = []
        self.module_priorities = {
            'backbone': 100,  # 절대 스왑 안함
            'heads': 90,      # 거의 스왑 안함
            'neural_': 50,    # 필요시 스왑
            'advanced_': 20,  # 우선 스왑
            'phase': 10       # 가장 먼저 스왑
        }
        
    def check_and_swap(self, model, current_epoch):
        """메모리 체크 및 스왑 결정"""
        current_memory = torch.cuda.memory_allocated()
        usage_ratio = current_memory / self.max_memory
        
        if usage_ratio > self.target_usage:
            # 스왑 필요
            modules_to_swap = self._select_swap_candidates(model, usage_ratio)
            for module_name in modules_to_swap:
                self._swap_to_cpu(model, module_name)
                self.swap_history.append({
                    'epoch': current_epoch,
                    'module': module_name,
                    'memory_before': usage_ratio,
                    'action': 'swap_out'
                })
                
        elif usage_ratio < self.target_usage - 0.1:
            # 여유 있으면 복원
            if self.swap_history:
                last_swapped = self.swap_history[-1]['module']
                self._swap_to_gpu(model, last_swapped)
                self.swap_history.append({
                    'epoch': current_epoch,
                    'module': last_swapped,
                    'memory_before': usage_ratio,
                    'action': 'swap_in'
                })
                
    def _select_swap_candidates(self, model, usage_ratio):
        """우선순위 기반 스왑 대상 선택"""
        candidates = []
        
        # Advanced modules first
        for name in model.analyzers.keys():
            if 'advanced_' in name:
                candidates.append((self.module_priorities.get('advanced_', 20), name))
                
        # Sort by priority (lower = swap first)
        candidates.sort(key=lambda x: x[0])
        
        # 메모리 초과량에 따라 스왑 개수 결정
        overflow = usage_ratio - self.target_usage
        num_to_swap = max(1, int(overflow * 10))  # 초과 10%당 1개
        
        return [name for _, name in candidates[:num_to_swap]]
        
    def _swap_to_cpu(self, model, module_name):
        """GPU → CPU 스왑"""
        if hasattr(model, 'analyzers') and module_name in model.analyzers:
            model.analyzers[module_name] = model.analyzers[module_name].cpu()
            torch.cuda.empty_cache()
            
    def _swap_to_gpu(self, model, module_name):
        """CPU → GPU 복원"""
        if hasattr(model, 'analyzers') and module_name in model.analyzers:
            model.analyzers[module_name] = model.analyzers[module_name].cuda()
```

---

## 4. Phase 3: Sweet Spot 분석

### 4.1 자동 Sweet Spot 탐지
```python
class SweetSpotAnalyzer:
    def __init__(self, checkpoint_dir):
        self.checkpoint_dir = checkpoint_dir
        self.metrics = self._load_all_metrics()
        
    def _load_all_metrics(self):
        """모든 에폭의 메트릭 로드"""
        metrics = {}
        for epoch in range(2, 62, 2):  # 2, 4, 6, ..., 60
            metrics_file = f'{self.checkpoint_dir}/metrics_epoch_{epoch:03d}.json'
            if os.path.exists(metrics_file):
                with open(metrics_file, 'r') as f:
                    metrics[epoch] = json.load(f)
        return metrics
        
    def find_module_sweet_spots(self):
        """모듈 그룹별 최적 에폭 찾기"""
        sweet_spots = {}
        
        # 1. 연동 그룹 A (Backbone-Heads)
        sweet_spots['group_a'] = self._find_best_epoch_for_group(
            ['backbone', 'emotion_head', 'bentham_head', 'regret_head', 'surd_head']
        )
        
        # 2. 연동 그룹 B (Neural Analyzers)
        sweet_spots['group_b'] = self._find_best_epoch_for_group(
            ['neural_emotion', 'neural_bentham', 'neural_regret', 'neural_surd']
        )
        
        # 3. 연동 그룹 C (DSP-Kalman)
        sweet_spots['group_c'] = self._find_best_epoch_for_group(
            ['dsp', 'kalman']
        )
        
        # 4. 독립 모듈들
        for module in ['advanced_emotion', 'advanced_regret', 'advanced_bentham']:
            sweet_spots[module] = self._find_best_epoch_for_module(module)
            
        return sweet_spots
        
    def _find_best_epoch_for_group(self, module_names):
        """그룹 내 모듈들의 평균 성능 기준 최적 에폭"""
        best_epoch = None
        best_score = float('inf')
        
        for epoch, metrics in self.metrics.items():
            # 그룹 내 모든 모듈의 손실 평균
            group_losses = []
            for module_name in module_names:
                if module_name in metrics.get('per_module_loss', {}):
                    loss = metrics['per_module_loss'][module_name]
                    if loss > 0:  # 유효한 손실만
                        group_losses.append(loss)
                        
            if group_losses:
                avg_loss = np.mean(group_losses)
                
                # 과적합 페널티 계산
                train_val_gap = abs(metrics['train_loss'] - metrics['val_loss'])
                overfit_penalty = 0.1 * train_val_gap if train_val_gap > 0.5 else 0
                
                # 종합 점수
                score = avg_loss + overfit_penalty
                
                if score < best_score:
                    best_score = score
                    best_epoch = epoch
                    
        return best_epoch
        
    def _find_best_epoch_for_module(self, module_name):
        """개별 모듈의 최적 에폭"""
        best_epoch = None
        best_loss = float('inf')
        
        for epoch, metrics in self.metrics.items():
            if module_name in metrics.get('per_module_loss', {}):
                loss = metrics['per_module_loss'][module_name]
                if 0 < loss < best_loss:
                    best_loss = loss
                    best_epoch = epoch
                    
        return best_epoch
        
    def generate_analysis_report(self, sweet_spots):
        """분석 보고서 생성 (논문용)"""
        report = {
            'analysis_timestamp': datetime.now().isoformat(),
            'sweet_spots': sweet_spots,
            'detailed_analysis': {}
        }
        
        for group_or_module, best_epoch in sweet_spots.items():
            if best_epoch and best_epoch in self.metrics:
                metrics = self.metrics[best_epoch]
                report['detailed_analysis'][group_or_module] = {
                    'best_epoch': best_epoch,
                    'train_loss': metrics['train_loss'],
                    'val_loss': metrics['val_loss'],
                    'overfit_score': metrics['train_loss'] - metrics['val_loss'],
                    'gradient_norm_stats': self._summarize_gradient_stats(metrics),
                    'weight_sparsity': self._calculate_sparsity(metrics)
                }
                
        # 저장
        report_path = 'C:/large_project/linux_red_heart/docs/data/sweet_spot_analysis.json'
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
            
        # 시각화용 데이터 생성
        self._generate_visualization_data(report)
        
        return report
        
    def _summarize_gradient_stats(self, metrics):
        """그래디언트 통계 요약"""
        if 'gradient_statistics' not in metrics:
            return {}
            
        all_norms = []
        for param_stats in metrics['gradient_statistics'].values():
            if 'norm' in param_stats:
                all_norms.append(param_stats['norm'])
                
        return {
            'mean_norm': np.mean(all_norms) if all_norms else 0,
            'max_norm': np.max(all_norms) if all_norms else 0,
            'min_norm': np.min(all_norms) if all_norms else 0
        }
        
    def _calculate_sparsity(self, metrics):
        """가중치 희소성 계산"""
        if 'weight_statistics' not in metrics:
            return 0
            
        sparsities = []
        for param_stats in metrics['weight_statistics'].values():
            if 'sparsity' in param_stats:
                sparsities.append(param_stats['sparsity'])
                
        return np.mean(sparsities) if sparsities else 0
        
    def _generate_visualization_data(self, report):
        """Matplotlib용 시각화 데이터 생성"""
        # 학습 곡선 데이터
        epochs = sorted(self.metrics.keys())
        train_losses = [self.metrics[e]['train_loss'] for e in epochs]
        val_losses = [self.metrics[e]['val_loss'] for e in epochs]
        
        viz_data = {
            'epochs': epochs,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'sweet_spots': report['sweet_spots']
        }
        
        viz_path = 'C:/large_project/linux_red_heart/docs/data/visualization_data.json'
        with open(viz_path, 'w') as f:
            json.dump(viz_data, f)
```

---

## 5. Phase 4: 파라미터 크로스오버

### 5.1 크로스오버 전략
```python
class ParameterCrossover:
    def __init__(self, checkpoint_dir, sweet_spots):
        self.checkpoint_dir = checkpoint_dir
        self.sweet_spots = sweet_spots
        
    def create_optimal_model(self):
        """Sweet spot 조합으로 최적 모델 생성"""
        
        # 빈 모델 초기화
        from unified_training_v2 import UnifiedTrainingSystemV2
        optimal_model = UnifiedTrainingSystemV2(args)
        
        # 1. 연동 그룹 A (Backbone-Heads) 로드
        if 'group_a' in self.sweet_spots:
            epoch = self.sweet_spots['group_a']
            checkpoint = torch.load(f'{self.checkpoint_dir}/epoch_{epoch:03d}.pt')
            
            # Backbone
            optimal_model.backbone.load_state_dict(
                checkpoint['model_state']['group_a']['backbone']
            )
            
            # Heads
            for head_name, head_state in checkpoint['model_state']['group_a']['heads'].items():
                if head_name in optimal_model.heads:
                    optimal_model.heads[head_name].load_state_dict(head_state)
                    
        # 2. 연동 그룹 B (Neural Analyzers) 로드
        if 'group_b' in self.sweet_spots:
            epoch = self.sweet_spots['group_b']
            checkpoint = torch.load(f'{self.checkpoint_dir}/epoch_{epoch:03d}.pt')
            
            for analyzer_name, analyzer_state in checkpoint['model_state']['group_b'].items():
                if analyzer_name in optimal_model.analyzers:
                    optimal_model.analyzers[analyzer_name].load_state_dict(analyzer_state)
                    
        # 3. 연동 그룹 C (DSP-Kalman) 로드
        if 'group_c' in self.sweet_spots:
            epoch = self.sweet_spots['group_c']
            checkpoint = torch.load(f'{self.checkpoint_dir}/epoch_{epoch:03d}.pt')
            
            if 'dsp' in optimal_model.analyzers:
                optimal_model.analyzers['dsp'].load_state_dict(
                    checkpoint['model_state']['group_c']['dsp']
                )
            if 'kalman' in optimal_model.analyzers:
                optimal_model.analyzers['kalman'].load_state_dict(
                    checkpoint['model_state']['group_c']['kalman']
                )
                
        # 4. 독립 모듈들 개별 로드
        for module_name in ['advanced_emotion', 'advanced_regret', 'advanced_bentham']:
            if module_name in self.sweet_spots and module_name in optimal_model.analyzers:
                epoch = self.sweet_spots[module_name]
                checkpoint = torch.load(f'{self.checkpoint_dir}/epoch_{epoch:03d}.pt')
                
                if module_name in checkpoint['model_state']['independent']:
                    optimal_model.analyzers[module_name].load_state_dict(
                        checkpoint['model_state']['independent'][module_name]
                    )
                    
        return optimal_model
        
    def create_ensemble_variants(self, delta_epochs=4):
        """Sweet spot ±2 에폭 범위에서 앙상블용 변형 생성"""
        variants = []
        
        for delta in [-4, -2, 0, 2, 4]:
            adjusted_spots = {}
            for key, epoch in self.sweet_spots.items():
                if epoch:
                    # 에폭 범위 제한 (2-60)
                    adjusted_epoch = max(2, min(60, epoch + delta))
                    adjusted_spots[key] = adjusted_epoch
                    
            # 조정된 sweet spot으로 모델 생성
            self.sweet_spots = adjusted_spots
            variant_model = self.create_optimal_model()
            variants.append({
                'delta': delta,
                'model': variant_model,
                'sweet_spots': adjusted_spots.copy()
            })
            
        return variants
        
    def evaluate_crossover_quality(self, model, test_loader):
        """크로스오버 모델 품질 평가"""
        model.eval()
        total_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in test_loader:
                outputs = model(batch)
                loss = model.compute_loss(outputs, batch)
                total_loss += loss.item()
                
                # 정확도 계산 (감정 분류 기준)
                if 'emotion' in outputs:
                    predictions = outputs['emotion'].argmax(dim=1)
                    targets = batch['emotion_target']
                    correct += (predictions == targets).sum().item()
                    total += targets.size(0)
                    
        metrics = {
            'avg_loss': total_loss / len(test_loader),
            'accuracy': correct / total if total > 0 else 0
        }
        
        return metrics
```

---

## 6. 실행 스크립트

### 6.1 통합 실행 스크립트
```bash
#!/bin/bash
# run_advanced_training.sh

# 환경 설정
export PYTHONPATH=/mnt/c/large_project/linux_red_heart
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# 로그 디렉토리 생성
LOG_DIR="logs/training_$(date +%Y%m%d_%H%M%S)"
mkdir -p $LOG_DIR

echo "🚀 Red Heart AI 고급 학습 시작"
echo "로그 디렉토리: $LOG_DIR"

# Phase 1: LR Sweep
echo "Phase 1: Learning Rate Sweep 시작..."
for lr in 1e-5 5e-5 1e-4 2e-4 5e-4; do
    echo "  LR $lr 테스트 중..."
    python unified_training_v2.py \
        --mode lr-sweep \
        --lr $lr \
        --epochs 5 \
        --batch-size 4 \
        --gradient-accumulation 16 \
        --mixed-precision \
        --save-metrics \
        > $LOG_DIR/lr_sweep_${lr}.log 2>&1
done

# 최적 LR 선택
echo "최적 LR 분석 중..."
python analyze_lr_sweep.py --sweep-dir $LOG_DIR > $LOG_DIR/best_lr.txt
BEST_LR=$(cat $LOG_DIR/best_lr.txt | grep "Best LR:" | cut -d: -f2)
echo "선택된 최적 LR: $BEST_LR"

# Phase 2: 본 학습
echo "Phase 2: 본 학습 시작 (60 epochs)..."
nohup python unified_training_v2.py \
    --mode full-train \
    --lr $BEST_LR \
    --epochs 60 \
    --batch-size 4 \
    --gradient-accumulation 16 \
    --mixed-precision \
    --use-dsm \
    --save-every 2 \
    --checkpoint-dir checkpoints \
    > $LOG_DIR/main_training.log 2>&1 &

TRAIN_PID=$!
echo "학습 프로세스 PID: $TRAIN_PID"

# 학습 모니터링
while kill -0 $TRAIN_PID 2>/dev/null; do
    echo "학습 진행 중... ($(date))"
    
    # GPU 메모리 체크
    nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits \
        >> $LOG_DIR/gpu_memory.log
    
    # 최근 로그 확인
    tail -n 5 $LOG_DIR/main_training.log
    
    sleep 300  # 5분마다 체크
done

echo "학습 완료!"

# Phase 3: Sweet Spot 분석
echo "Phase 3: Sweet Spot 분석 시작..."
python analyze_sweet_spots.py \
    --checkpoint-dir checkpoints \
    --output-dir analysis \
    > $LOG_DIR/sweet_spot_analysis.log 2>&1

# Phase 4: 크로스오버
echo "Phase 4: 파라미터 크로스오버 시작..."
python parameter_crossover.py \
    --checkpoint-dir checkpoints \
    --sweet-spots analysis/sweet_spots.json \
    --output-model final_model.pt \
    > $LOG_DIR/crossover.log 2>&1

echo "✅ 전체 학습 파이프라인 완료!"
echo "최종 모델: final_model.pt"
echo "분석 결과: analysis/"
echo "백업 데이터: C:/large_project/linux_red_heart/docs/data/"
```

### 6.2 Python 메인 실행 파일
```python
# main_training_pipeline.py
import argparse
import json
import os
from pathlib import Path
import torch
from datetime import datetime

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data-path', default='claude_api_preprocessing/claude_preprocessed_complete.json')
    parser.add_argument('--max-samples', type=int, default=10000)
    parser.add_argument('--gpu-id', type=int, default=0)
    args = parser.parse_args()
    
    # GPU 설정
    torch.cuda.set_device(args.gpu_id)
    
    # 데이터 백업 디렉토리 생성
    backup_base = Path('C:/large_project/linux_red_heart/docs/data')
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    session_dir = backup_base / f'session_{timestamp}'
    session_dir.mkdir(parents=True, exist_ok=True)
    
    # 세션 정보 저장
    session_info = {
        'start_time': datetime.now().isoformat(),
        'data_path': args.data_path,
        'max_samples': args.max_samples,
        'gpu_id': args.gpu_id,
        'cuda_device': torch.cuda.get_device_name(args.gpu_id),
        'total_gpu_memory': torch.cuda.get_device_properties(args.gpu_id).total_memory / 1e9
    }
    
    with open(session_dir / 'session_info.json', 'w') as f:
        json.dump(session_info, f, indent=2)
    
    print(f"📁 세션 디렉토리: {session_dir}")
    
    # Phase 1: LR Sweep
    from lr_sweep import run_lr_sweep
    best_lr = run_lr_sweep(args, session_dir)
    
    # Phase 2: Main Training  
    from main_training import run_main_training
    checkpoints = run_main_training(args, best_lr, session_dir)
    
    # Phase 3: Sweet Spot Analysis
    from sweet_spot_analysis import analyze_sweet_spots
    sweet_spots = analyze_sweet_spots(checkpoints, session_dir)
    
    # Phase 4: Crossover
    from parameter_crossover import create_crossover_model
    final_model = create_crossover_model(checkpoints, sweet_spots, session_dir)
    
    # 최종 저장
    torch.save(final_model.state_dict(), session_dir / 'final_model.pt')
    
    # 세션 종료 정보
    session_info['end_time'] = datetime.now().isoformat()
    session_info['final_model_path'] = str(session_dir / 'final_model.pt')
    session_info['sweet_spots'] = sweet_spots
    
    with open(session_dir / 'session_info_final.json', 'w') as f:
        json.dump(session_info, f, indent=2)
    
    print(f"✅ 학습 완료! 최종 모델: {session_dir / 'final_model.pt'}")

if __name__ == '__main__':
    main()
```

---

## 7. 모니터링 및 문제 해결

### 7.1 실시간 모니터링
```python
# monitor_training.py
class TrainingMonitor:
    def __init__(self, log_file, checkpoint_dir):
        self.log_file = log_file
        self.checkpoint_dir = checkpoint_dir
        
    def monitor(self, interval=60):
        """실시간 학습 모니터링"""
        while True:
            # GPU 메모리 체크
            gpu_memory = torch.cuda.memory_allocated() / 1e9
            gpu_util = torch.cuda.utilization()
            
            # 최근 체크포인트 확인
            latest_checkpoint = self._get_latest_checkpoint()
            
            # 학습 진행도
            if latest_checkpoint:
                epoch = int(latest_checkpoint.stem.split('_')[1])
                progress = epoch / 60 * 100
                
                print(f"[{datetime.now().strftime('%H:%M:%S')}]")
                print(f"  진행도: {progress:.1f}% (Epoch {epoch}/60)")
                print(f"  GPU: {gpu_memory:.1f}GB / {gpu_util}%")
                
            # 에러 체크
            self._check_for_errors()
            
            time.sleep(interval)
            
    def _get_latest_checkpoint(self):
        checkpoints = list(Path(self.checkpoint_dir).glob('epoch_*.pt'))
        return max(checkpoints, key=lambda p: p.stat().st_mtime) if checkpoints else None
        
    def _check_for_errors(self):
        """로그에서 에러 확인"""
        with open(self.log_file, 'r') as f:
            lines = f.readlines()[-100:]  # 마지막 100줄
            
        for line in lines:
            if 'ERROR' in line or 'CUDA out of memory' in line:
                print(f"⚠️ 에러 감지: {line.strip()}")
```

### 7.2 문제 해결 가이드

#### OOM (Out of Memory) 발생 시
```python
# 1. 배치 크기 감소
config['batch_size'] = 2  # 4 → 2

# 2. Gradient accumulation 증가
config['gradient_accumulation_steps'] = 32  # 16 → 32

# 3. DSM 공격적 스왑
dsm_scheduler.target_usage = 0.75  # 0.85 → 0.75
```

#### 학습 중단 시 재개
```python
def resume_training(checkpoint_path):
    checkpoint = torch.load(checkpoint_path)
    model.load_state_dict(checkpoint['model_state'])
    optimizer.load_state_dict(checkpoint['optimizer_state'])
    start_epoch = checkpoint['epoch'] + 1
    return start_epoch
```

---

## 8. 예상 결과 및 논문 활용

### 8.1 예상 성능
- **단일 모델**: 75-80% accuracy (과적합)
- **크로스오버**: 85-88% accuracy  
- **5-변형 앙상블**: 90%+ accuracy

### 8.2 논문용 데이터
1. **LR Sweep 그래프**: 5개 학습률별 수렴 곡선
2. **학습 곡선**: 60 에폭 train/val loss
3. **Sweet Spot 분석**: 모듈별 최적 에폭 히트맵
4. **크로스오버 효과**: 단일 vs 크로스오버 성능 비교
5. **DSM 효율성**: 메모리 사용량 및 스왑 패턴

### 8.3 백업 위치
```
C:/large_project/linux_red_heart/docs/data/
├── lr_sweep/           # LR 실험 데이터
├── checkpoints/        # 30개 체크포인트
├── metrics/           # 에폭별 메트릭
├── analysis/          # Sweet spot 분석
└── final/            # 최종 모델 및 보고서
```

---

## 9. 결론

이 전략은 제한된 데이터(10K)와 GPU(8GB)로 730M 모델을 학습하는 창의적 접근법입니다.
의도적 과적합 후 크로스오버를 통해 일반화 성능을 향상시키며,
DSM을 활용한 메모리 관리로 대규모 모델을 로컬에서 학습 가능하게 합니다.

총 소요 시간은 170-200시간(7-8일)이며, 
철저한 데이터 백업과 메트릭 기록으로 논문 작성에 필요한 모든 자료를 확보할 수 있습니다.