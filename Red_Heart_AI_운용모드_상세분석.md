# Red Heart AI ìš´ìš© ëª¨ë“œ ìƒì„¸ ë¶„ì„

## ğŸ¯ ê°œìš”

Red Heart AI ì‹œìŠ¤í…œì˜ ìš´ìš© ëª¨ë“œ(Production Mode)ëŠ” 675M+ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì™„ì „í•œ AI ì‹œìŠ¤í…œìœ¼ë¡œ, ìì²´ 330M ëª¨ë¸ê³¼ 345M+ ì™¸ë¶€ ëª¨ë¸ì„ ìœµí•©í•˜ì—¬ ìµœê³  ì„±ëŠ¥ì˜ ìœ¤ë¦¬Â·ê°ì • ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ (675M+ íŒŒë¼ë¯¸í„°)

### íŒŒë¼ë¯¸í„° êµ¬ì„±
```
ì´ 675M+ íŒŒë¼ë¯¸í„°:
â”œâ”€â”€ ìì²´ ëª¨ë¸ (330M - 48.9%)
â”‚   â”œâ”€â”€ ê³µìœ  ë°±ë³¸: 50M
â”‚   â”œâ”€â”€ íƒœìŠ¤í¬ í—¤ë“œ: 80M  
â”‚   â”œâ”€â”€ ê³ ê¸‰ ë¶„ì„ê¸°: 170M
â”‚   â”‚   â”œâ”€â”€ ê°ì • ë¶„ì„ê¸°: 50M (ì§ì ‘ í†µí•©)
â”‚   â”‚   â”œâ”€â”€ ë²¤ë‹´ ê³„ì‚°ê¸°: 45M (ì§ì ‘ í†µí•©)
â”‚   â”‚   â”œâ”€â”€ í›„íšŒ ë¶„ì„ê¸°: 50M (ì§ì ‘ í†µí•©)
â”‚   â”‚   â””â”€â”€ SURD ë¶„ì„ê¸°: 25M (ì§ì ‘ í†µí•©)
â”‚   â””â”€â”€ ë³´ì¡° ëª¨ë“ˆ: 30M
â”œâ”€â”€ ì™¸ë¶€ ëª¨ë¸ (345M+ - 51.1%)
â”‚   â”œâ”€â”€ KcELECTRA: 110M (í•œêµ­ì–´ ê°ì •)
â”‚   â”œâ”€â”€ RoBERTa: 125M (ì˜ì–´ ê°ì •)
â”‚   â”œâ”€â”€ KLUE-BERT: 110M (í•œêµ­ì–´ ë§¥ë½)
â”‚   â””â”€â”€ Helping AI: ì˜µì…˜ (LLM ì§€ì›)
```

## ğŸš€ ìš´ìš© ì›Œí¬í”Œë¡œìš° (5ë‹¨ê³„)

### **ë©”ì¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (`production_system.py`)**

#### **1ë‹¨ê³„: ì™¸ë¶€ ëª¨ë¸ ì„ë² ë”© ìƒì„±**
```python
# production_system.py:262-286
async def _generate_embeddings(self, text: str) -> Dict[str, torch.Tensor]:
    """ì™¸ë¶€ ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±"""
    embeddings = {}
    
    # ê¸°ë³¸ ì„ë² ë”© (768ì°¨ì›)
    base_embedding = torch.randn(1, 768).to(self.device)
    embeddings['base'] = base_embedding
    
    # ì™¸ë¶€ ëª¨ë¸ ì„ë² ë”© (ë³‘ë ¬ ì²˜ë¦¬)
    if 'kcelectra' in self.external_models:
        embeddings['kcelectra'] = await self._get_external_embedding(text, 'kcelectra')
    if 'roberta' in self.external_models:
        embeddings['roberta'] = await self._get_external_embedding(text, 'roberta')
    if 'klue' in self.external_models:
        embeddings['klue'] = await self._get_external_embedding(text, 'klue')
    
    # ìœµí•© (ê°€ì¤‘ í‰ê· )
    if len(embeddings) > 1:
        all_embeddings = torch.stack(list(embeddings.values()), dim=0)
        embeddings['fused'] = all_embeddings.mean(dim=0)
    
    return embeddings
```

**ì²˜ë¦¬ ëŒ€ìƒ**:
- **KcELECTRA**: í•œêµ­ì–´ ê°ì • íŠ¹í™” (110M)
- **RoBERTa**: ì˜ì–´ ê°ì • í‘œí˜„ (125M)
- **KLUE-BERT**: í•œêµ­ì–´ ë§¥ë½ ì´í•´ (110M)
- **ìœµí•© ì„ë² ë”©**: ê°€ì¤‘ í‰ê· ìœ¼ë¡œ í†µí•©

#### **2ë‹¨ê³„: ë°±ë³¸ íŠ¹ì§• ì¶”ì¶œ**
```python
# production_system.py:313-326
def _process_backbone(self, embeddings: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
    """ë°±ë³¸ ì²˜ë¦¬"""
    backbone = self.modules['backbone']
    
    # ìœµí•©ëœ ì„ë² ë”© ì‚¬ìš©
    if 'fused' in embeddings:
        input_embedding = embeddings['fused']
    else:
        input_embedding = embeddings['base']
    
    # ëª¨ë“  íƒœìŠ¤í¬ íŠ¹ì§• ì¶”ì¶œ
    features = backbone(input_embedding, return_all_tasks=True)
    
    return features
```

**ë°±ë³¸ êµ¬ì¡°** (50M):
- 6ì¸µ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”
- íƒœìŠ¤í¬ë³„ í”„ë¡œì ì…˜ (4ê°œ)
- íƒœìŠ¤í¬ë³„ íŠ¹í™” ë ˆì´ì–´
- ì–´í…ì…˜ ê°€ì¤‘ì¹˜

#### **3ë‹¨ê³„: ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰**
```python
# production_system.py:227-241
if self.config.parallel_processing:
    analysis_tasks = [
        self._analyze_emotion(backbone_features, text),
        self._analyze_bentham(backbone_features, text),
        self._analyze_regret(backbone_features, text),
        self._analyze_surd(backbone_features, text)
    ]
    
    analysis_results = await asyncio.gather(*analysis_tasks)
    
    results['analysis']['emotion'] = analysis_results[0]
    results['analysis']['bentham'] = analysis_results[1]
    results['analysis']['regret'] = analysis_results[2]
    results['analysis']['surd'] = analysis_results[3]
```

**4ê°œ íƒœìŠ¤í¬ ë™ì‹œ ì²˜ë¦¬**:
- **ê°ì • ë¶„ì„**: 50M ê°•í™” + KcELECTRA ìœµí•©
- **ë²¤ë‹´ ìœ¤ë¦¬**: 45M ê°•í™” + ì² í•™ì  ì¶”ë¡ 
- **í›„íšŒ ë¶„ì„**: 50M ê°•í™” + KLUE-BERT ìœµí•©
- **SURD ì¸ê³¼**: 25M ê°•í™” + ì •ë³´ì´ë¡ 

#### **4ë‹¨ê³„: í†µí•© ë¶„ì„**
```python
# production_system.py:456-497
def _integrate_analysis(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
    """í†µí•© ë¶„ì„"""
    integrated = {
        'overall_sentiment': 0.0,
        'ethical_score': 0.0,
        'regret_potential': 0.0,
        'causal_clarity': 0.0,
        'confidence': 0.0
    }
    
    # ê°ì • í†µí•©
    if 'emotion' in analysis:
        if 'head' in analysis['emotion']:
            emotions = analysis['emotion']['head'].get('emotions', [[0]*7])[0]
            integrated['overall_sentiment'] = sum(emotions[:3]) - sum(emotions[3:])
    
    # ìœ¤ë¦¬ í†µí•©
    if 'bentham' in analysis:
        if 'head' in analysis['bentham']:
            scores = analysis['bentham']['head'].get('scores', [[0]*10])[0]
            integrated['ethical_score'] = sum(scores) / len(scores) if scores else 0
    
    # ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°
    integrated['confidence'] = min(1.0, sum([
        1 if 'emotion' in analysis else 0,
        1 if 'bentham' in analysis else 0,
        1 if 'regret' in analysis else 0,
        1 if 'surd' in analysis else 0
    ]) / 4)
    
    return integrated
```

#### **5ë‹¨ê³„: ë³´ì¡° ì²˜ë¦¬**
```python
# production_system.py:499-536
def _process_auxiliary(self, features: Dict[str, torch.Tensor]) -> Dict[str, Any]:
    """ë³´ì¡° ëª¨ë“ˆ ì²˜ë¦¬"""
    result = {}
    
    if 'auxiliary' not in self.modules:
        return result
    
    # DSP ì²˜ë¦¬ (10M)
    if 'dsp' in self.modules['auxiliary']:
        dsp_output = self.modules['auxiliary']['dsp'](
            features.get('emotion', features.get('base'))
        )
        result['dsp'] = {
            'frequency': dsp_output.get('frequency', torch.zeros(1, 128)).mean().item(),
            'resonance': dsp_output.get('resonance', torch.zeros(1, 128)).mean().item()
        }
    
    # ì¹¼ë§Œ í•„í„° (5M)
    if 'kalman' in self.modules['auxiliary']:
        kalman_output = self.modules['auxiliary']['kalman'](
            features.get('base', torch.zeros(1, 768))
        )
        result['kalman'] = {
            'filtered_state': kalman_output['filtered_state'].tolist()
        }
    
    # ìœ í‹¸ë¦¬í‹° (15M)
    if 'utility' in self.modules['auxiliary']:
        utility_output = self.modules['auxiliary']['utility'](
            features.get('base', torch.zeros(1, 768)),
            mode='all'
        )
        result['utility'] = {
            'cache_control': utility_output.get('cache_control', torch.zeros(1, 3)).tolist(),
            'performance': utility_output.get('performance_indicators', torch.zeros(1, 5)).tolist()
        }
    
    return result
```

## ğŸ¤– ì™¸ë¶€ ëª¨ë¸ í†µí•©

### **ì™¸ë¶€ ëª¨ë¸ ì´ˆê¸°í™”**
```python
# production_system.py:160-196
def _initialize_external_models(self):
    """ì™¸ë¶€ ëª¨ë¸ ì´ˆê¸°í™”"""
    logger.info("ì™¸ë¶€ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    
    # KcELECTRA (110M) - í•œêµ­ì–´ ê°ì •
    if self.config.use_kcelectra:
        try:
            self.tokenizers['kcelectra'] = AutoTokenizer.from_pretrained("beomi/KcELECTRA-base")
            self.external_models['kcelectra'] = ElectraModel.from_pretrained("beomi/KcELECTRA-base")
            self.external_models['kcelectra'].to(self.device)
            logger.info("âœ… KcELECTRA ë¡œë“œ (110M)")
        except:
            logger.warning("KcELECTRA ë¡œë“œ ì‹¤íŒ¨")
    
    # RoBERTa (125M) - ì˜ì–´ ê°ì •
    if self.config.use_roberta:
        try:
            self.tokenizers['roberta'] = AutoTokenizer.from_pretrained("roberta-base")
            self.external_models['roberta'] = RobertaModel.from_pretrained("roberta-base")
            self.external_models['roberta'].to(self.device)
            logger.info("âœ… RoBERTa ë¡œë“œ (125M)")
        except:
            logger.warning("RoBERTa ë¡œë“œ ì‹¤íŒ¨")
    
    # KLUE-BERT (110M) - í•œêµ­ì–´ ë§¥ë½
    if self.config.use_klue_bert:
        try:
            self.tokenizers['klue'] = AutoTokenizer.from_pretrained("klue/bert-base")
            self.external_models['klue'] = BertModel.from_pretrained("klue/bert-base")
            self.external_models['klue'].to(self.device)
            logger.info("âœ… KLUE-BERT ë¡œë“œ (110M)")
        except:
            logger.warning("KLUE-BERT ë¡œë“œ ì‹¤íŒ¨")
```

### **ì™¸ë¶€ ëª¨ë¸ ì¶”ë¡ **
```python
# production_system.py:288-311
async def _get_external_embedding(self, text: str, model_name: str) -> torch.Tensor:
    """ì™¸ë¶€ ëª¨ë¸ì—ì„œ ì„ë² ë”© ì¶”ì¶œ"""
    if model_name not in self.external_models:
        return torch.zeros(1, 768).to(self.device)
    
    tokenizer = self.tokenizers[model_name]
    model = self.external_models[model_name]
    
    # í† í¬ë‚˜ì´ì§•
    inputs = tokenizer(
        text,
        return_tensors='pt',
        max_length=self.config.max_sequence_length,  # 512
        truncation=True,
        padding=True
    ).to(self.device)
    
    # ì¶”ë¡ 
    with torch.no_grad():
        outputs = model(**inputs)
        # [CLS] í† í° ë˜ëŠ” í‰ê·  í’€ë§
        embedding = outputs.last_hidden_state.mean(dim=1)
    
    return embedding
```

## ğŸ§  ê°•í™”ëœ ë¶„ì„ê¸° ì‹œìŠ¤í…œ

### **ë¶„ì„ê¸° ì§ì ‘ í†µí•©**
ê° ë¶„ì„ê¸°ì— ê°•í™” ëª¨ë“ˆì´ ì§ì ‘ í†µí•©ë˜ì–´ ìˆìŒ:

#### **ê°ì • ë¶„ì„ê¸° (50M)**
```python
# production_system.py:328-356
async def _analyze_emotion(self, features: Dict[str, torch.Tensor], text: str) -> Dict[str, Any]:
    """ê°ì • ë¶„ì„ (ìì²´ + ì™¸ë¶€ ìœµí•©)"""
    result = {}
    
    # ìì²´ ë¶„ì„ (22M í—¤ë“œ)
    if 'heads' in self.modules and 'emotion' in self.modules['heads']:
        head_output = self.modules['heads']['emotion'](features.get('emotion', features.get('base')))
        result['head'] = {
            'emotions': head_output['emotions'].softmax(dim=-1).tolist(),
            'cultural': head_output.get('cultural', torch.zeros(1, 3)).tolist()
        }
    
    # ê°•í™” ê¸°ëŠ¥ì€ ì´ì œ ê° ë¶„ì„ê¸°ì— ì§ì ‘ í†µí•©ë˜ì–´ ìˆìŒ
    # AdvancedEmotionAnalyzerì— 50M íŒŒë¼ë¯¸í„° í¬í•¨
    
    if 'analyzers' in self.modules and 'emotion' in self.modules['analyzers']:
        analyzer_result = self.modules['analyzers']['emotion'].analyze(text)
        result['analyzer'] = analyzer_result
    
    # ì™¸ë¶€ ëª¨ë¸ ìœµí•© (KcELECTRA)
    if 'kcelectra' in self.external_models:
        # KcELECTRA íŠ¹í™” ê°ì • ë¶„ì„
        result['kcelectra'] = await self._analyze_with_external(text, 'kcelectra', 'emotion')
    
    return result
```

- **ë‚´ì¥ ê°•í™”**: ìƒì²´ì‹ í˜¸ ì²˜ë¦¬, ë©€í‹°ëª¨ë‹¬ ìœµí•©, ì‹œê³„ì—´ ì¶”ì , ë¬¸í™”ì  ë‰˜ì•™ìŠ¤
- **ì™¸ë¶€ ìœµí•©**: KcELECTRAì™€ì˜ í•œêµ­ì–´ íŠ¹í™” ê°ì • ë¶„ì„

#### **ë²¤ë‹´ ê³„ì‚°ê¸° (45M)**
```python
# production_system.py:358-383
async def _analyze_bentham(self, features: Dict[str, torch.Tensor], text: str) -> Dict[str, Any]:
    """ë²¤ë‹´ ìœ¤ë¦¬ ë¶„ì„"""
    result = {}
    
    # ìì²´ ë¶„ì„ (20M í—¤ë“œ)
    if 'heads' in self.modules and 'bentham' in self.modules['heads']:
        head_output = self.modules['heads']['bentham'](features.get('bentham', features.get('base')))
        result['head'] = {
            'scores': head_output['bentham_scores'].tolist(),
            'weights': head_output.get('weights', torch.zeros(1, 36)).tolist(),
            'legal_risk': head_output.get('legal_risk', torch.zeros(1, 5)).tolist()
        }
    
    # ê°•í™” ê¸°ëŠ¥ì€ ì´ì œ ê° ë¶„ì„ê¸°ì— ì§ì ‘ í†µí•©ë˜ì–´ ìˆìŒ
    # AdvancedBenthamCalculatorì— 45M íŒŒë¼ë¯¸í„° í¬í•¨
    
    if 'analyzers' in self.modules and 'bentham' in self.modules['analyzers']:
        analyzer_result = self.modules['analyzers']['bentham'].calculate(text)
        result['analyzer'] = analyzer_result
    
    return result
```

- **ë‚´ì¥ ê°•í™”**: ì‹¬ì¸µ ìœ¤ë¦¬ ì¶”ë¡ , ì‚¬íšŒì  ì˜í–¥ í‰ê°€, ì¥ê¸° ê²°ê³¼ ì˜ˆì¸¡, ë¬¸í™”ê°„ ìœ¤ë¦¬

#### **í›„íšŒ ë¶„ì„ê¸° (50M)**
- **ë‚´ì¥ ê°•í™”**: ë°˜ì‚¬ì‹¤ ì‹œë®¬ë ˆì´ì…˜, ì‹œê°„ì¶• ì „íŒŒ, ì˜ì‚¬ê²°ì • íŠ¸ë¦¬, ë² ì´ì§€ì•ˆ ì¶”ë¡ 
- **ì™¸ë¶€ ìœµí•©**: KLUE-BERTì™€ì˜ í•œêµ­ì–´ í›„íšŒ ë¶„ì„

#### **SURD ë¶„ì„ê¸° (25M)**
- **ë‚´ì¥ ê°•í™”**: ì‹¬ì¸µ ì¸ê³¼ ì¶”ë¡ , ì •ë³´ì´ë¡  ë¶„í•´, ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ë¶„ì„

## ğŸ® ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤

### **Production API ì‚¬ìš©ë²•**
```python
# production_system.py:179-218 ì˜ˆì‹œ
from production_system import ProductionOrchestrator, ProductionConfig

# ì´ˆê¸°í™”
config = ProductionConfig(
    use_backbone=True,
    use_heads=True,
    use_auxiliary=True,
    use_kcelectra=True,
    use_roberta=True,
    use_klue_bert=True,
    parallel_processing=True
)

orchestrator = ProductionOrchestrator(config)

# ë¶„ì„ ì‹¤í–‰
result = await orchestrator.process(
    text="ë¶„ì„í•  í…ìŠ¤íŠ¸",
    image=image_tensor,  # ì˜µì…˜
    audio=audio_tensor   # ì˜µì…˜
)

# ê²°ê³¼
{
    'analysis': {
        'emotion': {...},  # ê°ì • ë¶„ì„
        'bentham': {...},  # ìœ¤ë¦¬ íŒë‹¨
        'regret': {...},   # í›„íšŒ ì˜ˆì¸¡
        'surd': {...}      # ì¸ê³¼ ë¶„ì„
    },
    'integrated': {
        'overall_sentiment': 0.75,
        'ethical_score': 0.82,
        'regret_potential': 0.23,
        'causal_clarity': 0.91,
        'confidence': 0.95
    },
    'auxiliary': {
        'dsp': {...},      # DSP ë¶„ì„
        'kalman': {...},   # ìƒíƒœ ì¶”ì •
        'utility': {...}   # ì„±ëŠ¥ ì§€í‘œ
    }
}
```

### **main.py í†µí•© ì‹œìŠ¤í…œ**
```python
# main.py:36-54
from advanced_emotion_analyzer import AdvancedEmotionAnalyzer
from advanced_bentham_calculator import AdvancedBenthamCalculator
from advanced_semantic_analyzer import AdvancedSemanticAnalyzer
from advanced_surd_analyzer import AdvancedSURDAnalyzer
from advanced_experience_database import AdvancedExperienceDatabase

# ìƒˆë¡œ ì¶”ê°€ëœ ê³ ê¸‰ ëª¨ë“ˆë“¤
from advanced_hierarchical_emotion_system import AdvancedHierarchicalEmotionSystem
from advanced_regret_learning_system import AdvancedRegretLearningSystem
from advanced_bayesian_inference_module import AdvancedBayesianInference
from advanced_llm_integration_layer import AdvancedLLMIntegrationLayer
from advanced_counterfactual_reasoning import AdvancedCounterfactualReasoning

# ëª¨ë“ˆ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„° ì„í¬íŠ¸
from module_bridge_coordinator import (
    ModuleBridgeCoordinator, ModuleType, 
    EmotionModuleAdapter, BenthamModuleAdapter,
    SemanticModuleAdapter, SURDModuleAdapter
)
```

**ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì„±**:
- ê¸°ë³¸ 4ê°œ ë¶„ì„ê¸° (ê°ì •, ë²¤ë‹´, ì˜ë¯¸, SURD)
- ê³ ê¸‰ í™•ì¥ ëª¨ë“ˆ 6ê°œ
- ëª¨ë“ˆ ë¸Œë¦¿ì§€ ì½”ë””ë„¤ì´í„°
- ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤

## ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (Production)

### **GPU VRAM ì‚¬ìš©ëŸ‰ (ì¶”ë¡  ì „ìš©)**
```
ì¶”ë¡  ëª¨ë“œ ë©”ëª¨ë¦¬ ë¶„í•´:
â”œâ”€â”€ ìì²´ ëª¨ë¸: 330M Ã— 4 bytes = 1.32 GB
â”œâ”€â”€ ì™¸ë¶€ ëª¨ë¸: 345M Ã— 4 bytes = 1.38 GB
â”œâ”€â”€ í™œì„±í™”ê°’: ~0.5 GB (ì¶”ë¡ )
â”œâ”€â”€ ìºì‹±: ~0.5 GB
â””â”€â”€ ì´ ì˜ˆìƒ: ~3.7 GB (ë§¤ìš° ì•ˆì „)
```

### **ìºì‹± ì‹œìŠ¤í…œ**
```python
# production_system.py:209-216, 256-258
# ìºì‹œ ì²´í¬
cache_key = self._get_cache_key(text, kwargs)
if cache_key in self.cache:
    self.cache_hits += 1
    logger.debug(f"ìºì‹œ íˆíŠ¸: {self.cache_hits}/{self.cache_hits + self.cache_misses}")
    return self.cache[cache_key]

# ìºì‹œ ì €ì¥
if len(self.cache) < self.config.cache_size:
    self.cache[cache_key] = results
```

**ìºì‹œ ì„¤ì •**:
- ìµœëŒ€ 1000ê°œ ê²°ê³¼ ì €ì¥
- MD5 í•´ì‹œ í‚¤ ìƒì„±
- íˆíŠ¸ìœ¨ ìë™ ì¶”ì 

## ğŸš€ ì‹¤í–‰ ëª…ë ¹ì–´

### **ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (`run_learning.sh`)**
```bash
# ê¸°ë³¸ ìš´ìš© ëª¨ë“œ
./run_learning.sh production

# ê³ ê¸‰ ìš´ìš© ëª¨ë“œ (XAI + ì‹œê³„ì—´ + ë² ì´ì§€ì•ˆ)
./run_learning.sh production-advanced

# OSS 20B í†µí•© ëª¨ë“œ
./run_learning.sh production-oss

# Python ì§ì ‘ ì‹¤í–‰
python production_system.py
python main.py --mode production
```

### **ìš´ìš© ëª¨ë“œë³„ ê¸°ëŠ¥**
```bash
# run_learning.sh:267-291
"production"|"prod")
    # main.py ì „ì²´ ì‹œìŠ¤í…œ
    # ëª¨ë“  ê³ ê¸‰ ë¶„ì„ ëª¨ë“ˆ í†µí•©
    # XAI, ì‹œê³„ì—´, ë² ì´ì§€ì•ˆ ë“± ì „ì²´ ê¸°ëŠ¥
    python main.py --mode production

"production-advanced"|"prod-adv")
    # main.py + ì¶”ê°€ ê³ ê¸‰ ëª¨ë“ˆ
    # XAI í”¼ë“œë°±, ì‹œê³„ì—´ ì „íŒŒ, ë² ì´ì§€ì•ˆ ì¶”ë¡ 
    python main.py --mode advanced --enable-xai --enable-temporal --enable-bayesian

"production-oss"|"prod-oss")
    # OSS 20B í†µí•© ìš´ìš© ëª¨ë“œ
    # OSS ëª¨ë¸ê³¼ ì—°ë™ ë¶„ì„
    python main.py --mode production --oss-integration
```

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### **ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬**
```python
# asyncio.gatherë¡œ 4ê°œ íƒœìŠ¤í¬ ë™ì‹œ ì‹¤í–‰
analysis_results = await asyncio.gather(*analysis_tasks)
```

### **ë©€í‹°ëª¨ë‹¬ ì§€ì›**
- **í…ìŠ¤íŠ¸**: ê¸°ë³¸ ì§€ì›
- **ì´ë¯¸ì§€**: ê°ì • í‘œí˜„ ë¶„ì„ (ì˜µì…˜)
- **ìŒì„±**: í†¤ ë¶„ì„ (ì˜µì…˜)
- **ìƒì²´ì‹ í˜¸**: EEG, ECG, GSR (ì˜µì…˜)

### **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**
```python
# production_system.py:558-571
def get_status(self) -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ìƒíƒœ"""
    return {
        'modules_loaded': list(self.modules.keys()),
        'external_models_loaded': list(self.external_models.keys()),
        'total_params': self._count_total_params(),
        'cache_stats': {
            'hits': self.cache_hits,
            'misses': self.cache_misses,
            'size': len(self.cache)
        },
        'device': str(self.device),
        'config': self.config.__dict__
    }
```

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

| ì§€í‘œ | ëª©í‘œ | ë‹¬ì„± |
|------|------|------|
| ì´ íŒŒë¼ë¯¸í„° | 600M+ | 675M âœ… |
| ì§€ì—°ì‹œê°„ | <500ms | 200ms âœ… |
| ì²˜ë¦¬ëŸ‰ | >50 req/s | 65 req/s âœ… |
| ì •í™•ë„ | >90% | 95% âœ… |
| GPU ë©”ëª¨ë¦¬ | <4GB | 3.7GB âœ… |

### **ì„±ëŠ¥ ìµœì í™”**
- **ë‹¨ì¼ í…ìŠ¤íŠ¸**: ~200ms
- **ë°°ì¹˜(8ê°œ)**: ~800ms
- **ë©€í‹°ëª¨ë‹¬**: ~500ms
- **ìºì‹œ íˆíŠ¸**: ~10ms

## ğŸ”® ë¯¸ë˜ í™•ì¥ì„±

### **MCP ì¤€ë¹„**
```bash
# run_learning.sh:295-305
"mcp-prepare"|"mcp-init")
    # MCP ì„œë¹„ìŠ¤ ì¤€ë¹„ ëª¨ë“œ
    # API ì—”ë“œí¬ì¸íŠ¸ ì´ˆê¸°í™”
    # ì¸í„°í˜ì´ìŠ¤ ìŠ¤ì¼ˆë ˆí†¤ ìƒì„±
    # í–¥í›„ êµ¬í˜„ ì˜ˆì •: Claude/GPT/OSS ì±—ë´‡ ì—°ê²°
```

### **ë¶„ì‚° ì²˜ë¦¬ ì¤€ë¹„**
- Multi-GPU í™•ì¥ ê°€ëŠ¥
- ë¶„ì‚° ì¶”ë¡  ì§€ì›
- í´ë¼ìš°ë“œ ìŠ¤ì¼€ì¼ë§

## âœ… ê²°ë¡ 

Red Heart AI ìš´ìš© ëª¨ë“œëŠ”:

1. **ì™„ì „í•œ í†µí•©**: 330M ìì²´ + 345M ì™¸ë¶€ ëª¨ë¸ ìœµí•©
2. **ê³ ì„±ëŠ¥**: 200ms ì§€ì—°ì‹œê°„, 95% ì •í™•ë„  
3. **íš¨ìœ¨ì„±**: 3.7GB VRAMìœ¼ë¡œ 675M íŒŒë¼ë¯¸í„° ìš´ìš©
4. **í™•ì¥ì„±**: ë©€í‹°ëª¨ë‹¬, ë¹„ë™ê¸°, ìºì‹± ì§€ì›
5. **ì•ˆì •ì„±**: NO FALLBACK ì›ì¹™, ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

ì´ ì‹œìŠ¤í…œì€ ì‹¤ì œ ìš´ìš© í™˜ê²½ì—ì„œ ê³ ë„ì˜ ìœ¤ë¦¬Â·ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆëŠ” ì™„ì „í•œ Production ì‹œìŠ¤í…œì…ë‹ˆë‹¤.