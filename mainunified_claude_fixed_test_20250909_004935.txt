2025-09-09 00:49:53 | RedHeart.MainUnified | INFO | 🖥️ 사용 디바이스: cuda
2025-09-09 00:49:53 | RedHeart.MainUnified | INFO |    GPU: NVIDIA GeForce RTX 2070 SUPER
2025-09-09 00:49:53 | RedHeart.MainUnified | INFO |    VRAM: 8.0GB
2025-09-09 00:49:53 | RedHeart.MainUnified | INFO | 🔄 Claude API 모드 감지 - 독립 워크플로우로 전환...
2025-09-09 00:49:53 | RedHeart.MainUnified | INFO | 📌 REDHEART_CLAUDE_MODE 환경변수 설정 - 로컬 LLM 엔진 비활성화
2025-09-09 00:49:53 | RedHeart.MainUnified | INFO | 📌 전역 모듈 사전 초기화 중...
2025-09-09 00:49:53 | local_translator | INFO | LocalTranslator 생성 - lazy loading 모드
2025-09-09 00:49:53 | RedHeart.Config | INFO | 🔥 register_system_module 호출: module_id=translator, instance_type=<class 'local_translator.LocalTranslator'>, config_section=None
2025-09-09 00:49:53 | RedHeart.Config | INFO | 🔥 모듈 인스턴스 등록 (config_section 없음): translator -> <class 'local_translator.LocalTranslator'>
2025-09-09 00:49:53 | RedHeart.MainUnified | INFO |    ✅ 번역기 전역 등록 완료
2025-09-09 00:49:53 | RedHeart.MainUnified | INFO | 📌 Claude Inference 직접 실행: text=AI 윤리적 문제 해결, epoch=50, debug=True
2025-09-09 00:49:53 | ClaudeInference | INFO | ======================================================================
2025-09-09 00:49:53 | ClaudeInference | INFO | 🚀 Claude API 독립 추론 시스템 초기화
2025-09-09 00:49:53 | ClaudeInference | INFO | ======================================================================
2025-09-09 00:49:53 | ClaudeInference | INFO | 📌 에폭: 50
2025-09-09 00:49:53 | ClaudeInference | INFO | 📌 디바이스: cuda
2025-09-09 00:49:53 | ClaudeInference | INFO | 📌 디버그 모드: True
2025-09-09 00:49:53 | ClaudeInference | INFO | 
📦 Phase 1: UnifiedModel 로드...
2025-09-09 00:49:58 | sentence_transformer_singleton | INFO | SentenceTransformerManager 초기화 완료 (Subprocess Server 기반)
2025-09-09 00:49:58 | training.enhanced_checkpoint_manager | INFO |   - 기존 메타데이터 로드: 30개 체크포인트
2025-09-09 00:49:58 | training.enhanced_checkpoint_manager | INFO | ✅ Enhanced CheckpointManager 초기화
2025-09-09 00:49:58 | training.enhanced_checkpoint_manager | INFO |   - 저장 디렉토리: training/checkpoints_final
2025-09-09 00:49:58 | training.enhanced_checkpoint_manager | INFO |   - 최대 체크포인트: 30개
2025-09-09 00:49:58 | training.enhanced_checkpoint_manager | INFO |   - 저장 간격: 1 에폭마다
2025-09-09 00:49:58 | unified_backbone | INFO | 백본 총 파라미터: 90,624,132 (90.62M)
2025-09-09 00:49:58 | unified_backbone | INFO | 학습 가능 파라미터: 90,624,132 (90.62M)
2025-09-09 00:49:58 | unified_heads | INFO | 감정 헤드 파라미터: 17,254,583 (17.25M)
2025-09-09 00:49:59 | unified_heads | INFO | 벤담 헤드 파라미터: 13,871,919 (13.87M)
2025-09-09 00:49:59 | unified_heads | INFO | 후회 헤드 파라미터: 19,897,161 (19.90M)
2025-09-09 00:49:59 | unified_heads | INFO | SURD 헤드 파라미터: 12,025,739 (12.03M)
2025-09-09 00:50:00 | analyzer_neural_modules | INFO | NeuralEmotionAnalyzer 초기화: 122,595,407 파라미터
2025-09-09 00:50:00 | analyzer_neural_modules | INFO | NeuralBenthamCalculator 초기화: 78,281,602 파라미터
2025-09-09 00:50:01 | analyzer_neural_modules | INFO | NeuralRegretAnalyzer 초기화: 153,872,666 파라미터
2025-09-09 00:50:02 | analyzer_neural_modules | INFO | NeuralSURDAnalyzer 초기화: 13,473,032 파라미터
2025-09-09 00:50:02 | analyzer_neural_modules | INFO | 전체 신경망 분석기 파라미터: 368,222,707 (368.2M)
2025-09-09 00:50:02 | emotion_dsp_simulator | INFO | EmotionDSPSimulator 초기화 완료 (~14M 파라미터)
2025-09-09 00:50:02 | ClaudeInference | INFO |    체크포인트 로드: training/checkpoints_final/checkpoint_epoch_0050_lr_0.000009_20250827_154403.pt
2025-09-09 00:50:31 | ClaudeInference | INFO |    ✅ UnifiedModel 로드 완료
2025-09-09 00:50:31 | ClaudeInference | INFO |    - Epoch: 50
2025-09-09 00:50:31 | ClaudeInference | INFO |    - LR: 9.261697283911905e-06
2025-09-09 00:50:31 | ClaudeInference | INFO | 
📦 Phase 2: 번역기 로드...
2025-09-09 00:50:31 | RedHeart.Config | INFO | 🔍 get_system_module 호출: module_id=translator
2025-09-09 00:50:31 | RedHeart.Config | INFO | 🔍 현재 등록된 모듈들: ['translator']
2025-09-09 00:50:31 | RedHeart.Config | INFO | 🔍 결과: <class 'local_translator.LocalTranslator'>
2025-09-09 00:50:31 | ClaudeInference | INFO |    ✅ 전역 번역기 재사용 (CPU)
2025-09-09 00:50:31 | ClaudeInference | INFO | 
📦 Phase 3: Neural Analyzers 로드...
2025-09-09 00:50:32 | analyzer_neural_modules | INFO | NeuralEmotionAnalyzer 초기화: 122,595,407 파라미터
2025-09-09 00:50:33 | analyzer_neural_modules | INFO | NeuralBenthamCalculator 초기화: 78,281,602 파라미터
2025-09-09 00:50:34 | analyzer_neural_modules | INFO | NeuralRegretAnalyzer 초기화: 153,872,666 파라미터
2025-09-09 00:50:34 | analyzer_neural_modules | INFO | NeuralSURDAnalyzer 초기화: 13,473,032 파라미터
2025-09-09 00:50:34 | ClaudeInference | INFO |    ✅ Neural Analyzers 로드 완료 (CPU)
2025-09-09 00:50:34 | ClaudeInference | INFO | 
📦 Phase 4: Advanced Wrappers 로드...
2025-09-09 00:51:31 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 17.4%, 필요: 500MB)
2025-09-09 00:51:31 | RedHeartLinux.AdvancedEmotion | INFO | 감정 임베딩 모델 초기화 시작...
2025-09-09 00:51:31 | sentence_transformer_singleton | INFO | 새 클라이언트 생성 시작: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-09 00:51:31 | sentence_transformer_client | INFO | 현재 Python이 venv 환경: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-09 00:51:31 | sentence_transformer_client | INFO | SentenceTransformer Client 초기화: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-09 00:51:31 | sentence_transformer_client | INFO | Python 실행파일: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-09 00:51:31 | sentence_transformer_singleton | INFO | 서버 시작 및 모델 로딩: sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (device: cuda)
2025-09-09 00:51:31 | sentence_transformer_client | INFO | SentenceTransformer 서버 시작: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-09 00:51:31 | sentence_transformer_client | INFO | PYTHONPATH: /mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages:/mnt/c/large_project/linux_red_heart
2025-09-09 00:51:31 | sentence_transformer_client | INFO | VIRTUAL_ENV: /mnt/c/large_project/linux_red_heart/red_heart_env
2025-09-09 00:51:31 | sentence_transformer_client | INFO | stderr 드레인 스레드 시작
2025-09-09 00:51:31 | sentence_transformer_client | INFO | stderr 드레인 스레드 생성 완료
2025-09-09 00:51:41 | sentence_transformer_client | INFO | 서버 연결 성공
2025-09-09 00:51:41 | sentence_transformer_client | INFO | 모델 로딩 요청: sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (device: cuda)
2025-09-09 00:53:09 | sentence_transformer_client | INFO | 모델 로딩 성공: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
2025-09-09 00:53:09 | sentence_transformer_singleton | INFO | 클라이언트 생성 및 모델 로딩 성공: sentence-transformers/paraphrase-multilingual-mpnet-base-v2_cuda
2025-09-09 00:53:09 | sentence_transformer_singleton | INFO | 새 클라이언트 생성 시작: jhgan/ko-sroberta-multitask_cuda
2025-09-09 00:53:09 | sentence_transformer_client | INFO | 현재 Python이 venv 환경: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-09 00:53:09 | sentence_transformer_client | INFO | SentenceTransformer Client 초기화: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-09 00:53:09 | sentence_transformer_client | INFO | Python 실행파일: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-09 00:53:09 | sentence_transformer_singleton | INFO | 서버 시작 및 모델 로딩: jhgan/ko-sroberta-multitask (device: cuda)
2025-09-09 00:53:09 | sentence_transformer_client | INFO | SentenceTransformer 서버 시작: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-09 00:53:09 | sentence_transformer_client | INFO | PYTHONPATH: /mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages:/mnt/c/large_project/linux_red_heart
2025-09-09 00:53:09 | sentence_transformer_client | INFO | VIRTUAL_ENV: /mnt/c/large_project/linux_red_heart/red_heart_env
2025-09-09 00:53:09 | sentence_transformer_client | INFO | stderr 드레인 스레드 시작
2025-09-09 00:53:09 | sentence_transformer_client | INFO | stderr 드레인 스레드 생성 완료
2025-09-09 00:53:20 | sentence_transformer_client | INFO | 서버 연결 성공
2025-09-09 00:53:20 | sentence_transformer_client | INFO | 모델 로딩 요청: jhgan/ko-sroberta-multitask (device: cuda)
2025-09-09 00:54:37 | sentence_transformer_client | INFO | 모델 로딩 성공: jhgan/ko-sroberta-multitask
2025-09-09 00:54:37 | sentence_transformer_singleton | INFO | 클라이언트 생성 및 모델 로딩 성공: jhgan/ko-sroberta-multitask_cuda
2025-09-09 00:54:37 | RedHeartLinux.AdvancedEmotion | INFO | 임베딩 모델 로드 완료 (싱글톤): sentence-transformers/paraphrase-multilingual-mpnet-base-v2, jhgan/ko-sroberta-multitask
2025-09-09 00:54:37 | RedHeartLinux.AdvancedEmotion | INFO | 임베딩 모델 초기화 완료: 2 모델 로드됨
2025-09-09 00:54:37 | RedHeart.Config | INFO | 🔍 get_system_module 호출: module_id=translator
2025-09-09 00:54:37 | RedHeart.Config | INFO | 🔍 현재 등록된 모듈들: ['translator']
2025-09-09 00:54:37 | RedHeart.Config | INFO | 🔍 결과: <class 'local_translator.LocalTranslator'>
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO | ✅ 감정 분석기 강화 모듈 통합: 56.4M 파라미터 추가
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO | 감정 분석용 MoE 시스템 초기화 완료 (4개 전문가)
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO |   - emotion_moe 타입: <class 'mixture_of_experts.MixtureOfExperts'>
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO |   - emotion_moe None 여부: False
2025-09-09 00:54:38 | emotion_dsp_simulator | INFO | EmotionDSPSimulator 초기화 완료 (~14M 파라미터)
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO |   - 칼만 필터 차원: 17개 감정
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO | ✅ DSP 시뮬레이터와 칼만 필터 초기화 완료
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO |   - DSP 시뮬레이터: 20M 파라미터
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO |   - 칼만 필터: 융합용
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO | 계층적 감정 모델 초기화 완료
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO | 📌 Claude 모드 감지 - 로컬 LLM 엔진 비활성화
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO | 고급 감정 분석 시스템이 초기화되었습니다.
2025-09-09 00:54:38 | RedHeartLinux.AdvancedEmotion | INFO | 🔍 hierarchical_model이 이미 존재함
2025-09-09 00:54:38 | advanced_analyzer_wrappers | INFO |   - biometric_processor 등록 (10M)
2025-09-09 00:54:38 | advanced_analyzer_wrappers | INFO |   - multimodal_fusion 등록 (10M)
2025-09-09 00:54:38 | advanced_analyzer_wrappers | INFO |   - temporal_emotion 등록 (10M)
2025-09-09 00:54:38 | advanced_analyzer_wrappers | INFO |   - cultural_nuance 등록 (13M)
2025-09-09 00:54:38 | advanced_analyzer_wrappers | INFO |   - advanced_moe 등록 (5M)
2025-09-09 00:54:38 | advanced_analyzer_wrappers | INFO |   - emotion_moe 등록
2025-09-09 00:54:38 | advanced_analyzer_wrappers | INFO | ✅ Advanced Emotion Analyzer Wrapper 초기화 (48M 파라미터)
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | ✅ 벤담 계산기 강화 모듈 통합: 72.8M 파라미터 추가
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 윤리 MoE 시스템 초기화 완료 (4개 전문가, input_dim=512)
2025-09-09 00:54:39 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-09 00:54:39 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 GPU 메모리 관리 활성화
2025-09-09 00:54:39 | RedHeart.ThreeViewScenarioSystem | INFO | 3뷰 시나리오 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 3뷰 시나리오 시스템 초기화 완료
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 신경망 가중치 예측기 로딩 중...
2025-09-09 00:54:39 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 24.4%, 필요: 100MB)
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 신경망 가중치 예측기 로드: cuda (100MB)
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 메모리 사용량: RAM 3028MB, GPU 1998MB
2025-09-09 00:54:39 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-09 00:54:39 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook GPU 메모리 관리 활성화
2025-09-09 00:54:39 | RedHeart.PhaseControllerHook | INFO | PhaseController Hook 시스템 초기화 완료
2025-09-09 00:54:39 | RedHeart.PhaseControllerHook | INFO | 성능 모니터링 시작
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 PhaseController Hook 초기화 완료
2025-09-09 00:54:39 | dynamic_gpu_manager | INFO | Dynamic GPU Manager initialized - Total GPU Memory: 8.0GB
2025-09-09 00:54:39 | RedHeart.LegalExpertSystem | INFO | 법률 전문가 시스템 GPU 메모리 관리 활성화
2025-09-09 00:54:39 | RedHeart.LegalExpertSystem | INFO | 법률 전문가 시스템 초기화 완료 (온디맨드 로딩 방식)
2025-09-09 00:54:39 | RedHeart.LegalExpertSystem | INFO | inference 모드 - 법률 전문가 시스템 활성화
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 벤담 계산기 법률 전문가 시스템 초기화 완료
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 고급 벤담 쾌락 계산기 초기화 완료 (레이지 로딩 활성화)
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 🔨 벤담 계산기 기본 PyTorch 네트워크 생성 중...
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | ✅ 벤담 계산기 기본 네트워크 생성 완료 (device: cuda:0)
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO |    - 파라미터 수: 3,137
2025-09-09 00:54:39 | RedHeart.AdvancedBenthamCalculator | INFO | 트랜스포머 맥락 분석기 로딩 중...
2025-09-09 00:54:39 | config | INFO | GPU 로딩 워커 스레드 시작
2025-09-09 00:54:39 | RedHeart.Config | INFO | 순차적 GPU 로딩 시스템 시작
Device set to use cpu
2025-09-09 00:54:49 | RedHeart.AdvancedBenthamCalculator | INFO | 감정 분석 모델 CPU 로드 완료: cpu
2025-09-09 00:54:49 | RedHeart.AdvancedBenthamCalculator | INFO | ✅ 윤리 분석: 감정→윤리 매핑 방식 (별도 모델 없음)
2025-09-09 00:54:49 | RedHeart.AdvancedBenthamCalculator | INFO | 한국어 감정 분석은 번역 후 영어 모델 사용
2025-09-09 00:54:49 | RedHeart.Config | INFO | GPU 직접 사용: None (사용률: 24.4%, 필요: 500MB)
2025-09-09 00:54:49 | sentence_transformer_singleton | INFO | 새 클라이언트 생성 시작: sentence-transformers/all-MiniLM-L6-v2_cuda
2025-09-09 00:54:49 | sentence_transformer_client | INFO | 현재 Python이 venv 환경: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-09 00:54:49 | sentence_transformer_client | INFO | SentenceTransformer Client 초기화: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-09 00:54:49 | sentence_transformer_client | INFO | Python 실행파일: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python3
2025-09-09 00:54:49 | sentence_transformer_singleton | INFO | 서버 시작 및 모델 로딩: sentence-transformers/all-MiniLM-L6-v2 (device: cuda)
2025-09-09 00:54:49 | sentence_transformer_client | INFO | SentenceTransformer 서버 시작: /mnt/c/large_project/linux_red_heart/sentence_transformer_server.py
2025-09-09 00:54:49 | sentence_transformer_client | INFO | PYTHONPATH: /mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages:/mnt/c/large_project/linux_red_heart
2025-09-09 00:54:49 | sentence_transformer_client | INFO | VIRTUAL_ENV: /mnt/c/large_project/linux_red_heart/red_heart_env
2025-09-09 00:54:49 | sentence_transformer_client | INFO | stderr 드레인 스레드 시작
2025-09-09 00:54:49 | sentence_transformer_client | INFO | stderr 드레인 스레드 생성 완료
2025-09-09 00:55:00 | sentence_transformer_client | INFO | 서버 연결 성공
2025-09-09 00:55:00 | sentence_transformer_client | INFO | 모델 로딩 요청: sentence-transformers/all-MiniLM-L6-v2 (device: cuda)
2025-09-09 00:55:52 | sentence_transformer_client | ERROR | 모델 로딩 실패: 모델 로딩 실패: sentence-transformers/all-MiniLM-L6-v2 - 캐시된 모델을 찾을 수 없습니다: sentence-transformers/all-MiniLM-L6-v2
확인된 경로: /mnt/c/large_project/linux_red_heart/models/sentence_transformers/models--sentence-transformers--all-MiniLM-L6-v2
모델을 먼저 다운로드하거나 캐시 경로를 확인하세요.
2025-09-09 00:55:52 | sentence_transformer_singleton | ERROR | 모델 로드 실패: sentence-transformers/all-MiniLM-L6-v2_cuda, 오류: 모델 로딩 실패: 모델 로딩 실패: sentence-transformers/all-MiniLM-L6-v2 - 캐시된 모델을 찾을 수 없습니다: sentence-transformers/all-MiniLM-L6-v2
확인된 경로: /mnt/c/large_project/linux_red_heart/models/sentence_transformers/models--sentence-transformers--all-MiniLM-L6-v2
모델을 먼저 다운로드하거나 캐시 경로를 확인하세요.
2025-09-09 00:55:52 | sentence_transformer_singleton | ERROR | 오류 타입: RuntimeError
2025-09-09 00:55:52 | sentence_transformer_singleton | ERROR | 스택 트레이스: Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/sentence_transformer_singleton.py", line 187, in get_model
    raise RuntimeError(f"모델 로딩 실패: {error_msg}")
RuntimeError: 모델 로딩 실패: 모델 로딩 실패: sentence-transformers/all-MiniLM-L6-v2 - 캐시된 모델을 찾을 수 없습니다: sentence-transformers/all-MiniLM-L6-v2
확인된 경로: /mnt/c/large_project/linux_red_heart/models/sentence_transformers/models--sentence-transformers--all-MiniLM-L6-v2
모델을 먼저 다운로드하거나 캐시 경로를 확인하세요.

2025-09-09 00:55:52 | ClaudeInference | ERROR | ❌ 초기화 실패: SentenceTransformer 모델 로드 실패: sentence-transformers/all-MiniLM-L6-v2
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/sentence_transformer_singleton.py", line 187, in get_model
    raise RuntimeError(f"모델 로딩 실패: {error_msg}")
RuntimeError: 모델 로딩 실패: 모델 로딩 실패: sentence-transformers/all-MiniLM-L6-v2 - 캐시된 모델을 찾을 수 없습니다: sentence-transformers/all-MiniLM-L6-v2
확인된 경로: /mnt/c/large_project/linux_red_heart/models/sentence_transformers/models--sentence-transformers--all-MiniLM-L6-v2
모델을 먼저 다운로드하거나 캐시 경로를 확인하세요.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/claude_inference.py", line 64, in initialize
    await self._load_advanced_wrappers()
  File "/mnt/c/large_project/linux_red_heart/claude_inference.py", line 177, in _load_advanced_wrappers
    'advanced_bentham': AdvancedBenthamCalculatorWrapper(),
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/advanced_analyzer_wrappers.py", line 268, in __init__
    self._register_internal_modules()
  File "/mnt/c/large_project/linux_red_heart/advanced_analyzer_wrappers.py", line 279, in _register_internal_modules
    attr = getattr(self.analyzer, attr_name, None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/advanced_bentham_calculator.py", line 1337, in context_analyzer
    self._context_analyzer = TransformerContextAnalyzer()
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/advanced_bentham_calculator.py", line 187, in __init__
    self.context_model = st_singleton.get_model("sentence-transformers/all-MiniLM-L6-v2")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/sentence_transformer_singleton.py", line 201, in get_model
    raise RuntimeError(f"SentenceTransformer 모델 로드 실패: {model_name}") from e
RuntimeError: SentenceTransformer 모델 로드 실패: sentence-transformers/all-MiniLM-L6-v2
2025-09-09 00:55:52 | ClaudeInference | ERROR | ❌ 실행 실패: SentenceTransformer 모델 로드 실패: sentence-transformers/all-MiniLM-L6-v2
Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/sentence_transformer_singleton.py", line 187, in get_model
    raise RuntimeError(f"모델 로딩 실패: {error_msg}")
RuntimeError: 모델 로딩 실패: 모델 로딩 실패: sentence-transformers/all-MiniLM-L6-v2 - 캐시된 모델을 찾을 수 없습니다: sentence-transformers/all-MiniLM-L6-v2
확인된 경로: /mnt/c/large_project/linux_red_heart/models/sentence_transformers/models--sentence-transformers--all-MiniLM-L6-v2
모델을 먼저 다운로드하거나 캐시 경로를 확인하세요.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/c/large_project/linux_red_heart/claude_inference.py", line 358, in main
    await system.initialize()
  File "/mnt/c/large_project/linux_red_heart/claude_inference.py", line 64, in initialize
    await self._load_advanced_wrappers()
  File "/mnt/c/large_project/linux_red_heart/claude_inference.py", line 177, in _load_advanced_wrappers
    'advanced_bentham': AdvancedBenthamCalculatorWrapper(),
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/advanced_analyzer_wrappers.py", line 268, in __init__
    self._register_internal_modules()
  File "/mnt/c/large_project/linux_red_heart/advanced_analyzer_wrappers.py", line 279, in _register_internal_modules
    attr = getattr(self.analyzer, attr_name, None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/advanced_bentham_calculator.py", line 1337, in context_analyzer
    self._context_analyzer = TransformerContextAnalyzer()
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/advanced_bentham_calculator.py", line 187, in __init__
    self.context_model = st_singleton.get_model("sentence-transformers/all-MiniLM-L6-v2")
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/large_project/linux_red_heart/sentence_transformer_singleton.py", line 201, in get_model
    raise RuntimeError(f"SentenceTransformer 모델 로드 실패: {model_name}") from e
RuntimeError: SentenceTransformer 모델 로드 실패: sentence-transformers/all-MiniLM-L6-v2
