#!/bin/bash
# Red Heart AI í†µí•© ì‹œìŠ¤í…œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# Unified System with Precision Mapping, Idle Learning, and Benchmarking
# 730M+ ëª¨ë¸ with ì •ë°€ ê°ì •â†’ë²¤ë‹´ ë§¤í•‘ í†µí•©

set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ

echo "ğŸš€ Red Heart AI í†µí•© ì‹œìŠ¤í…œ v2.0"
echo "==========================================="
echo "   730M+ íŒŒë¼ë¯¸í„° ëª¨ë¸"
echo "   ì •ë°€ ê°ì •â†’ë²¤ë‹´ ë§¤í•‘ ì‹œìŠ¤í…œ í†µí•©"
echo "   ìœ íœ´ ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ í¬í•¨"
echo "==========================================="

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# í•¨ìˆ˜ ì •ì˜
print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_module() {
    echo -e "${PURPLE}[MODULE]${NC} $1"
}

print_feature() {
    echo -e "${CYAN}[FEATURE]${NC} $1"
}

# í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

print_status "ì‘ì—… ë””ë ‰í† ë¦¬: $SCRIPT_DIR"

# ê°€ìƒí™˜ê²½ í™œì„±í™” í•¨ìˆ˜
activate_environment() {
    print_status "ê°€ìƒí™˜ê²½ í™•ì¸ ì¤‘..."
    
    # red_heart_env ìš°ì„  í™•ì¸
    if [ -f "red_heart_env/bin/activate" ]; then
        source red_heart_env/bin/activate
        print_success "âœ… red_heart_env ê°€ìƒí™˜ê²½ í™œì„±í™”"
        print_status "   Python: $(which python)"
        print_status "   Python ë²„ì „: $(python --version 2>&1)"
    elif [ -f "venv/bin/activate" ]; then
        source venv/bin/activate
        print_success "âœ… venv ê°€ìƒí™˜ê²½ í™œì„±í™”"
        print_status "   Python: $(which python)"
    else
        print_warning "âš ï¸ ê°€ìƒí™˜ê²½ ì—†ìŒ - ì‹œìŠ¤í…œ Python ì‚¬ìš©"
        print_warning "   ê¶Œì¥: python3 -m venv red_heart_env"
    fi
}

# í™˜ê²½ ê²€ì¦ í•¨ìˆ˜
check_environment() {
    print_status "í™˜ê²½ ê²€ì¦ ì¤‘..."
    
    # Python ë²„ì „ í™•ì¸
    python_version=$(python3 --version 2>&1 | awk '{print $2}')
    print_status "Python ë²„ì „: $python_version"
    
    # í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
    local missing_packages=()
    
    # PyTorch í™•ì¸
    if python3 -c "import torch; print(f'PyTorch {torch.__version__}')" 2>/dev/null; then
        print_success "âœ… PyTorch ì„¤ì¹˜ë¨"
        
        # GPU í™•ì¸
        if python3 -c "import torch; exit(0 if torch.cuda.is_available() else 1)" 2>/dev/null; then
            gpu_info=$(python3 -c "import torch; print(f'{torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB)')" 2>/dev/null)
            print_success "âœ… GPU ì‚¬ìš© ê°€ëŠ¥: $gpu_info"
            export DEVICE="cuda"
        else
            print_warning "âš ï¸ GPU ì—†ìŒ - CPU ëª¨ë“œë¡œ ì‹¤í–‰"
            export DEVICE="cpu"
        fi
    else
        missing_packages+=("torch")
    fi
    
    # Transformers í™•ì¸
    if python3 -c "import transformers" 2>/dev/null; then
        print_success "âœ… Transformers ì„¤ì¹˜ë¨"
    else
        missing_packages+=("transformers")
    fi
    
    # NumPy í™•ì¸ (ì •ë°€ ë§¤í•‘ì— í•„ìˆ˜)
    if python3 -c "import numpy" 2>/dev/null; then
        print_success "âœ… NumPy ì„¤ì¹˜ë¨"
    else
        missing_packages+=("numpy")
    fi
    
    # Sentence Transformers í™•ì¸ (ì„ íƒ)
    if python3 -c "import sentence_transformers" 2>/dev/null; then
        print_success "âœ… Sentence Transformers ì„¤ì¹˜ë¨"
    else
        print_warning "âš ï¸ Sentence Transformers ì—†ìŒ (ì„ íƒ ì‚¬í•­)"
    fi
    
    # ëˆ„ë½ëœ íŒ¨í‚¤ì§€ ì²˜ë¦¬
    if [ ${#missing_packages[@]} -gt 0 ]; then
        print_error "âŒ í•„ìˆ˜ íŒ¨í‚¤ì§€ ëˆ„ë½: ${missing_packages[*]}"
        print_warning "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:"
        print_warning "pip install ${missing_packages[*]}"
        return 1
    fi
    
    # ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    if [ -d "training/checkpoints_final" ]; then
        latest_checkpoint=$(ls -t training/checkpoints_final/*.pt 2>/dev/null | head -n1)
        if [ -n "$latest_checkpoint" ]; then
            print_success "âœ… ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: $(basename $latest_checkpoint)"
        else
            print_warning "âš ï¸ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ - ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ ì‚¬ìš©"
        fi
    fi
    
    return 0
}

# ëª¨ë“ˆ ìƒíƒœ ì²´í¬ í•¨ìˆ˜
check_modules() {
    print_status "í•µì‹¬ ëª¨ë“ˆ ìƒíƒœ í™•ì¸ (ì´ˆê¸° ë¡œë”© ìµœëŒ€ 60ì´ˆ)..."
    echo ""
    
    # ì¶©ë¶„í•œ ì‹œê°„ì„ ì£¼ê³  ì •í™•í•œ ì²´í¬ ìˆ˜í–‰ (NO FALLBACK)
    if [ -f "check_modules.py" ]; then
        # 60ì´ˆ íƒ€ì„ì•„ì›ƒ - ì´ˆê¸° CUDA/torch ë¡œë”©ì— ì¶©ë¶„í•œ ì‹œê°„
        timeout 60 python3 check_modules.py
        
        # ì‹¤íŒ¨í•˜ë©´ ì‹¤íŒ¨ (NO FALLBACK)
        if [ $? -ne 0 ]; then
            print_error "âŒ ëª¨ë“ˆ ì²´í¬ ì‹¤íŒ¨ - í•„ìˆ˜ ëª¨ë“ˆì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤"
            print_error "   í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:"
            print_error "   pip install numpy torch transformers"
            exit 1
        fi
    else
        print_error "âŒ check_modules.py íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"
        print_error "   ì‹œìŠ¤í…œ ë¬´ê²°ì„±ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤"
        exit 1
    fi
    
    echo ""
}

# HuggingFace ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •
setup_offline_mode() {
    export TRANSFORMERS_OFFLINE=1
    export HF_DATASETS_OFFLINE=1
    export HF_HUB_OFFLINE=1
    export TRANSFORMERS_VERBOSITY=error
    export HF_HUB_DISABLE_TELEMETRY=1
    print_status "ğŸ” HuggingFace ì˜¤í”„ë¼ì¸ ëª¨ë“œ í™œì„±í™”"
}

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
run_unified_system() {
    local mode="${1:-inference}"
    shift 2>/dev/null || true
    
    print_status "Red Heart AI í†µí•© ì‹œìŠ¤í…œ ì‹¤í–‰..."
    print_status "ì‹¤í–‰ ëª¨ë“œ: $mode"
    echo ""
    
    case "$mode" in
        # ================== ê¸°ë³¸ ì¶”ë¡  ëª¨ë“œ ==================
        "inference"|"infer")
            print_module "ğŸ¯ ì¶”ë¡  ëª¨ë“œ - 730M+ ì „ì²´ ëª¨ë¸"
            print_feature "âœ¨ ì •ë°€ ê°ì •â†’ë²¤ë‹´ ë§¤í•‘ í™œì„±í™”"
            if [ -n "$1" ]; then
                python main_unified.py --text "$@"
            else
                python main_unified.py "$@"
            fi
            ;;
            
        # ================== ëŒ€í™”í˜• ëª¨ë“œ ==================
        "interactive"|"chat")
            print_module "ğŸ’¬ ëŒ€í™”í˜• ëª¨ë“œ"
            print_feature "âœ¨ ì‹¤ì‹œê°„ ë¶„ì„ + ì •ë°€ ë§¤í•‘"
            print_status "   ì¢…ë£Œ: 'quit' ë˜ëŠ” Ctrl+C"
            python main_unified.py --mode interactive "$@"
            ;;
            
        # ================== ìš´ìš© ëª¨ë“œ ==================
        "production"|"prod")
            print_module "ğŸš€ ìš´ìš© ëª¨ë“œ"
            print_feature "âœ¨ ëª¨ë“  ìµœì í™” í™œì„±í™”"
            print_feature "âœ¨ ìœ íœ´ í•™ìŠµ ì‹œìŠ¤í…œ í™œì„±í™”"
            python main_unified.py --mode production "$@"
            ;;
            
        # ================== ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ ==================
        "benchmark"|"bench")
            print_module "ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ"
            print_feature "âœ¨ ì„±ëŠ¥ ì¸¡ì • ë° ë¹„êµ"
            
            # ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            if [ -f "benchmark_unified.py" ]; then
                python benchmark_unified.py "$@"
            else
                print_warning "ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸ ì—†ìŒ - ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
                for i in {1..5}; do
                    echo -n "   í…ŒìŠ¤íŠ¸ $i/5... "
                    time python main_unified.py --text "ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ $i" 2>&1 | tail -n1
                done
            fi
            ;;
            
        # ================== í…ŒìŠ¤íŠ¸ ëª¨ë“œ ==================
        "test")
            print_module "ğŸ§ª í†µí•© í…ŒìŠ¤íŠ¸ ëª¨ë“œ"
            print_feature "âœ¨ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ê²€ì¦"
            
            if [ -f "test_final_integration.py" ]; then
                python test_final_integration.py "$@"
            else
                python main_unified.py --text "í…ŒìŠ¤íŠ¸ ë¬¸ì¥" --verbose "$@"
            fi
            ;;
            
        # ================== ë©”ëª¨ë¦¬ ëª¨ë“œë³„ ì‹¤í–‰ ==================
        "minimal"|"light"|"normal"|"heavy"|"ultra"|"extreme")
            print_module "ğŸšï¸ ë©”ëª¨ë¦¬ ëª¨ë“œ: $mode"
            
            case "$mode" in
                "minimal")
                    print_feature "ìµœì†Œ ëª¨ë“œ - UnifiedModelë§Œ"
                    export MEMORY_MODE="minimal"
                    ;;
                "light")
                    print_feature "ê²½ëŸ‰ ëª¨ë“œ - +DSP, Kalman"
                    export MEMORY_MODE="light"
                    ;;
                "normal")
                    print_feature "ì¼ë°˜ ëª¨ë“œ - +ì •ë°€ ë§¤í¼, Phase"
                    export MEMORY_MODE="normal"
                    ;;
                "heavy")
                    print_feature "ê³ ì„±ëŠ¥ ëª¨ë“œ - +Neural Analyzers, ìœ íœ´ í•™ìŠµ"
                    export MEMORY_MODE="heavy"
                    ;;
                "ultra")
                    print_feature "ìš¸íŠ¸ë¼ ëª¨ë“œ - +Advanced Wrappers, ì‹œê³„ì—´"
                    export MEMORY_MODE="ultra"
                    ;;
                "extreme")
                    print_feature "ìµìŠ¤íŠ¸ë¦¼ ëª¨ë“œ - ëª¨ë“  ëª¨ë“ˆ + ì‹ ê²½ë§ ì–´ëŒ‘í„°"
                    export MEMORY_MODE="extreme"
                    ;;
            esac
            
            python main_unified.py --memory-mode $mode "$@"
            ;;
            
        # ================== LLM í†µí•© ëª¨ë“œ ==================
        "llm-local")
            print_module "ğŸ¤– ë¡œì»¬ LLM í†µí•© ëª¨ë“œ"
            print_feature "HelpingAI 9B + ì •ë°€ ë§¤í•‘"
            python main_unified.py --llm local "$@"
            ;;
            
        "llm-claude")
            print_module "ğŸ¤– Claude API í†µí•© ëª¨ë“œ"
            print_feature "Claude API + ìºì‹± ìµœì í™”"
            python main_unified.py --llm claude "$@"
            ;;
            
        # ================== ìœ íœ´ í•™ìŠµ ëª¨ë“œ ==================
        "idle"|"idle-learning")
            print_module "ğŸŒ™ ìœ íœ´ í•™ìŠµ ì‹œìŠ¤í…œ"
            print_feature "ê³„ì¸µì  ìœ íœ´ í•™ìŠµ í™œì„±í™”"
            python -c "
from idle_time_learner import HierarchicalIdleLearner
from main_unified import UnifiedInferenceSystem, InferenceConfig
import asyncio

async def run_idle():
    config = InferenceConfig()
    system = UnifiedInferenceSystem(config)
    await system.initialize()
    
    learner = HierarchicalIdleLearner(system.unified_model, config)
    await learner.start()
    print('ìœ íœ´ í•™ìŠµ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘... (Ctrl+Cë¡œ ì¢…ë£Œ)')
    
    try:
        await asyncio.sleep(86400)  # 24ì‹œê°„
    except KeyboardInterrupt:
        await learner.stop()
        print('ìœ íœ´ í•™ìŠµ ì¢…ë£Œ')

asyncio.run(run_idle())
" "$@"
            ;;
            
        # ================== ì •ë°€ ë§¤í•‘ í…ŒìŠ¤íŠ¸ ==================
        "mapping"|"precision")
            print_module "ğŸ¯ ì •ë°€ ë§¤í•‘ í…ŒìŠ¤íŠ¸"
            print_feature "ê°ì •â†’ë²¤ë‹´ ì˜ë¯¸ë¡ ì  ë§¤í•‘ ê²€ì¦"
            
            if [ -f "test_emotion_bentham_mapping.py" ]; then
                python test_emotion_bentham_mapping.py "$@"
            else
                print_warning "ë§¤í•‘ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì—†ìŒ"
            fi
            ;;
            
        # ================== ì‹œìŠ¤í…œ ìƒíƒœ ==================
        "status"|"info")
            print_module "ğŸ“ˆ ì‹œìŠ¤í…œ ìƒíƒœ"
            
            # GPU ìƒíƒœ
            if command -v nvidia-smi &> /dev/null; then
                print_status "GPU ìƒíƒœ:"
                nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu \
                    --format=csv,noheader,nounits | while read line; do
                    echo "      $line"
                done
            fi
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ
            print_status "ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬:"
            free -h | grep "^Mem:" | awk '{print "      ì „ì²´: "$2", ì‚¬ìš©: "$3", ì—¬ìœ : "$4}'
            
            # ëª¨ë“ˆ ì²´í¬
            check_modules
            ;;
            
        # ================== ì„¤ì • ==================
        "setup"|"install")
            print_module "ğŸ”§ í™˜ê²½ ì„¤ì •"
            
            # ê°€ìƒí™˜ê²½ ìƒì„±
            if [ ! -d "red_heart_env" ]; then
                print_status "ê°€ìƒí™˜ê²½ ìƒì„± ì¤‘..."
                python3 -m venv red_heart_env
            fi
            
            source red_heart_env/bin/activate
            
            print_status "í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì•ˆë‚´:"
            echo "      pip install numpy torch transformers"
            echo "      pip install sentence-transformers matplotlib seaborn"
            echo "      pip install pandas jinja2 markdown"
            
            print_warning "í”„ë¡œì íŠ¸ ê·œì¹™ì— ë”°ë¼ ìë™ ì„¤ì¹˜ëŠ” ë¶ˆê°€í•©ë‹ˆë‹¤."
            print_warning "ìœ„ ëª…ë ¹ì–´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
            ;;
            
        # ================== ë„ì›€ë§ ==================
        "help"|"-h"|"--help")
            show_unified_help
            ;;
            
        *)
            print_warning "ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: $mode"
            print_status "ì¶”ë¡  ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."
            python main_unified.py --text "$mode" "$@"
            ;;
    esac
}

# ë„ì›€ë§ í•¨ìˆ˜
show_unified_help() {
    echo ""
    echo "ğŸš€ Red Heart AI í†µí•© ì‹œìŠ¤í…œ ì‚¬ìš©ë²• v2.0"
    echo "========================================"
    echo ""
    echo "ê¸°ë³¸ ì‚¬ìš©ë²•:"
    echo "  $0 [ëª¨ë“œ] [ì˜µì…˜...] [--text \"ë¶„ì„í•  í…ìŠ¤íŠ¸\"]"
    echo ""
    echo "ğŸ¯ ì£¼ìš” ëª¨ë“œ:"
    echo "  inference         # ê¸°ë³¸ ì¶”ë¡  (ì •ë°€ ë§¤í•‘ í¬í•¨)"
    echo "  interactive       # ëŒ€í™”í˜• ëª¨ë“œ"
    echo "  production        # ìš´ìš© ëª¨ë“œ (ìœ íœ´ í•™ìŠµ í¬í•¨)"
    echo "  benchmark         # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"
    echo "  test             # í†µí•© í…ŒìŠ¤íŠ¸"
    echo ""
    echo "ğŸšï¸ ë©”ëª¨ë¦¬ ëª¨ë“œ:"
    echo "  minimal          # ìµœì†Œ (UnifiedModelë§Œ)"
    echo "  light            # ê²½ëŸ‰ (+DSP, Kalman)"
    echo "  normal           # ì¼ë°˜ (+ì •ë°€ ë§¤í¼)"
    echo "  heavy            # ê³ ì„±ëŠ¥ (+Neural Analyzers, ìœ íœ´ í•™ìŠµ)"
    echo "  ultra            # ìš¸íŠ¸ë¼ (+Advanced Wrappers)"
    echo "  extreme          # ìµìŠ¤íŠ¸ë¦¼ (ëª¨ë“  ëª¨ë“ˆ)"
    echo ""
    echo "âœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥:"
    echo "  mapping          # ì •ë°€ ê°ì •â†’ë²¤ë‹´ ë§¤í•‘ í…ŒìŠ¤íŠ¸"
    echo "  idle             # ìœ íœ´ í•™ìŠµ ì‹œìŠ¤í…œ ì‹¤í–‰"
    echo "  status           # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"
    echo ""
    echo "ğŸ¤– LLM í†µí•©:"
    echo "  llm-local        # ë¡œì»¬ LLM (HelpingAI)"
    echo "  llm-claude       # Claude API"
    echo ""
    echo "ğŸ’¡ ì˜ˆì‹œ:"
    echo "  $0 inference --text \"ë¶„ì„í•  í…ìŠ¤íŠ¸\""
    echo "  $0 interactive"
    echo "  $0 production --text \"í…ìŠ¤íŠ¸\" --verbose"
    echo "  $0 benchmark --samples 100"
    echo "  $0 heavy --text \"ê³ ì„±ëŠ¥ ë¶„ì„\""
    echo "  $0 mapping  # ë§¤í•‘ í…ŒìŠ¤íŠ¸"
    echo ""
    echo "ğŸ“Š ì‹œìŠ¤í…œ êµ¬ì„±:"
    echo "  - UnifiedModel: 730M"
    echo "  - ì •ë°€ ê°ì •â†’ë²¤ë‹´ ë§¤í¼ (ì˜ë¯¸ë¡ ì )"
    echo "  - ìœ íœ´ ì‹œê°„ í•™ìŠµ (5ë‹¨ê³„)"
    echo "  - ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ"
    echo "  - Neural Analyzers: 368M"
    echo "  - Advanced Wrappers: 112M"
    echo ""
    echo "ğŸ”§ ê³ ê¸‰ ì˜µì…˜:"
    echo "  --checkpoint PATH # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ"
    echo "  --batch-size N   # ë°°ì¹˜ í¬ê¸°"
    echo "  --device cuda/cpu# ë””ë°”ì´ìŠ¤ ì„ íƒ"
    echo "  --no-neural      # Neural Analyzers ë¹„í™œì„±í™”"
    echo "  --no-wrappers    # Advanced Wrappers ë¹„í™œì„±í™”"
    echo "  --no-dsp         # DSP Simulator ë¹„í™œì„±í™”"
    echo "  --llm MODE       # LLM ëª¨ë“œ"
    echo "  --verbose        # ìƒì„¸ ë¡œê·¸"
    echo "  --debug          # ë””ë²„ê·¸ ëª¨ë“œ"
    echo ""
    echo "ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ (NORMAL ëª¨ë“œ):"
    echo "  - ì§€ì—°ì‹œê°„: ~200ms"
    echo "  - ì²˜ë¦¬ëŸ‰: 5 req/s"
    echo "  - VRAM: 4.5GB"
    echo "  - ì •í™•ë„: 85%+"
    echo ""
}

# ì •ë¦¬ í•¨ìˆ˜
cleanup() {
    print_status "ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘..."
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if command -v nvidia-smi &> /dev/null; then
        python3 -c "import torch; torch.cuda.empty_cache()" 2>/dev/null || true
    fi
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    find . -name "*.pyc" -delete 2>/dev/null || true
    find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
    
    print_success "ì •ë¦¬ ì™„ë£Œ"
}

# ì‹ í˜¸ ì²˜ë¦¬
trap cleanup EXIT
trap 'print_warning "ì‹¤í–‰ ì¤‘ë‹¨ë¨"; cleanup; exit 130' INT TERM

# ë©”ì¸ ì‹¤í–‰
main() {
    local mode="${1:-help}"
    
    # ë„ì›€ë§ ìš”ì²­ ì²˜ë¦¬
    case "$mode" in
        --help|-h|help)
            show_unified_help
            exit 0
            ;;
    esac
    
    echo ""
    print_success "ğŸ¯ Red Heart AI í†µí•© ì‹œìŠ¤í…œ v2.0"
    print_status "   ì •ë°€ ê°ì •â†’ë²¤ë‹´ ë§¤í•‘ í†µí•©"
    print_status "   ìœ íœ´ ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ í¬í•¨"
    echo ""
    
    # í™˜ê²½ í™œì„±í™”
    activate_environment
    
    # í™˜ê²½ ê²€ì¦
    if ! check_environment; then
        print_error "âŒ í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨"
        print_warning "í•„ìˆ˜ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:"
        print_warning "pip install numpy torch transformers"
        exit 1
    fi
    
    echo ""
    
    # ëª¨ë“ˆ ì²´í¬
    check_modules
    
    # ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì„¤ì •
    setup_offline_mode
    
    echo "==========================================="
    echo ""
    
    # ì‹œìŠ¤í…œ ì‹¤í–‰
    run_unified_system "$@"
    
    echo ""
    print_success "ğŸ‰ Red Heart AI í†µí•© ì‹œìŠ¤í…œ ì™„ë£Œ!"
    echo ""
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main "$@"