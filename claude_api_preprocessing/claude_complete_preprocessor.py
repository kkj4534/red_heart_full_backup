#!/usr/bin/env python3
"""
Claude API ì™„ì „ ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ
data_preprocessing_pipeline_v3.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ Claude APIë¡œ êµ¬í˜„
- ê°ì • ë¶„ì„, í›„íšŒ ì§€ìˆ˜, ë²¤ë‹´ ì ìˆ˜, SURD ë©”íŠ¸ë¦­
- ì²´í¬í¬ì¸íŠ¸ ë° ì¬ê°œ ê¸°ëŠ¥
- í¬ë ˆë”§ ì†Œì§„ ê°ì§€ ë° ì²˜ë¦¬
"""

import os
import json
import time
import logging
import asyncio
import pickle
import re
import gc
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
from datetime import datetime
import anthropic
from anthropic import Anthropic, RateLimitError, APIError, AuthenticationError
from sentence_transformers import SentenceTransformer
import torch

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('Claude.CompletePreprocessor')

@dataclass
class ProcessingStats:
    """ì²˜ë¦¬ í†µê³„"""
    total_samples: int = 0
    processed: int = 0
    failed: int = 0
    retried: int = 0
    
    # í† í° ì¶”ì 
    emotion_input_tokens: int = 0
    emotion_output_tokens: int = 0
    regret_input_tokens: int = 0
    regret_output_tokens: int = 0
    bentham_input_tokens: int = 0
    bentham_output_tokens: int = 0
    surd_input_tokens: int = 0
    surd_output_tokens: int = 0
    
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    credit_exhausted: bool = False
    
    def get_total_tokens(self) -> Tuple[int, int]:
        """ì´ í† í° ìˆ˜ ë°˜í™˜"""
        total_input = (self.emotion_input_tokens + self.regret_input_tokens + 
                      self.bentham_input_tokens + self.surd_input_tokens)
        total_output = (self.emotion_output_tokens + self.regret_output_tokens + 
                       self.bentham_output_tokens + self.surd_output_tokens)
        return total_input, total_output
    
    def get_cost_estimate(self) -> float:
        """ë¹„ìš© ê³„ì‚° (USD)"""
        total_input, total_output = self.get_total_tokens()
        input_cost = (total_input / 1_000_000) * 3.0  # $3/1M
        output_cost = (total_output / 1_000_000) * 15.0  # $15/1M
        return input_cost + output_cost
    
    def get_cost_krw(self) -> float:
        """ì›í™” ë¹„ìš©"""
        return self.get_cost_estimate() * 1320  # í™˜ìœ¨ 1320ì› ê¸°ì¤€

class ClaudeCompletePreprocessor:
    """Claude API ì™„ì „ ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # API í‚¤ ë¡œë“œ
        api_key_path = Path("api_key.json")
        if not api_key_path.exists():
            raise ValueError("api_key.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        
        with open(api_key_path, 'r') as f:
            api_config = json.load(f)
        
        self.api_key = api_config.get('anthropic_api_key')
        if not self.api_key or self.api_key == "YOUR_ANTHROPIC_API_KEY_HERE":
            raise ValueError("api_key.jsonì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        # Claude í´ë¼ì´ì–¸íŠ¸
        self.client = Anthropic(api_key=self.api_key)
        
        # Sentence Transformer (ë¡œì»¬ ì„ë² ë”©ìš©)
        logger.info("Sentence Transformer ë¡œë”©...")
        self.sentence_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        
        # Rate limit ì„¤ì •
        self.rate_limit_delay = 3.5  # ì´ˆ (ë¶„ë‹¹ 17íšŒ, ì•ˆì „ ë§ˆì§„)
        self.last_request_time = 0
        
        # í†µê³„
        self.stats = ProcessingStats()
        
        # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        self.checkpoint_path = Path("checkpoint_complete.pkl")
        self.processed_ids = set()
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë“¤ (ìºì‹±ìš©)
        self.prompts = self._initialize_prompts()
    
    def _initialize_prompts(self) -> Dict[str, str]:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”"""
        return {
            'emotion': """You are an advanced emotion analysis system. Analyze emotions and return ONLY a JSON array with 7 float values (0.0-1.0) for:
[Joy, Trust, Fear, Surprise, Sadness, Disgust, Anger]

Rules:
1. Values should sum approximately to 1.0
2. Multiple emotions can coexist
3. Be nuanced - avoid 0.0 or 1.0 unless certain
4. Return ONLY the JSON array""",
            
            'regret': """Rate the regret level in this text from 0 (no regret) to 10 (extreme regret).
Consider: guilt, remorse, disappointment with past actions.
Return ONLY a single number 0-10.""",
            
            'bentham': """Analyze hedonic aspects (Bentham's felicific calculus).
Rate each 0-10:
1. Intensity: strength of happiness/pleasure
2. Duration: how long-lasting
3. Certainty: how likely/certain
4. Propinquity: how close in time

Format:
intensity: [number]
duration: [number]
certainty: [number]
propinquity: [number]""",
            
            'surd': """Analyze decision-making aspects:
1. Selection (0-10): How much choice/agency
2. Uncertainty (0-10): Level of unknown factors
3. Risk (0-10): Potential negative consequences
4. Decision (0-10): Importance of decision

Format:
selection: [number]
uncertainty: [number]
risk: [number]
decision: [number]"""
        }
    
    def load_checkpoint(self) -> Dict[str, Any]:
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        if self.checkpoint_path.exists():
            with open(self.checkpoint_path, 'rb') as f:
                checkpoint = pickle.load(f)
                self.processed_ids = checkpoint.get('processed_ids', set())
                self.stats = checkpoint.get('stats', ProcessingStats())
                logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {len(self.processed_ids)}ê°œ ì²˜ë¦¬ ì™„ë£Œ")
                
                # í¬ë ˆë”§ ì†Œì§„ ìƒíƒœ í™•ì¸
                if self.stats.credit_exhausted:
                    logger.warning("âš ï¸ ì´ì „ ì„¸ì…˜ì—ì„œ í¬ë ˆë”§ ì†Œì§„ìœ¼ë¡œ ì¤‘ë‹¨ë¨")
                    logger.info("ê³„ì†í•˜ë ¤ë©´ í¬ë ˆë”§ì„ ì¶©ì „í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                    response = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
                    if response.lower() != 'y':
                        raise SystemExit("ì‚¬ìš©ìê°€ ì¤‘ë‹¨í•¨")
                    self.stats.credit_exhausted = False
                
                return checkpoint.get('last_results', {})
        return {}
    
    def save_checkpoint(self, last_results: Dict[str, Any] = None):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'processed_ids': self.processed_ids,
            'stats': self.stats,
            'timestamp': datetime.now(),
            'last_results': last_results or {}
        }
        with open(self.checkpoint_path, 'wb') as f:
            pickle.dump(checkpoint, f)
    
    async def wait_for_rate_limit(self):
        """Rate limit ëŒ€ê¸°"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.rate_limit_delay:
            wait_time = self.rate_limit_delay - time_since_last
            await asyncio.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    async def analyze_emotion(self, text: str) -> Optional[List[float]]:
        """ê°ì • ë¶„ì„"""
        await self.wait_for_rate_limit()
        
        try:
            message = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=100,
                temperature=0.7,
                system=self.prompts['emotion'],
                messages=[{"role": "user", "content": f"Analyze: {text}"}]
            )
            
            response_text = message.content[0].text.strip()
            
            # í† í° ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸ (ì¶”ì •)
            self.stats.emotion_input_tokens += len(self.prompts['emotion'] + text) // 4
            self.stats.emotion_output_tokens += len(response_text) // 4
            
            # JSON íŒŒì‹±
            json_match = re.search(r'\[[\d\.,\s]+\]', response_text)
            if json_match:
                emotion_vector = json.loads(json_match.group())
                if len(emotion_vector) == 7:
                    # ì •ê·œí™”
                    total = sum(emotion_vector)
                    if total > 0:
                        emotion_vector = [v/total for v in emotion_vector]
                    return emotion_vector
            
            return None
            
        except AuthenticationError as e:
            logger.error("âŒ ì¸ì¦ ì‹¤íŒ¨ - API í‚¤ í™•ì¸ í•„ìš”")
            self.stats.credit_exhausted = True
            self.save_checkpoint()
            raise
            
        except Exception as e:
            if "credit" in str(e).lower() or "billing" in str(e).lower():
                logger.error("ğŸ’³ í¬ë ˆë”§ ì†Œì§„ ê°ì§€!")
                self.stats.credit_exhausted = True
                self.save_checkpoint()
                raise SystemExit("í¬ë ˆë”§ ì†Œì§„ - ì¶©ì „ í›„ ì¬ì‹¤í–‰í•˜ì„¸ìš”")
            raise
    
    async def calculate_regret(self, text: str) -> float:
        """í›„íšŒ ì§€ìˆ˜ ê³„ì‚°"""
        await self.wait_for_rate_limit()
        
        try:
            message = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=50,
                temperature=0.5,
                system=self.prompts['regret'],
                messages=[{"role": "user", "content": text}]
            )
            
            response_text = message.content[0].text.strip()
            
            # í† í° ì¹´ìš´íŠ¸
            self.stats.regret_input_tokens += len(self.prompts['regret'] + text) // 4
            self.stats.regret_output_tokens += len(response_text) // 4
            
            # ìˆ«ì ì¶”ì¶œ
            numbers = re.findall(r'\d+(?:\.\d+)?', response_text)
            if numbers:
                score = float(numbers[0])
                if 0 <= score <= 10:
                    return score / 10.0  # 0-1ë¡œ ì •ê·œí™”
            
            return 0.5  # ê¸°ë³¸ê°’
            
        except Exception as e:
            logger.error(f"í›„íšŒ ì§€ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5
    
    async def calculate_bentham(self, text: str) -> Dict[str, float]:
        """ë²¤ë‹´ ì ìˆ˜ ê³„ì‚°"""
        await self.wait_for_rate_limit()
        
        try:
            message = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=100,
                temperature=0.6,
                system=self.prompts['bentham'],
                messages=[{"role": "user", "content": text}]
            )
            
            response_text = message.content[0].text.lower()
            
            # í† í° ì¹´ìš´íŠ¸
            self.stats.bentham_input_tokens += len(self.prompts['bentham'] + text) // 4
            self.stats.bentham_output_tokens += len(response_text) // 4
            
            # íŒŒì‹±
            scores = {}
            aspects = ['intensity', 'duration', 'certainty', 'propinquity']
            
            for aspect in aspects:
                pattern = rf'{aspect}[^:]*:?\s*(\d+(?:\.\d+)?)'
                match = re.search(pattern, response_text)
                if match:
                    scores[aspect] = float(match.group(1)) / 10.0
                else:
                    scores[aspect] = 0.5
            
            return scores
            
        except Exception as e:
            logger.error(f"ë²¤ë‹´ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {'intensity': 0.5, 'duration': 0.5, 'certainty': 0.5, 'propinquity': 0.5}
    
    async def calculate_surd(self, text: str) -> Dict[str, float]:
        """SURD ë©”íŠ¸ë¦­ ê³„ì‚°"""
        await self.wait_for_rate_limit()
        
        try:
            message = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=100,
                temperature=0.6,
                system=self.prompts['surd'],
                messages=[{"role": "user", "content": text}]
            )
            
            response_text = message.content[0].text.lower()
            
            # í† í° ì¹´ìš´íŠ¸
            self.stats.surd_input_tokens += len(self.prompts['surd'] + text) // 4
            self.stats.surd_output_tokens += len(response_text) // 4
            
            # íŒŒì‹±
            scores = {}
            aspects = ['selection', 'uncertainty', 'risk', 'decision']
            
            for aspect in aspects:
                pattern = rf'{aspect}[^:]*:?\s*(\d+(?:\.\d+)?)'
                match = re.search(pattern, response_text)
                if match:
                    scores[aspect] = float(match.group(1)) / 10.0
                else:
                    scores[aspect] = 0.5
            
            return scores
            
        except Exception as e:
            logger.error(f"SURD ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {'selection': 0.5, 'uncertainty': 0.5, 'risk': 0.5, 'decision': 0.5}
    
    def generate_context_embedding(self, text: str) -> List[float]:
        """ì»¨í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ë¡œì»¬)"""
        try:
            embedding = self.sentence_model.encode(text, convert_to_numpy=True)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return [0.0] * 768  # ê¸°ë³¸ ì°¨ì›
    
    async def process_single_sample(self, sample: Dict[str, Any], retry_count: int = 0) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ìƒ˜í”Œ ì „ì²˜ë¦¬"""
        text = sample.get('text', '')
        if not text:
            return None
        
        try:
            # 1. ê°ì • ë¶„ì„
            emotions = await self.analyze_emotion(text)
            if not emotions:
                raise ValueError("ê°ì • ë¶„ì„ ì‹¤íŒ¨")
            
            # 2. í›„íšŒ ì§€ìˆ˜
            regret = await self.calculate_regret(text)
            
            # 3. ë²¤ë‹´ ì ìˆ˜
            bentham = await self.calculate_bentham(text)
            
            # 4. SURD ë©”íŠ¸ë¦­
            surd = await self.calculate_surd(text)
            
            # 5. ì»¨í…ìŠ¤íŠ¸ ì„ë² ë”© (ë¡œì»¬)
            embedding = self.generate_context_embedding(text)
            
            return {
                'id': sample.get('id', ''),
                'text': text[:500],  # ì²˜ìŒ 500ìë§Œ ì €ì¥
                'source': sample.get('type', 'unknown'),
                'emotion_vector': emotions,
                'emotion_labels': {
                    'joy': emotions[0],
                    'trust': emotions[1],
                    'fear': emotions[2],
                    'surprise': emotions[3],
                    'sadness': emotions[4],
                    'disgust': emotions[5],
                    'anger': emotions[6]
                },
                'regret_factor': regret,
                'bentham_scores': bentham,
                'surd_metrics': surd,
                'context_embedding': embedding,
                'timestamp': datetime.now().isoformat(),
                'metadata': {
                    'title': sample.get('title', ''),
                    'action': sample.get('action', ''),
                    'label': sample.get('label', ''),
                    'type': sample.get('type', '')
                }
            }
            
        except Exception as e:
            if retry_count < 3 and "rate" not in str(e).lower():
                logger.warning(f"ì¬ì‹œë„ {retry_count + 1}/3")
                await asyncio.sleep(5)
                return await self.process_single_sample(sample, retry_count + 1)
            
            logger.error(f"ìƒ˜í”Œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    async def process_batch(self, samples: List[Dict[str, Any]], output_dir: str = "."):
        """ë°°ì¹˜ ì²˜ë¦¬"""
        self.stats.total_samples = len(samples)
        self.stats.start_time = datetime.now()
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        self.load_checkpoint()
        
        # ì¶œë ¥ íŒŒì¼ ì¤€ë¹„
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        success_file = output_dir / "claude_preprocessed_complete.jsonl"
        failed_file = output_dir / "claude_failed_complete.jsonl"
        
        # ì˜ˆìƒ ë¹„ìš© ê³„ì‚°
        remaining = len(samples) - len(self.processed_ids)
        estimated_cost = remaining * 1720 * 3 / 1_000_000 + remaining * 210 * 15 / 1_000_000
        estimated_krw = estimated_cost * 1320
        estimated_time = remaining * 3.5 * 4 / 3600  # 4ê°œ API í˜¸ì¶œ
        
        logger.info(f"=== ì „ì²˜ë¦¬ ì‹œì‘ ===")
        logger.info(f"ì´ ìƒ˜í”Œ: {len(samples)}ê°œ")
        logger.info(f"ì´ë¯¸ ì²˜ë¦¬: {len(self.processed_ids)}ê°œ")
        logger.info(f"ë‚¨ì€ ìƒ˜í”Œ: {remaining}ê°œ")
        logger.info(f"ì˜ˆìƒ ë¹„ìš©: ${estimated_cost:.2f} (ì•½ {estimated_krw:,.0f}ì›)")
        logger.info(f"ì˜ˆìƒ ì‹œê°„: {estimated_time:.1f}ì‹œê°„")
        
        # ì²˜ë¦¬
        with open(success_file, 'a', encoding='utf-8') as sf, \
             open(failed_file, 'a', encoding='utf-8') as ff:
            
            for i, sample in enumerate(samples):
                sample_id = sample.get('id', str(i))
                
                # ì´ë¯¸ ì²˜ë¦¬ë¨
                if sample_id in self.processed_ids:
                    continue
                
                # ì§„í–‰ ìƒí™©
                if self.stats.processed % 10 == 0 and self.stats.processed > 0:
                    elapsed = (datetime.now() - self.stats.start_time).total_seconds()
                    speed = self.stats.processed / elapsed if elapsed > 0 else 0
                    eta = (remaining - self.stats.processed) / speed if speed > 0 else 0
                    
                    total_input, total_output = self.stats.get_total_tokens()
                    current_cost = self.stats.get_cost_estimate()
                    
                    logger.info(f"\n=== ì§„í–‰ ìƒí™© ===")
                    logger.info(f"ì²˜ë¦¬: {self.stats.processed}/{remaining} ({self.stats.processed/remaining*100:.1f}%)")
                    logger.info(f"ì†ë„: {speed*3600:.1f} samples/hour")
                    logger.info(f"ETA: {eta/3600:.1f}ì‹œê°„")
                    logger.info(f"í† í°: ì…ë ¥ {total_input:,} / ì¶œë ¥ {total_output:,}")
                    logger.info(f"í˜„ì¬ ë¹„ìš©: ${current_cost:.2f} ({current_cost*1320:,.0f}ì›)")
                
                # ì²˜ë¦¬
                try:
                    result = await self.process_single_sample(sample)
                    
                    if result:
                        # ì„±ê³µ
                        sf.write(json.dumps(result, ensure_ascii=False) + '\n')
                        sf.flush()
                        
                        self.processed_ids.add(sample_id)
                        self.stats.processed += 1
                        
                        logger.info(f"âœ… {sample_id}: ì„±ê³µ")
                    else:
                        # ì‹¤íŒ¨
                        failed_sample = {
                            'id': sample_id,
                            'text': sample.get('text', '')[:500],
                            'error': 'Processing failed',
                            'timestamp': datetime.now().isoformat()
                        }
                        ff.write(json.dumps(failed_sample, ensure_ascii=False) + '\n')
                        ff.flush()
                        
                        self.stats.failed += 1
                        logger.error(f"âŒ {sample_id}: ì‹¤íŒ¨")
                    
                except AuthenticationError:
                    logger.error("ğŸ’³ í¬ë ˆë”§ ë¬¸ì œ - ì¤‘ë‹¨")
                    self.save_checkpoint({'last_sample_id': sample_id})
                    break
                    
                except Exception as e:
                    logger.error(f"ì˜ˆì™¸ ë°œìƒ: {e}")
                    self.stats.failed += 1
                
                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (50ê°œë§ˆë‹¤)
                if self.stats.processed % 50 == 0:
                    self.save_checkpoint()
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                if i % 100 == 0:
                    gc.collect()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
        
        # ìµœì¢… í†µê³„
        self.stats.end_time = datetime.now()
        duration = (self.stats.end_time - self.stats.start_time).total_seconds()
        
        logger.info("\n=== ì²˜ë¦¬ ì™„ë£Œ ===")
        logger.info(f"ì„±ê³µ: {self.stats.processed}")
        logger.info(f"ì‹¤íŒ¨: {self.stats.failed}")
        logger.info(f"ì†Œìš” ì‹œê°„: {duration/3600:.1f}ì‹œê°„")
        logger.info(f"ì´ ë¹„ìš©: ${self.stats.get_cost_estimate():.2f} ({self.stats.get_cost_krw():,.0f}ì›)")
        
        # ìµœì¢… ì²´í¬í¬ì¸íŠ¸
        self.save_checkpoint()

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë°ì´í„° ë¡œë“œ
    input_file = Path("scruples_prepared.jsonl")
    if not input_file.exists():
        logger.error("scruples_prepared.jsonl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        logger.info("ë¨¼ì € prepare_scruples_data.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    samples = []
    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            samples.append(json.loads(line))
    
    logger.info(f"ë¡œë“œëœ ìƒ˜í”Œ: {len(samples)}ê°œ")
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    preprocessor = ClaudeCompletePreprocessor()
    
    try:
        await preprocessor.process_batch(samples)
    except KeyboardInterrupt:
        logger.info("\nì‚¬ìš©ì ì¤‘ë‹¨ - ì²´í¬í¬ì¸íŠ¸ ì €ì¥")
        preprocessor.save_checkpoint()
    except SystemExit as e:
        logger.info(f"\nì‹œìŠ¤í…œ ì¢…ë£Œ: {e}")
    except Exception as e:
        logger.error(f"\nì˜ˆì™¸ ë°œìƒ: {e}")
        preprocessor.save_checkpoint()

if __name__ == "__main__":
    asyncio.run(main())