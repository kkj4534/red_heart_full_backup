"""
í¼ì§€ ë¡œì§ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ (Fuzzy Logic Emotion-Ethics Mapper)
Fuzzy Logic Emotion-Ethics Mapping Module

ê°ì • ì „í™˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì²˜ë¦¬ì™€ ì—°ì†ì ì¸ ìœ¤ë¦¬ íŒë‹¨ì„ ìœ„í•œ í¼ì§€ ë¡œì§ ê¸°ë°˜ 
ë§¤í•‘ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì—¬ ì¸ê°„ì ì´ê³  ì§ê´€ì ì¸ ì˜ì‚¬ê²°ì •ì„ ì§€ì›í•©ë‹ˆë‹¤.

í•µì‹¬ ê¸°ëŠ¥:
1. ê°ì • ì„ê³„ì ì˜ ê²½ê³„ ëª¨í˜¸ì„± í•´ê²°
2. ì—°ì†ì  ê°ì •-ìœ¤ë¦¬ ë§¤í•‘
3. ì ì‘ì  í¼ì§€ ë©¤ë²„ì‹­ í•¨ìˆ˜
4. ì–¸ì–´ì  ë³€ìˆ˜ ê¸°ë°˜ ê°ì • í‘œí˜„
"""

import numpy as np
import torch
import logging
import json
import time
from typing import Dict, List, Any, Optional, Tuple, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import math

try:
    from config import ADVANCED_CONFIG, DEVICE
except ImportError:
    # config.pyì— ë¬¸ì œê°€ ìˆì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
    ADVANCED_CONFIG = {'enable_gpu': False}
    DEVICE = 'cpu'
    print("âš ï¸  config.py ì„í¬íŠ¸ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
from data_models import EmotionData

logger = logging.getLogger('FuzzyEmotionEthicsMapper')

class FuzzySet:
    """í¼ì§€ ì§‘í•© í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, membership_function: Callable[[float], float]):
        self.name = name
        self.membership_function = membership_function
    
    def membership(self, x: float) -> float:
        """ë©¤ë²„ì‹­ ê°’ ê³„ì‚°"""
        return np.clip(self.membership_function(x), 0.0, 1.0)

class LinguisticVariable:
    """ì–¸ì–´ì  ë³€ìˆ˜ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, universe: Tuple[float, float], fuzzy_sets: List[FuzzySet]):
        self.name = name
        self.universe = universe  # (min, max)
        self.fuzzy_sets = {fs.name: fs for fs in fuzzy_sets}
    
    def fuzzify(self, value: float) -> Dict[str, float]:
        """ê°’ì„ í¼ì§€í™”"""
        return {name: fs.membership(value) for name, fs in self.fuzzy_sets.items()}
    
    def defuzzify(self, fuzzy_values: Dict[str, float], method: str = 'centroid') -> float:
        """ì—­í¼ì§€í™”"""
        if method == 'centroid':
            return self._centroid_defuzzify(fuzzy_values)
        elif method == 'max_membership':
            return self._max_membership_defuzzify(fuzzy_values)
        else:
            raise ValueError(f"Unknown defuzzification method: {method}")
    
    def _centroid_defuzzify(self, fuzzy_values: Dict[str, float]) -> float:
        """ì¤‘ì‹¬ì  ë°©ë²•ìœ¼ë¡œ ì—­í¼ì§€í™”"""
        # ê° í¼ì§€ ì§‘í•©ì˜ ì¤‘ì‹¬ì  ì¶”ì •
        centroids = {
            'very_low': self.universe[0] + 0.1 * (self.universe[1] - self.universe[0]),
            'low': self.universe[0] + 0.3 * (self.universe[1] - self.universe[0]),
            'medium': self.universe[0] + 0.5 * (self.universe[1] - self.universe[0]),
            'high': self.universe[0] + 0.7 * (self.universe[1] - self.universe[0]),
            'very_high': self.universe[0] + 0.9 * (self.universe[1] - self.universe[0])
        }
        
        weighted_sum = 0.0
        weight_sum = 0.0
        
        for set_name, membership in fuzzy_values.items():
            if set_name in centroids and membership > 0:
                weighted_sum += centroids[set_name] * membership
                weight_sum += membership
        
        return weighted_sum / weight_sum if weight_sum > 0 else 0.5

    def _max_membership_defuzzify(self, fuzzy_values: Dict[str, float]) -> float:
        """ìµœëŒ€ ë©¤ë²„ì‹­ ë°©ë²•ìœ¼ë¡œ ì—­í¼ì§€í™”"""
        max_set = max(fuzzy_values.keys(), key=lambda k: fuzzy_values[k])
        
        # ìµœëŒ€ ë©¤ë²„ì‹­ ì§‘í•©ì˜ ëŒ€í‘œê°’ ë°˜í™˜
        set_representatives = {
            'very_low': 0.1,
            'low': 0.3,
            'medium': 0.5,
            'high': 0.7,
            'very_high': 0.9
        }
        
        return set_representatives.get(max_set, 0.5)

@dataclass
class FuzzyEmotionState:
    """í¼ì§€ ê°ì • ìƒíƒœ"""
    linguistic_representation: Dict[str, float] = field(default_factory=dict)
    numerical_values: Dict[str, float] = field(default_factory=dict)
    certainty_level: float = 0.7
    transition_momentum: float = 0.0

@dataclass
class FuzzyEthicsMapping:
    """í¼ì§€ ìœ¤ë¦¬ ë§¤í•‘ ê²°ê³¼"""
    ethics_weights: Dict[str, float] = field(default_factory=dict)
    confidence_levels: Dict[str, float] = field(default_factory=dict)
    linguistic_explanations: List[str] = field(default_factory=list)
    mapping_quality: float = 0.0

class FuzzyEmotionEthicsMapper:
    """í¼ì§€ ë¡œì§ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.logger = logger
        
        # ì–¸ì–´ì  ë³€ìˆ˜ ì •ì˜
        self.linguistic_variables = self._initialize_linguistic_variables()
        
        # í¼ì§€ ê·œì¹™ ë² ì´ìŠ¤
        self.fuzzy_rules = self._initialize_fuzzy_rules()
        
        # ê°ì • ì „í™˜ ì¶”ì 
        self.emotion_history = []
        self.transition_patterns = {}
        
        # ì ì‘ì  íŒŒë¼ë¯¸í„°
        self.adaptation_memory = {
            'successful_mappings': [],
            'failed_mappings': [],
            'user_feedback_history': []
        }
        
        # ë§¤í•‘ í†µê³„
        self.mapping_statistics = {
            'total_mappings': 0,
            'successful_mappings': 0,
            'average_confidence': 0.0,
            'average_quality': 0.0
        }
        
        self.logger.info("í¼ì§€ ë¡œì§ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_linguistic_variables(self) -> Dict[str, LinguisticVariable]:
        """ì–¸ì–´ì  ë³€ìˆ˜ ì´ˆê¸°í™”"""
        
        variables = {}
        
        # ê°ì • ê°•ë„ ë³€ìˆ˜
        emotion_intensity_sets = [
            FuzzySet('barely_felt', self._triangular_mf(0.0, 0.0, 0.3)),
            FuzzySet('noticeable', self._triangular_mf(0.1, 0.3, 0.5)),
            FuzzySet('moderate', self._triangular_mf(0.3, 0.5, 0.7)),
            FuzzySet('strong', self._triangular_mf(0.5, 0.7, 0.9)),
            FuzzySet('overwhelming', self._triangular_mf(0.7, 1.0, 1.0))
        ]
        variables['emotion_intensity'] = LinguisticVariable(
            'emotion_intensity', (0.0, 1.0), emotion_intensity_sets
        )
        
        # ìœ¤ë¦¬ì  ì¤‘ìš”ë„ ë³€ìˆ˜
        ethics_importance_sets = [
            FuzzySet('irrelevant', self._triangular_mf(0.0, 0.0, 0.25)),
            FuzzySet('somewhat_important', self._triangular_mf(0.1, 0.35, 0.6)),
            FuzzySet('important', self._triangular_mf(0.4, 0.65, 0.85)),
            FuzzySet('very_important', self._triangular_mf(0.7, 0.9, 1.0)),
            FuzzySet('critical', self._triangular_mf(0.85, 1.0, 1.0))
        ]
        variables['ethics_importance'] = LinguisticVariable(
            'ethics_importance', (0.0, 1.0), ethics_importance_sets
        )
        
        # í™•ì‹ ë„ ë³€ìˆ˜
        confidence_sets = [
            FuzzySet('very_uncertain', self._triangular_mf(0.0, 0.0, 0.3)),
            FuzzySet('uncertain', self._triangular_mf(0.1, 0.3, 0.5)),
            FuzzySet('moderate_confidence', self._triangular_mf(0.3, 0.5, 0.7)),
            FuzzySet('confident', self._triangular_mf(0.5, 0.7, 0.9)),
            FuzzySet('very_confident', self._triangular_mf(0.7, 1.0, 1.0))
        ]
        variables['confidence'] = LinguisticVariable(
            'confidence', (0.0, 1.0), confidence_sets
        )
        
        return variables
    
    def _triangular_mf(self, a: float, b: float, c: float) -> Callable[[float], float]:
        """ì‚¼ê°í˜• ë©¤ë²„ì‹­ í•¨ìˆ˜ ìƒì„±"""
        def membership(x: float) -> float:
            if x <= a or x >= c:
                return 0.0
            elif a < x <= b:
                return (x - a) / (b - a) if b != a else 1.0
            else:  # b < x < c
                return (c - x) / (c - b) if c != b else 1.0
        
        return membership
    
    def _gaussian_mf(self, mean: float, std: float) -> Callable[[float], float]:
        """ê°€ìš°ì‹œì•ˆ ë©¤ë²„ì‹­ í•¨ìˆ˜ ìƒì„±"""
        def membership(x: float) -> float:
            return math.exp(-0.5 * ((x - mean) / std) ** 2)
        
        return membership
    
    def _initialize_fuzzy_rules(self) -> List[Dict[str, Any]]:
        """í¼ì§€ ê·œì¹™ ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        
        rules = [
            # ê¸°ì¨ ê´€ë ¨ ê·œì¹™
            {
                'id': 'joy_care',
                'condition': 'IF emotion_intensity IS strong AND emotion_type IS joy',
                'conclusion': 'THEN care_harm IS very_important',
                'confidence': 0.8,
                'linguistic': "ê¸°ì  ë•ŒëŠ” íƒ€ì¸ì— ëŒ€í•œ ëŒë´„ì´ ë§¤ìš° ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤"
            },
            {
                'id': 'joy_fairness',
                'condition': 'IF emotion_intensity IS moderate AND emotion_type IS joy',
                'conclusion': 'THEN fairness IS important',
                'confidence': 0.7,
                'linguistic': "ì ë‹¹íˆ ê¸°ì  ë•ŒëŠ” ê³µì •ì„±ì„ ì¤‘ì‹œí•˜ê²Œ ë©ë‹ˆë‹¤"
            },
            
            # ìŠ¬í”” ê´€ë ¨ ê·œì¹™
            {
                'id': 'sadness_care',
                'condition': 'IF emotion_intensity IS strong AND emotion_type IS sadness',
                'conclusion': 'THEN care_harm IS critical',
                'confidence': 0.9,
                'linguistic': "ìŠ¬í”Œ ë•ŒëŠ” ëŒë´„ê³¼ í•´ì•… ë°©ì§€ê°€ ê·¹ë„ë¡œ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤"
            },
            {
                'id': 'sadness_authority',
                'condition': 'IF emotion_intensity IS moderate AND emotion_type IS sadness',
                'conclusion': 'THEN authority IS somewhat_important',
                'confidence': 0.5,
                'linguistic': "ìŠ¬í”Œ ë•ŒëŠ” ê¶Œìœ„ì— ëŒ€í•œ ê´€ì‹¬ì´ ë‚®ì•„ì§‘ë‹ˆë‹¤"
            },
            
            # ë¶„ë…¸ ê´€ë ¨ ê·œì¹™
            {
                'id': 'anger_fairness',
                'condition': 'IF emotion_intensity IS strong AND emotion_type IS anger',
                'conclusion': 'THEN fairness IS critical',
                'confidence': 0.9,
                'linguistic': "í™”ë‚  ë•ŒëŠ” ê³µì •ì„±ì´ ê·¹ë„ë¡œ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤"
            },
            {
                'id': 'anger_loyalty',
                'condition': 'IF emotion_intensity IS moderate AND emotion_type IS anger',
                'conclusion': 'THEN loyalty IS important',
                'confidence': 0.7,
                'linguistic': "í™”ë‚  ë•ŒëŠ” ì¶©ì„±ì‹¬ì„ ì¤‘ì‹œí•˜ê²Œ ë©ë‹ˆë‹¤"
            },
            
            # ë‘ë ¤ì›€ ê´€ë ¨ ê·œì¹™
            {
                'id': 'fear_authority',
                'condition': 'IF emotion_intensity IS strong AND emotion_type IS fear',
                'conclusion': 'THEN authority IS very_important',
                'confidence': 0.8,
                'linguistic': "ë‘ë ¤ìš¸ ë•ŒëŠ” ê¶Œìœ„ì™€ ì§ˆì„œë¥¼ ì¤‘ì‹œí•˜ê²Œ ë©ë‹ˆë‹¤"
            },
            {
                'id': 'fear_care',
                'condition': 'IF emotion_intensity IS overwhelming AND emotion_type IS fear',
                'conclusion': 'THEN care_harm IS critical',
                'confidence': 0.9,
                'linguistic': "ê·¹ë„ë¡œ ë‘ë ¤ìš¸ ë•ŒëŠ” ì•ˆì „ê³¼ ë³´í˜¸ê°€ ìµœìš°ì„ ì´ ë©ë‹ˆë‹¤"
            },
            
            # ì‚¬ë‘ ê´€ë ¨ ê·œì¹™
            {
                'id': 'love_care',
                'condition': 'IF emotion_intensity IS strong AND emotion_type IS love',
                'conclusion': 'THEN care_harm IS critical',
                'confidence': 0.9,
                'linguistic': "ì‚¬ë‘í•  ë•ŒëŠ” ëŒë´„ì´ ê°€ì¥ ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤"
            },
            {
                'id': 'love_loyalty',
                'condition': 'IF emotion_intensity IS moderate AND emotion_type IS love',
                'conclusion': 'THEN loyalty IS very_important',
                'confidence': 0.8,
                'linguistic': "ì‚¬ë‘í•  ë•ŒëŠ” ì¶©ì„±ì‹¬ì´ ë§¤ìš° ì¤‘ìš”í•´ì§‘ë‹ˆë‹¤"
            },
            
            # ë³µí•© ê°ì • ê·œì¹™
            {
                'id': 'mixed_balanced',
                'condition': 'IF emotion_intensity IS moderate AND emotion_certainty IS low',
                'conclusion': 'THEN ALL_ethics IS important',
                'confidence': 0.6,
                'linguistic': "ê°ì •ì´ ë³µì¡í•  ë•ŒëŠ” ëª¨ë“  ìœ¤ë¦¬ì  ê°€ì¹˜ë¥¼ ê· í˜•ìˆê²Œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤"
            }
        ]
        
        return rules
    
    def map_emotion_to_ethics(
        self,
        emotion_data: EmotionData,
        context: Dict[str, Any] = None
    ) -> FuzzyEthicsMapping:
        """ê°ì •ì„ ìœ¤ë¦¬ì  ê°€ì¤‘ì¹˜ë¡œ ë§¤í•‘"""
        
        start_time = time.time()
        
        # 1ë‹¨ê³„: ê°ì • í¼ì§€í™”
        fuzzy_emotion = self._fuzzify_emotion(emotion_data)
        
        # 2ë‹¨ê³„: í¼ì§€ ê·œì¹™ ì ìš©
        activated_rules = self._apply_fuzzy_rules(fuzzy_emotion, emotion_data, context)
        
        # 3ë‹¨ê³„: ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ì¶”ë¡ 
        ethics_weights = self._infer_ethics_weights(activated_rules)
        
        # 4ë‹¨ê³„: ì‹ ë¢°ë„ ê³„ì‚°
        confidence_levels = self._calculate_confidence_levels(activated_rules, fuzzy_emotion)
        
        # 5ë‹¨ê³„: ì–¸ì–´ì  ì„¤ëª… ìƒì„±
        linguistic_explanations = self._generate_linguistic_explanations(activated_rules)
        
        # 6ë‹¨ê³„: ë§¤í•‘ í’ˆì§ˆ í‰ê°€
        mapping_quality = self._evaluate_mapping_quality(
            fuzzy_emotion, activated_rules, ethics_weights, confidence_levels
        )
        
        # ê²°ê³¼ ìƒì„±
        mapping_result = FuzzyEthicsMapping(
            ethics_weights=ethics_weights,
            confidence_levels=confidence_levels,
            linguistic_explanations=linguistic_explanations,
            mapping_quality=mapping_quality
        )
        
        # ê°ì • íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        self._update_emotion_history(emotion_data, mapping_result)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self._update_mapping_statistics(mapping_result)
        
        processing_time = time.time() - start_time
        
        self.logger.debug(
            f"í¼ì§€ ë§¤í•‘ ì™„ë£Œ: í’ˆì§ˆ {mapping_quality:.3f}, "
            f"í™œì„± ê·œì¹™ {len(activated_rules)}ê°œ, ì²˜ë¦¬ì‹œê°„ {processing_time:.3f}ì´ˆ"
        )
        
        return mapping_result
    
    def _fuzzify_emotion(self, emotion_data: EmotionData) -> FuzzyEmotionState:
        """ê°ì • ë°ì´í„°ë¥¼ í¼ì§€í™”"""
        
        # ê°ì • ê°•ë„ ê³„ì‚° (VAD ë²¡í„°ì˜ í¬ê¸°)
        emotion_magnitude = math.sqrt(
            emotion_data.valence**2 + 
            emotion_data.arousal**2 + 
            emotion_data.dominance**2
        ) / math.sqrt(3)  # ì •ê·œí™”
        
        # ì–¸ì–´ì  í‘œí˜„ìœ¼ë¡œ ë³€í™˜
        intensity_var = self.linguistic_variables['emotion_intensity']
        linguistic_intensity = intensity_var.fuzzify(emotion_magnitude)
        
        # í™•ì‹ ë„ í¼ì§€í™”
        confidence_var = self.linguistic_variables['confidence']
        linguistic_confidence = confidence_var.fuzzify(emotion_data.confidence)
        
        # ìˆ˜ì¹˜ì  ê°’ë“¤
        numerical_values = {
            'valence': emotion_data.valence,
            'arousal': emotion_data.arousal,
            'dominance': emotion_data.dominance,
            'magnitude': emotion_magnitude,
            'confidence': emotion_data.confidence
        }
        
        # ì–¸ì–´ì  í‘œí˜„ í†µí•©
        linguistic_representation = {
            **{f"intensity_{k}": v for k, v in linguistic_intensity.items()},
            **{f"confidence_{k}": v for k, v in linguistic_confidence.items()}
        }
        
        return FuzzyEmotionState(
            linguistic_representation=linguistic_representation,
            numerical_values=numerical_values,
            certainty_level=emotion_data.confidence
        )
    
    def _apply_fuzzy_rules(
        self,
        fuzzy_emotion: FuzzyEmotionState,
        emotion_data: EmotionData,
        context: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """í¼ì§€ ê·œì¹™ ì ìš©"""
        
        activated_rules = []
        
        # ì£¼ìš” ê°ì • íƒ€ì… ê²°ì •
        emotion_type = self._determine_emotion_type(emotion_data)
        
        for rule in self.fuzzy_rules:
            # ê·œì¹™ ì¡°ê±´ í‰ê°€
            activation_level = self._evaluate_rule_condition(
                rule, fuzzy_emotion, emotion_type, context
            )
            
            if activation_level > 0.1:  # ìµœì†Œ í™œì„±í™” ì„ê³„ê°’
                activated_rule = {
                    'rule': rule,
                    'activation_level': activation_level,
                    'weighted_confidence': rule['confidence'] * activation_level
                }
                activated_rules.append(activated_rule)
        
        # í™œì„±í™” ìˆ˜ì¤€ìœ¼ë¡œ ì •ë ¬
        activated_rules.sort(key=lambda r: r['activation_level'], reverse=True)
        
        return activated_rules
    
    def _determine_emotion_type(self, emotion_data: EmotionData) -> str:
        """VAD ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ê°ì • íƒ€ì… ê²°ì •"""
        
        valence = emotion_data.valence
        arousal = emotion_data.arousal
        dominance = emotion_data.dominance
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê°ì • ë¶„ë¥˜
        if valence > 0.5:
            if arousal > 0.5:
                return 'joy' if dominance > 0.5 else 'excitement'
            else:
                return 'contentment' if dominance > 0.5 else 'love'
        elif valence < -0.3:
            if arousal > 0.5:
                return 'anger' if dominance > 0.5 else 'fear'
            else:
                return 'sadness' if dominance < 0.5 else 'disgust'
        else:
            if arousal > 0.7:
                return 'surprise'
            else:
                return 'neutral'
    
    def _evaluate_rule_condition(
        self,
        rule: Dict[str, Any],
        fuzzy_emotion: FuzzyEmotionState,
        emotion_type: str,
        context: Dict[str, Any] = None
    ) -> float:
        """ê·œì¹™ ì¡°ê±´ í‰ê°€"""
        
        activation = 0.0
        
        # ê·œì¹™ ID ê¸°ë°˜ í‰ê°€ (ê°„ë‹¨í•œ ë²„ì „)
        rule_id = rule['id']
        
        if rule_id.startswith(emotion_type):
            # ê°ì • íƒ€ì…ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
            intensity_activation = 0.0
            
            # ê°•ë„ ì¡°ê±´ í™•ì¸
            if 'strong' in rule['condition']:
                intensity_activation = fuzzy_emotion.linguistic_representation.get('intensity_strong', 0.0)
            elif 'moderate' in rule['condition']:
                intensity_activation = fuzzy_emotion.linguistic_representation.get('intensity_moderate', 0.0)
            elif 'overwhelming' in rule['condition']:
                intensity_activation = fuzzy_emotion.linguistic_representation.get('intensity_overwhelming', 0.0)
            else:
                # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ê°•ë„ ê³ ë ¤
                intensity_activation = max(
                    fuzzy_emotion.linguistic_representation.get('intensity_moderate', 0.0),
                    fuzzy_emotion.linguistic_representation.get('intensity_strong', 0.0),
                    fuzzy_emotion.linguistic_representation.get('intensity_overwhelming', 0.0)
                )
            
            activation = intensity_activation
            
        # ë³µí•© ê°ì • ê·œì¹™ ì²˜ë¦¬
        elif rule_id == 'mixed_balanced':
            # ê°ì • í™•ì‹¤ì„±ì´ ë‚®ì„ ë•Œ í™œì„±í™”
            uncertainty_activation = fuzzy_emotion.linguistic_representation.get('confidence_uncertain', 0.0)
            moderate_intensity = fuzzy_emotion.linguistic_representation.get('intensity_moderate', 0.0)
            activation = min(uncertainty_activation, moderate_intensity)
        
        # ë§¥ë½ ê¸°ë°˜ ì¡°ì •
        if context and activation > 0:
            # ìƒí™©ì  ë§¥ë½ì´ ê·œì¹™ í™œì„±í™”ì— ì˜í–¥
            situational_factor = context.get('situational_intensity', 1.0)
            activation *= situational_factor
        
        return np.clip(activation, 0.0, 1.0)
    
    def _infer_ethics_weights(self, activated_rules: List[Dict[str, Any]]) -> Dict[str, float]:
        """í™œì„±í™”ëœ ê·œì¹™ë“¤ë¡œë¶€í„° ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ì¶”ë¡ """
        
        # ìœ¤ë¦¬ ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ í•©ê³„
        ethics_weights = {
            'care_harm': 0.0,
            'fairness_cheating': 0.0,
            'loyalty_betrayal': 0.0,
            'authority_subversion': 0.0,
            'sanctity_degradation': 0.0
        }
        
        total_weights = {category: 0.0 for category in ethics_weights.keys()}
        
        for activated_rule in activated_rules:
            rule = activated_rule['rule']
            activation = activated_rule['activation_level']
            confidence = activated_rule['weighted_confidence']
            
            # ê·œì¹™ ê²°ë¡ ì—ì„œ ìœ¤ë¦¬ ì¹´í…Œê³ ë¦¬ì™€ ì¤‘ìš”ë„ ì¶”ì¶œ
            conclusion = rule['conclusion']
            
            # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì„œ í•„ìš”)
            if 'care_harm' in conclusion:
                importance = self._extract_importance_level(conclusion)
                weight_contribution = importance * activation * confidence
                ethics_weights['care_harm'] += weight_contribution
                total_weights['care_harm'] += activation * confidence
                
            elif 'fairness' in conclusion:
                importance = self._extract_importance_level(conclusion)
                weight_contribution = importance * activation * confidence
                ethics_weights['fairness_cheating'] += weight_contribution
                total_weights['fairness_cheating'] += activation * confidence
                
            elif 'loyalty' in conclusion:
                importance = self._extract_importance_level(conclusion)
                weight_contribution = importance * activation * confidence
                ethics_weights['loyalty_betrayal'] += weight_contribution
                total_weights['loyalty_betrayal'] += activation * confidence
                
            elif 'authority' in conclusion:
                importance = self._extract_importance_level(conclusion)
                weight_contribution = importance * activation * confidence
                ethics_weights['authority_subversion'] += weight_contribution
                total_weights['authority_subversion'] += activation * confidence
                
            elif 'ALL_ethics' in conclusion:
                # ëª¨ë“  ìœ¤ë¦¬ì— ê· ë“±í•˜ê²Œ ì ìš©
                importance = self._extract_importance_level(conclusion)
                weight_contribution = importance * activation * confidence / len(ethics_weights)
                for category in ethics_weights.keys():
                    ethics_weights[category] += weight_contribution
                    total_weights[category] += activation * confidence / len(ethics_weights)
        
        # ì •ê·œí™”
        for category in ethics_weights.keys():
            if total_weights[category] > 0:
                ethics_weights[category] /= total_weights[category]
            else:
                ethics_weights[category] = 0.5  # ê¸°ë³¸ê°’
            
            # ë²”ìœ„ ì œí•œ
            ethics_weights[category] = np.clip(ethics_weights[category], 0.1, 1.0)
        
        return ethics_weights
    
    def _extract_importance_level(self, conclusion: str) -> float:
        """ê²°ë¡ ì—ì„œ ì¤‘ìš”ë„ ìˆ˜ì¤€ ì¶”ì¶œ"""
        
        if 'critical' in conclusion:
            return 1.0
        elif 'very_important' in conclusion:
            return 0.9
        elif 'important' in conclusion:
            return 0.7
        elif 'somewhat_important' in conclusion:
            return 0.5
        elif 'irrelevant' in conclusion:
            return 0.1
        else:
            return 0.6  # ê¸°ë³¸ê°’
    
    def _calculate_confidence_levels(
        self,
        activated_rules: List[Dict[str, Any]],
        fuzzy_emotion: FuzzyEmotionState
    ) -> Dict[str, float]:
        """ì‹ ë¢°ë„ ìˆ˜ì¤€ ê³„ì‚°"""
        
        confidence_levels = {}
        
        # ì „ì²´ ì‹ ë¢°ë„
        if activated_rules:
            overall_confidence = np.mean([rule['weighted_confidence'] for rule in activated_rules])
        else:
            overall_confidence = 0.5
        
        confidence_levels['overall'] = overall_confidence
        
        # ê°ì • ê¸°ë°˜ ì‹ ë¢°ë„
        emotion_confidence = fuzzy_emotion.certainty_level
        confidence_levels['emotion_based'] = emotion_confidence
        
        # ê·œì¹™ í™œì„±í™” ê¸°ë°˜ ì‹ ë¢°ë„
        if activated_rules:
            max_activation = max(rule['activation_level'] for rule in activated_rules)
            activation_confidence = max_activation
        else:
            activation_confidence = 0.0
        
        confidence_levels['activation_based'] = activation_confidence
        
        # í†µí•© ì‹ ë¢°ë„
        integrated_confidence = (
            overall_confidence * 0.4 +
            emotion_confidence * 0.3 +
            activation_confidence * 0.3
        )
        
        confidence_levels['integrated'] = integrated_confidence
        
        return confidence_levels
    
    def _generate_linguistic_explanations(self, activated_rules: List[Dict[str, Any]]) -> List[str]:
        """ì–¸ì–´ì  ì„¤ëª… ìƒì„±"""
        
        explanations = []
        
        # ìƒìœ„ 3ê°œ í™œì„±í™”ëœ ê·œì¹™ì˜ ì„¤ëª… í¬í•¨
        top_rules = activated_rules[:3]
        
        for i, activated_rule in enumerate(top_rules):
            rule = activated_rule['rule']
            activation = activated_rule['activation_level']
            
            linguistic_desc = rule.get('linguistic', 'ê·œì¹™ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤')
            confidence_desc = f" (í™•ì‹ ë„: {activation:.2f})"
            
            explanations.append(f"{i+1}. {linguistic_desc}{confidence_desc}")
        
        # ì „ì²´ ìƒí™© ìš”ì•½
        if len(activated_rules) > 3:
            explanations.append(f"ì¶”ê°€ë¡œ {len(activated_rules) - 3}ê°œì˜ ê·œì¹™ì´ ë” ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if not activated_rules:
            explanations.append("í˜„ì¬ ê°ì • ìƒíƒœì—ì„œ ëª…í™•í•œ ìœ¤ë¦¬ì  ì§€ì¹¨ì„ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤.")
        
        return explanations
    
    def _evaluate_mapping_quality(
        self,
        fuzzy_emotion: FuzzyEmotionState,
        activated_rules: List[Dict[str, Any]],
        ethics_weights: Dict[str, float],
        confidence_levels: Dict[str, float]
    ) -> float:
        """ë§¤í•‘ í’ˆì§ˆ í‰ê°€"""
        
        quality_score = 0.0
        
        # 1. ê·œì¹™ í™œì„±í™” í’ˆì§ˆ (30%)
        if activated_rules:
            rule_quality = np.mean([rule['activation_level'] for rule in activated_rules])
            quality_score += rule_quality * 0.3
        
        # 2. ì‹ ë¢°ë„ í’ˆì§ˆ (25%)
        confidence_quality = confidence_levels.get('integrated', 0.5)
        quality_score += confidence_quality * 0.25
        
        # 3. ê°ì • ëª…í™•ì„± í’ˆì§ˆ (25%)
        emotion_clarity = fuzzy_emotion.certainty_level
        quality_score += emotion_clarity * 0.25
        
        # 4. ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ ê· í˜•ì„± (20%)
        weights_values = list(ethics_weights.values())
        if weights_values:
            # ê³¼ë„í•œ í¸ì¤‘ ë°©ì§€ (ì ë‹¹í•œ ë¶„ì‚° ì„ í˜¸)
            weights_std = np.std(weights_values)
            balance_score = 1.0 - min(weights_std / 0.5, 1.0)  # í‘œì¤€í¸ì°¨ê°€ 0.5ë¥¼ ë„˜ìœ¼ë©´ í˜ë„í‹°
            quality_score += balance_score * 0.2
        
        return np.clip(quality_score, 0.0, 1.0)
    
    def _update_emotion_history(self, emotion_data: EmotionData, mapping_result: FuzzyEthicsMapping):
        """ê°ì • íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸"""
        
        history_entry = {
            'timestamp': time.time(),
            'emotion': {
                'valence': emotion_data.valence,
                'arousal': emotion_data.arousal,
                'dominance': emotion_data.dominance,
                'confidence': emotion_data.confidence
            },
            'mapping_quality': mapping_result.mapping_quality,
            'ethics_weights': mapping_result.ethics_weights.copy()
        }
        
        self.emotion_history.append(history_entry)
        
        # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
        if len(self.emotion_history) > 100:
            self.emotion_history = self.emotion_history[-100:]
    
    def _update_mapping_statistics(self, mapping_result: FuzzyEthicsMapping):
        """ë§¤í•‘ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        self.mapping_statistics['total_mappings'] += 1
        
        if mapping_result.mapping_quality > 0.6:
            self.mapping_statistics['successful_mappings'] += 1
        
        # í‰ê·  ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
        total_count = self.mapping_statistics['total_mappings']
        current_avg_conf = self.mapping_statistics['average_confidence']
        new_confidence = mapping_result.confidence_levels.get('integrated', 0.5)
        new_avg_conf = (current_avg_conf * (total_count - 1) + new_confidence) / total_count
        self.mapping_statistics['average_confidence'] = new_avg_conf
        
        # í‰ê·  í’ˆì§ˆ ì—…ë°ì´íŠ¸
        current_avg_quality = self.mapping_statistics['average_quality']
        new_avg_quality = (current_avg_quality * (total_count - 1) + mapping_result.mapping_quality) / total_count
        self.mapping_statistics['average_quality'] = new_avg_quality
    
    def smooth_emotion_transition(
        self,
        current_emotion: EmotionData,
        target_emotion: EmotionData,
        transition_speed: float = 0.3
    ) -> EmotionData:
        """ê°ì • ì „í™˜ ìŠ¤ë¬´ë”©"""
        
        # í¼ì§€ ë©¤ë²„ì‹­ ê¸°ë°˜ ë¶€ë“œëŸ¬ìš´ ì „í™˜
        smoothed_valence = self._fuzzy_smooth_transition(
            current_emotion.valence, target_emotion.valence, transition_speed
        )
        
        smoothed_arousal = self._fuzzy_smooth_transition(
            current_emotion.arousal, target_emotion.arousal, transition_speed
        )
        
        smoothed_dominance = self._fuzzy_smooth_transition(
            current_emotion.dominance, target_emotion.dominance, transition_speed
        )
        
        # ì‹ ë¢°ë„ëŠ” ë” ë³´ìˆ˜ì ìœ¼ë¡œ ë³€í™”
        smoothed_confidence = self._fuzzy_smooth_transition(
            current_emotion.confidence, target_emotion.confidence, transition_speed * 0.5
        )
        
        return EmotionData(
            valence=smoothed_valence,
            arousal=smoothed_arousal,
            dominance=smoothed_dominance,
            confidence=smoothed_confidence
        )
    
    def _fuzzy_smooth_transition(self, current: float, target: float, speed: float) -> float:
        """í¼ì§€ ë©¤ë²„ì‹­ ê¸°ë°˜ ë¶€ë“œëŸ¬ìš´ ì „í™˜"""
        
        # ë³€í™”ëŸ‰ ê³„ì‚°
        difference = target - current
        
        # í¼ì§€ ë©¤ë²„ì‹­ìœ¼ë¡œ ë³€í™” ê°•ë„ ì¡°ì ˆ
        if abs(difference) < 0.1:
            # ì‘ì€ ë³€í™”: ë¶€ë“œëŸ½ê²Œ
            transition_factor = speed * 0.5
        elif abs(difference) < 0.3:
            # ì¤‘ê°„ ë³€í™”: ë³´í†µ ì†ë„
            transition_factor = speed
        else:
            # í° ë³€í™”: ë¹ ë¥´ê²Œ í•˜ì§€ë§Œ ì œí•œ
            transition_factor = speed * 1.5
        
        # ê²½ê³„ í´ë¨í•‘ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì œí•œ
        change = difference * transition_factor
        new_value = current + change
        
        return np.clip(new_value, -1.0, 1.0)
    
    def get_mapping_analytics(self) -> Dict[str, Any]:
        """ë§¤í•‘ ë¶„ì„ ì •ë³´ ë°˜í™˜"""
        
        analytics = {
            'statistics': self.mapping_statistics.copy(),
            'emotion_history_length': len(self.emotion_history),
            'fuzzy_rules_count': len(self.fuzzy_rules),
            'linguistic_variables': list(self.linguistic_variables.keys())
        }
        
        # ìµœê·¼ ê°ì • íŠ¸ë Œë“œ
        if len(self.emotion_history) >= 5:
            recent_emotions = self.emotion_history[-5:]
            analytics['recent_emotion_trend'] = {
                'avg_valence': np.mean([e['emotion']['valence'] for e in recent_emotions]),
                'avg_arousal': np.mean([e['emotion']['arousal'] for e in recent_emotions]),
                'avg_dominance': np.mean([e['emotion']['dominance'] for e in recent_emotions]),
                'avg_quality': np.mean([e['mapping_quality'] for e in recent_emotions])
            }
        
        # ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ íŠ¸ë Œë“œ
        if len(self.emotion_history) >= 3:
            recent_mappings = self.emotion_history[-3:]
            ethics_trends = {}
            
            for category in ['care_harm', 'fairness_cheating', 'loyalty_betrayal', 
                           'authority_subversion', 'sanctity_degradation']:
                values = [mapping['ethics_weights'].get(category, 0.5) for mapping in recent_mappings]
                ethics_trends[category] = {
                    'mean': np.mean(values),
                    'trend': values[-1] - values[0] if len(values) > 1 else 0.0
                }
            
            analytics['ethics_trends'] = ethics_trends
        
        return analytics


# í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ í•¨ìˆ˜
def test_fuzzy_emotion_ethics_mapper():
    """í¼ì§€ ë¡œì§ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ í…ŒìŠ¤íŠ¸"""
    print("ğŸŒŸ í¼ì§€ ë¡œì§ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ë§¤í¼ ì´ˆê¸°í™”
    mapper = FuzzyEmotionEthicsMapper()
    
    # í…ŒìŠ¤íŠ¸ ê°ì • ë°ì´í„°ë“¤
    test_emotions = [
        EmotionData(valence=0.8, arousal=0.7, dominance=0.6, confidence=0.9),  # ê¸°ì¨
        EmotionData(valence=-0.6, arousal=0.8, dominance=0.4, confidence=0.8),  # ë¶„ë…¸
        EmotionData(valence=-0.7, arousal=0.3, dominance=0.2, confidence=0.7),  # ìŠ¬í””
        EmotionData(valence=-0.3, arousal=0.9, dominance=0.2, confidence=0.6),  # ë‘ë ¤ì›€
        EmotionData(valence=0.6, arousal=0.2, dominance=0.8, confidence=0.8),   # ì‚¬ë‘
    ]
    
    emotion_names = ['ê¸°ì¨', 'ë¶„ë…¸', 'ìŠ¬í””', 'ë‘ë ¤ì›€', 'ì‚¬ë‘']
    
    print(f"í…ŒìŠ¤íŠ¸ ê°ì • ìˆ˜: {len(test_emotions)}ê°œ")
    
    # ê° ê°ì •ì— ëŒ€í•œ ë§¤í•‘ í…ŒìŠ¤íŠ¸
    for i, (emotion, name) in enumerate(zip(test_emotions, emotion_names)):
        print(f"\n--- {name} ê°ì • ë§¤í•‘ í…ŒìŠ¤íŠ¸ ---")
        print(f"VAD: ({emotion.valence:.2f}, {emotion.arousal:.2f}, {emotion.dominance:.2f})")
        
        # ë§¤í•‘ ì‹¤í–‰
        mapping_result = mapper.map_emotion_to_ethics(emotion)
        
        print(f"ğŸ“Š ë§¤í•‘ ê²°ê³¼:")
        print(f"- ë§¤í•‘ í’ˆì§ˆ: {mapping_result.mapping_quality:.3f}")
        print(f"- í†µí•© ì‹ ë¢°ë„: {mapping_result.confidence_levels.get('integrated', 0.0):.3f}")
        
        print(f"âš–ï¸ ìœ¤ë¦¬ ê°€ì¤‘ì¹˜:")
        for ethics, weight in mapping_result.ethics_weights.items():
            print(f"  â€¢ {ethics}: {weight:.3f}")
        
        print(f"ğŸ’­ ì–¸ì–´ì  ì„¤ëª…:")
        for j, explanation in enumerate(mapping_result.linguistic_explanations, 1):
            print(f"  {j}. {explanation}")
    
    # ê°ì • ì „í™˜ ìŠ¤ë¬´ë”© í…ŒìŠ¤íŠ¸
    print(f"\nğŸ”„ ê°ì • ì „í™˜ ìŠ¤ë¬´ë”© í…ŒìŠ¤íŠ¸")
    
    current_emotion = test_emotions[0]  # ê¸°ì¨
    target_emotion = test_emotions[2]   # ìŠ¬í””
    
    print(f"í˜„ì¬ ê°ì •: ê¸°ì¨ VAD({current_emotion.valence:.2f}, {current_emotion.arousal:.2f}, {current_emotion.dominance:.2f})")
    print(f"ëª©í‘œ ê°ì •: ìŠ¬í”” VAD({target_emotion.valence:.2f}, {target_emotion.arousal:.2f}, {target_emotion.dominance:.2f})")
    
    # ì—¬ëŸ¬ ë‹¨ê³„ì˜ ì „í™˜ ì‹œë®¬ë ˆì´ì…˜
    transition_emotion = current_emotion
    for step in range(5):
        transition_emotion = mapper.smooth_emotion_transition(
            transition_emotion, target_emotion, transition_speed=0.3
        )
        print(f"  ë‹¨ê³„ {step+1}: VAD({transition_emotion.valence:.2f}, {transition_emotion.arousal:.2f}, {transition_emotion.dominance:.2f})")
    
    # ë¶„ì„ ì •ë³´
    analytics = mapper.get_mapping_analytics()
    print(f"\nğŸ“ˆ ë§¤í•‘ ë¶„ì„:")
    print(f"- ì´ ë§¤í•‘ ìˆ˜: {analytics['statistics']['total_mappings']}")
    print(f"- ì„±ê³µì  ë§¤í•‘: {analytics['statistics']['successful_mappings']}")
    print(f"- í‰ê·  ì‹ ë¢°ë„: {analytics['statistics']['average_confidence']:.3f}")
    print(f"- í‰ê·  í’ˆì§ˆ: {analytics['statistics']['average_quality']:.3f}")
    print(f"- í¼ì§€ ê·œì¹™ ìˆ˜: {analytics['fuzzy_rules_count']}")
    print(f"- ì–¸ì–´ì  ë³€ìˆ˜: {', '.join(analytics['linguistic_variables'])}")
    
    if 'recent_emotion_trend' in analytics:
        trend = analytics['recent_emotion_trend']
        print(f"- ìµœê·¼ ê°ì • íŠ¸ë Œë“œ:")
        print(f"  í‰ê·  Valence: {trend['avg_valence']:.3f}")
        print(f"  í‰ê·  Arousal: {trend['avg_arousal']:.3f}")
        print(f"  í‰ê·  í’ˆì§ˆ: {trend['avg_quality']:.3f}")
    
    if 'ethics_trends' in analytics:
        print(f"- ìœ¤ë¦¬ ê°€ì¤‘ì¹˜ íŠ¸ë Œë“œ:")
        for category, trend_data in analytics['ethics_trends'].items():
            print(f"  {category}: í‰ê·  {trend_data['mean']:.3f}, ë³€í™” {trend_data['trend']:+.3f}")
    
    print("âœ… í¼ì§€ ë¡œì§ ê°ì •-ìœ¤ë¦¬ ë§¤í•‘ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    return mapper


if __name__ == "__main__":
    test_fuzzy_emotion_ethics_mapper()
