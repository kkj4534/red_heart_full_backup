"""
XAI í”¼ë“œë°± í†µí•©ê¸° (XAI Feedback Integrator)
XAI Feedback Integration Module

í•´ì„ ê°€ëŠ¥ì„±(XAI) ê²°ê³¼ë¥¼ ì‹œìŠ¤í…œ ê°œì„ ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” í”¼ë“œë°± ë£¨í”„ë¥¼ êµ¬í˜„í•˜ì—¬
ëª¨ë¸ì˜ íˆ¬ëª…ì„±ì„ í™œìš©í•œ ì§€ì†ì  í•™ìŠµê³¼ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

í•µì‹¬ ê¸°ëŠ¥:
1. XAI í•´ì„ ê²°ê³¼ì˜ êµ¬ì¡°í™”ëœ ë¶„ì„
2. í•´ì„ ê²°ê³¼ ê¸°ë°˜ ìë™ ì •ì±… ì¡°ì •
3. í”¼ë“œë°± ë£¨í”„ë¥¼ í†µí•œ ì ì§„ì  ëª¨ë¸ ê°œì„ 
4. ì‚¬ìš©ì ì´í•´ë„ ê¸°ë°˜ ì„¤ëª… í’ˆì§ˆ ìµœì í™”
"""

import numpy as np
import torch
import logging
import json
import time
from typing import Dict, List, Any, Optional, Tuple, Union, Callable
from dataclasses import dataclass, field
from collections import defaultdict, deque
from pathlib import Path
import threading

try:
    from config import ADVANCED_CONFIG, DEVICE
except ImportError:
    # config.pyì— ë¬¸ì œê°€ ìˆì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
    ADVANCED_CONFIG = {'enable_gpu': False}
    DEVICE = 'cpu'
    print("âš ï¸  config.py ì„í¬íŠ¸ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
from data_models import EmotionData

logger = logging.getLogger('XAIFeedbackIntegrator')

@dataclass
class XAIInterpretation:
    """XAI í•´ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    interpretation_id: str
    decision_id: str
    timestamp: float = field(default_factory=time.time)
    
    # íŠ¹ì„± ì¤‘ìš”ë„ (Feature Importance)
    feature_importance: Dict[str, float] = field(default_factory=dict)
    
    # ì£¼ì˜ ê°€ì¤‘ì¹˜ (Attention Weights)
    attention_weights: Dict[str, float] = field(default_factory=dict)
    
    # ë°˜ì‚¬ì‹¤ì  ì„¤ëª… (Counterfactual Explanations)
    counterfactuals: List[Dict[str, Any]] = field(default_factory=list)
    
    # ê·œì¹™ ê¸°ë°˜ ì„¤ëª… (Rule-based Explanations)
    rule_explanations: List[str] = field(default_factory=list)
    
    # ì‹ ë¢°ë„ ë° ë¶ˆí™•ì‹¤ì„±
    explanation_confidence: float = 0.7
    model_uncertainty: float = 0.3
    
    # ì‚¬ìš©ì í”¼ë“œë°±
    user_understanding: Optional[float] = None  # 0-1 (ì´í•´ë„)
    user_agreement: Optional[float] = None      # 0-1 (ë™ì˜ë„)
    explanation_quality: Optional[float] = None # 0-1 (ì„¤ëª… í’ˆì§ˆ)

@dataclass
class FeedbackAction:
    """í”¼ë“œë°± ê¸°ë°˜ ì•¡ì…˜"""
    action_type: str  # 'weight_adjustment', 'rule_modification', 'parameter_tuning'
    target_component: str  # ëŒ€ìƒ ì»´í¬ë„ŒíŠ¸
    adjustment_details: Dict[str, Any] = field(default_factory=dict)
    expected_impact: float = 0.0
    confidence: float = 0.5
    reasoning: str = ""

@dataclass
class IntegrationResult:
    """í†µí•© ê²°ê³¼"""
    interpretation: XAIInterpretation
    identified_issues: List[str] = field(default_factory=list)
    recommended_actions: List[FeedbackAction] = field(default_factory=list)
    system_improvements: Dict[str, float] = field(default_factory=dict)
    feedback_quality: float = 0.0
    integration_success: bool = False

class XAIFeedbackIntegrator:
    """XAI í”¼ë“œë°± í†µí•©ê¸°"""
    
    def __init__(self):
        self.logger = logger
        
        # í•´ì„ ê²°ê³¼ ì €ì¥ì†Œ
        self.interpretations_history = deque(maxlen=1000)
        self.feedback_actions_history = deque(maxlen=500)
        
        # í”¼ë“œë°± í†µê³„
        self.feedback_statistics = {
            'total_interpretations': 0,
            'successful_integrations': 0,
            'average_user_understanding': 0.0,
            'average_explanation_quality': 0.0,
            'improvement_rate': 0.0
        }
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì¶”ì 
        self.feature_importance_tracker = defaultdict(list)
        self.attention_patterns_tracker = defaultdict(list)
        
        # ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ë§¤í•‘
        self.component_mappings = {
            'emotion_analyzer': ['valence', 'arousal', 'dominance', 'emotion_confidence'],
            'bentham_calculator': ['intensity', 'duration', 'certainty', 'propinquity', 'fecundity', 'purity', 'extent'],
            'regret_system': ['anticipated_regret', 'regret_intensity', 'risk_aversion'],
            'ethics_policy': ['care_harm', 'fairness_cheating', 'loyalty_betrayal', 'authority_subversion'],
            'phase_controller': ['exploration_rate', 'safety_threshold', 'confidence_threshold']
        }
        
        # ê°œì„  ì„ê³„ê°’
        self.improvement_thresholds = {
            'feature_importance_change': 0.1,
            'attention_drift': 0.15,
            'user_understanding_drop': 0.2,
            'explanation_quality_drop': 0.25,
            'model_uncertainty_increase': 0.3
        }
        
        # ì ì‘ì  í•™ìŠµ íŒŒë¼ë¯¸í„°
        self.adaptation_config = {
            'learning_rate': 0.02,
            'momentum': 0.9,
            'feedback_weight': 0.7,
            'stability_factor': 0.8,
            'min_feedback_count': 3
        }
        
        self.logger.info("XAI í”¼ë“œë°± í†µí•©ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def integrate_xai_feedback(
        self, 
        interpretation: XAIInterpretation,
        system_components: Dict[str, Any]
    ) -> IntegrationResult:
        """XAI í•´ì„ ê²°ê³¼ë¥¼ ì‹œìŠ¤í…œ í”¼ë“œë°±ìœ¼ë¡œ í†µí•©"""
        
        start_time = time.time()
        
        # í•´ì„ ê²°ê³¼ ì €ì¥
        self.interpretations_history.append(interpretation)
        self.feedback_statistics['total_interpretations'] += 1
        
        # 1ë‹¨ê³„: íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
        feature_analysis = self._analyze_feature_importance(interpretation)
        
        # 2ë‹¨ê³„: ì£¼ì˜ íŒ¨í„´ ë¶„ì„
        attention_analysis = self._analyze_attention_patterns(interpretation)
        
        # 3ë‹¨ê³„: ì‚¬ìš©ì í”¼ë“œë°± ë¶„ì„
        user_feedback_analysis = self._analyze_user_feedback(interpretation)
        
        # 4ë‹¨ê³„: ì´ìƒ íŒ¨í„´ íƒì§€
        anomaly_detection = self._detect_interpretation_anomalies(interpretation)
        
        # 5ë‹¨ê³„: ê°œì„  ì•¡ì…˜ ìƒì„±
        improvement_actions = self._generate_improvement_actions(
            interpretation, feature_analysis, attention_analysis, 
            user_feedback_analysis, anomaly_detection
        )
        
        # 6ë‹¨ê³„: ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸
        system_improvements = self._apply_system_improvements(
            improvement_actions, system_components
        )
        
        # 7ë‹¨ê³„: í”¼ë“œë°± í’ˆì§ˆ í‰ê°€
        feedback_quality = self._evaluate_feedback_quality(
            interpretation, improvement_actions, system_improvements
        )
        
        # ê²°ê³¼ ìƒì„±
        result = IntegrationResult(
            interpretation=interpretation,
            identified_issues=anomaly_detection,
            recommended_actions=improvement_actions,
            system_improvements=system_improvements,
            feedback_quality=feedback_quality,
            integration_success=len(system_improvements) > 0
        )
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self._update_integration_statistics(result)
        
        # ì•¡ì…˜ íˆìŠ¤í† ë¦¬ ì €ì¥
        self.feedback_actions_history.extend(improvement_actions)
        
        processing_time = time.time() - start_time
        
        self.logger.info(
            f"XAI í”¼ë“œë°± í†µí•© ì™„ë£Œ: {len(improvement_actions)}ê°œ ì•¡ì…˜, "
            f"í’ˆì§ˆ ì ìˆ˜ {feedback_quality:.3f}, ì²˜ë¦¬ì‹œê°„ {processing_time:.3f}ì´ˆ"
        )
        
        return result
    
    def _analyze_feature_importance(self, interpretation: XAIInterpretation) -> Dict[str, Any]:
        """íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„"""
        
        analysis = {
            'high_importance_features': [],
            'low_importance_features': [],
            'importance_changes': {},
            'stability_score': 0.0
        }
        
        # í˜„ì¬ íŠ¹ì„± ì¤‘ìš”ë„
        current_importance = interpretation.feature_importance
        
        # ì¤‘ìš”ë„ë³„ íŠ¹ì„± ë¶„ë¥˜
        for feature, importance in current_importance.items():
            if importance > 0.7:
                analysis['high_importance_features'].append(feature)
            elif importance < 0.3:
                analysis['low_importance_features'].append(feature)
        
        # ê³¼ê±° ì¤‘ìš”ë„ì™€ ë¹„êµ
        for feature, importance in current_importance.items():
            if feature in self.feature_importance_tracker:
                past_importances = self.feature_importance_tracker[feature]
                if past_importances:
                    avg_past_importance = np.mean(past_importances[-10:])  # ìµœê·¼ 10ê°œ í‰ê· 
                    change = importance - avg_past_importance
                    analysis['importance_changes'][feature] = change
            
            # í˜„ì¬ ì¤‘ìš”ë„ ì €ì¥
            self.feature_importance_tracker[feature].append(importance)
        
        # ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚°
        if analysis['importance_changes']:
            changes = list(analysis['importance_changes'].values())
            stability_score = 1.0 - np.std(changes)  # ë³€í™”ëŸ‰ì˜ í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì 
            analysis['stability_score'] = max(0.0, stability_score)
        
        return analysis
    
    def _analyze_attention_patterns(self, interpretation: XAIInterpretation) -> Dict[str, Any]:
        """ì£¼ì˜ íŒ¨í„´ ë¶„ì„"""
        
        analysis = {
            'attention_focus': [],
            'attention_drift': {},
            'pattern_consistency': 0.0,
            'unexpected_patterns': []
        }
        
        current_attention = interpretation.attention_weights
        
        # ì£¼ì˜ ì§‘ì¤‘ ì˜ì—­ ì‹ë³„
        if current_attention:
            sorted_attention = sorted(current_attention.items(), key=lambda x: x[1], reverse=True)
            top_3_attention = sorted_attention[:3]
            analysis['attention_focus'] = [item[0] for item in top_3_attention]
        
        # ì£¼ì˜ íŒ¨í„´ ë³€í™” ë¶„ì„
        for component, weight in current_attention.items():
            if component in self.attention_patterns_tracker:
                past_weights = self.attention_patterns_tracker[component]
                if past_weights:
                    avg_past_weight = np.mean(past_weights[-5:])  # ìµœê·¼ 5ê°œ í‰ê· 
                    drift = weight - avg_past_weight
                    if abs(drift) > self.improvement_thresholds['attention_drift']:
                        analysis['attention_drift'][component] = drift
            
            # í˜„ì¬ ì£¼ì˜ ê°€ì¤‘ì¹˜ ì €ì¥
            self.attention_patterns_tracker[component].append(weight)
        
        # ì˜ˆìƒì¹˜ ëª»í•œ íŒ¨í„´ íƒì§€
        for component, weight in current_attention.items():
            # ì¼ë°˜ì ìœ¼ë¡œ ì¤‘ìš”í•˜ì§€ ì•Šì€ ì»´í¬ë„ŒíŠ¸ê°€ ë†’ì€ ì£¼ì˜ë¥¼ ë°›ëŠ” ê²½ìš°
            if component in ['temporal_urgency', 'external_pressure'] and weight > 0.8:
                analysis['unexpected_patterns'].append(f"ë†’ì€ ì£¼ì˜: {component} ({weight:.3f})")
        
        return analysis
    
    def _analyze_user_feedback(self, interpretation: XAIInterpretation) -> Dict[str, Any]:
        """ì‚¬ìš©ì í”¼ë“œë°± ë¶„ì„"""
        
        analysis = {
            'feedback_available': False,
            'understanding_level': 0.5,
            'agreement_level': 0.5,
            'quality_rating': 0.5,
            'improvement_needed': False
        }
        
        # ì‚¬ìš©ì í”¼ë“œë°± ì¡´ì¬ ì—¬ë¶€
        if (interpretation.user_understanding is not None or 
            interpretation.user_agreement is not None or 
            interpretation.explanation_quality is not None):
            analysis['feedback_available'] = True
        
        # í”¼ë“œë°± ê°’ ì„¤ì •
        if interpretation.user_understanding is not None:
            analysis['understanding_level'] = interpretation.user_understanding
        
        if interpretation.user_agreement is not None:
            analysis['agreement_level'] = interpretation.user_agreement
        
        if interpretation.explanation_quality is not None:
            analysis['quality_rating'] = interpretation.explanation_quality
        
        # ê°œì„  í•„ìš”ì„± íŒë‹¨
        if (analysis['understanding_level'] < 0.6 or 
            analysis['quality_rating'] < 0.6):
            analysis['improvement_needed'] = True
        
        return analysis
    
    def _detect_interpretation_anomalies(self, interpretation: XAIInterpretation) -> List[str]:
        """í•´ì„ ê²°ê³¼ ì´ìƒ íŒ¨í„´ íƒì§€"""
        
        anomalies = []
        
        # 1. íŠ¹ì„± ì¤‘ìš”ë„ ì´ìƒ
        importance_values = list(interpretation.feature_importance.values())
        if importance_values:
            if max(importance_values) < 0.3:  # ëª¨ë“  íŠ¹ì„±ì´ ë‚®ì€ ì¤‘ìš”ë„
                anomalies.append("ëª¨ë“  íŠ¹ì„±ì˜ ì¤‘ìš”ë„ê°€ ë‚®ìŒ - ëª¨ë¸ ì‹ ë¢°ì„± ê²€í†  í•„ìš”")
            
            if len([v for v in importance_values if v > 0.8]) > len(importance_values) * 0.7:
                anomalies.append("ê³¼ë„í•˜ê²Œ ë§ì€ íŠ¹ì„±ì´ ë†’ì€ ì¤‘ìš”ë„ - ê³¼ì í•© ê°€ëŠ¥ì„±")
        
        # 2. ëª¨ë¸ ë¶ˆí™•ì‹¤ì„± ì´ìƒ
        if interpretation.model_uncertainty > 0.7:
            anomalies.append("ë†’ì€ ëª¨ë¸ ë¶ˆí™•ì‹¤ì„± - ì¶”ê°€ í•™ìŠµ ë°ì´í„° í•„ìš”")
        
        # 3. ì„¤ëª… ì‹ ë¢°ë„ ì´ìƒ
        if interpretation.explanation_confidence < 0.4:
            anomalies.append("ë‚®ì€ ì„¤ëª… ì‹ ë¢°ë„ - XAI ëª¨ë¸ ê°œì„  í•„ìš”")
        
        # 4. ì‚¬ìš©ì í”¼ë“œë°± ì´ìƒ
        if (interpretation.user_understanding is not None and 
            interpretation.user_understanding < 0.3):
            anomalies.append("ì‚¬ìš©ì ì´í•´ë„ ë§¤ìš° ë‚®ìŒ - ì„¤ëª… ë°©ì‹ ì¬ê²€í†  í•„ìš”")
        
        # 5. ë°˜ì‚¬ì‹¤ì  ì„¤ëª… ë¶€ì¡±
        if len(interpretation.counterfactuals) == 0:
            anomalies.append("ë°˜ì‚¬ì‹¤ì  ì„¤ëª… ë¶€ì¡± - ëŒ€ì•ˆ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± í•„ìš”")
        
        return anomalies
    
    def _generate_improvement_actions(
        self,
        interpretation: XAIInterpretation,
        feature_analysis: Dict[str, Any],
        attention_analysis: Dict[str, Any],
        user_feedback_analysis: Dict[str, Any],
        anomalies: List[str]
    ) -> List[FeedbackAction]:
        """ê°œì„  ì•¡ì…˜ ìƒì„±"""
        
        actions = []
        
        # 1. íŠ¹ì„± ì¤‘ìš”ë„ ê¸°ë°˜ ì•¡ì…˜
        if feature_analysis['importance_changes']:
            for feature, change in feature_analysis['importance_changes'].items():
                if abs(change) > self.improvement_thresholds['feature_importance_change']:
                    component = self._map_feature_to_component(feature)
                    if component:
                        action = FeedbackAction(
                            action_type='weight_adjustment',
                            target_component=component,
                            adjustment_details={
                                'feature': feature,
                                'importance_change': change,
                                'adjustment_magnitude': min(abs(change) * 0.5, 0.1)
                            },
                            expected_impact=abs(change) * 0.3,
                            confidence=0.7,
                            reasoning=f"íŠ¹ì„± {feature}ì˜ ì¤‘ìš”ë„ê°€ {change:.3f} ë³€í™”"
                        )
                        actions.append(action)
        
        # 2. ì£¼ì˜ íŒ¨í„´ ê¸°ë°˜ ì•¡ì…˜
        if attention_analysis['attention_drift']:
            for component, drift in attention_analysis['attention_drift'].items():
                action = FeedbackAction(
                    action_type='parameter_tuning',
                    target_component=component,
                    adjustment_details={
                        'attention_drift': drift,
                        'tuning_direction': 'increase' if drift < 0 else 'decrease',
                        'tuning_magnitude': min(abs(drift) * 0.3, 0.05)
                    },
                    expected_impact=abs(drift) * 0.2,
                    confidence=0.6,
                    reasoning=f"ì£¼ì˜ íŒ¨í„´ì´ {drift:.3f} ë³€í™”í•œ {component} ì¡°ì •"
                )
                actions.append(action)
        
        # 3. ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ì•¡ì…˜
        if user_feedback_analysis['improvement_needed']:
            if user_feedback_analysis['understanding_level'] < 0.6:
                action = FeedbackAction(
                    action_type='rule_modification',
                    target_component='explanation_generator',
                    adjustment_details={
                        'understanding_level': user_feedback_analysis['understanding_level'],
                        'modification_type': 'simplify_explanations',
                        'complexity_reduction': 0.3
                    },
                    expected_impact=0.4,
                    confidence=0.8,
                    reasoning="ì‚¬ìš©ì ì´í•´ë„ í–¥ìƒì„ ìœ„í•œ ì„¤ëª… ë‹¨ìˆœí™”"
                )
                actions.append(action)
            
            if user_feedback_analysis['quality_rating'] < 0.6:
                action = FeedbackAction(
                    action_type='rule_modification',
                    target_component='explanation_generator',
                    adjustment_details={
                        'quality_rating': user_feedback_analysis['quality_rating'],
                        'modification_type': 'enhance_detail',
                        'detail_enhancement': 0.4
                    },
                    expected_impact=0.3,
                    confidence=0.7,
                    reasoning="ì„¤ëª… í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ìƒì„¸ë„ ì¦ê°€"
                )
                actions.append(action)
        
        # 4. ì´ìƒ íŒ¨í„´ ê¸°ë°˜ ì•¡ì…˜
        for anomaly in anomalies:
            if "ëª¨ë“  íŠ¹ì„±ì˜ ì¤‘ìš”ë„ê°€ ë‚®ìŒ" in anomaly:
                action = FeedbackAction(
                    action_type='parameter_tuning',
                    target_component='feature_selector',
                    adjustment_details={
                        'tuning_type': 'feature_selection_threshold',
                        'threshold_adjustment': -0.1
                    },
                    expected_impact=0.5,
                    confidence=0.6,
                    reasoning="íŠ¹ì„± ì„ íƒ ì„ê³„ê°’ ì¡°ì •ìœ¼ë¡œ ë” ë§ì€ íŠ¹ì„± í™œìš©"
                )
                actions.append(action)
            
            elif "ë†’ì€ ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±" in anomaly:
                action = FeedbackAction(
                    action_type='parameter_tuning',
                    target_component='uncertainty_estimator',
                    adjustment_details={
                        'tuning_type': 'confidence_calibration',
                        'calibration_strength': 0.2
                    },
                    expected_impact=0.4,
                    confidence=0.5,
                    reasoning="ë¶ˆí™•ì‹¤ì„± ì¶”ì • ëª¨ë¸ ë³´ì •"
                )
                actions.append(action)
        
        return actions
    
    def _map_feature_to_component(self, feature: str) -> Optional[str]:
        """íŠ¹ì„±ì„ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ì— ë§¤í•‘"""
        
        for component, features in self.component_mappings.items():
            if feature in features:
                return component
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤í•‘
        if any(keyword in feature.lower() for keyword in ['emotion', 'feeling', 'sentiment']):
            return 'emotion_analyzer'
        elif any(keyword in feature.lower() for keyword in ['bentham', 'pleasure', 'pain', 'utility']):
            return 'bentham_calculator'
        elif any(keyword in feature.lower() for keyword in ['regret', 'counterfactual']):
            return 'regret_system'
        elif any(keyword in feature.lower() for keyword in ['ethics', 'moral', 'fairness']):
            return 'ethics_policy'
        elif any(keyword in feature.lower() for keyword in ['phase', 'exploration', 'execution']):
            return 'phase_controller'
        
        return None
    
    def _apply_system_improvements(
        self,
        actions: List[FeedbackAction],
        system_components: Dict[str, Any]
    ) -> Dict[str, float]:
        """ì‹œìŠ¤í…œ ê°œì„  ì ìš©"""
        
        improvements = {}
        
        for action in actions:
            component_name = action.target_component
            
            if component_name in system_components:
                component = system_components[component_name]
                
                try:
                    # ê°€ì¤‘ì¹˜ ì¡°ì • ì•¡ì…˜
                    if action.action_type == 'weight_adjustment':
                        improvement = self._apply_weight_adjustment(component, action)
                        if improvement > 0:
                            improvements[f"{component_name}_weight_adjustment"] = improvement
                    
                    # íŒŒë¼ë¯¸í„° íŠœë‹ ì•¡ì…˜
                    elif action.action_type == 'parameter_tuning':
                        improvement = self._apply_parameter_tuning(component, action)
                        if improvement > 0:
                            improvements[f"{component_name}_parameter_tuning"] = improvement
                    
                    # ê·œì¹™ ìˆ˜ì • ì•¡ì…˜
                    elif action.action_type == 'rule_modification':
                        improvement = self._apply_rule_modification(component, action)
                        if improvement > 0:
                            improvements[f"{component_name}_rule_modification"] = improvement
                
                except Exception as e:
                    self.logger.warning(f"ì•¡ì…˜ ì ìš© ì‹¤íŒ¨ ({component_name}): {e}")
                    continue
        
        return improvements
    
    def _apply_weight_adjustment(self, component: Any, action: FeedbackAction) -> float:
        """ê°€ì¤‘ì¹˜ ì¡°ì • ì ìš©"""
        
        details = action.adjustment_details
        
        # ì»´í¬ë„ŒíŠ¸ì— adjust_weights ë©”ì„œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        if hasattr(component, 'adjust_weights'):
            try:
                adjustment_result = component.adjust_weights(
                    feature=details.get('feature'),
                    magnitude=details.get('adjustment_magnitude', 0.05)
                )
                return action.expected_impact
            except Exception as e:
                self.logger.warning(f"ê°€ì¤‘ì¹˜ ì¡°ì • ì‹¤íŒ¨: {e}")
                return 0.0
        
        # ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¡°ì • ì‹œë„
        elif hasattr(component, 'config') and isinstance(component.config, dict):
            feature = details.get('feature')
            magnitude = details.get('adjustment_magnitude', 0.05)
            
            if feature in component.config:
                old_value = component.config[feature]
                component.config[feature] = np.clip(old_value + magnitude, 0.0, 1.0)
                return action.expected_impact * 0.7
        
        return 0.0
    
    def _apply_parameter_tuning(self, component: Any, action: FeedbackAction) -> float:
        """íŒŒë¼ë¯¸í„° íŠœë‹ ì ìš©"""
        
        details = action.adjustment_details
        
        # ì»´í¬ë„ŒíŠ¸ì— tune_parameters ë©”ì„œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        if hasattr(component, 'tune_parameters'):
            try:
                tuning_result = component.tune_parameters(
                    tuning_type=details.get('tuning_type'),
                    magnitude=details.get('tuning_magnitude', 0.05)
                )
                return action.expected_impact
            except Exception as e:
                self.logger.warning(f"íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤íŒ¨: {e}")
                return 0.0
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì¡°ì •
        elif hasattr(component, 'learning_config') and isinstance(component.learning_config, dict):
            tuning_type = details.get('tuning_type')
            magnitude = details.get('tuning_magnitude', 0.05)
            
            if tuning_type == 'learning_rate' and 'learning_rate' in component.learning_config:
                old_lr = component.learning_config['learning_rate']
                component.learning_config['learning_rate'] = np.clip(old_lr * (1 + magnitude), 0.001, 0.1)
                return action.expected_impact * 0.5
        
        return 0.0
    
    def _apply_rule_modification(self, component: Any, action: FeedbackAction) -> float:
        """ê·œì¹™ ìˆ˜ì • ì ìš©"""
        
        details = action.adjustment_details
        
        # ì»´í¬ë„ŒíŠ¸ì— modify_rules ë©”ì„œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
        if hasattr(component, 'modify_rules'):
            try:
                modification_result = component.modify_rules(
                    modification_type=details.get('modification_type'),
                    parameters=details
                )
                return action.expected_impact
            except Exception as e:
                self.logger.warning(f"ê·œì¹™ ìˆ˜ì • ì‹¤íŒ¨: {e}")
                return 0.0
        
        # ì„¤ëª… ìƒì„±ê¸° íŠ¹ë³„ ì²˜ë¦¬
        elif hasattr(component, 'explanation_config'):
            mod_type = details.get('modification_type')
            
            if mod_type == 'simplify_explanations':
                component.explanation_config['complexity_level'] = max(
                    component.explanation_config.get('complexity_level', 0.5) - 0.2, 0.1
                )
                return action.expected_impact * 0.6
            
            elif mod_type == 'enhance_detail':
                component.explanation_config['detail_level'] = min(
                    component.explanation_config.get('detail_level', 0.5) + 0.2, 1.0
                )
                return action.expected_impact * 0.6
        
        return 0.0
    
    def _evaluate_feedback_quality(
        self,
        interpretation: XAIInterpretation,
        actions: List[FeedbackAction],
        improvements: Dict[str, float]
    ) -> float:
        """í”¼ë“œë°± í’ˆì§ˆ í‰ê°€"""
        
        quality_score = 0.0
        
        # 1. í•´ì„ ê²°ê³¼ í’ˆì§ˆ (30%)
        interpretation_quality = (
            interpretation.explanation_confidence * 0.5 +
            (1.0 - interpretation.model_uncertainty) * 0.5
        )
        quality_score += interpretation_quality * 0.3
        
        # 2. ì•¡ì…˜ í’ˆì§ˆ (40%)
        if actions:
            action_confidence = np.mean([action.confidence for action in actions])
            action_impact = np.mean([action.expected_impact for action in actions])
            action_quality = (action_confidence + action_impact) / 2.0
            quality_score += action_quality * 0.4
        else:
            quality_score += 0.2  # ì•¡ì…˜ì´ ì—†ì–´ë„ ìµœì†Œ ì ìˆ˜
        
        # 3. ê°œì„  íš¨ê³¼ (30%)
        if improvements:
            improvement_quality = min(np.mean(list(improvements.values())), 1.0)
            quality_score += improvement_quality * 0.3
        
        return np.clip(quality_score, 0.0, 1.0)
    
    def _update_integration_statistics(self, result: IntegrationResult):
        """í†µí•© í†µê³„ ì—…ë°ì´íŠ¸"""
        
        if result.integration_success:
            self.feedback_statistics['successful_integrations'] += 1
        
        # ì‚¬ìš©ì ì´í•´ë„ ì—…ë°ì´íŠ¸
        if result.interpretation.user_understanding is not None:
            current_understanding = self.feedback_statistics['average_user_understanding']
            total_count = self.feedback_statistics['total_interpretations']
            new_understanding = (
                current_understanding * (total_count - 1) + result.interpretation.user_understanding
            ) / total_count
            self.feedback_statistics['average_user_understanding'] = new_understanding
        
        # ì„¤ëª… í’ˆì§ˆ ì—…ë°ì´íŠ¸
        if result.interpretation.explanation_quality is not None:
            current_quality = self.feedback_statistics['average_explanation_quality']
            total_count = self.feedback_statistics['total_interpretations']
            new_quality = (
                current_quality * (total_count - 1) + result.interpretation.explanation_quality
            ) / total_count
            self.feedback_statistics['average_explanation_quality'] = new_quality
        
        # ê°œì„ ë¥  ì—…ë°ì´íŠ¸
        if result.system_improvements:
            improvement_count = len(result.system_improvements)
            self.feedback_statistics['improvement_rate'] = (
                self.feedback_statistics['successful_integrations'] / 
                max(self.feedback_statistics['total_interpretations'], 1)
            )
    
    def get_feedback_analytics(self) -> Dict[str, Any]:
        """í”¼ë“œë°± ë¶„ì„ ì •ë³´ ë°˜í™˜"""
        
        return {
            'statistics': self.feedback_statistics.copy(),
            'recent_interpretations': len(self.interpretations_history),
            'recent_actions': len(self.feedback_actions_history),
            'feature_importance_trends': {
                feature: np.mean(values[-10:]) if values else 0.0
                for feature, values in self.feature_importance_tracker.items()
            },
            'attention_patterns_trends': {
                component: np.mean(values[-5:]) if values else 0.0
                for component, values in self.attention_patterns_tracker.items()
            },
            'top_improvement_areas': self._identify_top_improvement_areas(),
            'system_stability': self._calculate_system_stability()
        }
    
    def _identify_top_improvement_areas(self) -> List[str]:
        """ì£¼ìš” ê°œì„  ì˜ì—­ ì‹ë³„"""
        
        improvement_areas = []
        
        # ìµœê·¼ ì•¡ì…˜ë“¤ ë¶„ì„
        recent_actions = list(self.feedback_actions_history)[-20:]  # ìµœê·¼ 20ê°œ
        
        # ì•¡ì…˜ íƒ€ì…ë³„ ë¹ˆë„
        action_type_counts = defaultdict(int)
        target_component_counts = defaultdict(int)
        
        for action in recent_actions:
            action_type_counts[action.action_type] += 1
            target_component_counts[action.target_component] += 1
        
        # ê°€ì¥ ë¹ˆë²ˆí•œ ì•¡ì…˜ íƒ€ì…
        if action_type_counts:
            top_action_type = max(action_type_counts.keys(), key=lambda k: action_type_counts[k])
            improvement_areas.append(f"ì£¼ìš” ì•¡ì…˜ íƒ€ì…: {top_action_type}")
        
        # ê°€ì¥ ë¬¸ì œê°€ ë§ì€ ì»´í¬ë„ŒíŠ¸
        if target_component_counts:
            top_problem_component = max(target_component_counts.keys(), key=lambda k: target_component_counts[k])
            improvement_areas.append(f"ê°œì„  í•„ìš” ì»´í¬ë„ŒíŠ¸: {top_problem_component}")
        
        # ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ê°œì„  ì˜ì—­
        if self.feedback_statistics['average_user_understanding'] < 0.7:
            improvement_areas.append("ì„¤ëª… ì´í•´ë„ í–¥ìƒ í•„ìš”")
        
        if self.feedback_statistics['average_explanation_quality'] < 0.7:
            improvement_areas.append("ì„¤ëª… í’ˆì§ˆ í–¥ìƒ í•„ìš”")
        
        return improvement_areas
    
    def _calculate_system_stability(self) -> float:
        """ì‹œìŠ¤í…œ ì•ˆì •ì„± ê³„ì‚°"""
        
        if len(self.interpretations_history) < 5:
            return 0.5  # ë°ì´í„° ë¶€ì¡±
        
        # ìµœê·¼ í•´ì„ ê²°ê³¼ë“¤ì˜ ì¼ê´€ì„± ë¶„ì„
        recent_interpretations = list(self.interpretations_history)[-10:]
        
        # ì„¤ëª… ì‹ ë¢°ë„ì˜ ì¼ê´€ì„±
        confidence_scores = [interp.explanation_confidence for interp in recent_interpretations]
        confidence_stability = 1.0 - np.std(confidence_scores)
        
        # ëª¨ë¸ ë¶ˆí™•ì‹¤ì„±ì˜ ì¼ê´€ì„±
        uncertainty_scores = [interp.model_uncertainty for interp in recent_interpretations]
        uncertainty_stability = 1.0 - np.std(uncertainty_scores)
        
        # ì „ì²´ ì•ˆì •ì„± ì ìˆ˜
        stability_score = (confidence_stability + uncertainty_stability) / 2.0
        
        return np.clip(stability_score, 0.0, 1.0)
    
    def save_feedback_state(self, filepath: str):
        """í”¼ë“œë°± ìƒíƒœ ì €ì¥"""
        
        state_data = {
            'feedback_statistics': self.feedback_statistics,
            'interpretations_count': len(self.interpretations_history),
            'actions_count': len(self.feedback_actions_history),
            'feature_importance_summary': {
                feature: {
                    'mean': float(np.mean(values)) if values else 0.0,
                    'std': float(np.std(values)) if values else 0.0,
                    'count': len(values)
                }
                for feature, values in self.feature_importance_tracker.items()
            },
            'attention_patterns_summary': {
                component: {
                    'mean': float(np.mean(values)) if values else 0.0,
                    'std': float(np.std(values)) if values else 0.0,
                    'count': len(values)
                }
                for component, values in self.attention_patterns_tracker.items()
            },
            'analytics': self.get_feedback_analytics()
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(state_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"XAI í”¼ë“œë°± ìƒíƒœë¥¼ {filepath}ì— ì €ì¥ ì™„ë£Œ")


# í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ í•¨ìˆ˜
def test_xai_feedback_integrator():
    """XAI í”¼ë“œë°± í†µí•©ê¸° í…ŒìŠ¤íŠ¸"""
    print("ğŸ” XAI í”¼ë“œë°± í†µí•©ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í†µí•©ê¸° ì´ˆê¸°í™”
    integrator = XAIFeedbackIntegrator()
    
    # í…ŒìŠ¤íŠ¸ í•´ì„ ê²°ê³¼ ìƒì„±
    test_interpretation = XAIInterpretation(
        interpretation_id="test_interp_1",
        decision_id="decision_123",
        feature_importance={
            'valence': 0.8,
            'arousal': 0.6,
            'intensity': 0.9,
            'care_harm': 0.7,
            'fairness_cheating': 0.4
        },
        attention_weights={
            'emotion_analyzer': 0.7,
            'bentham_calculator': 0.8,
            'ethics_policy': 0.6,
            'regret_system': 0.3
        },
        counterfactuals=[
            {'scenario': 'if valence was higher', 'probability': 0.8},
            {'scenario': 'if intensity was lower', 'probability': 0.6}
        ],
        rule_explanations=[
            "ë†’ì€ ê°ì • ê°•ë„ë¡œ ì¸í•œ ê²°ì •",
            "ëŒë´„-í•´ì•… ì›ì¹™ì´ ì£¼ìš” ì˜í–¥"
        ],
        explanation_confidence=0.75,
        model_uncertainty=0.25,
        user_understanding=0.6,
        user_agreement=0.8,
        explanation_quality=0.7
    )
    
    # ê°€ìƒì˜ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸
    mock_components = {
        'emotion_analyzer': type('MockComponent', (), {
            'config': {'valence_weight': 0.8, 'arousal_weight': 0.6},
            'adjust_weights': lambda self, feature, magnitude: True
        })(),
        'bentham_calculator': type('MockComponent', (), {
            'learning_config': {'learning_rate': 0.01},
            'tune_parameters': lambda self, tuning_type, magnitude: True
        })(),
        'explanation_generator': type('MockComponent', (), {
            'explanation_config': {'complexity_level': 0.7, 'detail_level': 0.6},
            'modify_rules': lambda self, modification_type, parameters: True
        })()
    }
    
    print(f"í•´ì„ ê²°ê³¼ ìƒì„± ì™„ë£Œ:")
    print(f"- íŠ¹ì„± ì¤‘ìš”ë„: {len(test_interpretation.feature_importance)}ê°œ")
    print(f"- ì£¼ì˜ ê°€ì¤‘ì¹˜: {len(test_interpretation.attention_weights)}ê°œ")
    print(f"- ë°˜ì‚¬ì‹¤ì  ì„¤ëª…: {len(test_interpretation.counterfactuals)}ê°œ")
    print(f"- ì‚¬ìš©ì ì´í•´ë„: {test_interpretation.user_understanding:.3f}")
    
    # í”¼ë“œë°± í†µí•© ì‹¤í–‰
    result = integrator.integrate_xai_feedback(test_interpretation, mock_components)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š í”¼ë“œë°± í†µí•© ê²°ê³¼:")
    print(f"- í†µí•© ì„±ê³µ: {'ì˜ˆ' if result.integration_success else 'ì•„ë‹ˆì˜¤'}")
    print(f"- íƒì§€ëœ ì´ìŠˆ: {len(result.identified_issues)}ê°œ")
    print(f"- ê¶Œì¥ ì•¡ì…˜: {len(result.recommended_actions)}ê°œ")
    print(f"- ì‹œìŠ¤í…œ ê°œì„ : {len(result.system_improvements)}ê°œ")
    print(f"- í”¼ë“œë°± í’ˆì§ˆ: {result.feedback_quality:.3f}")
    
    if result.identified_issues:
        print(f"\nâš ï¸ íƒì§€ëœ ì´ìŠˆë“¤:")
        for i, issue in enumerate(result.identified_issues, 1):
            print(f"  {i}. {issue}")
    
    if result.recommended_actions:
        print(f"\nğŸ”§ ê¶Œì¥ ì•¡ì…˜ë“¤:")
        for i, action in enumerate(result.recommended_actions, 1):
            print(f"  {i}. {action.action_type} -> {action.target_component}")
            print(f"     ì˜ˆìƒ ì˜í–¥: {action.expected_impact:.3f}, ì‹ ë¢°ë„: {action.confidence:.3f}")
            print(f"     ì´ìœ : {action.reasoning}")
    
    if result.system_improvements:
        print(f"\nğŸ“ˆ ì‹œìŠ¤í…œ ê°œì„ ë“¤:")
        for improvement, value in result.system_improvements.items():
            print(f"  - {improvement}: {value:.3f}")
    
    # ì¶”ê°€ í•´ì„ ê²°ê³¼ë¡œ í…ŒìŠ¤íŠ¸ (ì‹œê°„ì— ë”°ë¥¸ ë³€í™” ì‹œë®¬ë ˆì´ì…˜)
    print(f"\nğŸ”„ ì‹œê°„ì— ë”°ë¥¸ ë³€í™” ì‹œë®¬ë ˆì´ì…˜")
    
    for i in range(3):
        # ë³€í™”ëœ í•´ì„ ê²°ê³¼ ìƒì„±
        modified_interpretation = XAIInterpretation(
            interpretation_id=f"test_interp_{i+2}",
            decision_id=f"decision_{i+124}",
            feature_importance={
                'valence': 0.8 + (i * 0.1),
                'arousal': 0.6 - (i * 0.05),
                'intensity': 0.9 - (i * 0.1),
                'care_harm': 0.7 + (i * 0.08),
                'fairness_cheating': 0.4 + (i * 0.15)
            },
            attention_weights={
                'emotion_analyzer': 0.7 - (i * 0.1),
                'bentham_calculator': 0.8 + (i * 0.05),
                'ethics_policy': 0.6 + (i * 0.1),
                'regret_system': 0.3 + (i * 0.2)
            },
            explanation_confidence=0.75 - (i * 0.1),
            model_uncertainty=0.25 + (i * 0.1),
            user_understanding=0.6 + (i * 0.1),
            explanation_quality=0.7 + (i * 0.05)
        )
        
        # í†µí•© ì‹¤í–‰
        iter_result = integrator.integrate_xai_feedback(modified_interpretation, mock_components)
        print(f"  ë°˜ë³µ {i+1}: ì•¡ì…˜ {len(iter_result.recommended_actions)}ê°œ, "
              f"í’ˆì§ˆ {iter_result.feedback_quality:.3f}")
    
    # ë¶„ì„ ì •ë³´
    analytics = integrator.get_feedback_analytics()
    print(f"\nğŸ“ˆ í”¼ë“œë°± ë¶„ì„:")
    print(f"- ì´ í•´ì„ ìˆ˜: {analytics['statistics']['total_interpretations']}")
    print(f"- ì„±ê³µì  í†µí•©: {analytics['statistics']['successful_integrations']}")
    print(f"- í‰ê·  ì‚¬ìš©ì ì´í•´ë„: {analytics['statistics']['average_user_understanding']:.3f}")
    print(f"- í‰ê·  ì„¤ëª… í’ˆì§ˆ: {analytics['statistics']['average_explanation_quality']:.3f}")
    print(f"- ì‹œìŠ¤í…œ ì•ˆì •ì„±: {analytics['system_stability']:.3f}")
    
    if analytics['top_improvement_areas']:
        print(f"- ì£¼ìš” ê°œì„  ì˜ì—­:")
        for area in analytics['top_improvement_areas']:
            print(f"  â€¢ {area}")
    
    print("âœ… XAI í”¼ë“œë°± í†µí•©ê¸° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    return integrator, result


if __name__ == "__main__":
    test_xai_feedback_integrator()
