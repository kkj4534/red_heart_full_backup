"""
ì›Œí¬í”Œë¡œìš° ì¸ì‹ ë©”ëª¨ë¦¬ ê´€ë¦¬ì - Red Heart AI
Workflow-Aware Memory Manager for Red Heart AI

ì¤‘ìš”í•œ ì›Œí¬í”Œë¡œìš°ì˜ ì—°ê³„ì„±ì„ ì´í•´í•˜ê³  ë³´í˜¸í•˜ëŠ” ì§€ëŠ¥ì  ë©”ëª¨ë¦¬ ê´€ë¦¬
"""

import torch
import torch.nn as nn
from typing import Dict, List, Set, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
import asyncio
import logging
from datetime import datetime
import weakref
from collections import defaultdict, deque
import gc
import time

logger = logging.getLogger(__name__)

class WorkflowStage(Enum):
    """ì›Œí¬í”Œë¡œìš° ë‹¨ê³„"""
    INITIALIZATION = "initialization"
    DATA_LOADING = "data_loading"
    BACKBONE_FORWARD = "backbone_forward"
    HEAD_PROCESSING = "head_processing"
    SYNERGY_COMPUTATION = "synergy_computation"
    LOSS_COMPUTATION = "loss_computation"
    BACKWARD_PASS = "backward_pass"
    OPTIMIZATION = "optimization"
    EVALUATION = "evaluation"
    FINALIZATION = "finalization"

class TaskDependency:
    """íƒœìŠ¤í¬ ì˜ì¡´ì„± ì •ì˜"""
    def __init__(self, task_id: str):
        self.task_id = task_id
        self.dependencies: Set[str] = set()
        self.dependents: Set[str] = set()
        self.required_models: Set[str] = set()
        self.produces_data: Set[str] = set()
        self.consumes_data: Set[str] = set()
        
    def add_dependency(self, dep_task_id: str):
        """ì˜ì¡´ì„± ì¶”ê°€"""
        self.dependencies.add(dep_task_id)
        
    def add_dependent(self, dep_task_id: str):
        """ì´ íƒœìŠ¤í¬ì— ì˜ì¡´í•˜ëŠ” íƒœìŠ¤í¬ ì¶”ê°€"""
        self.dependents.add(dep_task_id)

@dataclass
class WorkflowUnit:
    """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ë‹¨ìœ„"""
    unit_id: str
    stage: WorkflowStage
    tasks: List[str] = field(default_factory=list)
    required_models: Set[str] = field(default_factory=set)
    active_models: Set[str] = field(default_factory=set)
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    estimated_memory_mb: float = 0.0
    actual_memory_mb: float = 0.0
    is_active: bool = False
    is_protected: bool = False  # ì–¸ë¡œë“œ ë³´í˜¸
    
    def add_task(self, task_id: str, required_models: Set[str]):
        """íƒœìŠ¤í¬ ì¶”ê°€"""
        self.tasks.append(task_id)
        self.required_models.update(required_models)
        
    def activate(self):
        """ì›Œí¬í”Œë¡œìš° ë‹¨ìœ„ í™œì„±í™”"""
        self.is_active = True
        self.is_protected = True
        self.start_time = datetime.now()
        
    def deactivate(self):
        """ì›Œí¬í”Œë¡œìš° ë‹¨ìœ„ ë¹„í™œì„±í™”"""
        self.is_active = False
        self.is_protected = False
        self.end_time = datetime.now()

class WorkflowTracker:
    """ì›Œí¬í”Œë¡œìš° ì¶”ì ê¸°"""
    
    def __init__(self):
        self.current_stage = WorkflowStage.INITIALIZATION
        self.active_units: Dict[str, WorkflowUnit] = {}
        self.completed_units: deque = deque(maxlen=100)
        self.task_dependencies: Dict[str, TaskDependency] = {}
        self.stage_history: deque = deque(maxlen=50)
        self.model_usage_map: Dict[str, Set[str]] = defaultdict(set)  # model -> units
        
    def register_task_dependency(self, task_id: str, dependencies: List[str], 
                                required_models: List[str]):
        """íƒœìŠ¤í¬ ì˜ì¡´ì„± ë“±ë¡"""
        task_dep = TaskDependency(task_id)
        task_dep.required_models.update(required_models)
        
        for dep in dependencies:
            task_dep.add_dependency(dep)
            if dep in self.task_dependencies:
                self.task_dependencies[dep].add_dependent(task_id)
                
        self.task_dependencies[task_id] = task_dep
        
    def start_workflow_unit(self, unit_id: str, stage: WorkflowStage, 
                           required_models: Set[str]) -> WorkflowUnit:
        """ì›Œí¬í”Œë¡œìš° ë‹¨ìœ„ ì‹œì‘"""
        unit = WorkflowUnit(
            unit_id=unit_id,
            stage=stage,
            required_models=required_models
        )
        unit.activate()
        
        self.active_units[unit_id] = unit
        self.current_stage = stage
        self.stage_history.append((stage, datetime.now()))
        
        # ëª¨ë¸ ì‚¬ìš© ë§µ ì—…ë°ì´íŠ¸
        for model in required_models:
            self.model_usage_map[model].add(unit_id)
            
        logger.info(f"ì›Œí¬í”Œë¡œìš° ë‹¨ìœ„ ì‹œì‘: {unit_id} (ë‹¨ê³„: {stage.value})")
        return unit
        
    def complete_workflow_unit(self, unit_id: str):
        """ì›Œí¬í”Œë¡œìš° ë‹¨ìœ„ ì™„ë£Œ"""
        if unit_id in self.active_units:
            unit = self.active_units[unit_id]
            unit.deactivate()
            
            # ëª¨ë¸ ì‚¬ìš© ë§µ ì •ë¦¬
            for model in unit.required_models:
                self.model_usage_map[model].discard(unit_id)
                
            self.completed_units.append(unit)
            del self.active_units[unit_id]
            
            logger.info(f"ì›Œí¬í”Œë¡œìš° ë‹¨ìœ„ ì™„ë£Œ: {unit_id}")
            
    def get_protected_models(self) -> Set[str]:
        """ë³´í˜¸ë˜ì–´ì•¼ í•  ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        protected_models = set()
        
        for unit in self.active_units.values():
            if unit.is_protected:
                protected_models.update(unit.required_models)
                
        return protected_models
        
    def predict_next_stage(self) -> Optional[WorkflowStage]:
        """ë‹¤ìŒ ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ì˜ˆì¸¡"""
        stage_transitions = {
            WorkflowStage.INITIALIZATION: WorkflowStage.DATA_LOADING,
            WorkflowStage.DATA_LOADING: WorkflowStage.BACKBONE_FORWARD,
            WorkflowStage.BACKBONE_FORWARD: WorkflowStage.HEAD_PROCESSING,
            WorkflowStage.HEAD_PROCESSING: WorkflowStage.SYNERGY_COMPUTATION,
            WorkflowStage.SYNERGY_COMPUTATION: WorkflowStage.LOSS_COMPUTATION,
            WorkflowStage.LOSS_COMPUTATION: WorkflowStage.BACKWARD_PASS,
            WorkflowStage.BACKWARD_PASS: WorkflowStage.OPTIMIZATION,
            WorkflowStage.OPTIMIZATION: WorkflowStage.EVALUATION,
            WorkflowStage.EVALUATION: WorkflowStage.DATA_LOADING,  # ë‹¤ìŒ ë°°ì¹˜
        }
        
        return stage_transitions.get(self.current_stage)

class WorkflowAwareMemoryManager:
    """ì›Œí¬í”Œë¡œìš° ì¸ì‹ ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""
    
    def __init__(self, memory_threshold_mb: float = 6500.0):  # ~6.5GB for 8GB GPU
        self.memory_threshold_mb = memory_threshold_mb
        self.workflow_tracker = WorkflowTracker()
        self.model_registry: Dict[str, Tuple[nn.Module, float]] = {}  # name -> (model, size_mb)
        self.gpu_models: Set[str] = set()
        self.swap_history: deque = deque(maxlen=1000)
        self.memory_predictions: deque = deque(maxlen=100)
        self.memory_allocations: Dict[str, Tuple[float, float]] = {}  # module -> (size_mb, timestamp)
        
        # ë©”ì¸ ë£¨í”„ ì°¸ì¡°
        self.main_loop = None  # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ì£¼ì…í•  ë©”ì¸ ì´ë²¤íŠ¸ ë£¨í”„
        
        # ì›Œí¬í”Œë¡œìš°ë³„ ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼
        self.workflow_memory_profiles = {
            WorkflowStage.BACKBONE_FORWARD: 1500.0,  # MB
            WorkflowStage.HEAD_PROCESSING: 2000.0,
            WorkflowStage.SYNERGY_COMPUTATION: 500.0,
            WorkflowStage.BACKWARD_PASS: 2500.0,
            WorkflowStage.OPTIMIZATION: 1000.0,
        }
        
        # GPU ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (HF ë˜í¼ì™€ ê³µìœ )
        self._gpu_models = {}  # model_id -> {model, size_mb, owner, last_used}
        
        # HF ë˜í¼ í†µí•©
        try:
            from hf_model_wrapper import get_hf_wrapper
            hf_wrapper = get_hf_wrapper()
            hf_wrapper.set_memory_manager(self)
            logger.info("âœ… HF ëª¨ë¸ ë˜í¼ì™€ ë©”ëª¨ë¦¬ ë§¤ë‹ˆì € í†µí•© ì™„ë£Œ")
        except ImportError:
            logger.warning("âš ï¸ HF ëª¨ë¸ ë˜í¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - ìˆ˜ë™ ëª¨ë¸ ì¶”ì  ëª¨ë“œ")
        
    def register_model(self, name: str, model: nn.Module):
        """ëª¨ë¸ ë“±ë¡"""
        size_mb = self._calculate_model_size(model)
        self.model_registry[name] = (model, size_mb)
        logger.info(f"ëª¨ë¸ ë“±ë¡: {name} ({size_mb:.1f}MB)")
        
    def _calculate_model_size(self, model: nn.Module) -> float:
        """ëª¨ë¸ í¬ê¸° ê³„ì‚° (MB)"""
        param_size = 0
        buffer_size = 0
        
        for param in model.parameters():
            param_size += param.numel() * param.element_size()
            
        for buffer in model.buffers():
            buffer_size += buffer.numel() * buffer.element_size()
            
        total_size_mb = (param_size + buffer_size) / (1024 * 1024)
        return total_size_mb
        
    def get_current_gpu_usage(self) -> float:
        """í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / (1024 * 1024)
            reserved = torch.cuda.memory_reserved() / (1024 * 1024)
            return allocated
        return 0.0
        
    def predict_memory_requirement(self, stage: WorkflowStage, 
                                 required_models: Set[str]) -> float:
        """ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ ì˜ˆì¸¡"""
        base_memory = self.workflow_memory_profiles.get(stage, 500.0)
        
        model_memory = 0.0
        for model_name in required_models:
            if model_name in self.model_registry:
                _, size_mb = self.model_registry[model_name]
                model_memory += size_mb
                
        total_requirement = base_memory + model_memory
        
        # íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë³´ì •
        if len(self.memory_predictions) > 10:
            recent_errors = []
            for pred in list(self.memory_predictions)[-10:]:
                if pred['stage'] == stage:
                    error = pred['actual'] - pred['predicted']
                    recent_errors.append(error)
                    
            if recent_errors:
                avg_error = sum(recent_errors) / len(recent_errors)
                total_requirement += avg_error
                
        return total_requirement
        
    async def prepare_for_workflow(self, unit_id: str, stage: WorkflowStage,
                                  required_models: Set[str]) -> bool:
        """ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ ì¤€ë¹„"""
        logger.info(f"ì›Œí¬í”Œë¡œìš° ì¤€ë¹„: {unit_id} (ë‹¨ê³„: {stage.value})")
        
        # í˜„ì¬ GPU ì‚¬ìš©ëŸ‰ í™•ì¸
        current_usage = self.get_current_gpu_usage()
        required_memory = self.predict_memory_requirement(stage, required_models)
        
        logger.info(f"í˜„ì¬ GPU ì‚¬ìš©ëŸ‰: {current_usage:.1f}MB, "
                   f"ì˜ˆìƒ í•„ìš”ëŸ‰: {required_memory:.1f}MB, "
                   f"ì„ê³„ê°’: {self.memory_threshold_mb:.1f}MB")
        
        # ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜ˆìƒì‹œ ìŠ¤ì™‘ ì¤€ë¹„
        if current_usage + required_memory > self.memory_threshold_mb:
            await self._prepare_memory_space(required_memory)
            
        # ì›Œí¬í”Œë¡œìš° ë‹¨ìœ„ ì‹œì‘
        unit = self.workflow_tracker.start_workflow_unit(unit_id, stage, required_models)
        
        # í•„ìš”í•œ ëª¨ë¸ë“¤ GPUë¡œ ë¡œë“œ
        for model_name in required_models:
            if model_name not in self.gpu_models:
                await self._load_model_to_gpu(model_name)
                
        return True
        
    async def _prepare_memory_space(self, required_mb: float):
        """í•„ìš”í•œ ë©”ëª¨ë¦¬ ê³µê°„ í™•ë³´"""
        protected_models = self.workflow_tracker.get_protected_models()
        current_usage = self.get_current_gpu_usage()
        
        # ì–¸ë¡œë“œ ê°€ëŠ¥í•œ ëª¨ë¸ ì°¾ê¸°
        unloadable_models = []
        for model_name in self.gpu_models:
            if model_name not in protected_models:
                _, size_mb = self.model_registry.get(model_name, (None, 0))
                if size_mb > 0:
                    # ëª¨ë¸ ì‚¬ìš© ë¹ˆë„ í™•ì¸
                    usage_count = len(self.workflow_tracker.model_usage_map.get(model_name, set()))
                    unloadable_models.append((model_name, size_mb, usage_count))
                    
        # ì‚¬ìš© ë¹ˆë„ê°€ ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        unloadable_models.sort(key=lambda x: (x[2], -x[1]))
        
        # í•„ìš”í•œ ë§Œí¼ ì–¸ë¡œë“œ
        freed_memory = 0.0
        for model_name, size_mb, _ in unloadable_models:
            if current_usage - freed_memory + required_mb < self.memory_threshold_mb:
                break
                
            await self._unload_model_from_gpu(model_name)
            freed_memory += size_mb
            
        logger.info(f"ë©”ëª¨ë¦¬ í™•ë³´ ì™„ë£Œ: {freed_memory:.1f}MB í•´ì œ")
        
    async def _load_model_to_gpu(self, model_name: str):
        """ëª¨ë¸ì„ GPUë¡œ ë¡œë“œ"""
        if model_name in self.model_registry:
            model, size_mb = self.model_registry[model_name]
            model.cuda()
            self.gpu_models.add(model_name)
            logger.debug(f"ëª¨ë¸ GPU ë¡œë“œ: {model_name} ({size_mb:.1f}MB)")
            
    async def _unload_model_from_gpu(self, model_name: str):
        """ëª¨ë¸ì„ GPUì—ì„œ ì–¸ë¡œë“œ"""
        if model_name in self.gpu_models:
            model, size_mb = self.model_registry[model_name]
            model.cpu()
            self.gpu_models.remove(model_name)
            
            # ì¦‰ì‹œ GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.cuda.empty_cache()
            
            logger.debug(f"ëª¨ë¸ GPU ì–¸ë¡œë“œ: {model_name} ({size_mb:.1f}MB)")
            
    def complete_workflow(self, unit_id: str):
        """ì›Œí¬í”Œë¡œìš° ì™„ë£Œ"""
        self.workflow_tracker.complete_workflow_unit(unit_id)
        
    def get_workflow_status(self) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë°˜í™˜"""
        return {
            'current_stage': self.workflow_tracker.current_stage.value,
            'active_units': len(self.workflow_tracker.active_units),
            'protected_models': list(self.workflow_tracker.get_protected_models()),
            'gpu_models': list(self.gpu_models),
            'gpu_usage_mb': self.get_current_gpu_usage(),
            'memory_threshold_mb': self.memory_threshold_mb
        }
        
    async def optimize_for_next_stage(self):
        """ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•œ ìµœì í™”"""
        next_stage = self.workflow_tracker.predict_next_stage()
        if next_stage:
            logger.info(f"ë‹¤ìŒ ë‹¨ê³„ ì˜ˆì¸¡: {next_stage.value}")
            
            # ë‹¤ìŒ ë‹¨ê³„ì—ì„œ í•„ìš”í•  ëª¨ë¸ ì˜ˆì¸¡ (íˆìŠ¤í† ë¦¬ ê¸°ë°˜)
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ì˜ˆì¸¡ ë¡œì§ í•„ìš”
            
    def emergency_cleanup(self):
        """ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        logger.warning("ê¸´ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘!")
        
        # ë³´í˜¸ë˜ì§€ ì•Šì€ ëª¨ë“  ëª¨ë¸ ì–¸ë¡œë“œ
        protected_models = self.workflow_tracker.get_protected_models()
        models_to_unload = [m for m in self.gpu_models if m not in protected_models]
        
        for model_name in models_to_unload:
            model, _ = self.model_registry[model_name]
            model.cpu()
            self.gpu_models.remove(model_name)
            
        torch.cuda.empty_cache()
        gc.collect()
        
        freed_memory = self.get_current_gpu_usage()
        logger.warning(f"ê¸´ê¸‰ ì •ë¦¬ ì™„ë£Œ: {len(models_to_unload)}ê°œ ëª¨ë¸ ì–¸ë¡œë“œ")
        
    def _estimate_bundle_mb(self, module_name: str, deps: List[str]) -> float:
        """
        ëª¨ë“ˆê³¼ ì˜ì¡´ì„±ì˜ ì´ ë©”ëª¨ë¦¬ í¬ê¸° ì¶”ì • (NO FALLBACK - ì‹¤ì¸¡ì¹˜ë§Œ ì‚¬ìš©)
        
        Args:
            module_name: ëª¨ë“ˆ ì´ë¦„
            deps: ì˜ì¡´ì„± ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            float: ì¶”ì • ë©”ëª¨ë¦¬ í¬ê¸° (MB)
        """
        total_mb = 0.0
        
        # NO FALLBACK - MODULE_SPECSì˜ ì¶”ì •ì¹˜ ì‚¬ìš© ê¸ˆì§€
        # DSMì— ë“±ë¡ëœ ì‹¤ì œ í¬ê¸° í™•ì¸
        from dynamic_swap_manager import get_swap_manager
        swap_manager = get_swap_manager()
        
        if swap_manager and module_name in swap_manager.models:
            actual_size = swap_manager.models[module_name].size_mb
            if actual_size > 0:
                total_mb += actual_size
                logger.debug(f"  {module_name}: {actual_size}MB (DSM ì‹¤ì¸¡)")
        
        # ì˜ì¡´ì„± ëª¨ë“ˆë“¤ì˜ ì‹¤ì œ í¬ê¸°
        for dep in deps:
            if swap_manager and dep in swap_manager.models:
                dep_size = swap_manager.models[dep].size_mb
                if dep_size > 0:
                    total_mb += dep_size
                    logger.debug(f"  ì˜ì¡´ì„± {dep}: {dep_size}MB (DSM ì‹¤ì¸¡)")
        
        # 2. HF ë˜í¼ ì‹¤ì¸¡ì¹˜ ë°˜ì˜
        if hasattr(self, '_gpu_models'):
            for model_id, model_info in self._gpu_models.items():
                if (model_info.get('owner') == module_name or 
                    model_info.get('owner') in deps):
                    actual_mb = model_info.get('size_mb', 0)
                    # ì‹¤ì¸¡ì¹˜ê°€ ìˆìœ¼ë©´ ìŠ¤í™ë³´ë‹¤ ìš°ì„  (90% ì ìš©)
                    total_mb = max(total_mb, actual_mb * 0.9)
                    logger.debug(f"  {model_id}: {actual_mb}MB (ì‹¤ì¸¡, owner={model_info.get('owner')})")
        
        # 3. ì˜¤ë²„í—¤ë“œ ë²„í¼ ì¶”ê°€
        overhead_mb = max(100, 0.05 * total_mb)
        total_mb += overhead_mb
        
        logger.info(f"[GPU MEM] ë²ˆë“¤ í¬ê¸° ì¶”ì •: {module_name} + deps = {total_mb:.1f}MB (ì˜¤ë²„í—¤ë“œ {overhead_mb:.1f}MB í¬í•¨)")
        return total_mb

    async def request_gpu(self, module_name: str, required_mb: float = None, 
                         deps: List[str] = None, target_util: float = 0.85,
                         must_succeed: bool = True, timeout: float = 30.0) -> bool:
        """
        GPU ê³µê°„ ìš”ì²­ - ì˜ì¡´ì„± ë‹¨ìœ„ ìŠ¹ì¸
        
        Args:
            module_name: ëª¨ë“ˆ ì´ë¦„
            required_mb: í•„ìš”í•œ ë©”ëª¨ë¦¬ (MB), Noneì´ë©´ ìë™ ì¶”ì •
            deps: ì˜ì¡´ì„± ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸
            target_util: ëª©í‘œ GPU ì‚¬ìš©ë¥  (0.85 = 85%)
            
        Returns:
            bool: í• ë‹¹ ì„±ê³µ ì—¬ë¶€
        """
        from config import get_gpu_memory_info
        
        deps = deps or []
        
        # required_mbê°€ ì—†ìœ¼ë©´ ìë™ ì¶”ì •
        if required_mb is None:
            required_mb = self._estimate_bundle_mb(module_name, deps)
        else:
            # ì˜ì¡´ì„±ì´ ìˆìœ¼ë©´ ë²ˆë“¤ í¬ê¸° ê³„ì‚°
            if deps:
                bundle_mb = self._estimate_bundle_mb(module_name, deps)
                required_mb = max(required_mb, bundle_mb)
        
        # í˜„ì¬ GPU ì‚¬ìš©ë¥  í™•ì¸ (empty_cache í›„ ì¸¡ì •)
        torch.cuda.empty_cache()
        gpu_info = get_gpu_memory_info()
        if not gpu_info:
            logger.warning("[GPU MEM] GPU ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False
            
        current_usage = gpu_info['usage_percent'] / 100.0
        total_mb = gpu_info['total_mb']
        
        # reserved ë©”ëª¨ë¦¬ë„ ê³ ë ¤í•œ ì‹¤ì œ ì—¬ìœ  ê³µê°„ ê³„ì‚°
        actual_free = gpu_info['free_mb']
        reserved_free = max(0, gpu_info['cached_mb'] - gpu_info['allocated_mb'])
        total_available = actual_free + reserved_free
        
        logger.info(f"[GPU QUEUE] {module_name}: {required_mb:.1f}MB ìš”ì²­ (ì˜ì¡´ì„± {len(deps)}ê°œ)")
        logger.info(f"[GPU MEM] í˜„ì¬: {current_usage*100:.1f}% ì‚¬ìš©, {total_available:.1f}MB ì‹¤ì œ ì—¬ìœ ")
        
        # ê³µê°„ì´ ë¶€ì¡±í•˜ë©´ free_gpu_space_intelligent í˜¸ì¶œ
        if total_available < required_mb:
            logger.info(f"[GPU MEM] ê³µê°„ ë¶€ì¡± - {required_mb:.1f}MB í•„ìš”, {total_available:.1f}MB ì—¬ìœ ")
            
            # DynamicSwapManagerì˜ ì§€ëŠ¥ì  ê³µê°„ í™•ë³´ ì‹œë„
            from dynamic_swap_manager import get_swap_manager
            swap_manager = get_swap_manager()
            if swap_manager:
                success = await swap_manager.free_gpu_space_intelligent(
                    required_mb=required_mb,
                    target_usage=target_util,
                    hard_timeout_s=timeout
                )
                if not success:
                    logger.error(f"[GPU MEM] ê³µê°„ í™•ë³´ ì‹¤íŒ¨: {module_name}")
                    if must_succeed:
                        raise RuntimeError(f"[GPU] í•„ìˆ˜ ëª¨ë“ˆ ê³µê°„ í™•ë³´ ì‹¤íŒ¨(owner={module_name}, needâ‰ˆ{required_mb}MB, target={target_util})")
                    return False
                logger.info(f"[GPU MEM] ê³µê°„ í™•ë³´ ì„±ê³µ: {required_mb:.1f}MB")
            else:
                logger.error("[GPU MEM] SwapManagerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
        
        # ë©”ëª¨ë¦¬ í• ë‹¹ ê¸°ë¡
        self.memory_allocations[module_name] = (required_mb, time.time())
        logger.info(f"[GPU MEM] âœ… {module_name} í• ë‹¹ ì™„ë£Œ: {required_mb:.1f}MB")
        return True
        
    def set_boot_completed(self):
        """ë¶€íŒ… ì™„ë£Œ í‘œì‹œ - deprecated, í˜¸í™˜ì„±ì„ ìœ„í•´ ë¹ˆ í•¨ìˆ˜ë¡œ ìœ ì§€"""
        logger.info("ğŸš€ set_boot_completed í˜¸ì¶œë¨ (deprecated)")
    
    def request_gpu_blocking(self, module_name: str, required_mb: float = None,
                           deps: List[str] = None, target_util: float = 0.85,
                           timeout: float = 30.0, is_required: bool = False) -> bool:
        """
        ë™ê¸° GPU ë©”ëª¨ë¦¬ ìš”ì²­ - ë©”ëª¨ë¦¬ê°€ í™•ë³´ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        
        Args:
            module_name: ëª¨ë“ˆ ì´ë¦„
            required_mb: í•„ìš”í•œ ë©”ëª¨ë¦¬ (MB)
            deps: ì˜ì¡´ì„± ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸
            target_util: ëª©í‘œ GPU ì‚¬ìš©ë¥ 
            timeout: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
            is_required: í•„ìˆ˜ ëª¨ë“ˆ ì—¬ë¶€ (Trueë©´ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ)
            
        Returns:
            bool: í• ë‹¹ ì„±ê³µ ì—¬ë¶€
        """
        import asyncio
        from config import get_gpu_memory_info
        
        # GPU í• ë‹¹ ì •ì±… ê²€ì‚¬ (ë¶€íŒ… í”Œë˜ê·¸ ì œê±°)
        
        start_time = time.time()
        deps = deps or []
        
        # required_mbê°€ ì—†ìœ¼ë©´ ì¶”ì •
        if required_mb is None:
            required_mb = self._estimate_bundle_mb(module_name, deps)
            
        logger.info(f"[GPU BLOCKING] {module_name}: {required_mb:.1f}MB ë™ê¸° ìš”ì²­ ì‹œì‘")
        
        # ì´ë²¤íŠ¸ ë£¨í”„ ì²˜ë¦¬
        try:
            # ìŠ¤ë ˆë“œ ì•ˆì „ì„±: main_loopë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ í™•ì¸
            loop = None
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                # ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ ì¤‘ì´ë©´ main_loop ì‚¬ìš©
                loop = self.main_loop
            
            if loop and loop.is_running():
                # ì´ë¯¸ ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì´ë©´ í´ë§ ë°©ì‹ ì‚¬ìš©
                while time.time() - start_time < timeout:
                    # empty_cache í˜¸ì¶œ í›„ ì¬ì¸¡ì •ìœ¼ë¡œ ì‹¤ì œ ì—¬ìœ  ê³µê°„ í™•ì¸
                    torch.cuda.empty_cache()
                    gpu_info = get_gpu_memory_info()
                    
                    if gpu_info:
                        # reserved ë©”ëª¨ë¦¬ë„ ê³ ë ¤í•œ ì‹¤ì œ ì—¬ìœ  ê³µê°„ ê³„ì‚°
                        # empty_cache í›„ì´ë¯€ë¡œ reserved-allocatedê°€ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ê³µê°„
                        actual_free = gpu_info['free_mb']
                        reserved_free = max(0, gpu_info['cached_mb'] - gpu_info['allocated_mb'])
                        total_available = actual_free + reserved_free
                        
                        logger.debug(f"[GPU BLOCKING] ì—¬ìœ  ê³µê°„: free={actual_free:.1f}MB, reserved_free={reserved_free:.1f}MB, total={total_available:.1f}MB")
                        
                        if total_available >= required_mb:
                            # ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë©´ í• ë‹¹ ê¸°ë¡í•˜ê³  ì„±ê³µ ë°˜í™˜
                            self.memory_allocations[module_name] = (required_mb, time.time())
                            logger.info(f"[GPU BLOCKING] âœ… {module_name} í• ë‹¹ ì„±ê³µ (í´ë§)")
                            return True
                    
                    # 50ms ëŒ€ê¸°
                    time.sleep(0.05)
                    
                    # ì£¼ê¸°ì ìœ¼ë¡œ ê³µê°„ í™•ë³´ ì‹œë„
                    if int((time.time() - start_time) * 10) % 10 == 0:  # 1ì´ˆë§ˆë‹¤
                        from dynamic_swap_manager import get_swap_manager
                        swap_manager = get_swap_manager()
                        if swap_manager:
                            # ë™ê¸°ì ìœ¼ë¡œ ê³µê°„ í™•ë³´ ì‹œë„
                            logger.debug(f"[GPU BLOCKING] ê³µê°„ í™•ë³´ ì‹œë„...")
                            # TODO: free_gpu_space_intelligentë¥¼ ë™ê¸° ë²„ì „ìœ¼ë¡œ í˜¸ì¶œ
                
                # íƒ€ì„ì•„ì›ƒ
                msg = f"[GPU BLOCKING] âŒ {module_name} í• ë‹¹ ì‹¤íŒ¨: íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)"
                logger.error(msg)
                if is_required:
                    raise RuntimeError(msg)
                return False
                
            else:
                # ë£¨í”„ê°€ ì—†ê±°ë‚˜ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ ë•Œ
                if loop is None:
                    # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        success = loop.run_until_complete(
                            self.request_gpu(module_name, required_mb, deps, target_util, 
                                        must_succeed=is_required, timeout=timeout)
                        )
                    finally:
                        loop.close()
                else:
                    # ë£¨í”„ëŠ” ìˆì§€ë§Œ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹Œ ê²½ìš°
                    success = loop.run_until_complete(
                        self.request_gpu(module_name, required_mb, deps, target_util, 
                                        must_succeed=is_required, timeout=timeout)
                    )
                
                if not success and is_required:
                    msg = f"[GPU BLOCKING] âŒ í•„ìˆ˜ ëª¨ë“ˆ {module_name} ë©”ëª¨ë¦¬ í• ë‹¹ ì‹¤íŒ¨"
                    raise RuntimeError(msg)
                return success
                
        except Exception as e:
            msg = f"[GPU BLOCKING] âŒ {module_name} í• ë‹¹ ì¤‘ ì˜¤ë¥˜: {e}"
            logger.error(msg)
            if is_required:
                raise RuntimeError(msg) from e
            return False
        
    def register_cpu_preloaded(self, module_name: str, estimated_mb: float):
        """
        CPU í”„ë¦¬ë¡œë“œ ëª¨ë“ˆ ë“±ë¡
        
        Args:
            module_name: ëª¨ë“ˆ ì´ë¦„
            estimated_mb: ì˜ˆìƒ ë©”ëª¨ë¦¬ í¬ê¸° (MB)
        """
        # CPU í”„ë¦¬ë¡œë“œ ëª¨ë“ˆ ì¶”ì 
        if not hasattr(self, 'cpu_preloaded_models'):
            self.cpu_preloaded_models = {}
            
        self.cpu_preloaded_models[module_name] = estimated_mb
        logger.info(f"[CPU í”„ë¦¬ë¡œë“œ] {module_name} ë“±ë¡ ({estimated_mb}MB)")
        
        # GPU ëª©ë¡ì—ì„œ ì œê±° (ìˆë‹¤ë©´)
        if module_name in self.gpu_models:
            self.gpu_models.remove(module_name)