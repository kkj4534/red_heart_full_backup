#!/usr/bin/env python3
"""
ê³ ê¸‰ í•™ìŠµ ì‹¤í–‰ê¸° - Red Heart ì‹¤ì œ í•™ìŠµ ì‹œìŠ¤í…œ
Advanced Learning Executor for Red Heart System

ì‹¤ì œ í•™ìŠµ íŒŒë¼ë¯¸í„°:
- ìŠ¤í…ë‹¹ í›„íšŒ íšŸìˆ˜: 7íšŒ
- í™˜ê²½ë³„ ë²¤ë‹´ ê³„ì‚°: 3íšŒ (ì´ 21íšŒ/ìŠ¤í…)
- ì¼ë°˜ ë°ì´í„°: 3íšŒ ì„ íšŒ
- EBS ë°ì´í„°: 6íšŒ ì„ íšŒ
"""

import os
import json
import time
import asyncio
import logging
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
# pathlib ì œê±° - WSL í˜¸í™˜ì„±ì„ ìœ„í•´ os.path ì‚¬ìš©
import uuid
import random
from collections import defaultdict

# Red Heart ëª¨ë“ˆë“¤
from config import ADVANCED_CONFIG, PROCESSED_DATASETS_DIR, LOGS_DIR
from data_models import DecisionScenario, EmotionData, HedonicValues
from advanced_emotion_analyzer import AdvancedEmotionAnalyzer
from advanced_bentham_calculator import AdvancedBenthamCalculator
from advanced_regret_learning_system import AdvancedRegretLearningSystem
from advanced_hierarchical_emotion_system import AdvancedHierarchicalEmotionSystem
from advanced_bayesian_inference_module import AdvancedBayesianInference
from advanced_surd_analyzer import AdvancedSURDAnalyzer
from advanced_rumbaugh_analyzer import AdvancedRumbaughAnalyzer
from utils import save_json, load_json

logger = logging.getLogger('RedHeart.LearningExecutor')

@dataclass
class LearningConfig:
    """í•™ìŠµ ì„¤ì •"""
    regrets_per_step: int = 7           # ìŠ¤í…ë‹¹ í›„íšŒ íšŸìˆ˜
    bentham_per_environment: int = 3    # í™˜ê²½ë³„ ë²¤ë‹´ ê³„ì‚° íšŸìˆ˜
    general_data_cycles: int = 3        # ì¼ë°˜ ë°ì´í„° ì„ íšŒ íšŸìˆ˜
    ebs_data_cycles: int = 6           # EBS ë°ì´í„° ì„ íšŒ íšŸìˆ˜
    max_scenarios_per_batch: int = 50   # ë°°ì¹˜ë‹¹ ìµœëŒ€ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜

@dataclass
class LearningProgress:
    """í•™ìŠµ ì§„í–‰ ìƒí™©"""
    current_cycle: int = 0
    current_batch: int = 0
    current_scenario: int = 0
    total_regrets: int = 0
    total_bentham_calculations: int = 0
    total_scenarios_processed: int = 0
    phase_transitions: int = 0
    start_time: datetime = None
    
class AdvancedLearningExecutor:
    """ê³ ê¸‰ í•™ìŠµ ì‹¤í–‰ê¸°"""
    
    def __init__(self, config: LearningConfig = None):
        self.config = config or LearningConfig()
        self.progress = LearningProgress()
        
        # ê³ ê¸‰ ì‹œìŠ¤í…œë“¤ ì´ˆê¸°í™”
        self.emotion_analyzer = AdvancedEmotionAnalyzer()
        self.bentham_calculator = AdvancedBenthamCalculator()
        self.regret_system = AdvancedRegretLearningSystem()
        self.emotion_system = AdvancedHierarchicalEmotionSystem()
        self.bayesian_inference = AdvancedBayesianInference()
        
        # êµ¬ì¡°ì  ë¶„ì„ ì‹œìŠ¤í…œë“¤
        self.surd_analyzer = AdvancedSURDAnalyzer()
        self.rumbaugh_analyzer = AdvancedRumbaughAnalyzer()
        
        # í•™ìŠµ í†µê³„
        self.learning_stats = {
            'regret_history': [],
            'bentham_scores': [],
            'phase_transitions': [],
            'emotion_evolution': [],
            'performance_metrics': []
        }
        
    async def execute_full_learning(self, samples: Optional[int] = None) -> Dict[str, Any]:
        """ì „ì²´ í•™ìŠµ ì‹¤í–‰"""
        logger.info("ğŸš€ Red Heart ê³ ê¸‰ í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘")
        if samples:
            logger.info(f"ğŸ¯ ìƒ˜í”Œ ì œí•œ ëª¨ë“œ: ìµœëŒ€ {samples}ê°œ ì‹œë‚˜ë¦¬ì˜¤ë§Œ ì²˜ë¦¬")
        logger.info(f"ğŸ“‹ í•™ìŠµ ì„¤ì •: ìŠ¤í…ë‹¹ í›„íšŒ {self.config.regrets_per_step}íšŒ, ë²¤ë‹´ ê³„ì‚° {self.config.bentham_per_environment}íšŒ")
        
        self.progress.start_time = datetime.now()
        
        try:
            # 1. ë°ì´í„°ì…‹ ë¡œë“œ
            datasets = await self._load_all_datasets()
            logger.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°ì…‹: {len(datasets)}ê°œ")
            
            # samples ì œí•œ ì ìš©
            if samples:
                datasets = self._limit_datasets_by_samples(datasets, samples)
                logger.info(f"ğŸ¯ ìƒ˜í”Œ ì œí•œ ì ìš©: ìµœëŒ€ {samples}ê°œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì œí•œë¨")
            
            # 2. EBS ë°ì´í„° íŠ¹ë³„ ì²˜ë¦¬ (6íšŒ ì„ íšŒ)
            await self._process_ebs_data_cycles(datasets.get('ebs_korean_literature', []))
            
            # 3. ì¼ë°˜ ë°ì´í„° ì²˜ë¦¬ (3íšŒ ì„ íšŒ)
            await self._process_general_data_cycles(datasets)
            
            # 4. ìµœì¢… í•™ìŠµ ê²°ê³¼ ì €ì¥
            results = await self._save_learning_results()
            
            logger.info("âœ… ëª¨ë“  í•™ìŠµ ì™„ë£Œ!")
            return results
            
        except Exception as e:
            logger.error(f"í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
    
    async def _load_all_datasets(self) -> Dict[str, List[Dict]]:
        """ëª¨ë“  ë°ì´í„°ì…‹ ë¡œë“œ"""
        datasets = {}
        
        # EBS í•œêµ­ ë¬¸í•™ ë°ì´í„°
        ebs_dir = os.path.join(PROCESSED_DATASETS_DIR, 'ebs_korean_literature')
        if os.path.exists(ebs_dir):
            datasets['ebs_korean_literature'] = await self._load_dataset_files(ebs_dir)
            
        # Scruples ë°ì´í„° (ìƒ˜í”Œë§)
        scruples_dir = os.path.join(PROCESSED_DATASETS_DIR, 'scruples')
        if os.path.exists(scruples_dir):
            # 100ê°œ íŒŒì¼ ì¤‘ ì²˜ìŒ 5ê°œë§Œ ìƒ˜í”Œë§ (í•™ìŠµ ì‹œê°„ ë‹¨ì¶•)
            import glob
            scruples_files = glob.glob(os.path.join(scruples_dir, '*.json'))[:5]
            datasets['scruples'] = []
            for file_path in scruples_files:
                data = load_json(file_path)
                if data and 'scenarios' in data:
                    datasets['scruples'].extend(data['scenarios'][:50])  # ê° íŒŒì¼ì—ì„œ 50ê°œë§Œ
            
        # ê³ ì „ ë¬¸í•™ ë°ì´í„°
        literature_dir = os.path.join(PROCESSED_DATASETS_DIR, 'classic_literature')
        if os.path.exists(literature_dir):
            datasets['classic_literature'] = await self._load_dataset_files(literature_dir)
            
        return datasets
    
    def _limit_datasets_by_samples(self, datasets: Dict[str, List[Dict]], max_samples: int) -> Dict[str, List[Dict]]:
        """samples íŒŒë¼ë¯¸í„°ì— ë”°ë¼ ë°ì´í„°ì…‹ í¬ê¸° ì œí•œ"""
        limited_datasets = {}
        total_allocated = 0
        
        for dataset_name, scenarios in datasets.items():
            if total_allocated >= max_samples:
                # ì´ë¯¸ í• ë‹¹ëŸ‰ ì´ˆê³¼
                limited_datasets[dataset_name] = []
                logger.info(f"  ğŸ“Š {dataset_name}: 0ê°œ (í• ë‹¹ëŸ‰ ì´ˆê³¼)")
                continue
                
            remaining_quota = max_samples - total_allocated
            allocated_for_this_dataset = min(len(scenarios), remaining_quota)
            
            limited_datasets[dataset_name] = scenarios[:allocated_for_this_dataset]
            total_allocated += allocated_for_this_dataset
            
            logger.info(f"  ğŸ“Š {dataset_name}: {allocated_for_this_dataset}ê°œ (ì›ë³¸: {len(scenarios)}ê°œ)")
        
        logger.info(f"ğŸ¯ ì´ í• ë‹¹ëœ ì‹œë‚˜ë¦¬ì˜¤: {total_allocated}ê°œ (ìš”ì²­: {max_samples}ê°œ)")
        return limited_datasets
    
    async def _load_dataset_files(self, directory: str) -> List[Dict]:
        """ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  JSON íŒŒì¼ ë¡œë“œ"""
        scenarios = []
        import glob
        json_files = glob.glob(os.path.join(directory, '*.json'))
        for file_path in json_files:
            try:
                data = load_json(file_path)
                if data and 'scenarios' in data:
                    scenarios.extend(data['scenarios'])
            except Exception as e:
                logger.warning(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}")
        return scenarios
    
    async def _process_ebs_data_cycles(self, ebs_data: List[Dict]) -> None:
        """EBS ë°ì´í„° 6íšŒ ì„ íšŒ ì²˜ë¦¬"""
        if not ebs_data:
            logger.warning("EBS ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        logger.info(f"ğŸ“š EBS ë°ì´í„° í•™ìŠµ ì‹œì‘: {len(ebs_data)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ Ã— 6íšŒ ì„ íšŒ")
        
        for cycle in range(self.config.ebs_data_cycles):
            logger.info(f"  ğŸ”„ EBS ë°ì´í„° Cycle {cycle + 1}/6")
            self.progress.current_cycle = cycle + 1
            
            await self._process_dataset_scenarios(ebs_data, f"EBS_Cycle_{cycle + 1}", is_ebs=True)
    
    async def _process_general_data_cycles(self, datasets: Dict[str, List[Dict]]) -> None:
        """ì¼ë°˜ ë°ì´í„° 3íšŒ ì„ íšŒ ì²˜ë¦¬"""
        general_datasets = {k: v for k, v in datasets.items() if k != 'ebs_korean_literature'}
        
        if not general_datasets:
            logger.warning("ì¼ë°˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        total_scenarios = sum(len(scenarios) for scenarios in general_datasets.values())
        logger.info(f"ğŸ“– ì¼ë°˜ ë°ì´í„° í•™ìŠµ ì‹œì‘: {total_scenarios}ê°œ ì‹œë‚˜ë¦¬ì˜¤ Ã— 3íšŒ ì„ íšŒ")
        
        for cycle in range(self.config.general_data_cycles):
            logger.info(f"  ğŸ”„ ì¼ë°˜ ë°ì´í„° Cycle {cycle + 1}/3")
            self.progress.current_cycle = cycle + 1
            
            for dataset_name, scenarios in general_datasets.items():
                await self._process_dataset_scenarios(scenarios, f"{dataset_name}_Cycle_{cycle + 1}")
    
    async def _process_dataset_scenarios(self, scenarios: List[Dict], dataset_label: str, is_ebs: bool = False) -> None:
        """ë°ì´í„°ì…‹ì˜ ì‹œë‚˜ë¦¬ì˜¤ë“¤ ì²˜ë¦¬"""
        if not scenarios:
            return
            
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        batches = [scenarios[i:i + self.config.max_scenarios_per_batch] 
                  for i in range(0, len(scenarios), self.config.max_scenarios_per_batch)]
        
        logger.info(f"    ğŸ“¦ {dataset_label}: {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ â†’ {len(batches)}ê°œ ë°°ì¹˜")
        
        for batch_idx, batch_scenarios in enumerate(batches):
            self.progress.current_batch = batch_idx + 1
            logger.info(f"      ë°°ì¹˜ {batch_idx + 1}/{len(batches)} ì²˜ë¦¬ ì¤‘...")
            
            await self._process_scenario_batch(batch_scenarios, dataset_label, is_ebs)
    
    async def _process_scenario_batch(self, scenarios: List[Dict], dataset_label: str, is_ebs: bool = False) -> None:
        """ì‹œë‚˜ë¦¬ì˜¤ ë°°ì¹˜ ì²˜ë¦¬"""
        for scenario_idx, scenario_data in enumerate(scenarios):
            self.progress.current_scenario = scenario_idx + 1
            self.progress.total_scenarios_processed += 1
            
            try:
                # ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬
                await self._process_single_scenario(scenario_data, dataset_label, is_ebs)
                
                # 100ê°œ ì‹œë‚˜ë¦¬ì˜¤ë§ˆë‹¤ ì§„í–‰ ìƒí™© ë¡œê¹…
                if self.progress.total_scenarios_processed % 100 == 0:
                    await self._log_progress_milestone()
                    
            except Exception as e:
                # ë¬´ê²°ì„± ë³´ì¥: graceful degradation ì œê±°
                # ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨ëŠ” ì‹¬ê°í•œ ë¬¸ì œë¡œ ê°„ì£¼
                logger.error(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬ ì‹¬ê°í•œ ì‹¤íŒ¨: {e}")
                logger.error(f"   ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°: {scenario_data.get('title', 'Unknown')}")
                logger.error(f"   ë°ì´í„°ì…‹: {dataset_label}")
                
                # ì‹œìŠ¤í…œ ë¬´ê²°ì„±ì„ ìœ„í•´ ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´
                # ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­: "fallback ì œê±°í•´ì„œ ì‹¤ì œ í•™ìŠµì´ ì˜¤ì—¼ë˜ì§€ ì•Šê²Œ ì²˜ë¦¬"
                raise Exception(f"ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ì¸í•œ í•™ìŠµ ë¬´ê²°ì„± ì˜¤ì—¼ ë°©ì§€: {e}")
    
    async def _process_single_scenario(self, scenario_data: Dict, dataset_label: str, is_ebs: bool = False) -> None:
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬: êµ¬ì¡°ì  ë¶„ì„ + 7íšŒ í›„íšŒ + 3íšŒ ë²¤ë‹´ ê³„ì‚°"""
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
        scenario_title = scenario_data.get('title', f'Scenario_{self.progress.total_scenarios_processed}')
        scenario_description = scenario_data.get('description', '')
        
        # 0. êµ¬ì¡°ì  ë¶„ì„ ìˆ˜í–‰ (SURD + Rumbaugh)
        structural_analysis = await self._perform_structural_analysis(scenario_title, scenario_description, scenario_data)
        
        # 1. ìŠ¤í…ë‹¹ 7íšŒ í›„íšŒ í•™ìŠµ
        regret_results = []
        for regret_idx in range(self.config.regrets_per_step):
            regret_result = await self._execute_regret_learning(
                scenario_title, scenario_description, regret_idx + 1, dataset_label, is_ebs
            )
            regret_results.append(regret_result)
            self.progress.total_regrets += 1
        
        # 2. í™˜ê²½ë³„ 3íšŒ ë²¤ë‹´ ê³„ì‚° (ì´ 21íšŒ)
        bentham_results = []
        environments = ['optimistic', 'realistic', 'pessimistic']
        
        for regret_result in regret_results:  # 7ê°œ í›„íšŒ ê²°ê³¼ ê°ê°ì— ëŒ€í•´
            for env in environments:  # 3ê°œ í™˜ê²½ì—ì„œ
                bentham_result = await self._execute_bentham_calculation(
                    scenario_title, scenario_description, regret_result, env
                )
                bentham_results.append(bentham_result)
                self.progress.total_bentham_calculations += 1
        
        # 3. í•™ìŠµ í†µê³„ ì—…ë°ì´íŠ¸
        await self._update_learning_statistics(regret_results, bentham_results, is_ebs, structural_analysis)
    
    async def _execute_regret_learning(self, title: str, description: str, regret_idx: int, 
                                     dataset_label: str, is_ebs: bool) -> Dict[str, Any]:
        """í›„íšŒ í•™ìŠµ ì‹¤í–‰"""
        
        # í›„íšŒ ìœ í˜• ì„ íƒ (ìˆœí™˜)
        regret_types = ['ACTION', 'INACTION', 'TIMING', 'CHOICE', 'EMPATHY', 'PREDICTION']
        regret_type = regret_types[regret_idx % len(regret_types)]
        
        # í›„íšŒ ê°•ë„ ê³„ì‚° (EBS ë°ì´í„°ëŠ” ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        base_intensity = random.uniform(0.1, 0.8)
        if is_ebs:
            regret_intensity = min(base_intensity * 1.3, 1.0)  # EBS ë°ì´í„°ëŠ” 30% ê°•í™”
        else:
            regret_intensity = base_intensity
        
        # ê°ì • ë¶„ì„
        emotion_result = self.emotion_analyzer.analyze_emotion(description, language="ko")
        
        # ê³„ì¸µì  ê°ì • ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ (ì‹¤ì œ API ì‚¬ìš©)
        literary_data = [{
            'emotion': emotion_result,
            'context': {
                'scenario': title,
                'regret_type': regret_type,
                'description': description[:200]
            },
            'timestamp': datetime.now().isoformat()
        }]
        emotion_learning_result = await self.emotion_system.process_literary_emotion_sequence(
            literary_data=literary_data,
            time_series_mode=True
        )
        
        # í›„íšŒ í•™ìŠµ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ (ì‹¤ì œ API ì‚¬ìš©)
        situation = {
            'scenario': title,
            'regret_type': regret_type,
            'description': description[:200],
            'dataset_label': dataset_label,
            'is_ebs': is_ebs
        }
        outcome = {
            'regret_intensity': regret_intensity,
            'emotion_analysis': emotion_result,
            'emotion_learning': emotion_learning_result
        }
        alternatives = [{
            'regret_type': alt_type,
            'description': f"Alternative regret type: {alt_type}"
        } for alt_type in ['ACTION', 'INACTION', 'TIMING', 'CHOICE', 'EMPATHY', 'PREDICTION']
                       if alt_type != regret_type]
        
        regret_learning_result = await self.regret_system.process_regret(
            situation=situation,
            outcome=outcome,
            alternatives=alternatives,
            literary_context={'scenario': title, 'regret_type': regret_type}
        )
        
        # ë² ì´ì§€ì•ˆ ì¶”ë¡  (ì‹¤ì œ API ì‚¬ìš©)
        evidence = {
            'regret_intensity': regret_intensity,
            'regret_type': regret_type,
            'emotion_result': emotion_result,
            'dataset': dataset_label,
            'is_ebs': is_ebs
        }
        context = {
            'scenario': title,
            'dataset': dataset_label,
            'is_ebs': is_ebs
        }
        
        # ì¶”ë¡  ì‹¤í–‰
        bayesian_result = await self.bayesian_inference.infer(
            query_node='regret_prediction',
            given_evidence=evidence,
            context=context
        )
        
        # ê²°ê³¼ ì—…ë°ì´íŠ¸
        await self.bayesian_inference.update_from_outcome(
            prediction_node='regret_prediction',
            predicted_value=regret_intensity,
            actual_value=regret_intensity,
            context=context
        )
        
        # ë¡œê¹…
        logger.debug(f"í›„íšŒ í•™ìŠµ {regret_idx}: {regret_type} (ê°•ë„: {regret_intensity:.3f})")
        
        result = {
            'regret_type': regret_type,
            'regret_intensity': regret_intensity,
            'emotion_result': emotion_result,
            'emotion_learning': emotion_learning_result,
            'regret_learning': regret_learning_result,
            'bayesian_inference': bayesian_result,
            'timestamp': datetime.now().isoformat()
        }
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.learning_stats['regret_history'].append({
            'scenario_id': self.progress.total_scenarios_processed,
            'regret_type': regret_type,
            'intensity': regret_intensity,
            'dataset': dataset_label,
            'is_ebs': is_ebs
        })
        
        return result
    
    async def _execute_bentham_calculation(self, title: str, description: str, 
                                         regret_result: Dict, environment: str) -> Dict[str, Any]:
        """ë²¤ë‹´ ì¾Œë½ ê³„ì‚° ì‹¤í–‰"""
        
        # í™˜ê²½ë³„ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
        context_modifiers = {
            'optimistic': {'certainty': 1.2, 'fecundity': 1.1, 'purity': 1.1},
            'realistic': {'certainty': 1.0, 'fecundity': 1.0, 'purity': 1.0},
            'pessimistic': {'certainty': 0.8, 'fecundity': 0.9, 'purity': 0.9}
        }
        
        # ë²¤ë‹´ ê³„ì‚° ì…ë ¥ ì¤€ë¹„
        bentham_input = {
            'scenario_description': description,
            'regret_context': regret_result.get('regret_type', ''),
            'regret_intensity': regret_result.get('regret_intensity', 0.5),
            'environment_modifiers': context_modifiers[environment]
        }
        
        # ê³ ê¸‰ ë²¤ë‹´ ê³„ì‚° ì‹¤í–‰ (ì‹¤ì œ API ì‚¬ìš© - ë™ê¸°)
        bentham_result = self.bentham_calculator.calculate_with_advanced_layers(
            input_data=bentham_input,
            use_cache=True
        )
        
        # ë¡œê¹…
        hedonic_score = bentham_result.hedonic_values.hedonic_total if bentham_result.hedonic_values else 0.0
        logger.debug(f"ë²¤ë‹´ ê³„ì‚° ({environment}): ì¾Œë½ ì ìˆ˜ {hedonic_score:.3f}")
        
        result = {
            'environment': environment,
            'hedonic_score': hedonic_score,
            'bentham_result': bentham_result,
            'timestamp': datetime.now().isoformat()
        }
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.learning_stats['bentham_scores'].append({
            'scenario_id': self.progress.total_scenarios_processed,
            'environment': environment,
            'hedonic_score': hedonic_score,
            'regret_type': regret_result.get('regret_type', ''),
            'regret_intensity': regret_result.get('regret_intensity', 0.0)
        })
        
        return result
    
    async def _update_learning_statistics(self, regret_results: List[Dict], 
                                        bentham_results: List[Dict], is_ebs: bool, 
                                        structural_analysis: Dict = None) -> None:
        """í•™ìŠµ í†µê³„ ì—…ë°ì´íŠ¸"""
        
        # í˜ì´ì¦ˆ ì „í™˜ í™•ì¸ (ì‹¤ì œ API ì‚¬ìš©)
        # í›„íšŒ ì‹œìŠ¤í…œ: phase ë©”ì„œë“œê°€ ì—†ìœ¼ë¯€ë¡œ í˜„ì¬ ì²˜ë¦¬ëœ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì •
        total_scenarios = self.progress.total_scenarios_processed
        if total_scenarios < 100:
            current_phase = "PHASE_0"
        elif total_scenarios < 300:
            current_phase = "PHASE_1"
        else:
            current_phase = "PHASE_2"
            
        # ê°ì • ì‹œìŠ¤í…œ: phase ê°ì²´ë“¤ ì¡´ì¬ ì—¬ë¶€ë¡œ í™•ì¸
        if hasattr(self.emotion_system, 'phase0_calibrator'):
            emotion_phase = "CALIBRATION"
        elif hasattr(self.emotion_system, 'phase1_learner'):
            emotion_phase = "EMPATHY_LEARNING"
        elif hasattr(self.emotion_system, 'phase2_expander'):
            emotion_phase = "COMMUNITY_EXPANSION"
        else:
            emotion_phase = "UNKNOWN"
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_regret = np.mean([r['regret_intensity'] for r in regret_results])
        avg_hedonic = np.mean([b['hedonic_score'] for b in bentham_results])
        
        performance_metric = {
            'scenario_id': self.progress.total_scenarios_processed,
            'avg_regret_intensity': avg_regret,
            'avg_hedonic_score': avg_hedonic,
            'regret_phase': current_phase,
            'emotion_phase': emotion_phase,
            'is_ebs_data': is_ebs,
            'timestamp': datetime.now().isoformat()
        }
        
        # êµ¬ì¡°ì  ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if structural_analysis:
            performance_metric.update({
                'structural_complexity': structural_analysis.get('structural_complexity', 0.5),
                'surd_available': bool(structural_analysis.get('surd_analysis')),
                'rumbaugh_available': bool(structural_analysis.get('rumbaugh_analysis'))
            })
        
        self.learning_stats['performance_metrics'].append(performance_metric)
    
    async def _log_progress_milestone(self) -> None:
        """ì§„í–‰ ìƒí™© ë§ˆì¼ìŠ¤í†¤ ë¡œê¹…"""
        elapsed_time = datetime.now() - self.progress.start_time
        
        logger.info(f"ğŸ“Š í•™ìŠµ ì§„í–‰ ìƒí™© (ì‹œë‚˜ë¦¬ì˜¤ {self.progress.total_scenarios_processed}ê°œ ì™„ë£Œ)")
        logger.info(f"   â±ï¸  ê²½ê³¼ ì‹œê°„: {elapsed_time}")
        logger.info(f"   ğŸ”„ ì´ í›„íšŒ í•™ìŠµ: {self.progress.total_regrets}íšŒ")
        logger.info(f"   âš–ï¸  ì´ ë²¤ë‹´ ê³„ì‚°: {self.progress.total_bentham_calculations}íšŒ")
        
        # ìµœê·¼ ì„±ëŠ¥ ì§€í‘œ
        if self.learning_stats['performance_metrics']:
            recent_metrics = self.learning_stats['performance_metrics'][-10:]  # ìµœê·¼ 10ê°œ
            avg_regret = np.mean([m['avg_regret_intensity'] for m in recent_metrics])
            avg_hedonic = np.mean([m['avg_hedonic_score'] for m in recent_metrics])
            
            logger.info(f"   ğŸ“ˆ ìµœê·¼ í‰ê·  í›„íšŒ ê°•ë„: {avg_regret:.3f}")
            logger.info(f"   ğŸ“ˆ ìµœê·¼ í‰ê·  ì¾Œë½ ì ìˆ˜: {avg_hedonic:.3f}")
    
    async def _save_learning_results(self) -> Dict[str, Any]:
        """í•™ìŠµ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ìµœì¢… ê²°ê³¼ ìƒì„±
        final_results = {
            'learning_config': asdict(self.config),
            'learning_progress': asdict(self.progress),
            'learning_statistics': self.learning_stats,
            'summary': {
                'total_scenarios_processed': self.progress.total_scenarios_processed,
                'total_regrets': self.progress.total_regrets,
                'total_bentham_calculations': self.progress.total_bentham_calculations,
                'total_duration': str(datetime.now() - self.progress.start_time),
                'regrets_per_scenario': self.config.regrets_per_step,
                'bentham_per_scenario': self.config.regrets_per_step * self.config.bentham_per_environment,
                'ebs_cycles': self.config.ebs_data_cycles,
                'general_cycles': self.config.general_data_cycles
            }
        }
        
        # íŒŒì¼ ì €ì¥
        results_file = os.path.join(LOGS_DIR, f"advanced_learning_results_{timestamp}.json")
        save_json(final_results, str(results_file))
        
        logger.info(f"ğŸ’¾ í•™ìŠµ ê²°ê³¼ ì €ì¥: {results_file}")
        return final_results
    
    async def _perform_structural_analysis(self, title: str, description: str, scenario_data: Dict) -> Dict[str, Any]:
        """êµ¬ì¡°ì  ë¶„ì„ ìˆ˜í–‰ (SURD + Rumbaugh)"""
        logger.debug(f"ğŸ” êµ¬ì¡°ì  ë¶„ì„ ì‹œì‘: {title}")
        
        try:
            # 1. SURD ë¶„ì„ - ì¸ê³¼ê´€ê³„ ë° ì •ë³´ íë¦„ ë¶„ì„
            surd_result = await self._perform_surd_analysis(title, description, scenario_data)
            
            # 2. Rumbaugh ë¶„ì„ - ê°ì²´ ì§€í–¥ êµ¬ì¡° ë¶„ì„
            rumbaugh_result = await self._perform_rumbaugh_analysis(title, description, scenario_data)
            
            # 3. í†µí•© êµ¬ì¡°ì  ë¶„ì„ ê²°ê³¼
            structural_analysis = {
                'surd_analysis': surd_result,
                'rumbaugh_analysis': rumbaugh_result,
                'structural_complexity': self._calculate_structural_complexity(surd_result, rumbaugh_result),
                'analysis_timestamp': datetime.now().isoformat()
            }
            
            logger.debug(f"âœ… êµ¬ì¡°ì  ë¶„ì„ ì™„ë£Œ: ë³µì¡ë„={structural_analysis['structural_complexity']:.3f}")
            return structural_analysis
            
        except Exception as e:
            logger.warning(f"êµ¬ì¡°ì  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'surd_analysis': {},
                'rumbaugh_analysis': {},
                'structural_complexity': 0.5,
                'analysis_timestamp': datetime.now().isoformat(),
                'error': str(e)
            }
    
    async def _perform_surd_analysis(self, title: str, description: str, scenario_data: Dict) -> Dict[str, Any]:
        """SURD ë¶„ì„ ìˆ˜í–‰"""
        try:
            # SURD ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œë‚˜ë¦¬ì˜¤ì˜ ì¸ê³¼ê´€ê³„ ë¶„ì„
            analysis_result = await self.surd_analyzer.analyze_scenario_surd(
                scenario_text=f"{title}\n\n{description}",
                context_data=scenario_data
            )
            return analysis_result
        except Exception as e:
            logger.warning(f"SURD ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    async def _perform_rumbaugh_analysis(self, title: str, description: str, scenario_data: Dict) -> Dict[str, Any]:
        """Rumbaugh êµ¬ì¡°ì  ë¶„ì„ ìˆ˜í–‰"""
        try:
            # Rumbaugh ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œë‚˜ë¦¬ì˜¤ì˜ ê°ì²´ êµ¬ì¡° ë¶„ì„
            analysis_result = await self.rumbaugh_analyzer.analyze_structural_model(
                scenario_text=f"{title}\n\n{description}",
                ethical_context=scenario_data
            )
            return analysis_result
        except Exception as e:
            logger.warning(f"Rumbaugh ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _calculate_structural_complexity(self, surd_result: Dict, rumbaugh_result: Dict) -> float:
        """êµ¬ì¡°ì  ë³µì¡ë„ ê³„ì‚°"""
        try:
            # SURD ë³µì¡ë„ (ì¸ê³¼ê´€ê³„ ë…¸ë“œ ìˆ˜, ìƒí˜¸ì •ë³´ëŸ‰ ë“±)
            surd_complexity = 0.5
            if surd_result and 'causal_graph' in surd_result:
                graph_data = surd_result['causal_graph']
                if 'nodes' in graph_data:
                    surd_complexity = min(len(graph_data['nodes']) / 20.0, 1.0)
            
            # Rumbaugh ë³µì¡ë„ (ê°ì²´ ìˆ˜, ê´€ê³„ ìˆ˜ ë“±)
            rumbaugh_complexity = 0.5
            if rumbaugh_result and 'structural_elements' in rumbaugh_result:
                elements = rumbaugh_result['structural_elements']
                if 'objects' in elements:
                    rumbaugh_complexity = min(len(elements['objects']) / 10.0, 1.0)
            
            # í†µí•© ë³µì¡ë„ (ê°€ì¤‘ í‰ê· )
            combined_complexity = (surd_complexity * 0.6 + rumbaugh_complexity * 0.4)
            return min(max(combined_complexity, 0.0), 1.0)
            
        except Exception as e:
            logger.warning(f"êµ¬ì¡°ì  ë³µì¡ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(name)s | %(levelname)s | %(message)s'
    )
    
    # í•™ìŠµ ì„¤ì •
    config = LearningConfig(
        regrets_per_step=3,  # ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ìš©
        bentham_per_environment=2,  # ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ìš©
        general_data_cycles=1,  # ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ìš©
        ebs_data_cycles=1,  # ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ìš©
        max_scenarios_per_batch=3  # ë² ì´ìŠ¤ë¼ì¸ ê²€ì¦ìš©
    )
    
    # í•™ìŠµ ì‹¤í–‰ê¸° ìƒì„±
    executor = AdvancedLearningExecutor(config)
    
    try:
        # í•™ìŠµ ì‹¤í–‰
        results = await executor.execute_full_learning()
        
        print("\n" + "="*80)
        print("ğŸ‰ Red Heart ê³ ê¸‰ í•™ìŠµ ì™„ë£Œ!")
        print("="*80)
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ì‹œë‚˜ë¦¬ì˜¤: {results['summary']['total_scenarios_processed']}ê°œ")
        print(f"ğŸ”„ ì´ í›„íšŒ í•™ìŠµ: {results['summary']['total_regrets']}íšŒ")
        print(f"âš–ï¸  ì´ ë²¤ë‹´ ê³„ì‚°: {results['summary']['total_bentham_calculations']}íšŒ")
        print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {results['summary']['total_duration']}")
        print("="*80)
        
    except Exception as e:
        logger.error(f"í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())