# Red Heart AI í†µí•© í•™ìŠµ ì‹œìŠ¤í…œ - ì‹¤í–‰ ëª¨ë“œ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

Red Heart AI 730M íŒŒë¼ë¯¸í„° ëª¨ë¸ì˜ ë‹¤ì–‘í•œ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ëª¨ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ëª¨ë“  ëª…ë ¹ì€ `run_learning.sh` ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ì‹¤í–‰ë˜ë©°, ê°€ìƒí™˜ê²½ê³¼ ì˜ì¡´ì„±ì´ ìë™ìœ¼ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.

## ğŸš€ Quick Start

```bash
# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (2 ì—í­)
bash run_learning.sh unified-test

# ìƒ˜í”Œ ì œí•œ í…ŒìŠ¤íŠ¸ (3 ì—í­)
SAMPLES=3 bash run_learning.sh unified-test

# ì „ì²´ í•™ìŠµ (60 ì—í­)
bash run_learning.sh unified-train

# nohupìœ¼ë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (20ë¶„ íƒ€ì„ì•„ì›ƒ)
nohup timeout 1200 bash run_learning.sh unified-test --samples 3 --debug --verbose &
```

## ğŸ”§ ì‹¤í–‰ ëª¨ë“œ ìƒì„¸

### 1. unified-test (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)
**ìš©ë„**: ì‹œìŠ¤í…œ ê²€ì¦ ë° ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
```bash
# ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (2 ì—í­)
bash run_learning.sh unified-test

# ìƒ˜í”Œ ìˆ˜ ì§€ì • (N ì—í­)
SAMPLES=5 bash run_learning.sh unified-test

# ë””ë²„ê·¸ ëª¨ë“œ
bash run_learning.sh unified-test --debug --verbose
```

**íŠ¹ì§•**:
- 730M íŒŒë¼ë¯¸í„° ëª¨ë¸ ì‚¬ìš©
- LR ìŠ¤ìœ• í¬í•¨ (5ê°œ LR í…ŒìŠ¤íŠ¸)
- Sweet Spot íƒì§€ í™œì„±í™”
- Parameter Crossover í¬í•¨
- Advanced Training Techniques í™œì„±í™”
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  (ë°°ì¹˜ ì‚¬ì´ì¦ˆ 2)

### 2. unified-train (ì „ì²´ í•™ìŠµ ëª¨ë“œ)
**ìš©ë„**: 60 ì—í­ ì „ì²´ í•™ìŠµ
```bash
# ê¸°ë³¸ 60 ì—í­ í•™ìŠµ
bash run_learning.sh unified-train

# ì»¤ìŠ¤í…€ ì—í­ ìˆ˜
bash run_learning.sh unified-train --epochs 30

# ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
bash run_learning.sh unified-train --resume training/checkpoints_final/checkpoint_epoch_0020.pt
```

**íŠ¹ì§•**:
- 60 ì—í­ í•™ìŠµ (ì•½ 2-3ì¼ ì†Œìš”)
- ì§ìˆ˜ ì—í­ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ì´ 30ê°œ)
- ëª¨ë“ˆë³„ Sweet Spot ìë™ íƒì§€
- í•™ìŠµ ì™„ë£Œ í›„ Parameter Crossover ì‹¤í–‰
- ìµœì¢… crossover_final.pth ìƒì„±

### 3. unified-test-v1 (ë ˆê±°ì‹œ ëª¨ë“œ)
**ìš©ë„**: ê¸°ì¡´ 800M/320M ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
```bash
bash run_learning.sh unified-test-v1
```

### 4. train-local (ë¡œì»¬ í•™ìŠµ í…ŒìŠ¤íŠ¸)
**ìš©ë„**: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ ì†Œê·œëª¨ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸
```bash
bash run_learning.sh train-local
SAMPLES=10 bash run_learning.sh train-local
```

### 5. validate (ì‹œìŠ¤í…œ ê²€ì¦)
**ìš©ë„**: í•™ìŠµ ì—†ì´ ì‹œìŠ¤í…œ ë¬´ê²°ì„± ê²€ì‚¬
```bash
bash run_learning.sh validate
```

## ğŸ“Š í•™ìŠµ ì„¤ì •

### ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
```python
# ëª¨ë¸ ì„¤ì •
model_params = 730_000_000  # 730M íŒŒë¼ë¯¸í„°
hidden_dim = 1280
num_layers = 18
num_heads = 20

# í•™ìŠµ ì„¤ì •
total_epochs = 60
micro_batch_size = 2  # GPU ë©”ëª¨ë¦¬ ì ˆì•½
gradient_accumulation = 32  # ìœ íš¨ ë°°ì¹˜ = 64
base_lr = 1e-4

# LR ìŠ¤ìœ•
lr_sweep_range = (1e-5, 1e-2)
lr_sweep_points = 5

# Advanced Training
label_smoothing = 0.1
rdrop_alpha = 1.0
ema_decay = 0.999
```

### ë©”ëª¨ë¦¬ ê´€ë¦¬
- **ì´ˆê¸° ë°°ì¹˜ ì‚¬ì´ì¦ˆ**: 2 (ì•ˆì •ì„± ìš°ì„ )
- **OOM í•¸ë“¤ë§**: ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ìë™ ì •ë¦¬ (í´ë°± ë¹„í™œì„±í™”)
- **Gradient Accumulation**: 32 ìŠ¤í… (ìœ íš¨ ë°°ì¹˜ = 64)
- **Dynamic Swap Manager**: ìë™ í™œì„±í™” ê°€ëŠ¥

## ğŸ¯ ê¶Œì¥ ì›Œí¬í”Œë¡œìš°

### 1ë‹¨ê³„: í™˜ê²½ ê²€ì¦
```bash
# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
bash run_learning.sh validate
```

### 2ë‹¨ê³„: ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
```bash
# ë¹ ë¥¸ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
python training/test_unified_training.py --quick
```

### 3ë‹¨ê³„: ë¯¸ë‹ˆ í•™ìŠµ í…ŒìŠ¤íŠ¸
```bash
# 2-3 ì—í­ í…ŒìŠ¤íŠ¸
SAMPLES=3 bash run_learning.sh unified-test --debug
```

### 4ë‹¨ê³„: ë³¸ í•™ìŠµ
```bash
# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (nohup)
nohup bash run_learning.sh unified-train > training.log 2>&1 &

# ë˜ëŠ” screen/tmux ì‚¬ìš©
screen -S training
bash run_learning.sh unified-train
# Ctrl+A, Dë¡œ detach
```

### 5ë‹¨ê³„: ëª¨ë‹ˆí„°ë§
```bash
# ë¡œê·¸ ëª¨ë‹ˆí„°ë§
tail -f training.log

# GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# ì²´í¬í¬ì¸íŠ¸ í™•ì¸
ls -lah training/checkpoints_final/
```

## ğŸ” ë””ë²„ê·¸ ì˜µì…˜

### --debug í”Œë˜ê·¸
ìƒì„¸í•œ ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
```bash
bash run_learning.sh unified-test --debug
```

### --verbose í”Œë˜ê·¸
ëª¨ë“  ë¡œê·¸ ë©”ì‹œì§€ ì¶œë ¥
```bash
bash run_learning.sh unified-test --verbose
```

### --samples N
í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ/ì—í­ ìˆ˜ ì œí•œ
```bash
SAMPLES=5 bash run_learning.sh unified-test
```

## ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
training/
â”œâ”€â”€ checkpoints_final/        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
â”‚   â”œâ”€â”€ checkpoint_epoch_0002_lr_0.000100_*.pt
â”‚   â”œâ”€â”€ checkpoint_epoch_0004_lr_0.000095_*.pt
â”‚   â””â”€â”€ crossover_final.pth   # ìµœì¢… ëª¨ë¸
â”œâ”€â”€ lr_sweep_results/          # LR ìŠ¤ìœ• ê²°ê³¼
â”‚   â”œâ”€â”€ lr_sweep_*.json
â”‚   â””â”€â”€ lr_sweep_plot_*.png
â”œâ”€â”€ sweet_spot_analysis/       # Sweet Spot ë¶„ì„
â”‚   â”œâ”€â”€ sweet_spot_analysis_*.json
â”‚   â”œâ”€â”€ sweet_spot_report_*.txt
â”‚   â””â”€â”€ plots/
â”œâ”€â”€ oom_stats/                 # OOM í†µê³„
â”‚   â””â”€â”€ oom_stats_*.json
â””â”€â”€ logs/                      # í•™ìŠµ ë¡œê·¸
    â””â”€â”€ training_*.log
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­**
   - GPU: ìµœì†Œ 8GB VRAM (RTX 2070S ì´ìƒ)
   - RAM: ìµœì†Œ 16GB (ê¶Œì¥ 32GB)
   - ë””ìŠ¤í¬: ìµœì†Œ 50GB ì—¬ìœ  ê³µê°„

2. **í•™ìŠµ ì‹œê°„**
   - í…ŒìŠ¤íŠ¸ ëª¨ë“œ (2 ì—í­): ì•½ 1-2ì‹œê°„
   - ì „ì²´ í•™ìŠµ (60 ì—í­): ì•½ 2-3ì¼

3. **ë°°ì¹˜ ì‚¬ì´ì¦ˆ**
   - ê¸°ë³¸ê°’ 2 ìœ ì§€ ê¶Œì¥ (ì•ˆì •ì„±)
   - OOM ë°œìƒ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ì¬ì‹œë„

4. **ì²´í¬í¬ì¸íŠ¸**
   - ì§ìˆ˜ ì—í­ë§ˆë‹¤ ìë™ ì €ì¥
   - ìµœëŒ€ 30ê°œ ìœ ì§€ (ì˜¤ë˜ëœ ê²ƒ ìë™ ì‚­ì œ)

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### OOM (Out of Memory) ì—ëŸ¬
```bash
# ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
python -c "import torch; print(torch.cuda.memory_summary())"

# ìºì‹œ ì •ë¦¬
python -c "import torch; torch.cuda.empty_cache()"

# ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¤„ì´ê¸° (ì´ë¯¸ 2ë¡œ ì„¤ì •ë¨)
bash run_learning.sh unified-test --batch-size 1
```

### ê°€ìƒí™˜ê²½ ë¬¸ì œ
```bash
# ê°€ìƒí™˜ê²½ ì¬ìƒì„±
rm -rf red_heart_env
python3 -m venv red_heart_env
source red_heart_env/bin/activate
pip install -r requirements_venv.txt
```

### ì²´í¬í¬ì¸íŠ¸ ë³µêµ¬
```bash
# ìµœì‹  ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
LATEST=$(ls -t training/checkpoints_final/*.pt | head -1)
bash run_learning.sh unified-train --resume $LATEST
```

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ í™•ì¸
```python
# Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ë©”íŠ¸ë¦­ í™•ì¸
import json
with open('training/checkpoints_final/metadata.json') as f:
    metadata = json.load(f)
    for checkpoint in metadata:
        print(f"Epoch {checkpoint['epoch']}: Loss={checkpoint['metrics']['loss']:.4f}")
```

### Sweet Spot ë¶„ì„ í™•ì¸
```bash
# ìµœì‹  Sweet Spot ë¦¬í¬íŠ¸ í™•ì¸
cat training/sweet_spot_analysis/sweet_spot_report_*.txt
```

### í•™ìŠµ ê³¡ì„  ì‹œê°í™”
```python
# ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python training/plot_training_curves.py
```

## ğŸ¯ ìµœì¢… ëª¨ë¸ ì‚¬ìš©

í•™ìŠµ ì™„ë£Œ í›„:
```python
import torch

# Crossover ëª¨ë¸ ë¡œë“œ
model = torch.load('training/checkpoints_final/crossover_final.pth')

# ë˜ëŠ” íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
checkpoint = torch.load('training/checkpoints_final/checkpoint_epoch_0060.pt')
model.load_state_dict(checkpoint['model_state'])
```

## ğŸ“š ì¶”ê°€ ì°¸ê³ ìë£Œ

- [RED_HEART_AI_FINAL_TRAINING_STRATEGY.md](RED_HEART_AI_FINAL_TRAINING_STRATEGY.md) - ì „ì²´ í•™ìŠµ ì „ëµ
- [requirements_venv.txt](requirements_venv.txt) - Python ì˜ì¡´ì„±
- [training/test_unified_training.py](training/test_unified_training.py) - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-08-18
**ëª¨ë¸ ë²„ì „**: 730M (ìµœì¢…)
**ë¬¸ì„œ ë²„ì „**: 1.0