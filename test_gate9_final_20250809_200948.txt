🚀 Red Heart AI 통합 학습 시스템 시작
===========================================
[0;34m[INFO][0m 작업 디렉토리: /mnt/c/large_project/linux_red_heart
[0;34m[INFO][0m Red Heart AI 통합 환경 상태 확인 중...
[0;32m[SUCCESS][0m ✅ red_heart_env 가상환경 존재
[0;32m[SUCCESS][0m ✅ faiss-test conda 환경 존재
[0;32m[SUCCESS][0m ✅ FAISS 설치됨 및 작동 확인
✅ Red Heart AI 통합 환경 활성화 완료
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (함께 활성화됨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;32m[SUCCESS][0m ✅ 주요 패키지 (torch, transformers, numpy) 설치됨
[0;32m[SUCCESS][0m 🎉 모든 환경이 이미 준비되어 있습니다!
✅ Red Heart AI 통합 환경 활성화 완료
   - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
   - conda: faiss-test (함께 활성화됨)
   - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
   - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;32m[SUCCESS][0m ✅ Red Heart AI 통합 환경 활성화 완료
[0;32m[SUCCESS][0m    - venv: /mnt/c/large_project/linux_red_heart/red_heart_env
[0;32m[SUCCESS][0m    - conda: faiss-test 환경 준비됨
[0;32m[SUCCESS][0m    - python: /mnt/c/large_project/linux_red_heart/red_heart_env/bin/python
[0;32m[SUCCESS][0m    - 환경 분리: faiss→conda subprocess, 나머지→venv
[0;34m[INFO][0m Red Heart AI 통합 학습 시스템 시작
[0;34m[INFO][0m 환경 분리: conda(faiss) + venv(transformers,torch)
[0;34m[INFO][0m Red Heart AI 통합 학습 시스템 실행 시작...
[0;34m[INFO][0m 실행 모드: unified-test
[0;34m[INFO][0m 🧪 800M 통합 시스템 테스트 모드...
🔍 [초기화 시작 전] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 0.000GB (0.0%)
   📦 예약됨: 0.000GB
   💚 여유: 8.000GB
   🔄 config.py 측정: 0.0%
/mnt/c/large_project/linux_red_heart/red_heart_env/lib/python3.12/site-packages/torch/__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
   🧠 GPU 텐서: 0개, 0.000GB
   🗂️ 캐시된 메모리: 0.000GB
🔍 fast_init_mode = False
🌐 전역 모듈 순차 초기화 시작 - MasterMemoryOrchestrator 관리
Device set to use cuda:0
Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.
Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cuda:0
요청 전송 실패: 서버 프로세스가 예기치 않게 종료됨
요청 실패 (시도 1/2): 서버 프로세스가 예기치 않게 종료됨
Device set to use cuda:0
Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.
Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cuda:0
요청 실패 (시도 1/2): 서버 프로세스가 실행되지 않음
Device set to use cuda:0
Device set to use cuda:0
언로드 요청된 모델이 레지스트리에 없음: semantic_analyzer
HierarchicalPatternStructure: PyTorch 네트워크가 없음 (딕셔너리 기반 구조)
HierarchicalPatternStructure: PyTorch 네트워크가 없음 (딕셔너리 기반 구조)
   ⚠️ DSM 등록 스킵: neural_components (nn.Module 추출 실패)
⚠️ 클래스 'AdvancedSurdAnalyzer' 대신 'AdvancedSURDAnalyzer' 사용 (유사도 기반)
   ⚠️ DSM 등록 스킵: surd_analyzer (nn.Module 추출 실패)
⚠️ 클래스 'AdvancedBayesianInferenceModule' 대신 'AdvancedBayesianInference' 사용 (유사도 기반)
   ⚠️ DSM 등록 스킵: bayesian_engine (nn.Module 추출 실패)
   ⚠️ DSM 등록 스킵: llm_engine (nn.Module 추출 실패)
   ⚠️ DSM 등록 스킵: experience_database (nn.Module 추출 실패)
   ⚠️ DSM 등록 스킵: hierarchical_emotion (nn.Module 추출 실패)
   ⚠️ DSM 등록 스킵: usage_pattern_analyzer (nn.Module 추출 실패)
⚠️ meta_integration 이미 등록됨 (동일 타입: AdvancedMetaIntegrationSystem), 스킵
⚠️ GPU 사용률이 낮습니다 (47.5%) - 더 적극적 로딩 필요
✅ 전역 모듈 순차 초기화 완료
🔍 [전역 모듈 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 3.780GB (47.3%)
   📦 예약됨: 3.875GB
   💚 여유: 4.220GB
   🔄 config.py 측정: 47.3%
   🧠 GPU 텐서: 1767개, 3.750GB
   📋 큰 텐서 TOP 5:
      1. [50265, 1024] (torch.float32) - 196.3MB
      2. [54343, 768] (torch.float32) - 159.2MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [50265, 768] (torch.float32) - 147.3MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.095GB
   🔝 새로운 Peak 메모리: 3.807GB (at 전역 모듈 초기화 후)
🔍 [백본 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.501GB (68.8%)
   📦 예약됨: 5.629GB
   💚 여유: 2.499GB
   🔄 config.py 측정: 68.8%
   🧠 GPU 텐서: 2011개, 5.435GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.128GB
   🔝 새로운 Peak 메모리: 5.501GB (at 백본 초기화 후)
🔍 [스왑 매니저 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.501GB (68.8%)
   📦 예약됨: 5.629GB
   💚 여유: 2.499GB
   🔄 config.py 측정: 68.8%
   🧠 GPU 텐서: 2011개, 5.435GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.128GB
🔍 [헤드 호환성 매니저 생성 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.501GB (68.8%)
   📦 예약됨: 5.629GB
   💚 여유: 2.499GB
   🔄 config.py 측정: 68.8%
   🧠 GPU 텐서: 2011개, 5.435GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.128GB
🚨 헤드 초기화 시작 - 메모리 폭발 의심 구간!
🔍 head_compatibility_manager = <class 'head_compatibility_interface.HeadCompatibilityManager'>
🔍 head_compatibility_manager.initialized = False
🔍 initialize_all_heads() 호출 직전...
⚠️ 메모리 관리 주의: 69.7% (85% 초과)
📊 추가 활용 가능: 현재 72.4% (목표 82%)
🔍 initialize_all_heads() 호출 완료!
🚨 헤드 초기화 완료 - 메모리 상태 확인 중...
🔍 [모든 헤드 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.794GB (72.4%)
   📦 예약됨: 5.941GB
   💚 여유: 2.205GB
   🔄 config.py 측정: 72.4%
   🧠 GPU 텐서: 2056개, 5.727GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.147GB
   🔝 새로운 Peak 메모리: 5.794GB (at 모든 헤드 초기화 후)
🚨 긴급 GPU 메모리 정리 시작
🚨 초기 GPU 메모리: 72.4% 사용 중
🔍 실제 GPU 상주 모델 전면 스캔 시작...
🔍 PyTorch 실제 메모리: 할당=5.79GB, 예약=5.94GB
🗑️ 총 334개 모델 중 CRITICAL 외 모든 모델 언로드 시작
🧹 최종 전면 메모리 정리 시작...
🧹 가비지 컬렉션 1회: 256개 객체 정리
🧹 가비지 컬렉션 2회: 0개 객체 정리
🧹 가비지 컬렉션 3회: 0개 객체 정리
🚀 CUDA 캐시 완전 정리 완료
✅ 긴급 정리 완료:
   📊 메모리 사용률: 72.4% → 72.4% (+0.0%)
   🗑️ 언로드된 모델: 0개
   💾 해제된 메모리: 0MB
🔍 [자동 메모리 정리 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.794GB (72.4%)
   📦 예약됨: 5.941GB
   💚 여유: 2.205GB
   🔄 config.py 측정: 72.4%
   🧠 GPU 텐서: 2056개, 5.727GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.147GB
🔍 [시너지 시스템 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 5.794GB (72.4%)
   📦 예약됨: 5.941GB
   💚 여유: 2.205GB
   🔄 config.py 측정: 72.4%
   🧠 GPU 텐서: 2056개, 5.727GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50265, 1024] (torch.float32) - 196.3MB
      3. [54343, 768] (torch.float32) - 159.2MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [50265, 768] (torch.float32) - 147.3MB
   🗂️ 캐시된 메모리: 0.147GB
🔍 [학습 시스템 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 7.516GB (94.0%)
   📦 예약됨: 7.697GB
   💚 여유: 0.484GB
   🔄 config.py 측정: 94.0%
   🧠 GPU 텐서: 2300개, 7.412GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50265, 1024] (torch.float32) - 196.3MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   🗂️ 캐시된 메모리: 0.181GB
   ⚠️ WARNING: 높은 메모리 사용률 (94.0%)
   🔝 새로운 Peak 메모리: 7.516GB (at 학습 시스템 초기화 후)
🔍 [패턴 분석기 초기화 후] GPU 메모리 상태:
   💾 총 메모리: 8.00GB
   📊 할당됨: 7.516GB (94.0%)
   📦 예약됨: 7.697GB
   💚 여유: 0.484GB
   🔄 config.py 측정: 94.0%
   🧠 GPU 텐서: 2300개, 7.412GB
   📋 큰 텐서 TOP 5:
      1. [50000, 1280] (torch.float32) - 244.1MB
      2. [50000, 1280] (torch.float32) - 244.1MB
      3. [50265, 1024] (torch.float32) - 196.3MB
      4. [54343, 768] (torch.float32) - 159.2MB
      5. [54343, 768] (torch.float32) - 159.2MB
   🗂️ 캐시된 메모리: 0.181GB
   ⚠️ WARNING: 높은 메모리 사용률 (94.0%)
🚨 HIGH GPU MEMORY ALERT: 94.0% 사용 중!
   할당된 메모리: 7.52GB
   예약된 메모리: 7.70GB
   여유 메모리: 0.48GB
   전체 메모리: 8.00GB
📊 TORCH.CUDA 상세 정보:
   memory_allocated(): 7.516GB
   memory_reserved(): 7.697GB
   max_memory_allocated(): 7.516GB
   max_memory_reserved(): 7.697GB
🔍 메모리 사용률 계산 비교:
   할당 기준: 93.96%
   예약 기준: 96.22%
   config.py 기준: 93.96%
🔍 GPU 모듈별 메모리 분석 (1개 모듈):
   📦 unified_backbone:
      파라미터: 441,815,040개
      메모리: 1685.39MB
      디바이스: cuda:0
      훈련 모드: True
🔢 전체 추적된 파라미터: 441,815,040개
🧠 GPU 텐서 분석:
   GPU 텐서 개수: 2300개
   GPU 텐서 메모리: 7.412GB
============================================================
🚀 Red Heart AI 통합 시스템 (800M 파라미터)
============================================================
모드: test
시작 시간: 2025-08-09 20:11:12
------------------------------------------------------------

신호 15 수신 - 시스템 종료 중...
🔧 klue/bert-base 모델: 안정성 보장을 위한 15.0% 할당
📋 Transformer 모델: 최적화된 배치 처리 방식 활성화
[20:20:35] ✅ 시스템 초기화 완료
[20:20:35] 🧪 테스트 모드 시작...
[20:20:36] ✅ 테스트 모드 완료

==================================================
🧪 테스트 결과 요약
==================================================
시스템 상태: ready
전체 건강도: 80.0%
복구 시도: 0회
==================================================
[1;33m[WARNING][0m 학습 중단됨
[0;34m[INFO][0m 학습 시스템 정리 중...
[0;34m[INFO][0m GPU 메모리 정리...
[0;32m[SUCCESS][0m 정리 완료
[0;34m[INFO][0m 학습 시스템 정리 중...
[0;34m[INFO][0m GPU 메모리 정리...
[0;32m[SUCCESS][0m 정리 완료
