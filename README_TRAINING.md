# Red Heart XAI ν›„ν κΈ°λ° ν•™μµ μ‹μ¤ν…

## π― ν•™μµ μ¤€λΉ„ μ™„λ£

μ‹μ¤ν…μ΄ ν•™μµ κ°€λ¥ν• μƒνƒλ΅ μ¤€λΉ„λμ—μµλ‹λ‹¤.

### π“ ν•™μµ μ„¤μ •

- **ν›„ν νμ**: 7ν/μ¤ν…
- **λ²¤λ‹΄ μΎλ½ κ³„μ‚°**: 3ν/ν›„ν (μ΄ 21ν/μ¤ν…)
- **ν•™μµ μ„ ν**: 3λ² (3 epochs)
- **λ΅κΉ… μ£ΌκΈ°**: 20μ¤ν…λ§λ‹¤
- **μ¤ν† λ¦¬μ§€ ν•κ³„**: 200GB
- **λ¨λΈ νλΌλ―Έν„°**: 2μ–µκ°

### π€ ν•™μµ μ‹μ‘ λ°©λ²•

ν•™μµμ„ μ‹μ‘ν•λ ¤λ©΄ λ‹¤μ λ…λ Ήμ„ μ‹¤ν–‰ν•μ„Έμ”:

```bash
cd /mnt/c/large_project/linux_red_heart
python training/start_training.py
```

λλ” Pythonμ—μ„ μ§μ ‘:

```python
from training.regret_based_training_pipeline import RegretTrainer, RegretTrainingConfig

# μ„¤μ • μƒμ„±
config = RegretTrainingConfig(
    regrets_per_step=7,
    bentham_calculations_per_regret=3,
    epochs=3,
    log_every_n_steps=20,
    max_storage_gb=200.0
)

# ν•™μµ μ‹¤ν–‰
trainer = RegretTrainer(config)
report, checkpoint = trainer.train()
```

### π“ λ°μ΄ν„°μ…‹ μ •λ³΄

- **μ΄ μ‹λ‚λ¦¬μ¤**: 28,882κ°
- **λ°μ΄ν„° μ†μ¤**: Scruples, λ¬Έν•™, ν•κµ­ λ¬Έν™”, AI μƒμ„±
- **λ³µμ΅λ„**: 69.4% λ†’μ€ λ³µμ΅λ„, 30.6% μ¤‘κ°„ λ³µμ΅λ„

### π”§ μ£Όμ” κµ¬μ„± μ”μ†

#### 1. ν›„ν κ³„μ‚° μ‹μ¤ν…
- **5κ°€μ§€ ν›„ν μ ν•**: λ°μ‚¬μ‹¤μ , μ‹κ°„μ , λ„λ•μ , κΈ°ν, μ‚¬νμ 
- **λ²¤λ‹΄ μΎλ½ κ³„μ‚°**: 7κ°€μ§€ μ”μ† (κ°•λ„, μ§€μ†μ„±, ν™•μ‹¤μ„±, κ·Όμ ‘μ„±, λ‹¤μ‚°μ„±, μμμ„±, λ²”μ„)

#### 2. λ¨λΈ κµ¬μ΅°
- **λ©”κ°€ μ¤μΌ€μΌ XAI λ¨λΈ**: 33μ–µ νλΌλ―Έν„°
- **κ³„μΈµμ  κ°μ • λ¨λΈ**: λ‹¤λ‹¨κ³„ κ°μ • μ²λ¦¬
- **XAI μ¶”μ **: μ‹¤μ‹κ°„ μ„¤λ… μƒμ„±
- **LLM ν†µν•©**: μ–Έμ–΄ λ¨λΈ μ—°λ™

#### 3. ν•™μµ μµμ ν™”
- **κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν…**: λ©”λ¨λ¦¬ ν¨μ¨μ„±
- **λ™μ  μ¤ν† λ¦¬μ§€ κ΄€λ¦¬**: μλ™ λ΅κ·Έ μ •λ¦¬
- **λ°°μΉ μ²λ¦¬**: ν¨μ¨μ μΈ λ°μ΄ν„° λ΅λ”©

### π“ λ¨λ‹ν„°λ§

ν•™μµ μ¤‘ λ‹¤μ λ©”νΈλ¦­μ΄ λ¨λ‹ν„°λ§λ©λ‹λ‹¤:

- **μ†μ‹¤ νΈλ λ“**: μ΄ μ†μ‹¤, λ¶„λ¥ μ†μ‹¤
- **ν›„ν μƒμ„±**: μ¤ν…λ‹Ή ν›„ν μ, ν¨μ¨μ„±
- **λ²¤λ‹΄ κ³„μ‚°**: κ³„μ‚° μ, ν‰κ·  μ μ
- **μ‹μ¤ν… μμ›**: λ©”λ¨λ¦¬, μ¤ν† λ¦¬μ§€ μ‚¬μ©λ‰
- **XAI μ¶”μ **: λ΅κ·Έ μƒμ„±, μ‹ λΆ°λ„

### π“ κ²°κ³Ό λ¶„μ„

ν•™μµ μ™„λ£ ν›„ μλ™μΌλ΅ μƒμ„±λλ” λ¬Έμ„:

1. **λ§ν¬λ‹¤μ΄ λ¦¬ν¬νΈ** (`docs/training_report_*.md`)
2. **HTML λ€μ‹λ³΄λ“** (`docs/training_report_*.html`)
3. **μ‹κ°ν™”** (`docs/visualizations/`)
4. **μ”μ•½ JSON** (`docs/latest_training_summary.json`)

### π” λ¶„μ„ λ‚΄μ©

- **κΈ°λ³Έ λ©”νΈλ¦­**: μ¤ν… μ, ν›„ν μ, λ²¤λ‹΄ κ³„μ‚°, ν•™μµ μ‹κ°„
- **ν¨μ¨μ„± λ¶„μ„**: μ‹κ°„λ‹Ή μ²λ¦¬λ‰, μμ› μ‚¬μ© ν¨μ¨μ„±
- **ν›„ν ν¨ν„΄**: ν›„ν μƒμ„± ν¨ν„΄, λ²¤λ‹΄ κ³„μ‚° λ¶„ν¬
- **μ„±λ¥ νΈλ λ“**: μ†μ‹¤ κ°μ„ , μλ ΄ λ¶„μ„
- **κ¶μ¥μ‚¬ν•­**: μµμ ν™” μ μ•, λ¬Έμ μ  μ§€μ 

### β οΈ μ£Όμμ‚¬ν•­

- **μ¤ν† λ¦¬μ§€**: 200GB ν•κ³„ λ¨λ‹ν„°λ§
- **λ©”λ¨λ¦¬**: GPU λ©”λ¨λ¦¬ κ΄€λ¦¬
- **μ¤‘λ‹¨**: Ctrl+Cλ΅ μ•μ „ μ¤‘λ‹¨ κ°€λ¥
- **μ²΄ν¬ν¬μΈνΈ**: μλ™ μ €μ¥μΌλ΅ μ¤‘λ‹¨ μ§€μ λ¶€ν„° μ¬μ‹μ‘ κ°€λ¥

### π› οΈ λ¬Έμ  ν•΄κ²°

#### λ©”λ¨λ¦¬ λ¶€μ΅±
```python
# λ°°μΉ ν¬κΈ° κ°μ†
config.batch_size = 8
```

#### μ¤ν† λ¦¬μ§€ λ¶€μ΅±
```python
# λ΅κΉ… μ£ΌκΈ° μ¦κ°€
config.log_every_n_steps = 50
```

#### ν•™μµ μ†λ„ κ°μ„ 
```python
# κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν… λΉ„ν™μ„±ν™” (λ©”λ¨λ¦¬ μ¶©λ¶„ν• κ²½μ°)
config.use_gradient_checkpointing = False
```

---

**μ¤€λΉ„ μ™„λ£! μ–Έμ λ“ μ§€ ν•™μµμ„ μ‹μ‘ν•μ„Έμ”.**

```bash
python training/start_training.py
```