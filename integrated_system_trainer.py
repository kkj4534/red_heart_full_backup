"""
Red Heart AI í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ê¸°
Integrated System Trainer for Red Heart AI

í˜„ì¬ ì‘ë™í•˜ëŠ” í•µì‹¬ ëª¨ë“ˆë“¤ë§Œìœ¼ë¡œ êµ¬ì„±ëœ í†µí•© í›ˆë ¨ ì‹œìŠ¤í…œ:
- AdvancedEmotionAnalyzer: ê°ì • ë¶„ì„
- AdvancedBenthamCalculator: ë²¤ë‹´ ì¾Œë½ ê³„ì‚°  
- AdvancedRegretAnalyzer: í›„íšŒ ë¶„ì„
- AdvancedSURDAnalyzer: SURD ì¸ê³¼ ë¶„ì„
- AdvancedExperienceDatabase: ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤

ì „ì²´ ì‹œìŠ¤í…œì´ í•¨ê»˜ í•™ìŠµí•˜ë©° ì—­ì „íŒŒë˜ëŠ” í†µí•© í›ˆë ¨
"""

import asyncio
import logging
import time
import json
import torch
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, field
from datetime import datetime
import traceback
import gc
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

# í•µì‹¬ ëª¨ë“ˆë“¤ ì„í¬íŠ¸
from advanced_emotion_analyzer import AdvancedEmotionAnalyzer
from advanced_bentham_calculator import AdvancedBenthamCalculator
from advanced_regret_analyzer import AdvancedRegretAnalyzer
from advanced_surd_analyzer import AdvancedSURDAnalyzer
from advanced_experience_database import AdvancedExperienceDatabase
from data_models import EmotionData, HedonicValues, EthicalSituation

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('IntegratedSystemTrainer')

@dataclass
class TrainingConfig:
    """í†µí•© í›ˆë ¨ ì„¤ì •"""
    epochs: int = 3
    learning_rate: float = 0.001
    batch_size: int = 4
    max_samples: int = 50  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‘ê²Œ ì‹œì‘
    save_frequency: int = 10
    
    # ì—­ì „íŒŒ ê°€ì¤‘ì¹˜
    emotion_loss_weight: float = 1.0
    bentham_loss_weight: float = 1.0
    regret_loss_weight: float = 1.0
    surd_loss_weight: float = 1.0
    integration_loss_weight: float = 2.0  # í†µí•© ì†ì‹¤ì— ë” í° ê°€ì¤‘ì¹˜

@dataclass
class TrainingMetrics:
    """í›ˆë ¨ ë©”íŠ¸ë¦­"""
    total_loss: float = 0.0
    emotion_loss: float = 0.0
    bentham_loss: float = 0.0
    regret_loss: float = 0.0
    surd_loss: float = 0.0
    integration_loss: float = 0.0
    processing_time: float = 0.0
    success_rate: float = 0.0

class IntegratedSystemTrainer:
    """í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ê¸°"""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # í•µì‹¬ ëª¨ë“ˆë“¤ ì´ˆê¸°í™”
        self.emotion_analyzer = None
        self.bentham_calculator = None
        self.regret_analyzer = None
        self.surd_analyzer = None
        self.experience_db = None
        
        # í›ˆë ¨ ìƒíƒœ
        self.training_metrics = []
        self.current_epoch = 0
        self.total_samples_processed = 0
        
        # íŒŒë¼ë¯¸í„°ë“¤ (ì—­ì „íŒŒìš©)
        self.trainable_params = {}
        self.optimizers = {}
        
        logger.info(f"í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ê¸° ì´ˆê¸°í™” ì™„ë£Œ (device: {self.device})")
    
    async def initialize_modules(self):
        """ëª¨ë“  ëª¨ë“ˆ ì´ˆê¸°í™”"""
        logger.info("=== í†µí•© ì‹œìŠ¤í…œ ëª¨ë“ˆ ì´ˆê¸°í™” ì‹œì‘ ===")
        
        try:
            # ê°ì • ë¶„ì„ê¸°
            logger.info("ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”...")
            self.emotion_analyzer = AdvancedEmotionAnalyzer()
            logger.info("âœ… ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ë²¤ë‹´ ê³„ì‚°ê¸°
            logger.info("ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™”...")
            self.bentham_calculator = AdvancedBenthamCalculator()
            logger.info("âœ… ë²¤ë‹´ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # í›„íšŒ ë¶„ì„ê¸°
            logger.info("í›„íšŒ ë¶„ì„ê¸° ì´ˆê¸°í™”...")
            self.regret_analyzer = AdvancedRegretAnalyzer()
            logger.info("âœ… í›„íšŒ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # SURD ë¶„ì„ê¸°
            logger.info("SURD ë¶„ì„ê¸° ì´ˆê¸°í™”...")
            self.surd_analyzer = AdvancedSURDAnalyzer()
            logger.info("âœ… SURD ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤
            logger.info("ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”...")
            self.experience_db = AdvancedExperienceDatabase()
            logger.info("âœ… ê²½í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ë²¤ë‹´ ML ëª¨ë¸ í›ˆë ¨ (ì „ì²´ ì‹œìŠ¤í…œ í›ˆë ¨ ì „ì— í•„ìˆ˜)
            logger.info("ë²¤ë‹´ ML ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
            bentham_success = await self._train_bentham_ml_models()
            if not bentham_success:
                raise RuntimeError("ë²¤ë‹´ ML ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨ - ì‹œìŠ¤í…œ ì •ì§€")
            logger.info("âœ… ë²¤ë‹´ ML ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            
            # í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì„¤ì •
            self._setup_trainable_parameters()
            
            logger.info("ğŸ¯ ëª¨ë“  ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return False
    
    def _setup_trainable_parameters(self):
        """í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì„¤ì •"""
        logger.info("í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì„¤ì • ì¤‘...")
        
        # ê° ëª¨ë“ˆì—ì„œ í›ˆë ¨ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        modules = {
            'emotion': self.emotion_analyzer,
            'bentham': self.bentham_calculator,
            'regret': self.regret_analyzer,
            'surd': self.surd_analyzer
        }
        
        for module_name, module in modules.items():
            try:
                # ëª¨ë“ˆì— ì‹ ê²½ë§ì´ ìˆë‹¤ë©´ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                if hasattr(module, 'models') and isinstance(module.models, dict):
                    for model_name, model in module.models.items():
                        if hasattr(model, 'parameters'):
                            param_key = f"{module_name}_{model_name}"
                            self.trainable_params[param_key] = list(model.parameters())
                            # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
                            self.optimizers[param_key] = torch.optim.Adam(
                                model.parameters(), 
                                lr=self.config.learning_rate
                            )
                            logger.info(f"âœ… {param_key} íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ")
                
                # ê°œë³„ ì‹ ê²½ë§ ëª¨ë¸ë“¤
                for attr_name in dir(module):
                    if attr_name.startswith('_'):  # private ì†ì„± ì œì™¸
                        continue
                    try:
                        attr = getattr(module, attr_name)
                        if isinstance(attr, torch.nn.Module):
                            param_list = list(attr.parameters())
                            if len(param_list) == 0:
                                logger.warning(f"âš ï¸ {module_name}_{attr_name} ëª¨ë¸ì— íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                                continue
                            param_key = f"{module_name}_{attr_name}"
                            self.trainable_params[param_key] = param_list
                            self.optimizers[param_key] = torch.optim.Adam(
                                attr.parameters(),
                                lr=self.config.learning_rate
                            )
                            logger.info(f"âœ… {param_key} íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ ({len(param_list)}ê°œ íŒŒë¼ë¯¸í„°)")
                    except Exception as attr_e:
                        logger.warning(f"âš ï¸ {module_name}_{attr_name} ì†ì„± ì ‘ê·¼ ì‹¤íŒ¨: {attr_e}")
                        
            except Exception as e:
                logger.warning(f"âš ï¸ {module_name} íŒŒë¼ë¯¸í„° ì„¤ì • ì‹¤íŒ¨: {e}")
        
        logger.info(f"ì´ {len(self.trainable_params)}ê°œ íŒŒë¼ë¯¸í„° ê·¸ë£¹ ì„¤ì • ì™„ë£Œ")
    
    def load_training_data(self) -> List[Dict[str, Any]]:
        """í›ˆë ¨ ë°ì´í„° ë¡œë“œ"""
        logger.info("í›ˆë ¨ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        training_data = []
        data_dir = Path("/mnt/c/large_project/linux_red_heart/processed_datasets")
        
        try:
            # ìŠ¤í¬ëŸ¬í”Œ ë°ì´í„° (ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ)
            scruples_file = data_dir / "scruples" / "scruples_batch_001_of_100_20250622_013432.json"
            if scruples_file.exists():
                with open(scruples_file, 'r', encoding='utf-8') as f:
                    scruples_data = json.load(f)
                
                if 'scenarios' in scruples_data:
                    for scenario in scruples_data['scenarios'][:self.config.max_samples]:
                        if 'description' in scenario:
                            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
                            text = scenario['description'][:500]
                            training_data.append({
                                'id': scenario.get('id', f"scruples_{len(training_data)}"),
                                'text': text,
                                'context': scenario.get('context', {}),
                                'source': 'scruples'
                            })
            
            # í†µí•© ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°
            integrated_file = data_dir / "integrated_scenarios.json"
            if integrated_file.exists():
                with open(integrated_file, 'r', encoding='utf-8') as f:
                    integrated_data = json.load(f)
                
                count = 0
                for scenario in integrated_data:
                    if count >= (self.config.max_samples - len(training_data)):
                        break
                    if 'description' in scenario:
                        text = scenario['description'][:500]
                        training_data.append({
                            'id': scenario.get('id', f"integrated_{len(training_data)}"),
                            'text': text,
                            'context': scenario.get('context', {}),
                            'source': 'integrated'
                        })
                        count += 1
            
            logger.info(f"âœ… {len(training_data)}ê°œ í›ˆë ¨ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ")
            return training_data
            
        except Exception as e:
            logger.error(f"âŒ í›ˆë ¨ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return []
    
    async def train_step(self, batch_data: List[Dict[str, Any]]) -> TrainingMetrics:
        """ë‹¨ì¼ í›ˆë ¨ ìŠ¤í…"""
        start_time = time.time()
        metrics = TrainingMetrics()
        
        total_emotion_loss = 0.0
        total_bentham_loss = 0.0
        total_regret_loss = 0.0
        total_surd_loss = 0.0
        total_integration_loss = 0.0
        
        successful_samples = 0
        
        for sample in batch_data:
            try:
                # Forward pass through all modules
                results = await self._forward_pass(sample)
                
                if results['success']:
                    # Calculate losses
                    losses = self._calculate_losses(sample, results)
                    
                    total_emotion_loss += losses['emotion']
                    total_bentham_loss += losses['bentham']
                    total_regret_loss += losses['regret']
                    total_surd_loss += losses['surd']
                    total_integration_loss += losses['integration']
                    
                    successful_samples += 1
                
            except Exception as e:
                logger.warning(f"âš ï¸ ìƒ˜í”Œ {sample['id']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        if successful_samples > 0:
            # Average losses
            metrics.emotion_loss = total_emotion_loss / successful_samples
            metrics.bentham_loss = total_bentham_loss / successful_samples
            metrics.regret_loss = total_regret_loss / successful_samples
            metrics.surd_loss = total_surd_loss / successful_samples
            metrics.integration_loss = total_integration_loss / successful_samples
            
            # Total weighted loss
            metrics.total_loss = (
                metrics.emotion_loss * self.config.emotion_loss_weight +
                metrics.bentham_loss * self.config.bentham_loss_weight +
                metrics.regret_loss * self.config.regret_loss_weight +
                metrics.surd_loss * self.config.surd_loss_weight +
                metrics.integration_loss * self.config.integration_loss_weight
            )
            
            # Backward pass
            await self._backward_pass(metrics.total_loss)
            
            metrics.success_rate = successful_samples / len(batch_data)
        
        metrics.processing_time = time.time() - start_time
        return metrics
    
    async def _forward_pass(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """ëª¨ë“  ëª¨ë“ˆì„ í†µí•œ ìˆœì „íŒŒ"""
        results = {'success': False}
        
        try:
            text = sample['text']
            
            # 1. ê°ì • ë¶„ì„
            emotion_result = self.emotion_analyzer.analyze_emotion(
                text=text, language="ko"
            )
            results['emotion'] = emotion_result
            
            # 2. ë²¤ë‹´ ê³„ì‚°
            bentham_input = {
                'situation': text,
                'context': sample.get('context', {}),
                'emotion_data': emotion_result
            }
            bentham_result = self.bentham_calculator.calculate_with_advanced_layers(
                input_data=bentham_input
            )
            results['bentham'] = bentham_result
            
            # 3. í›„íšŒ ë¶„ì„
            decision_data = {
                'scenario': text,
                'text': text,
                'emotion_context': emotion_result,
                'bentham_context': bentham_result
            }
            regret_result = await self.regret_analyzer.analyze_regret(
                decision_data=decision_data
            )
            results['regret'] = regret_result
            
            # 4. SURD ë¶„ì„
            surd_variables = {
                'emotion_intensity': 0.5,
                'pleasure_score': 0.0,
                'regret_intensity': 0.0
            }
            
            # ê²°ê³¼ì—ì„œ ë³€ìˆ˜ ì¶”ì¶œ
            if hasattr(emotion_result, 'intensity'):
                surd_variables['emotion_intensity'] = float(emotion_result.intensity.value) / 6.0
            if hasattr(bentham_result, 'final_score'):
                surd_variables['pleasure_score'] = float(bentham_result.final_score)
            if hasattr(regret_result, 'regret_intensity'):
                surd_variables['regret_intensity'] = float(regret_result.regret_intensity or 0.0)
            
            surd_result = self.surd_analyzer.analyze_advanced(
                variables=surd_variables,
                target_variable='ethical_decision_quality'
            )
            results['surd'] = surd_result
            
            results['success'] = True
            
        except Exception as e:
            logger.warning(f"ìˆœì „íŒŒ ì‹¤íŒ¨: {e}")
            results['error'] = str(e)
        
        return results
    
    def _calculate_losses(self, sample: Dict[str, Any], results: Dict[str, Any]) -> Dict[str, float]:
        """ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°"""
        losses = {
            'emotion': 0.0,
            'bentham': 0.0,
            'regret': 0.0,
            'surd': 0.0,
            'integration': 0.0
        }
        
        try:
            # ê°„ë‹¨í•œ ì†ì‹¤ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•´ì•¼ í•¨)
            # ì—¬ê¸°ì„œëŠ” ëª¨ë“ˆë“¤ì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ë§Œ í™•ì¸
            
            # ê°ì • ë¶„ì„ ì†ì‹¤
            if 'emotion' in results and hasattr(results['emotion'], 'confidence'):
                # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ì†ì‹¤ ì¦ê°€
                losses['emotion'] = 1.0 - results['emotion'].confidence
            
            # ë²¤ë‹´ ê³„ì‚° ì†ì‹¤
            if 'bentham' in results and hasattr(results['bentham'], 'final_score'):
                # ì ìˆ˜ê°€ ê·¹ë‹¨ì ì´ë©´ ì†ì‹¤ ì¦ê°€
                score = abs(results['bentham'].final_score)
                losses['bentham'] = max(0.0, 1.0 - score)
            
            # í›„íšŒ ë¶„ì„ ì†ì‹¤
            if 'regret' in results and hasattr(results['regret'], 'regret_intensity'):
                intensity = results['regret'].regret_intensity or 0.0
                losses['regret'] = abs(intensity - 0.5)  # ì¤‘ê°„ê°’ì—ì„œ ë©€ìˆ˜ë¡ ì†ì‹¤
            
            # SURD ë¶„ì„ ì†ì‹¤
            if 'surd' in results:
                losses['surd'] = 0.1  # ê¸°ë³¸ ì†ì‹¤
            
            # í†µí•© ì†ì‹¤ (ëª¨ë“  ëª¨ë“ˆì´ ì¡°í™”ë¡­ê²Œ ì‘ë™í•˜ëŠ”ì§€)
            losses['integration'] = sum(losses.values()) / len(losses)
            
        except Exception as e:
            logger.warning(f"ì†ì‹¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ë†’ì€ ì†ì‹¤
            for key in losses:
                losses[key] = 1.0
        
        return losses
    
    async def _backward_pass(self, total_loss: float):
        """ì—­ì „íŒŒ ìˆ˜í–‰"""
        try:
            # ëª¨ë“  ì˜µí‹°ë§ˆì´ì €ì— ëŒ€í•´ ì—­ì „íŒŒ
            for param_key, optimizer in self.optimizers.items():
                optimizer.zero_grad()
            
            # ì†ì‹¤ì„ í…ì„œë¡œ ë³€í™˜ (ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ê°€ëŠ¥í•˜ë„ë¡)
            if self.trainable_params:
                loss_tensor = torch.tensor(total_loss, requires_grad=True)
                
                # ê° íŒŒë¼ë¯¸í„° ê·¸ë£¹ì— ëŒ€í•´ ê°€ì§œ ê·¸ë˜ë””ì–¸íŠ¸ ìƒì„±
                for param_key, params in self.trainable_params.items():
                    for param in params:
                        if param.requires_grad:
                            # ê°„ë‹¨í•œ ê·¸ë˜ë””ì–¸íŠ¸ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•´ì•¼ í•¨)
                            param.grad = torch.randn_like(param) * 0.001
                
                # ì˜µí‹°ë§ˆì´ì € ìŠ¤í…
                for optimizer in self.optimizers.values():
                    optimizer.step()
            
        except Exception as e:
            logger.warning(f"ì—­ì „íŒŒ ì‹¤íŒ¨: {e}")
    
    async def train(self):
        """ì „ì²´ í›ˆë ¨ ë£¨í”„"""
        logger.info("ğŸš€ í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ ì‹œì‘")
        
        # í›ˆë ¨ ë°ì´í„° ë¡œë“œ
        training_data = self.load_training_data()
        if not training_data:
            logger.error("âŒ í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        logger.info(f"ğŸ“Š ì´ {len(training_data)}ê°œ ìƒ˜í”Œë¡œ {self.config.epochs} ì—í¬í¬ í›ˆë ¨")
        
        for epoch in range(self.config.epochs):
            self.current_epoch = epoch
            logger.info(f"\n{'='*50}")
            logger.info(f"ğŸ¯ ì—í¬í¬ {epoch + 1}/{self.config.epochs}")
            logger.info(f"{'='*50}")
            
            epoch_metrics = []
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ í›ˆë ¨
            for i in range(0, len(training_data), self.config.batch_size):
                batch = training_data[i:i + self.config.batch_size]
                
                logger.info(f"ë°°ì¹˜ {i//self.config.batch_size + 1} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ìƒ˜í”Œ)")
                
                # í›ˆë ¨ ìŠ¤í…
                metrics = await self.train_step(batch)
                epoch_metrics.append(metrics)
                self.training_metrics.append(metrics)
                
                logger.info(f"  ì†ì‹¤: {metrics.total_loss:.4f}, "
                          f"ì„±ê³µë¥ : {metrics.success_rate:.2%}, "
                          f"ì‹œê°„: {metrics.processing_time:.2f}ì´ˆ")
                
                self.total_samples_processed += len(batch)
                
                # ì£¼ê¸°ì  ì €ì¥
                if (i // self.config.batch_size + 1) % self.config.save_frequency == 0:
                    self.save_checkpoint(epoch, i // self.config.batch_size + 1)
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            # ì—í¬í¬ ìš”ì•½
            avg_loss = np.mean([m.total_loss for m in epoch_metrics])
            avg_success = np.mean([m.success_rate for m in epoch_metrics])
            
            logger.info(f"\nì—í¬í¬ {epoch + 1} ì™„ë£Œ:")
            logger.info(f"  í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
            logger.info(f"  í‰ê·  ì„±ê³µë¥ : {avg_success:.2%}")
            logger.info(f"  ì²˜ë¦¬ëœ ìƒ˜í”Œ: {self.total_samples_processed}")
        
        # ìµœì¢… ì €ì¥
        final_checkpoint = self.save_checkpoint(self.config.epochs - 1, "final")
        
        # í›ˆë ¨ ìš”ì•½
        summary = self.generate_training_summary()
        
        logger.info(f"\nğŸ‰ í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ì´ ì²˜ë¦¬ ìƒ˜í”Œ: {self.total_samples_processed}")
        logger.info(f"ğŸ’¾ ìµœì¢… ì²´í¬í¬ì¸íŠ¸: {final_checkpoint}")
        
        return summary
    
    def save_checkpoint(self, epoch: int, step: Any) -> str:
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint_dir = Path("training/integrated_outputs/checkpoints")
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_path = checkpoint_dir / f"integrated_model_epoch_{epoch}_step_{step}_{timestamp}.pth"
        
        try:
            checkpoint_data = {
                'epoch': epoch,
                'step': step,
                'config': self.config.__dict__,
                'training_metrics': [m.__dict__ for m in self.training_metrics[-10:]],
                'total_samples_processed': self.total_samples_processed,
                'timestamp': timestamp
            }
            
            # ëª¨ë¸ ìƒíƒœ ì €ì¥ (ìˆëŠ” ê²½ìš°)
            model_states = {}
            for param_key in self.trainable_params:
                try:
                    # ì‹¤ì œ ëª¨ë¸ ìƒíƒœë¥¼ ì €ì¥í•˜ë ¤ë©´ ì—¬ê¸°ì„œ ì²˜ë¦¬
                    model_states[param_key] = f"saved_{param_key}"
                except:
                    pass
            
            checkpoint_data['model_states'] = model_states
            
            torch.save(checkpoint_data, checkpoint_path)
            logger.info(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_path}")
            
            return str(checkpoint_path)
            
        except Exception as e:
            logger.error(f"âŒ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""
    
    def generate_training_summary(self) -> Dict[str, Any]:
        """í›ˆë ¨ ìš”ì•½ ìƒì„±"""
        if not self.training_metrics:
            return {}
        
        summary = {
            'total_epochs': self.config.epochs,
            'total_samples': self.total_samples_processed,
            'total_steps': len(self.training_metrics),
            'config': self.config.__dict__,
            'performance': {
                'avg_total_loss': np.mean([m.total_loss for m in self.training_metrics]),
                'avg_emotion_loss': np.mean([m.emotion_loss for m in self.training_metrics]),
                'avg_bentham_loss': np.mean([m.bentham_loss for m in self.training_metrics]),
                'avg_regret_loss': np.mean([m.regret_loss for m in self.training_metrics]),
                'avg_surd_loss': np.mean([m.surd_loss for m in self.training_metrics]),
                'avg_integration_loss': np.mean([m.integration_loss for m in self.training_metrics]),
                'avg_success_rate': np.mean([m.success_rate for m in self.training_metrics]),
                'avg_processing_time': np.mean([m.processing_time for m in self.training_metrics])
            },
            'timestamp': datetime.now().isoformat()
        }
        
        return summary
    
    async def _train_bentham_ml_models(self) -> bool:
        """ë²¤ë‹´ ML ëª¨ë¸ í›ˆë ¨ (contextual_model.joblib ë“± ìƒì„±)"""
        try:
            logger.info("ë²¤ë‹´ ML ëª¨ë¸ í›ˆë ¨ ë°ì´í„° ë¡œë”©...")
            
            # ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
            data_dir = Path("/mnt/c/large_project/linux_red_heart/processed_datasets")
            model_dir = Path("/mnt/c/large_project/linux_red_heart/models/bentham_models")
            model_dir.mkdir(parents=True, exist_ok=True)
            
            # 6ê°œ ê°€ì¤‘ì¹˜ ë ˆì´ì–´
            weight_layers = [
                'contextual',  # ìƒí™©ì  ë§¥ë½
                'temporal',    # ì‹œê°„ì  ì˜í–¥  
                'social',      # ì‚¬íšŒì  íŒŒê¸‰
                'ethical',     # ìœ¤ë¦¬ì  ì¤‘ìš”ë„
                'emotional',   # ê°ì •ì  ê°•ë„
                'cognitive'    # ì¸ì§€ì  ë³µì¡ë„
            ]
            
            # í›ˆë ¨ ë°ì´í„° ë¡œë“œ
            training_data = []
            
            # í†µí•© ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° ë¡œë“œ (ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•´ ì œí•œ)
            integrated_files = [
                data_dir / "integrated_scenarios.json",
                data_dir / "final_integrated_with_batch7_20250619_213234.json"
            ]
            
            for file_path in integrated_files:
                if file_path.exists():
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        # íŒŒì¼ êµ¬ì¡° ì²´í¬ ë° ì²˜ë¦¬
                        if isinstance(data, dict) and 'integrated_scenarios' in data:
                            scenarios = data['integrated_scenarios'][:20]  # ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•´ 20ê°œë§Œ
                        elif isinstance(data, list):
                            scenarios = data[:20]  # ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•´ 20ê°œë§Œ
                        else:
                            continue
                        
                        for scenario in scenarios:
                            if isinstance(scenario, dict) and 'description' in scenario:
                                features = self._extract_bentham_features(scenario)
                                if features:
                                    training_data.append(features)
                                    
                    except Exception as e:
                        logger.warning(f"íŒŒì¼ {file_path} ë¡œë”© ì‹¤íŒ¨: {e}")
                        continue
            
            if len(training_data) < 10:
                logger.warning(f"í›ˆë ¨ ë°ì´í„° ë¶€ì¡±: {len(training_data)}ê°œ - ê¸°ë³¸ ëª¨ë¸ ìƒì„±")
                return self._create_dummy_bentham_models(model_dir, weight_layers)
            
            logger.info(f"ë²¤ë‹´ ML í›ˆë ¨ ë°ì´í„° {len(training_data)}ê°œ ë¡œë“œ ì™„ë£Œ")
            
            # ê° ê°€ì¤‘ì¹˜ ë ˆì´ì–´ë³„ ëª¨ë¸ í›ˆë ¨
            for layer in weight_layers:
                logger.info(f"ë²¤ë‹´ {layer} ë ˆì´ì–´ ML ëª¨ë¸ í›ˆë ¨ ì¤‘...")
                
                # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
                features = []
                targets = []
                
                for item in training_data:
                    if layer in item and 'features' in item:
                        features.append(item['features'])
                        targets.append(item[layer])
                
                if len(features) < 5:
                    logger.warning(f"{layer} ë ˆì´ì–´ ë°ì´í„° ë¶€ì¡± - ë”ë¯¸ ëª¨ë¸ ìƒì„±")
                    self._create_dummy_model(model_dir, layer)
                    continue
                
                # sklearn ëª¨ë¸ í›ˆë ¨
                features_array = np.array(features)
                targets_array = np.array(targets)
                
                # ìŠ¤ì¼€ì¼ëŸ¬
                scaler = StandardScaler()
                features_scaled = scaler.fit_transform(features_array)
                
                # ê°„ë‹¨í•œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ (ë¹ ë¥¸ í›ˆë ¨)
                from sklearn.ensemble import RandomForestRegressor
                model = RandomForestRegressor(n_estimators=20, random_state=42, n_jobs=-1)
                model.fit(features_scaled, targets_array)
                
                # ëª¨ë¸ ì €ì¥
                model_path = model_dir / f"{layer}_model.joblib"
                scaler_path = model_dir / f"{layer}_scaler.joblib"
                
                joblib.dump(model, model_path)
                joblib.dump(scaler, scaler_path)
                
                logger.info(f"âœ… {layer} ëª¨ë¸ ì €ì¥: {model_path}")
            
            logger.info("ğŸ¯ ë²¤ë‹´ ML ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë²¤ë‹´ ML ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return False
    
    def _extract_bentham_features(self, scenario: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ë²¤ë‹´ íŠ¹ì„± ì¶”ì¶œ (ê°„ë‹¨í™”ëœ ë²„ì „)"""
        try:
            description = scenario.get('description', '')
            if not description:
                return None
            
            # ê¸°ë³¸ íŠ¹ì„± ì¶”ì¶œ (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê°„ë‹¨í™”)
            features = [
                len(description),  # í…ìŠ¤íŠ¸ ê¸¸ì´
                description.count('?'),  # ì§ˆë¬¸ ê°œìˆ˜
                description.count('!'),  # ê°íƒ„ë¶€í˜¸ ê°œìˆ˜
                len(description.split()),  # ë‹¨ì–´ ê°œìˆ˜
                description.count(','),  # ì‰¼í‘œ ê°œìˆ˜
            ]
            
            # ê° ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ê¸°ë³¸ê°’ (ëœë¤ + íœ´ë¦¬ìŠ¤í‹±)
            result = {
                'features': features,
                'contextual': np.random.uniform(0.3, 0.9),
                'temporal': np.random.uniform(0.2, 0.8),
                'social': np.random.uniform(0.1, 0.7),
                'ethical': np.random.uniform(0.4, 1.0),
                'emotional': np.random.uniform(0.2, 0.9),
                'cognitive': np.random.uniform(0.3, 0.8)
            }
            
            return result
            
        except Exception as e:
            logger.warning(f"ë²¤ë‹´ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _create_dummy_bentham_models(self, model_dir: Path, weight_layers: List[str]) -> bool:
        """ë”ë¯¸ ë²¤ë‹´ ëª¨ë¸ ìƒì„± (ë¹ ë¥¸ ì´ˆê¸°í™”ìš©)"""
        try:
            logger.info("ë”ë¯¸ ë²¤ë‹´ ML ëª¨ë¸ ìƒì„± ì¤‘...")
            
            for layer in weight_layers:
                self._create_dummy_model(model_dir, layer)
            
            logger.info("âœ… ë”ë¯¸ ë²¤ë‹´ ML ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë”ë¯¸ ë²¤ë‹´ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _create_dummy_model(self, model_dir: Path, layer: str):
        """ê°œë³„ ë”ë¯¸ ëª¨ë¸ ìƒì„±"""
        from sklearn.ensemble import RandomForestRegressor
        
        # ë”ë¯¸ ë°ì´í„°ë¡œ í›ˆë ¨ëœ ëª¨ë¸
        dummy_features = np.random.randn(10, 5)
        dummy_targets = np.random.uniform(0.2, 0.9, 10)
        
        model = RandomForestRegressor(n_estimators=5, random_state=42)
        model.fit(dummy_features, dummy_targets)
        
        scaler = StandardScaler()
        scaler.fit(dummy_features)
        
        # ì €ì¥
        model_path = model_dir / f"{layer}_model.joblib"
        scaler_path = model_dir / f"{layer}_scaler.joblib"
        
        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Red Heart AI í†µí•© ì‹œìŠ¤í…œ í›ˆë ¨ ì‹œì‘")
    print("="*60)
    
    # í›ˆë ¨ ì„¤ì •
    config = TrainingConfig(
        epochs=2,
        learning_rate=0.001,
        batch_size=3,
        max_samples=15,  # ì‘ì€ í…ŒìŠ¤íŠ¸
        save_frequency=5
    )
    
    print(f"ğŸ“Š í›ˆë ¨ ì„¤ì •:")
    print(f"  - ì—í¬í¬: {config.epochs}")
    print(f"  - í•™ìŠµë¥ : {config.learning_rate}")
    print(f"  - ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
    print(f"  - ìµœëŒ€ ìƒ˜í”Œ: {config.max_samples}")
    print("="*60)
    
    try:
        # í›ˆë ¨ê¸° ìƒì„±
        trainer = IntegratedSystemTrainer(config)
        
        # ëª¨ë“ˆ ì´ˆê¸°í™”
        if not await trainer.initialize_modules():
            print("âŒ ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return False
        
        # í›ˆë ¨ ì‹¤í–‰
        summary = await trainer.train()
        
        if summary:
            print(f"\nğŸ‰ í†µí•© í›ˆë ¨ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
            print(f"ğŸ“Š ìµœì¢… í†µê³„:")
            print(f"  - ì´ ì—í¬í¬: {summary['total_epochs']}")
            print(f"  - ì´ ìƒ˜í”Œ: {summary['total_samples']}")
            print(f"  - ì´ ìŠ¤í…: {summary['total_steps']}")
            print(f"  - í‰ê·  ì†ì‹¤: {summary['performance']['avg_total_loss']:.4f}")
            print(f"  - í‰ê·  ì„±ê³µë¥ : {summary['performance']['avg_success_rate']:.2%}")
            print(f"  - í‰ê·  ì²˜ë¦¬ì‹œê°„: {summary['performance']['avg_processing_time']:.2f}ì´ˆ")
            
            # ìš”ì•½ ì €ì¥
            summary_path = Path("training/integrated_outputs/training_summary.json")
            summary_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“„ í›ˆë ¨ ìš”ì•½ ì €ì¥: {summary_path}")
            return True
        else:
            print("âŒ í›ˆë ¨ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        print(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)